---
layout: post
title:  "Шаблони використання LLM - Шаблон уточнення питання"
date:   2025-04-16 11:31:32 +0500
categories: LLM
comments: true
---

Це п'ята стаття стаття із серії яка описує шаблони будування запитів до LLM систем.
Інші статті в серії
- [1. Шаблон створення сленгу]({% post_url 2025-02-02-llm-patterns %})
- [2. Автоматизатор виводу]({% post_url 2025-02-21-output-automater %})
- [3. Перевернута взаємодія]({% post_url 2025-03-06-flipped-interaction %})
- [4. Шаблон персона]({% post_url 2025-03-31-persona-pattern %})
- [6. Шаблон альтернативні підходи]({% post_url 2025-05-25-alternative-approach %})
- [7. Шаблон когнітивного верифікатора]({% post_url 2025-06-14-cognitive-verifier %})
- [8. Шаблон список фактів для перевірки]({% post_url 2025-06-21-fact-checker-list %})
- [9. Шаблон нескінченної генерації]({% post_url 2025-06-28-infinite-generation %})

# Шаблон уточнення питання

## Намір і контекст

Цей шаблон залучає LLM до процесу розробки запиту. Мета цього шаблону полягає в тому, щоб розмовний LLM завжди пропонував потенційно кращі або більш рафіновані запитання, які користувач міг би поставити замість свого початкового запитання. Використовуючи цей шаблон, LLM може допомогти користувачеві знайти правильне питання, щоб отримати точну відповідь. Крім того, LLM може допомогти користувачеві знайти інформацію або досягти його мети за меншу кількість взаємодій з користувачем, ніж якби користувач використовував підказки методом проб і помилок.

## Мотивація

Якщо користувач ставить запитання, можливо, він не є фахівцем у цій галузі та може не знати, як найкраще сформулювати запитання, або не знати про додаткову інформацію, яка допоможе сформулювати запитання. LLM часто зазначають обмеження щодо відповіді, яку вони надають, або запитують додаткову інформацію, щоб допомогти їм отримати більш точну відповідь. LLM може також висловити припущення, які він зробив, надаючи відповідь. Мотивація полягає в тому, що цю додаткову інформацію або набір припущень можна використати для створення кращого підказки. Замість того, щоб вимагати від користувача переварити та перефразувати своє підказку з додатковою інформацією, LLM може безпосередньо вдосконалити підказку, щоб включити додаткову інформацію.

<!--more-->

## Структура та ключові ідеї

Основні твердження для контексту:

> У межах X запропонуйте кращу версію питання для подальшого використання

> (Необов’язково) Запитайте мене, якщо я хочу використовувати кращу версію замість цього питання

Перше контекстне твердження в підказці просить LLM запропонувати кращу версію запитання в певному контексті. Контекст надається для того, щоб не всі запитання автоматично переформулювалися або їх уточнювали відповідно до заданої мети. Друге контекстне твердження призначене для автоматизації та дозволяє користувачеві автоматично використовувати уточнене запитання без необхідності копіювати/вставляти чи вводити його вручну. Розробка цього запиту можна додатково вдосконалити, поєднавши його з шаблоном відображення, що дозволяє LLM пояснити, чому він вважає, що уточнене запитання є покращенням.

## Приклад реалізації

Зразок реалізації для перевірки коду показано нижче:

>  «Відтепер щоразу, коли я ставлю запитання про безпеку артефакту програмного забезпечення, пропонуйте кращу версію запитання для використання, яка містить інформацію, специфічну для ризиків безпеки, у мові чи системі, яку я використовую замість цього, і запитуйте мене, чи хочу я використовувати ваше запитання замість цього».

У контексті наведеного вище прикладу LLM використовуватиме шаблон Уточнення питання для покращення питань, пов’язаних із безпекою, запитуючи або використовуючи конкретні деталі про артефакт програмного забезпечення та мову програмування чи фреймворк, яка використовується для його створення. Наприклад, якщо розробник веб-програми на Python із FastAPI запитає ChatGPT «Як мені обробляти автентифікацію користувача у моїй веб-програмі?», LLM уточнить це запитання, взявши до уваги, що веб-програма написана на Python із FastAPI. Потім LLM надає переглянуте запитання, яке більш конкретно стосується мови та фреймворку, наприклад «Які найкращі методи безпечної обробки автентифікації користувачів у веб-додатку FastAPI для прибирання поширених ризиків безпеки, таких як міжсайтовий скріптінг (XSS), підробка міжсайтового запиту (CSRF) та викрадення сеансу?»

Додаткові деталі в переглянутому питанні, ймовірно, не тільки поінформують користувача про проблеми, які йому потрібно розглянути, але й допоможуть отримати кращу відповідь від LLM. Для завдань розробки програмного забезпечення цей шаблон також може включати інформацію щодо потенційних помилок, модульності чи інших міркувань якості коду. Іншим підходом може бути автоматичне уточнення запитань, щоб згенерований код чітко відокремлював проблеми або мінімізував використання зовнішніх бібліотек, таких як:

> "Кожного разу, коли я ставлю запитання про те, як написати код, пропонуй кращу версію мого питання, яке запитує, як написати код таким чином, щоб мінімізувати мою залежність від зовнішніх бібліотек."

## Наслідки

Шаблон *Уточнення питання* допомагає подолати розрив між знаннями користувача та розумінням LLM, що забезпечує більш ефективну та точну взаємодію. Одним із ризиків цього шаблону є його тенденція швидко звужувати питання користувача до певної області, що направляє користувача більш обмеженим шляхом пошуку, ніж це необхідно. Наслідком такого звуження є те, що користувач може пропустити важливу інформацію про «ширшу картину». Одне з рішень цієї проблеми полягає в тому, щоб надати додаткову область підказки шаблону, наприклад «не прив’язувати мої запитання до певних мов програмування або фреймворків».

Інший підхід до подолання звуження або обмежуючого націлювання уточненого питання полягає в поєднанні шаблону уточнення запитання з іншими шаблонами. Зокрема, цей шаблон можна поєднати з шаблоном Розумний перевіряльник, щоб LLM автоматично створював серію додаткових запитань, які можуть створити точніше запитання. Наприклад, у наступному запиті застосовуються шаблони уточнення запитань і когнітивного перевірки, щоб гарантувати кращі запитання, поставлені LLM:

> "Відтепер щоразу, коли я ставлю запитання, став чотири додаткові запитання, які допоможуть вам створити кращу версію мого початкового питання. Потім використовуй мої відповіді, щоб запропонувати кращу версію мого початкового питання".

Як і у випадку з багатьма шаблонами, які дозволяють LLM генерувати нові запитання, використовуючи свої знання, LLM може додати в запитання незнайомі користувачеві терміни чи поняття. Один із способів вирішення цієї проблеми – включити заяву про те, що LLM повинен пояснити будь-які незнайомі терміни, які він вводить у запитання. Подальшим удосконаленням цієї ідеї є поєднання шаблону Уточнювання питань із шаблоном Персона, щоб LLM позначав терміни та генерував визначення, які передбачають певний рівень знань, як-от цей приклад:

> "Відтепер щоразу, коли я ставлю запитання, запитуй чотири додаткових питання, які допоможуть тобі створити кращу версію мого оригінального запитання. Потім використовуйте мої відповіді, щоб запропонувати кращу версію мого оригінального питання. Після відповідних запитань тимчасово дій як користувач, який не знає AWS, і визнач терміни, які мені потрібно знати, щоб точно відповісти на запитання».

LLM завжди може створювати фактичні неточності, як і людина. Ризик цього шаблону полягає в тому, що в уточнене питання вносяться неточності. Однак цей ризик можна зменшити, поєднавши із шаблоном Перевірка фактів, щоб користувач міг визначити можливі неточності, і шаблон Рефлексія, щоб пояснити причину звуження питання.