{"index":14713154,"examples_quantiles":[{"quantile_name":"Top Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.94,0.0,0.86,0.0],"train_token_ind":6,"is_repeated_datapoint":false,"tokens":["<EOT>","this"," article"," does"," that"," for"," the"," most"," part",".","\u23ce\u23ce","------","\u23ce","g","ing","erl","ime","\u23ce"," I"," can"," totally"," relate"," to"," the"," things"," the"," author"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Soon",","," we"," will"," be"," able"," to"," have"," a"," new"," life","\""," \"","We"," have"," come"," to"," steal"," information"," from"," the"," anti","-","nar","co","tics"," bureau"," of"," the"," H","K"," police","\""," \"","So"," we"," can"," make"," a"," large"," sum"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.92,0.0,0.0,0.0,0.96,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":10,"is_repeated_datapoint":false,"tokens":["<EOT>","\u23ce","There"," has"," been"," no"," shortage"," of"," attempts"," in"," the"," past"," to"," solve"," the"," problem"," posed"," by"," the"," high"," visc","osity"," of"," ","ani","onic"," surf","act","ant"," pas","tes"]},{"tokens_acts_list":[0.0,0.0,0.0,0.99,0.0,0.0,0.96,0.0,0.0,0.0,0.91,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.96,0.0,0.0],"train_token_ind":3,"is_repeated_datapoint":false,"tokens":["<EOT>","designed"," for"," the"," purpose"," on"," the"," exterior"," wall"," of"," the"," vehicle","."," This"," external"," arrangement"," tends"," to"," det","ract"," from"," the"," overall"," appearance"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":4,"is_repeated_datapoint":false,"tokens":["<EOT>","that"," nobody"," in"," the"," linked"," thread","\u23ce"," succe","eds"," at"," this"," (","one"," guy"," proves"," that"," ","12"," ","works"," by"," exhaust","ive"," search"]},{"tokens_acts_list":[0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.91,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.86,0.0,0.0,0.0,0.0],"train_token_ind":2,"is_repeated_datapoint":false,"tokens":["<EOT>","allowing"," the"," full"," circular"," rotation"," of"," the"," sw","ivel"," and"," span"," structure"," without"," binding"," or"," tw","isting"," the"," w","ires"," ","8"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["conservative"," values",","," while"," Wells"," sees"," himself"," as"," a","\u23ce"," scientific"," man"," \"","never"," been"," shocked"," to"," outc","ries"," by"," the"," existence"," of"," water","\u23ce"," clos","ets"," and"," men","str","ual"," band","ages","\".","\u23ce\u23ce","(","\u2191","Presumably"," a"," reference"," to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.94,0.0,0.0,0.0,0.0,0.91,0.0,0.0,0.0],"train_token_ind":4,"is_repeated_datapoint":false,"tokens":["<EOT>","gather"," information"," from"," the"," data"," acquisition"," means"," of"," the"," missile"," to"," complement"," data"," gathered"," by"," the"," data"," acquisition"," means"," of"," the"," launching"," platform"," ("]},{"tokens_acts_list":[0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.94,0.0,0.0,0.0,0.0],"train_token_ind":3,"is_repeated_datapoint":false,"tokens":["<EOT>","problem"," for"," the","\u2191"," La","place"," equation"," is"," ill","-","posed",","," as"," any"," neglig","ible"," errors"," in"," the"," condition"," may"," result"," in"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.96,0.0,0.0,0.92,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["some"," in"," favour"," of"," natural"," science",","," others"," of"," a"," more"," popular"," treatment"," of"," ethics",","," introducing"," many"," changes"," into"," the","\u2191"," Aristot","el","ian"," doctrine"," in"," a"," natur","alistic"," direction","."," A"," return"," to"," the"," views"," of"," the"," founder"," first"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.96,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["<EOT>","While"," you"," can"," never"," reduce","\u23ce"," something"," as"," complex"," as"," building"," a"," business"," down"," to"," a"," \"","paint"," by"," the"," numbers","\"","\u23ce","process",",","\u21ea"," T","FS","TTE"," is"," about"," as"," close"," to"," a"," \"","paint"," by"," the"," numbers"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.96,0.0,0.0,0.0,0.0],"train_token_ind":16,"is_repeated_datapoint":false,"tokens":["<EOT>","communication"," to"," cause"," a"," reduction"," of"," radiation"," efficiency"," as"," a"," result","."," As"," described"," in"," the"," fore","going",","," conventional"," portable"," tele","phones"," have"," short","com","ings"," that"," a"," reduction"," in"," the"," amount"," of"," electromagnetic"," waves"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":4,"is_repeated_datapoint":false,"tokens":["<EOT>","abe"," believe"," in"," the"," tooth"," fairy"," again",",\""," \"","I","'m"," gonna"," take"," that"," chance",".\""," \"","And"," it"," has"," nothing"," to"," do"," with"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.89,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.97,0.0,0.0,0.0,0.0,0.92],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","society"," is"," made"," of"," individuals",".","\u23ce\u23ce","------","\u23ce","stret","chw","ith","me","\u23ce"," When"," something"," is"," regulated"," by"," the"," government",","," the"," nature"," of"," that"," regulation","\u23ce"," is"," subject"," to"," being"," influenced"," by"," the"," regulated",".","\u23ce\u23ce","If"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":7,"is_repeated_datapoint":false,"tokens":["<EOT>","purpose"," is"," to"," get"," something"," from"," the","\u23ce"," startup"," as"," a"," reward"," for"," beta"," testing"," their"," app","."," (","A"," free"," upgraded"," plan",","," or"," some","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["was"," never"," subject"," ","\u23ce\u23ce","to"," Copyright"," or"," whose"," legal"," Copyright"," term"," has"," expired","."," Whether"," a"," book"," is"," in"," the"," public"," domain"," may"," vary"," country"," to"," country","."," Public"," domain"," books"," ","\u23ce\u23ce","are"," our"," g","ate","ways"," to"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":14,"is_repeated_datapoint":false,"tokens":["<EOT>","make"," it"," wrong",".\""," \"","What"," happened"," to"," your"," speech"," about"," getting"," into"," the"," company","?\""," \"","Did"," you"," want"," to"," get"," in"," or"," did"," you"," just"," say"," that"," for"," effect","?\""," \"","I"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["work"," were"," given"," more"," opportunities"," to"," choose"," what"," type"," of"," work","\u23ce"," they"," did",".","\u2191"," Forget"," found"," that"," in"," the"," period"," that","\u2191"," Min","come"," was"," administered",",","\u23ce","hospital"," visits"," dropped"," ","8",".","5"," ","percent",","," with"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.97,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["to"," be"," placed"," on"," the"," _","\"","traditionally","\"","_"," there",".","\u23ce","There"," is"," absolutely"," no"," archaeological"," evidence"," for"," the","\u2191"," Exodus","."," It",","," and","\u23ce"," necessarily"," Moses"," as"," he"," is"," known"," as"," well",","," are"," f","ictions","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.66,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":7,"is_repeated_datapoint":false,"tokens":["<EOT>","\""," because"," of","\u23ce"," accidents"," in"," the"," timing"," of"," computer"," science"," culture"," and"," its"," victories",".","\u23ce\u23ce","The"," Linux"," /"," BSD"," driven"," revival"," of"," Unix"," happened",","]}]},{"quantile_name":"Subsample Interval 0","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.63,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.85,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.85,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," to"," form"," a"," thermal"," barrier"," coating"," system","."," The"," ceramic"," thermal"," barrier"," coating"," layer"," ins","ulates"," the"," component"," from"," the"," exha","ust"," gas",","," perm","itting"," the"," exha","ust"," gas"," to"," be"," h","otter"," than"," would"," otherwise"," be"," possible"," with"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.89,0.0,0.0,0.0,0.0,0.87,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["period","."," A"," path"," delay"," fault"," model"," calc","ulates"," a"," sum"," of"," delays"," at"," each"," element"," in"," a"," path"," within"," the"," C","UT"," and"," det","ects"," f","aults"," by"," comparing"," the"," sum"," of"," delays"," of"," the"," path"," with"," a"," delay"," of"]},{"tokens_acts_list":[0.0,0.0,0.82,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.85,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.83,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ionally",","," the"," back"," plate"," and"," indicator"," module"," may"," be"," int","egr","ally"," mol","ded"," to"," limit"," water"," entry"," into"," the"," module",","," whereby"," the"," illumin","ation"," source"," and","/","or"," light"," directing"," film"," or"," the"," like"," may"," be"," sealed"," at"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ung","sf","onds"," des"," ","\u23ce","\u2191","Bundes","verb","andes"," deutscher","\u2191"," Ban","ken"," e",".","V",".)"," nor"," by"," the"," German","  ","\u23ce","\u2191","Deposit","\u2191"," Guarantee"," and","\u2191"," Investor","\u2191"," Compensation"," Act"," ","\u23ce","(","\u2191","Ein","lag","ens"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.63,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["trade",","," and"," of"," proving"," that"," plan"," to"," be"," better"," than"," the"," plan"," h","ith","erto"," followed",","," lay"," on"," the"," New"," Company","."," The"," Old"," Company"," had"," merely"," to"," find"," obj","ections"," to"," every"," change"," that"," was"," proposed"," ;"," and"]}]},{"quantile_name":"Subsample Interval 1","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.91,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.85,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ht","ha","lic"," acid"," is"," prepared"," by"," the"," d","iac","et","ate"," process"," using"," ac","etic"," an","hyd","ride",","," the"," following"," reaction"," sequence"," takes"," place",":"," ##","ST","R","1","##","\u23ce","The"," condens","ation"," of"," the"," di","ester"," with"]},{"tokens_acts_list":[0.0,0.0,0.0,0.85,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.85,0.0,0.0,0.0,0.87,0.0,0.0,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.85,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[")"," None"," of"," the"," prior"," art"," provides"," a"," simple"," way"," of"," monitoring"," the"," correct"," functioning"," of"," the"," arc"," discharge"," so"," the"," amount"," of"," nit","ric"," oxide"," generated"," can"," be"," accurately"," predicted",".","\u23ce","6",")"," None"," of"," the"," prior"," art"," dis"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.82,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["rok","eshire",","," ","\u23ce\u23ce\u23ce","1","875",".","]"," ","\u23ce\u23ce\u23ce","","ation",",","  ","T","in","de","T","  ","the","  ","able","  ","conduct","  ","of","  ","Sir"," ","\u23ce","Gilbert","  ","Scott",",","  ","and","  ","the","  ","blue"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.65,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["'s"," hand"," with"," h","ones","'t"," ier","vor","."," Here"," they"," separated","."," The"," major"," hast","ened"," ","10"," ","the"," side"," of","\u2191"," M","aud",","," to"," fold"," her"," to"," h","ie"," heart",","," and"," console"," her"," wi","ih"," his"]},{"tokens_acts_list":[0.89,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," order"," is"," which"," th","ia"," tras","\u23ce"," ","ae","tk","ra"," took"," place","."," I"," d","ati","T","ed"," the"," bt","\u23ce"," pre","es","ie"," t","kat"," a"," similar"," ga","ase"," of","pr","ia","sc","\u23ce"," ar","'s"," base"," pr"]}]},{"quantile_name":"Subsample Interval 2","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.66,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["enh","owers"," At","\u23ce"," The"," White"," House","\u23ce"," Trip","\u2191"," Scheduled"," Over","\u23ce"," Nation"," After"," Three","\u23ce"," Day"," Visit"," In"," The","\u23ce"," Nation","'s"," Capital","\u23ce","!","\u21ea"," NATIONAL","\u21ea"," ENTERTAINMENT","\u23ce","\u21ea"," COMMITTEE","\u21ea"," NAMED","\u23ce"," Washington","."," \u2014","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.91,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["on"," their"," now","-","\u23ce","working"," idea",".","\u23ce\u23ce","~~~","\u23ce","oh","ashi","\u23ce"," So"," basically"," addressing"," the"," issue"," of"," The","\u2191"," D","ip"," (","to"," use"," Seth","\u2191"," Go","din","'s"," words",")?","\u23ce\u23ce","~~~","\u23ce","w","car","ss","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.89,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["accessing"," your","\u23ce"," market","."," This"," often"," comes"," from"," having"," worked"," in"," a"," particular"," industries"," for","\u23ce"," years","."," (","The"," market"," should"," always"," come"," first",","," not"," the"," idea","."," Be"," ready"," to"," throw","\u23ce"," away"," many"," ideas"," to"," get"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.93,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.86],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["b","enson",","," Smith"," &"," Co",".,"," General","\u2191"," Agents",","," Territory"," of"," Hawaii","."," FREE"," New","\u2191"," Subscribers"," to"," The"," Century"," Magazine"," who"," begin"," with"," the"," number"," for"," November",","," ","1","900",","," will"," receive"," free"," of"," charge"," the"]},{"tokens_acts_list":[0.0,0.61,0.0,0.0,0.85,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","The"," funeral"," of"," the"," late"," Preston"," C",".","\u2191"," D","uff",",","\u23ce","whose"," sudden"," death"," vas"," noted"," in"," The"," Star","\u23ce"," yesterday",","," w","4","U"," take"," place"," from"," the"," family","\u23ce"," residence",","," ","1","887"," ","\u2191"]}]},{"quantile_name":"Subsample Interval 3","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.76,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["onic","/","a","md","64","/","wi","resh","ark","-","gtk","/","fil","elist","\u23ce","<","alk","i","sg",">"," The"," package"," \"","wi","resh","ark","-","gtk","\""," ships"," the"," file"," \"/","usr","/","share","/","applications","/","wi","resh"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.86,0.0,0.0,0.0,0.0,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.81],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["628"," ","26",",","616",",","666"," ","466"," ","\u2191","Commerc","k","d"," Chronicle"," and"," J","Re","view",","," The"," val","ae"," of"," produce"," brought"," down"," the"," c","aD","ala"," constit","utes"," the"," r","eft","l"," wealth"," of",","," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.89,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.85,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["is"," custom","arily"," in"," the"," range"," of"," from"," ","1",":","100"," ","to"," ","100",":","1",".","\u23ce","The"," concentration"," of"," the"," f","ormal","in"," solution"," is"," generally"," from"," ","35"," ","to"," ","37"," ","per"," cent"," by"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," a"," pressure"," sensor",","," a"," flow"," sensor",","," a"," pressure"," switch",","," or"," a"," combination"," thereof",".","\u23ce"," ","The"," electronic"," v","apor","izer"," ","100"," ","further"," includes"," a"," power"," manager"," ","230"," ","that"," controls"," a"," power"," output"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.86,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.85,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.0,0.0,0.0,0.81,0.0,0.0,0.81,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["means"," suitable"," for"," recovering"," the"," therm","is","tor"," raw"," material"," powder"," as"," the"," pow","d","ery"," raw"," material",".","\u23ce","The"," recovering"," means"," (","6",")"," may"," include"," a"," cycl","one"," on"," the"," upstream"," side"," and"," the"," filter"," or"," the"," electric"]}]},{"quantile_name":"Subsample Interval 4","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","\u21ea"," RAL","STON",",","\u2191"," Le","aven","\u23ce"," worth",",","\u2191"," Che","lan"," Co",".,","\u2191"," Wash",".","\u23ce","THE","\u21ea"," RANCH",".","\u23ce","I"," All"," |"," It"," depends"," entirely"," upon"," the"," feeding"," ","rations","."," Fresh","\u23ce","\u25a0",""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["before","  ","M","R",".","  ","\u21ea","JUSTICE","  ","\u21ea","WILLIAMS","."," ","\u23ce\u23ce\u23ce","\u21ea","REGINA","  ","V",".","  ","THE","  ","\u21ea","INHABITANTS","  ","OF","  ","\u21ea","Y","ARK","HILL",".","\u2014"," p",".","  ","218","."," ","\u23ce\u23ce","A"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.61,0.0,0.0,0.0,0.87,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["occurred"," whilst"," they"," were"," at","\u2191"," Beth","le","hem"," ?"," ","\u23ce\u23ce\u23ce\u23ce","\u21ea","PA","BT"," ","2","."," ","\u23ce\u23ce","THE","\u21ea"," I","KO","A","BN","ATION","."," ","\u23ce\u23ce\u23ce\u23ce","The"," simple"," narrative"," of"," the","\u2191"," Sav","iour","'s"," birth"," \u2014"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u21ea","T","ENTS",","," (","suitable"," for"," camp","\u23ce"," ing"," and"," surve","ying"," parties",".)","\u23ce","11"," ","tf","\u23ce"," THE","\u23ce","\u21ea"," GREAT","\u21ea"," REAL","\u21ea"," ESTATE","\u23ce"," AND",".","\u23ce","10","\u23ce","OF",".","\u23ce","J","."," E","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.89,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["850"," ","rt"," ","42","-","td",","," ,"," i"," ."," ","1","\u23ce","\u21ea","ADMINISTRATORS","\u21ea"," NOTICE",",","\u23ce","THE"," unders","igned"," having"," been"," appointed"," by","\u23ce"," the","\u2191"," Prob","ate"," Court"," of"," Madison","\u2191"," Con","nt","v"," ","nt"]}]},{"quantile_name":"Subsample Interval 5","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["no"," imp","air","ment"," charges"," recognized"," in"," ","2","022"," ","and"," ","2","020",".","Im","pa","irm","ents","The"," Company"," will"," recognize"," imp","air","ments"," in"," relation"," to"," property",","," plant"," and"," equipment",","," investments",","," good","w","ill"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.88,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.93,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["used"," is"," one"," of"," the"," most"," efficient"," means"," of"," pre","\u23ce"," v","enting"," or"," over","coming"," it","\".","\u23ce","iv","The"," reason"," it"," is"," a"," remarkable"," remedy"," in"," the"," treatment"," and"," relief","\u23ce"," of"," grip",","," c","oughs",","," c","olds"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.86,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["how","\u23ce"," ever",","," was"," inactive",".","\u23ce","Kansas"," City","\u2191"," Grain","\u2191"," M","ni","ket","."," ,","\u23ce","I","The"," range"," of"," prices"," for"," grain"," futures"," on","\u23ce","."," the"," Kansas"," City"," Board"," of"," Trade"," aa"," re","\u23ce"," ","ported"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["A",".","\u2191"," Pic","kett",".","\u2191"," K","cs","ider",".","ce"," !","\u23ce","How","\u2191"," Nl",":","ar","To","The","\u2191"," Fi","mt","\u2191"," V","ell"," Do","\u2191"," Y","qu"," Want"," To"," ","6","et","-","?","\u23ce","Members"," of"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.62,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce\u23ce\u23ce","2","o","  ","January",",","  ","1","912"," ","\u23ce\u23ce\u23ce","The","  ","Saturday","  ","Review","."," ","\u23ce\u23ce\u23ce","S","The","  ","Great","  ","Central","  ","\u2191","R","ly","."," ","\u23ce","The","  ","\u2191","Comfortable","  ","Line","/"," ","\u23ce\u23ce\u23ce"]}]},{"quantile_name":"Subsample Interval 6","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["should"," buy"," us"," enough"," of"," a"," dist","raction"," to"," get"," the"," stolen"," goods","...\""," \"","..."," out","f","rom","under","the"," for","eman",".\""," \"","Z","O","E",":\""," \"","You","'re"," really"," gonna"," have"," to"," start"," again",".\""," \"","\u2191"]},{"tokens_acts_list":[0.73,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.31,0.0,0.0,0.31,0.0,0.3,0.0,0.57,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," weather"," w","rl","b","r"," was"," generally"," r","ener","aly"," ","lair"," l","air","The"," l","air","The"," air","The","\u23ce"," The"," high"," I","I","sh"," pressure"," pre","uur"," which"," wa"," was"," M"," over"," Canada","\u2191"," C","anta"," was"," was"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["am"," with"," you",".\""," \"","What"," are"," we"," gonna"," do",",","l","ili","?\""," \"","We"," will"," keep"," play","ing","the"," game",",","jack",",","until"," the"," game"," is"," over",".\""," \"\"","but"," if",".","...."," that"," is"," ","...."," correct"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["."," A"," company"," is"," being"," promoted"," for"," the"," purpose"," of"," introducing"," a"," novel"," machine"," for"," ant","omat","ically"," turning"," over","the"," leaves"," of"," books",","," which"," is"," especially"," adapt","able"," for"," libraries",","," hotels",","," railway"," stations",","," gh","op"," windows"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\"","How"," about"," that","?\""," \"","\u2191","L","inus","\u2191"," Lar","rab","ee",","," wizard"," of"," finance",","," chairman"," of","the"," board",","," getting"," mixed"," up"," with"," his"," cha","uff","eur","'s"," daughter",".\""," \"","That","'s"," enough",","," David",".\""]}]},{"quantile_name":"Subsample Interval 7","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ner","."," Le"," je","une"," homme"," \u00e9tait"," res","t\u00e9"," pr\u00e8s"," d","'","elle","."," \u2014"," Ma"," pa","uvre","\u2191"," Mar","the",","," ta"," n","'","as"," pas"," de"," chance",","," dit","-","il",","," mais"," que"," f","ais","-","tu"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["l","ors"," ho","i","oted"," to"," show"," her"," nationality",","," the","\u23ce"," State"," sc","ho","oner","\u2191"," An","ia","ron","the"," tf","ied"," a"," blank"," co","co","ro","it","d","ge"," to","\u23ce"," remind"," t","l"," e"," vi","ou","tn","r"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["","arine",","," cas","tor","."," ","\u23ce","\u2191","Larg","eur","\u2191"," O","ln","98"," ","15"," ","co","rin","the","."," gre","nat","."," n","\u00e8g","re",","," noir","."," ","\u23ce","Le"," m","\u00e8","tre","."," ","23"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["hh","h","\u23ce","<","ni","xt","ernal",">"," I"," just"," read"," that"," as"," well"," :",")","\u23ce","<","ts","mi","the",">"," can"," i"," get"," reviews"," for"," all"," the"," ub","unt","ust","udio","-","*"," packages"," on"," re","vu","?","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","der","\u2191"," Geme","inde"," zu"," ve","rans","tal","ten",".","\u23ce","\u2191","Wenn"," der"," an","erk","enn","ens","wer","the"," Plan","\u23ce"," verw","ir","kl","icht"," wird",","," ist"," es"," s","icher",","," da","\u00df","\u23ce","\u2191"," Luxemb","urg"," eine"]}]},{"quantile_name":"Subsample Interval 8","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Oscar","\u2191"," Fo","rero",">"," Thanks"," a"," lot"," b","ro","!","\u23ce","<","ub","pt","g","bot",">"," H","ank","The","Sw","ede"," was"," added"," by",":"," H","ank","The","Sw","ede","\u23ce","<","ub","pt","g","bot",">"," <","advoc"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["tech","no","_","fr","eak",">"," but"," how"," is"," it"," assumed"," that"," people"," know"," this"," rule","?","\u23ce","<","a","The","res","No","E","TA",">"," well","\u23ce","<","H","ori","zon","X","P",">"," ","\u00ef","\u00bb","\\xc2","\\xbf","q"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["fie"," le"," Lieutenant","\u2191"," G\u00e9n\u00e9ral"," ,"," \u00e0"," l","aq","uelle"," la","\u2191"," Ma","r\u00e9","ch","ale"," de"," la","\u2191"," Mo","the"," r\u00e9","pon","dit"," d","'","v","ne"," man","i\u00e8re"," des"," plus"," jud","ici","-.","uses",",","e","&","amp",";"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["<","ub","otu",">","\u2191"," Uns","ure"," how"," you"," should"," beh","ave"," on"," this"," channel","?"," See"," !","A","sk","The","Bot",","," !","Co","C",","," !","Guidelines",","," !","\u2191","Of","ft","opic",","," !","Language",","," !","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["  ","i","iot",".)."," ","\u23ce","\u2191","","Ane",".","  ","rep",".","  ","noble","."," ","\u23ce","\u2191","Mo","the","  ","(","  ","La","  ","),","  ","b",".","  ","c","\"","  ","de","  ","\u2191","Sen","il","ric","ux"]}]},{"quantile_name":"Bottom Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.85,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["attered"," his"," br","ains"," all"," over"," the"," walls","?\""," \"","Yes",","," this"," was"," the"," house"," he"," always"," wanted"," to"," die"," in",",\""," \"","And",","," boy",","," did"," he"," ever"," do"," it",".\""," \"","I"," want"," to"," thank"," all"," of"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","Ne","uf","ch","\u00e2","tel"," \u00e0","\u2191"," El","bing",","," je"," ne"," conn","ais"," pas"," sa"," situation",";"," on"," la"," dit"," fort"," r","\u00e9d","uite"," ;"," je"," ne"," con","\u00e7","ois"," pas"," comment"," il"," peut"," en"," \u00eatre"," ainsi",";"," \u00e0"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","recommendation",".","\u23ce\u23ce","<EOT>","\u23ce\u23ce","\u2191","Quantum"," computing"," since","\u2191"," Democ","r","itus"," -"," j","ey","\u23ce"," http","://","scott","aa","ron","son",".","com","/","democ","r","itus","\u23ce\u23ce","======","\u23ce","_","b","q","\u23ce","\u2191"," Awesome","!","\u23ce\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["30","/","how","-","doctors","-","\u23ce","die","/","ideas","/","nex","us","/)","\u23ce\u23ce","\"","How"," doctors"," choose"," to"," die","\"","\u23ce","[","http","://","www",".","th","egu","ard","ian",".","com","/","society","/","2","012","/","feb"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\"","All"," good"," girls"," want"," to"," die",".\""," \"","Let","'s"," just"," go",".\""," \"","All"," good"," girls"," want"," to"," die",".\""," \"","We","'re"," losing"," day","light",".\""," \"","Is"," this"," it","?\""," \"","Yeah",","," this"," is"," it",".\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["in"," it",".\""," \"","He","'s"," a"," science"," monkey",".\""," \"","\u2191","Mm","m","-","hm","m",".\""," \"","\u2191","Scott","ie",","," can"," I"," get"," a"," couple"," of"," pat","ties","?\""," \"","\u2191","Okay",".\""," \""," Two"," royal"," with"," cheese"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.92,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["!\""," \"","Why"," are"," you","...\""," \"","No",","," no",","," no",","," no","!\""," \"","No"," dancing"," on"," the"," bulld","o","zer","!\""," \"","Oh","!\""," \"","No",","," no",","," no",","," no","!\""," \"","Stop"," it","!\""," \""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["insight"," to"," understand"," is"," that","\u23ce"," crypt","ography"," can","'t"," establish"," trust",","," only"," maintain"," it",".","\u23ce\u23ce","~~~","\u23ce","The","O","t","her","H","ob","bes","\u23ce"," Those"," users"," see"," an"," extra"," layer"," of"," friction"," for"," no"," obvious"," benefit","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".\""," \"","Then"," fix"," it",".\""," \"","All"," good"," girls"," want"," to"," die",".\""," \"","All"," good"," girls"," want"," to"," die",".\""," \"","I"," can","'t"," do"," that",".\""," \"","Wait",",","\u2191"," J","ess",".\""," \"","\u2191"," J","ess",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\"","All"," good"," girls"," want"," to"," die",".\""," \"","Thank"," you",","," Ted",".\""," \"","All"," good"," girls"," want"," to"," die",".\""," \"","All"," good"," girls"," want"," to"," die",".\""," \"","All"," good"," girls"," want"," to"," die",".\""," \"","All"," good"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["good"," boys"," want"," to"," die",".\""," \"","All"," good"," boys"," want"," to"," die",".\""," \"","All"," good"," boys"," want"," to"," die",".\""," \"","All"," good"," boys"," want"," to"," die",".\""," \"","All"," good"," boys"," want"," to"," die",".\""," \"","All"," good"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.67],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["I","...\""," \"","Want","...\""," \"","Want","...\""," \"","To","...\""," \"","Die",".\""," \"","I"," don","'t"," want"," to"," die","!\""," \"","\u2191","Fuck"," you",","," buddy",".\""," \"","Hey",","," pull"," over",".\""," \"","Pull"," over",".\""," \"","The"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["O",".\""," \"","U",".\""," \"","R",".","\u2191"," Mou","rir",".\""," \"","To"," die",".\""," \"","You"," want"," to"," die","?\""," \"","How"," can"," you"," say"," that","?\""," \"","There"," are"," people"," who"," love"," you",","," who"," care"," for"," you"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["lt","l","kl","re"," C","lt","l","kl","re","The","ir"," ","Child","r","ens","The","ir"," Si"," S","i","The","ir","\u23ce"," Their"," story"," has"," h"," h","R","a","other"," has","an","other"," aj","rov","M"," aj","rov","Man","other"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["as","ino",".","\u2191"," Wild","park",".","\u2191"," Tenn","is","pl","\u00e4t","ze",".","\u2191"," Rad","l","erw","ege"," auf"," der","\u2191"," D\u00fc","ne"," und"," Int","\u2191"," ","Wald"," neu","an","gel","egt",".","\u2191"," Beste","\u2191"," K","inder","-"," mil"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.88,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".\""," \"","What","'s"," the"," matter","?\""," \"","You"," don","'t"," feel"," well","?\""," \"","I"," don","'t"," want"," to"," die"," yet","!\""," \"","I"," say"," you"," will"," be"," fine",".\""," \"","I","'m"," not"," saying"," this"," because"," my"," life"," is"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," yeah",".\""," \"","I","'ll"," see"," you"," soon",".\""," \"","\u2191","Bye",".\""," \"","All"," good"," boys"," want"," to"," die",".\""," \"","All"," good"," boys"," want"," to"," die",".\""," \"","All"," good"," boys"," want"," to"," die",".\""," \"","All"," good"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["b\u00f6","se",".","\u2191"," Und"," das","\u2191"," Str","eben"," nach"," absolut","em","\u2191"," Ideal","ismus"," ent","fal","tet"," sich"," in"," der"," un","ge","he","uren","\u2191"," Ba","ust","elle"," des","\u2191"," Opus"," post","um","um",","," in"," wel","c","hem","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","Zwe","isp","rach","igkeit",".","\u23ce","Der","\u2191"," Br","uch"," in"," der","\u2191"," Bi","ografie"," manifest","iert"," sich"," auf"," der"," form","alen","\u2191"," Eb","ene","\u23ce"," in"," der","\u2191"," Redu","ktion"," ander","ssp","rach","iger","\u2191"," El","emente","."," Es"]}]}],"top_logits":["same","following","whole","first","entire","rest","correct","current","original","last"],"bottom_logits":["the","populacional","delen","bzw","letal","he","of","ana","izan","and"]}