{"index":29636672,"examples_quantiles":[{"quantile_name":"Top Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\"","You","'re"," cool"," and"," proud",".\""," \"","And"," suddenly",":"," metro"," man",".\""," \"","I"," say"," David","\u2191"," Beck","ham",".\""," \"","I"," say","..."," doesn","'t"," matter",".\""," \"","The"," role"," pattern"," between"," man"," and"," woman"," disappeared",".\""," \""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.98,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["fool"," out"," of"," me",","," man",".\""," \""," Who",","," Sant","?\""," \""," This"," commercial",".\""," \"","David","\u2191"," Beck","ham"," gets","\u2191"," Gill","ette",","," and"," I"," get"," fre","aking","..."," to","fu","?\""," \"","You"," got"," to"," start"," somewhere"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.96,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a"," free"," kick",".\""," \"","Even"," he"," ","'s"," not"," quite"," found"," his"," range"," tonight",".\""," \"","David","\u2191"," Beck","ham"," with"," the"," cross",".\""," \"","Here"," ","'s","\u2191"," Ga","vin"," Harris","!\""," \"","Goal"," for"," Real"," Madrid","!\""," \""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.96,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","Ch","uck","les",")\""," \"","I"," love"," those"," cook","ery"," shows",".\""," \"","It","'s"," David","\u2191"," At","ten","borough",".\""," \"","Where","'s"," this"," Chinese"," food","?\""," \"","I","'m"," star","ving",".\""," \"","Don","'t"," mind"," the"," mess"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.96,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\"","\u2191","Ra","ul","!\""," \"","\u2191","R","amos"," back"," to"," clear"," off"," the"," line",".\""," \"","David","\u2191"," Beck","ham"," now",".\""," \"","Just"," about"," ho","oked"," away"," by"," Valencia",".\""," \"","Under"," a"," bit"," of"," pressure"," here",".\""," \""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","is"," it"," an"," idea"," all"," women"," are"," on"," board"," with",".","\u23ce\u23ce","For"," example","."," George","\u2191"," C","lo","oney"," had"," to"," ask"," his"," wife"," out"," three"," times"," before"," she","\u23ce"," said"," yes","."," I"," believe","\u2191"," Mel","inda"," Gates"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.94,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["prod","uzione","\u23ce"," ","\u2191","Tin"," Machine","\u23ce"," ","Tim"," Palmer","\u23ce\u23ce","\u2191"," Music","isti","\u23ce"," ","David","\u2191"," B","owie"," \u2013"," vo","ce",","," chit","arra","\u23ce"," ","\u2191","Re","eves","\u2191"," Gab","rels"," \u2013"," chit","arra"," sol","ista","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.93,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\\xaa","","\u2191"," O","oh","-","o","oh","-","o","oh","\""," \"","In"," every"," sense",","," David","\u2191"," B","owie"," was"," the"," predecessor"," to"," so"," many"," of"," these"," artists"," on"," MTV",".\""," \"","They"," lear","nt"," to"," be"," brave"," from"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.35,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.93,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.13,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\"","And"," she"," moved"," on"," to"," Johnny","\u2191"," De","pp",".\""," \""," Chris"," Cornell",".\""," \""," George","\u2191"," C","lo","oney",".\""," \"","\u2191"," Zig","gy","\u2191"," Mar","ley",".\""," \"","\u2191"," Pa","uly"," Shore",".\""," \"","I"," went"," out"," with"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.93,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a"," lot"," of"," books"," on"," this"," list",".\""," \"","Any"," come"," on"," tape",","," read"," by"," George","\u2191"," C","lo","oney","?\""," \"","You","'re"," entering"," a"," new"," realm",","," one"," for"," which"," I"," myself"," am"," not"," entirely"," prepared",".\""," \""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.93,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\""," You"," remind"," me"," of"," someone",".\""," \"","You"," know"," who"," I"," get"," a"," lot","?\""," \"","David","\u2191"," Beck","ham",".\""," \""," Larry"," King",".\""," \""," Larry"," King","?\""," \"","Larry"," King"," is"," old",".\""," \"","Larry"," King"," is"," so"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["help"," twice"," a"," week",".\""," \"","You"," need"," a"," guy"," like","...\""," \"","Tom"," Ford"," or"," George","\u2191"," C","lo","oney",".\""," \"","You","'re"," not"," that",".\""," \"","You","'re"," a","--"," you","'re"," a","--"," a"," man","'s"," man"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["You","'re"," what","?\""," \""," My","\u2191"," ","Ama","...\""," \"","The"," woman"," who"," t","amed"," George","\u2191"," C","lo","oney",".\""," \"","I"," want"," to"," find"," that"," woman"," to"," t","ame"," me","...\""," \"","\u2191","A","mal","\u2191"," Alam","ud"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\"","\\xe2\\x99","\\xaa",""," The"," Jean"," g","enie",","," let"," yourself"," go"," ","\\xe2\\x99","\\xaa","\""," \"","David","\u2191"," B","owie"," ra","dic","alized"," mascul","inity"," in"," popular"," music",".\""," \"","So"," he"," changed"," the"," way"," that"," we"," think"," about"," gender"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.89,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".\""," \"","She"," was"," a"," weather"," girl"," when"," you"," first"," met"," her",","," right","?\""," \"","Like"," Sarah","\u2191"," Pa","lin","?\""," \"","\u2191","Week","ends",","," local"," affiliate",".\""," \"","I"," had"," a"," crush",".\""," \"","I","'m"," so"," glad"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.89,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.18,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," I","'m"," gonna"," lay"," this"," on"," the"," line"," for"," you",".\""," \"","You","'re"," no"," George","\u2191"," C","lo","oney",".\""," \"","You","'re"," not"," even"," George","\u2191"," Cost","anza",".\""," \"","These"," sheets"," are"," amazing"," and"," you"," are"," never"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.57,0.0,0.0,0.0,0.0,0.0,0.89,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.15,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["You"," hurt"," my"," feelings",".\""," \"","I"," know"," I","'m"," not"," Brad","\u2191"," P","itt"," or"," George","\u2191"," C","lo","oney"," or"," Matt","\u2191"," D","amon"," or"," Casey","\u2191"," Affl","eck"," or"," James","\u2191"," C","aan","'s"," son","...\""," \"","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.87,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["<EOT>","Baby"," Universal"," \u00e8"," un"," b","rano"," music","ale"," dei","\u2191"," Tin"," Machine",","," scr","itto"," da"," David","\u2191"," B","owie"," e","\u2191"," Re","eves","\u2191"," Gab","rels",","," pubblic","ato"," come"," secondo"," sing","olo"," estrat","to"," dall","'","album","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.87,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".\""," \"","Who"," are"," our"," favorite"," entertain","ers",","," ever","?\""," \"","James"," Brown",","," Prince",","," David","\u2191"," B","owie",","," because"," they"," embrac","ed","...\""," \"","the"," r","azz","le"," d","azz","le",".\""," \"","To"," take"," the"," power"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.87,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","Hu","bb","ard",","," a"," triple"," rainbow","!\""," \"","A"," human"," cent","ip","ede"," with"," George","\u2191"," C","lo","oney"," at"," the"," front","!\""," \"(","gas","ps",")"," A","\u2191"," Neb","uc","had","n","ezz","ar"," of"," wine","!\""," \""]}]},{"quantile_name":"Subsample Interval 0","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.93,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["\""," You"," remind"," me"," of"," someone",".\""," \"","You"," know"," who"," I"," get"," a"," lot","?\""," \"","David","\u2191"," Beck","ham",".\""," \""," Larry"," King",".\""," \""," Larry"," King","?\""," \"","Larry"," King"," is"," old",".\""," \"","Larry"," King"," is"," so"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["help"," twice"," a"," week",".\""," \"","You"," need"," a"," guy"," like","...\""," \"","Tom"," Ford"," or"," George","\u2191"," C","lo","oney",".\""," \"","You","'re"," not"," that",".\""," \"","You","'re"," a","--"," you","'re"," a","--"," a"," man","'s"," man"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["You","'re"," what","?\""," \""," My","\u2191"," ","Ama","...\""," \"","The"," woman"," who"," t","amed"," George","\u2191"," C","lo","oney",".\""," \"","I"," want"," to"," find"," that"," woman"," to"," t","ame"," me","...\""," \"","\u2191","A","mal","\u2191"," Alam","ud"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["\"","\\xe2\\x99","\\xaa",""," The"," Jean"," g","enie",","," let"," yourself"," go"," ","\\xe2\\x99","\\xaa","\""," \"","David","\u2191"," B","owie"," ra","dic","alized"," mascul","inity"," in"," popular"," music",".\""," \"","So"," he"," changed"," the"," way"," that"," we"," think"," about"," gender"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.89,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":[".\""," \"","She"," was"," a"," weather"," girl"," when"," you"," first"," met"," her",","," right","?\""," \"","Like"," Sarah","\u2191"," Pa","lin","?\""," \"","\u2191","Week","ends",","," local"," affiliate",".\""," \"","I"," had"," a"," crush",".\""," \"","I","'m"," so"," glad"]}]},{"quantile_name":"Subsample Interval 1","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.31,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ede"," en"," r\u00e6kke"," num","re"," sk","revet"," af"," koll","eger"," som"," Bob"," Dylan",","," John"," Denver"," og"," Pete","\u2191"," Se","eger",","," og"," det"," blev"," til"," store"," hits"," med"," ant","ik","rig","ss","ange"," som"," \"","\u2191","Blo","win","'"," in"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\"","And"," for"," his"," tale"," of"," genetics"," gone"," ha","yw","ire"," in"," a"," retirement"," community",",\""," \"","Steven","\u2191"," Spiel","berg",","," \"","\u2191","Ger","iat","ric"," Park","\"",".\""," \"(","\u2191","C","oughs",")\""," \"","The"," winner"," is","...\""," \""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","ga","ius","\u23ce"," G","S"," had"," already"," arranged"," to"," be"," \"","b","ailed"," out","\""," by"," Warren","\u2191"," Buff","ett","."," They"," took"," the","\u23ce","\u21ea"," T","ARP"," money"," because"," the"," government"," made"," it"," mandatory"," to"," do"," so"," (","so"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["be"," a"," \"","free","\""," open"," source"," world","."," I"," would"," bet"," if"," Bill","\u23ce"," Gates"," and"," Warren","\u2191"," Buff","ett"," each"," put"," ","5"," ","billion"," dollars"," toward"," find"," a"," cure"," or","\u23ce"," sharing"," code"," and"," paying"," creators"," there"," would"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.79,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["index","ing","\u23ce"," was"," the"," right"," strategy"," for"," most"," people"," (","and"," even"," sophisticated"," investors"," like","\u23ce"," Warren","\u2191"," Buff","ett"," have"," instruct","ed"," his"," tru","sts"," to"," use"," an"," index","ing"," approach",").","\u23ce\u23ce","\u2191","Beating"," the"," index"," is"," a"]}]},{"quantile_name":"Subsample Interval 2","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","see"," as"," \"","evil","\","," like","\u2191"," Scient","ology",","," or"," the"," Iranian"," regime",","," or"," Sarah","\u2191"," Pa","lin","\u23ce\u23ce"," Or"," Korean"," pop"," star"," Rain","?"," Or","\u2191"," Hab","bo"," Hotel","?","\u23ce\u23ce","I"," generally"," find","\u2191"," An","on"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," bank",","," that","'s"," fantastic",".\""," \""," I","'ve"," never"," been"," more"," moved"," than"," running"," a"," Charlie","\u2191"," Chap","lin"," film"," this"," year"," and"," watching"," audiences"," respond"," exactly"," how"," they"," responded"," all"," those"," years"," ago",".\""," \"","How"," his"," movies"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["working"," at"," start","ups",","," myself"," included",","," had","\u23ce"," no"," del","usions"," of"," becoming"," Mark","\u2191"," Z","uc","ker","berg"," or"," winning"," it"," big",".","\u2191"," Start","ups"," can","\u23ce"," provide"," a"," great"," quality"," of"," life"," with"," good"," benefits"," for"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["'s"," not"," a"," true"," democracy"," when"," the"," rich"," (","whether"," that"," be"," the"," Koch"," brothers"," or","\u23ce"," George","\u2191"," S","oros",")"," ind","irect","ly"," get"," way"," more"," voting"," power"," than"," the"," lower"," and"," middle","\u23ce"," classes"," get",".","\u23ce\u23ce","If"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["g",","," was"," formed"," and"," placed"," under"," the"," exclusive",","," private",","," absolute"," control"," of"," Vice"," President"," Dick","\u2191"," Che","ney",".\""," \"","Its"," records"," were"," kept"," a"," secret",","," its"," minutes"," were"," kept"," a"," secret",","," seven"," pages"," were"," released"]}]},{"quantile_name":"Subsample Interval 3","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.61,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\"","Just"," see","'","em"," and"," talk"," to","'","em",","," you"," know",","," like"," a"," Bruce","\u2191"," Spr","ings","teen"," song",".\""," \"","You"," call",","," you"," ask","'","em"," how"," they"," are",","," and"," you"," see"," if"," they","\u00b4"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.62,0.64,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.61,0.0,0.0,0.0,0.0,0.0,0.68,0.57,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["dangerous","?\""," \"","Kill"," John","\u2191"," Lenn","on","!\""," \"{","*","Hey"," }","Dad",","," where"," does"," John","\u2191"," Lenn","on"," live","?\""," \"","John","\u2191"," Lenn","on","'s"," dead","{","*,","\u2191"," But","ters","}",".\""," \"","\u2191","Dang","it"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","G","ump",".\""," \"","The","\u2191"," Animated"," Adventures"," of","\u2191"," For","rest","\u2191"," G","ump",".\""," \"","Tom","\u2191"," Cruise"," has"," nothing"," to"," do"," with"," this"," equation",".\""," \""," I"," get"," that",","," I"," got"," that",".\""," \""," So"," he"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["for"," itself"," again"," and"," again",".\""," \"","All"," day"," long",",","\u2191"," A","pu"," goes"," on"," about"," Lady","\u2191"," G","aga",","," who"," is"," doing"," nothing"," that","\u2191"," ","Rava","\u2191"," Kh","atan"," was"," not"," doing","\""," \"","20"," ","years"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ns"," hon","king","]"," [","up","beat"," music","]","\""," \"","Where"," are"," you"," guys","?\""," \"","Lady","\u2191"," G","aga"," and","\u2191"," B","ono"," are"," about"," to"," get"," hol","ogram","med"," in",".\""," \""," No","!\""," \""," [","gro","aning"]}]},{"quantile_name":"Subsample Interval 4","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.51,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["d","ude"," in"," the"," college"," a"," capp","ella"," group",".\""," \""," Yes",","," we"," sound"," wh","iter"," than","\u2191"," Mitt"," Romney"," in"," a"," snow","st","orm",".\""," \"","You"," know"," what"," I"," mean","?\""," \"","But"," that","'s"," just","-"," that"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.51,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["The"," fact"," that"," some"," people","'s"," comp","uls","ive"," behavior"," is"," triggered"," by"," fake"," videos"," of","\u23ce"," Nancy","\u2191"," Pel","osi"," doesn","'t"," matter"," to"," Facebook","."," There"," is"," no"," political"," angle"," there",",","\u23ce","only"," financial",".","\u23ce\u23ce","<EOT>","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["in","\u23ce","\"","\u2191","Stall","ion"," Road","\""," in"," that"," one","\u23ce"," she","'ll"," have","\u2191"," Humph","rey","\u2191"," Bo","gart","\u23ce"," opposite"," her"," again",".","\u23ce","Nick"," Castle",","," directing"," the"," ice","\u23ce"," bal","lets"," in"," \"","\u2191","Glam","our"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["we"," be"," asking"," a"," w","orm","?\""," \"","I"," have"," never"," heard"," an"," actor"," say"," that"," to"," James","\u2191"," Li","pton",".\""," \"","When"," he"," says",","," \"","what"," noise"," do"," you"," hate","?\"","\""," \"\"","what","?\""," \"","As"," me"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," old"," style"," conform","ist"," film","making",".\""," \"","Because"," the"," movie"," was"," about"," endings",":\""," \"","Peter","\u2191"," F","onda"," f","ores","ees"," that"," their"," journey"," won","'t"," last"," forever",".\""," \"","They","'re"," killed"," by"," conservative"," duck","-","hunters"]}]},{"quantile_name":"Subsample Interval 5","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["en","dom"," aan"," te"," v","allen","."," Ook"," ond","ert","ek","ende"," hij"," een"," brief"," aan"," president"," George"," W","."," Bush",","," waarin"," een"," theolog","ische"," ond","erb","ouw","ing"," werd"," geg","even"," voor"," de"," ju","is","theid"," voor"," de"," aan"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["I"," think"," Al","\u2191"," Pac","ino"," wants"," to"," play","\u2191"," Tw","ister"," with"," your"," sister",".\""," \"","Adam","\u2191"," Sand","ler","'s"," funny",".\""," \"","You"," have"," a"," visitor",".\""," \"","I","'m"," sorry",".\""," \"","I","'ve"," been"," a"," sh"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["l"," threw"," them"," all"," away","."," I"," had"," no"," talent",".\""," \"","I"," just"," wanted"," to"," be"," Van","\u2191"," Go","gh",".\""," \"","\u2191","Bo","nj","our",",","\u2191"," Fran\u00e7","oise",".\""," \"","\u2191"," Bo","nj","our",",","\u2191"," M","adem"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["to"," give"," a"," copy","."," That","'s"," the"," way"," to"," be"," a"," decent"," person","._","\u23ce\u23ce","\u2014"," Richard","\u2191"," Stall","man",","," ","2","001"," ","([","https","://","www",".","gnu",".","org","/","philosophy","/","r","ms","-","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.16,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ad"," est"," jo","lie"," \u00e0"," so","uh","ait",","," Gary"," Cooper",","," Charles","\u2191"," Laugh","ton"," et","\u2191"," C","ary"," Grant"," ont"," un"," j","eu"," tr\u00e8s"," express","if","."," Le"," film"," est"," do","ubl","\u00e9"," en"," fran\u00e7ais","."," ","\u23ce","L"]}]},{"quantile_name":"Subsample Interval 6","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," viv","acity"," of"," st"," de"," beer","."," I"," have"," heard"," a"," whis","per"," that"," Mr","."," Henry","\u2191"," Chap","lin"," is"," to"," receive"," a"," peer","-"," age","."," I"," pray"," that"," this"," may"," be"," so","."," Mr","."," Mr","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.22,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce\u23ce","~~~","\u23ce","st","cr","edz","ero","\u23ce"," My"," friend"," the"," ex","-","\u2191","Anime","\u2191"," Expo"," MC"," or"," Alan"," Kay","?","\u23ce\u23ce","~~~","\u23ce","vo","rador","\u23ce"," Alan"," Kay",","," of"," course",".","\u23ce\u23ce","------","\u23ce","j","r","p","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".\""," \"","On"," September"," ","11","th",","," the"," American"," public"," is"," left"," un","aware"," of"," Vice"," President","\u2191"," Che","ney","'s"," location",".\""," \"","The"," whole"," story"," is"," not"," fully"," reported"," for"," the"," next"," ","14"," ","years",".\""," \""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["to"," talk"," about"," it","."," Plus"," the"," game"," is"," pretty"," damn","\u23ce"," good"," :","D","\u23ce\u23ce","-","Joe","\u2191"," Lieb","erman","\u2191"," Indie"," Game"," PR"," Guy","\u23ce\u23ce","------","\u23ce","emp","ress","play","\u23ce"," Cool",","," looks"," like"," a"," re","-","imag"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["u","fer"," des","\u2191"," F","lus","ses","."," Als"," am"," ","27","."," Januar","\u2191"," Mor","gens"," Jules","\u2191"," Fa","vre"," mit"," seinen"," milit","\u00e4r","ischen","\u2191"," Be","gl","ei","tern"," die","\u2191"," Br","\u00fcc","ke"," \u00fcb","ersch","ritt",","," w"]}]},{"quantile_name":"Subsample Interval 7","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a"," tool"," with","\u23ce"," incredible"," power"," and"," access"," to"," the"," power"," is"," poorly"," gu","arded",".","\u2191"," Z","uc","ker","berg"," may"," be","\u23ce"," all"," powerful"," but"," even"," worse"," he"," is"," enabling"," anonymous"," bad"," organized"," actors"," to","\u23ce"," wr","eck"," hav"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","Ie"," ","23"," ","\u2191","D\u00e9c","embre"," ","1","681",","," en"," g","ericht"," aan"," Philip"," Ernst","\u2191"," Veg","elin","."," Hij"," is"," daar"," ju","ist"," te","ru","gg","ek","eerd"," en"," we"," m","ogen"," a","ann","emen",","," dat"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["and"," thank"," you",".\""," \"","Good",".\""," \"","I"," play"," tomorrow"," at"," the"," cons","ulate",".\""," \"","\u2191","Prok","of","iev",".\""," \"","I"," hope"," you"," can"," come",".\""," \"","But"," no"," fire"," this"," time",","," h","uh","?\""," \"","No"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["'t"," even"," got"," a"," recorder",".\""," \""," Bad"," enough",".\""," \"","What","'s"," the"," score","?\""," \"","\u2191","Beck","enb","auer",",","\u2191"," R","udi","\u2191"," V\u00f6l","ler","...\""," \"","You"," don","'t"," want"," to"," see"," it","...\""," \"","Germany"," made"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["impe","ached"," rather"," than"," be","he","aded",".\""," \"","Still",","," while"," in"," her"," day",","," Marie","\u2191"," Ant","oin","ette"," said"," \"","Let"," them"," eat"," cake",",\"","\""," \"","perhaps"," today"," she"," would"," say",","," \"","Let"," them"," eat"," fast"]}]},{"quantile_name":"Subsample Interval 8","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["sville",","," Ohio",".\""," \"","\u2191","Ended",".\""," \"","Add"," this"," to"," the"," night"," desk",".\""," \"","Mike","\u2191"," Con","ley",","," keep"," this"," under"," your"," hat",",","\u2191"," Gar","field"," f","ainted"," and"," I"," covered",".\""," \"","Give"," her"," a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Hotel","  ","de","  ","\u2191","Ville","  ","are","  ","bu","sts","  ","of","  ","Cardinal"," ","\u23ce","\u2191","Ric","hel","ieu","  ","and","  ","the","  ","Duke","  ","de","  ","\u2191","Gu","ise",".","  ","There","  ","are","  ","one","  "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".\""," \"","He"," claims"," to"," be"," the"," property","..."," of"," an","\u2191"," O","bi","-","\u2191","Wan","\u2191"," Ke","no","bi",".\""," \"","Is"," he"," a"," relative"," of"," yours","?\""," \"","Do"," you"," know"," who"," he","'s"," talking"," about","?\""," \""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["cameras",".\""," \"","This"," is"," Vietnam",":\""," \"","The"," Movie",".\""," \"","Yeah",",","\u2191"," Jo","ker"," can"," be"," John"," Wayne",","," I","'ll"," be"," a"," horse",".\""," \"","T",".","H",".","E","."," Rock"," can"," be"," a"," rock",".\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["liberty"," is"," no"," vice",".\""," \"","\u2191","Mod","eration"," in"," the"," pursuit"," of"," freedom"," is"," no"," virtue",".\""," \"[","Bob"," Dylan"," s","ings"," The"," Times"," They"," Are"," A","-","\u2191","Chan","gin","']","\""," \"","\\xe2\\x99","\\xab",""," Don","'t"," stand"]}]},{"quantile_name":"Bottom Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ie"," in"," f",","," opus"," ","49",","," F",".","\u2191"," Cho","pin","."," ","2",".","\u2191"," Pa","gan","ini"," \u00e9t","ude"," no"," .","5"," ","in"," E",","," F",".","\u2191"," Lis","zt","."," (","\u2191","Gr",".","p"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.07,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["bad",".\""," \"","Now"," let","'s"," try"," it"," with"," somebody"," else",".\""," \"","Mr","...","?\""," \"","\u2191","Mar","iol","ini",".\""," \"","Mr",".","\u2191"," Mar","iol","ini",".\""," \"","And"," where"," are"," you"," from","?\""," \"","\u2191","Nap","oli"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["."," It","'s"," beyond"," me"," as"," to"," how"," anyone"," could"," watch"," that"," talk","\u23ce"," and"," agree"," with"," Mr","\u2191"," Lev","itt","'s"," conclusions",".","\u23ce\u23ce","He"," flat"," out"," admits"," that"," his"," only"," sources"," of"," his"," \"","research","\""," are"," ","1"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["feel"," sorry"," for"," her",","," though",".\""," \"","How"," come","?\""," \"","Her"," ex","-","boyfriend",","," Ray","\u2191"," Don","ovan",".\""," \"","What"," a"," psych","o",".\""," \"","It","'s"," amazing"," how"," frag","ile"," the"," human"," body"," is",".\""," \""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","money","."," Americans"," are"," just"," better"," at"," sharing"," down"," the"," food"," chain",".","\u23ce\u23ce","------","\u23ce","j","lan","gen","auer","\u23ce","\u2191"," Apro","pos"," of"," this",","," I"," was"," in"," Paris"," recently"," at"," a"," startup"," event",","," and"," was","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.11,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["on"," a"," lieutenant","'s"," uniform",".\""," \"","I","'ll"," give"," the"," commission"," to"," M","."," d","'","\u2191","Ar","tag","nan",","," after"," you"," have"," breakfast"," in"," the"," Saint","-","\u2191","G","erv","ais"," bas","tion",".\""," \"","\u2191","Breakfast"," under"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\"","He"," is"," not"," quite"," another",".\""," \"","He"," is"," not"," a"," Super","\u2191"," S","ai","yan"," like","\u2191"," G","oku"," or","\u2191"," Veg","eta",".\""," \"","But",","," I"," know"," he"," has","\u2191"," S","ai","yan","'s"," blood"," and"," his"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["'d"," be"," by"," around"," ","11",":","00",".\""," \"","Hi",".\""," \"","Here"," to"," see"," Joy","\u2191"," Sc","ro","ggs",".\""," \"","Oh",","," you"," must"," be"," from"," the"," alarm"," company",".\""," \"","Yes",".\""," \"","May"," I"," come"," in"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["us",".\""," \"","\u2191","Fran","zen","'s"," here",".\""," \"","He","'d"," like"," a"," word",".\""," \"","Jonathan","\u2191"," Fran","zen","?\""," \"","No",",","\u2191"," P","eric","les","\u2191"," Fran","zen",".\""," \"","Yes",","," Jonathan",","," come"," on",".\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["thought"," you"," had","\u2191"," Sy","lar",".\""," \"","I"," will"," again","..."," soon",".\""," \"","You"," mean","\u2191"," Pe","tr","elli",".\""," \"","Where"," is"," he","?\""," \"","I"," think"," he","'s"," been"," here"," this"," all"," time",","," and"," I","'ve"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["with"," Google"," or"," another"," big"," company",","," what"," could"," go"," wrong","\u23ce"," here","?","\u23ce\u23ce","~~~","\u23ce","\u2191","Sp","iv","ak","\u23ce"," I"," mean"," the"," entire"," trick"," to"," domain"," fron","ting"," is"," that"," some"," large"," company",","," whose","\u23ce"," site"," no"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["'","un"," roman"," esp","agn","ol",","," La","\u2191"," Cost","anza",","," de"," po","\u00e8","mes",","," L","\u2191"," Etern","elle"," all","\u00e9e",","," et"," d","'","une"," trag","\u00e9","die",","," Le"," Crime"," du"," mas","que",".","do"," M","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["richard","i\u00e8re","."," admin"," st"," r","aton"," r"," de"," la"," succession","\u2191"," La","vo","cat","."," rue","\u2191"," Ric","hel","ieu",","," ","15"," ",";"," ","2","\u00ae"," et"," \u00e0"," Me","\u21ea"," GIR","ARD","1","N",","," not","oire"," \u00e0"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ress","\u00e9es"," A","V","\u21ea"," DIRECT","EUR","-","\u21ea","G\u00c9","RANT"," ","85",","," \u2014"," rue"," de","\u2191"," Ric","hel","ieu",","," \u2014"," ","85","\u21ea","PAR","ISLE","\u21ea"," MONIT","EUR","\u21ea"," INDUSTRI","EL"," c","S","o"," F","I","3","NT"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["man","\u23ce","\u2191"," Personally"," directed"," by"," Allan","\u2191"," D","wan","\u23ce"," Also"," a","\u23ce","\u21ea"," M","ACK","\u21ea"," S","ENN","ETT"," ","2"," ","\u2191","K","eel"," Comedy","\u23ce","'","\u21ea","HARD","\u21ea"," KN","OCKS"," and","\u21ea"," LOVE","\u21ea"," T","APS"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["pass","ait"," pour"," avoir"," de"," for","tes"," \u00e9conom","ies","."," ","\u23ce","Le"," par","quet"," de"," Saint","-","\u2191","Et","ienne"," s","'","est"," transport","\u00e9"," sur"," les"," l","ieux","."," ","\u23ce","\u2191","Vers","ailles"," ","\u23ce","Un"," journ","al"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","5"," ","to"," ","100","k"," M","R","R"," in"," ","24"," ","months"," -"," raf","w","ever","ber","gh","\u23ce"," http","://","t","hen","ex","tw","eb",".","com","/","entrepreneur","/","2","016","/","06","/","09","/"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","It"," is"," fantastic"," to"," see"," a"," programming"," community"," venture"," between"," Joel","\u2191"," Spol","sky","\u23ce"," and"," Jeff","\u2191"," At","wood"," take"," off",".","\u23ce\u23ce","I"," am"," so"," looking"," forward"," to"," this"," and"," my"," expect","ation"," is"," already"," very"," high"," which"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["more"," to"," do"," with"," it",".","\u23ce\u23ce","~~~","\u23ce","fr","gt","ps","sw","rd","l","ame","\u23ce"," Well","\u2191"," Bub","ba"," has"," no"," more"," right"," to"," a"," good"," life"," than"," Liu","\u2191"," Chu"," but"," if"," you"," live"," next","\u23ce"," door"," to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce\u23ce","------","\u23ce","ul","adz","isl","au","\u23ce","\"","The"," Engineer"," -"," unauthorized"," biography"," of","\u2191"," E","lon","\u2191"," M","usk","\""," looks"," much"," better"," for"," the","\u23ce"," title"," of"," H","N"," submission",".","\u23ce\u23ce","------","\u23ce","h","k","__","2"]}]}],"top_logits":["'s","Jr","and","(","Sr","of",",","III","jr","once"],"bottom_logits":["Zobacz","nicarag","jerusal","begriff","pembelaj","Wydarzenia","\u00c5r","gheorgh","brit","j\u00f3z"]}