{"index":7609336,"examples_quantiles":[{"quantile_name":"Top Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.21,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["expression"," studies","."," At"," present",","," phot","om","ult","ipl","ier"," tubes"," (\"","PM","Ts","\")"," are"," still"," the"," detector"," of"," choice"," although"," charge"," coupled"," devices"," (\"","CC","Ds","\")"," and"," aval","anche"," photo","di","odes"," (\"","AP","Ds","\")"," can"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["W","er","ks",">"," tk"," can"," do"," a"," lot"," more"," than"," zen","ity","."," It"," used"," to"," be"," my"," gui"," of"," choice"," when"," I"," was"," developing"," on"," Linux"," for"," windows"," at"," work"," (","15"," ","-"," ","20"," ","years"," ago"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.13,0.87,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["in"," a"," waiting"," room",","," train",","," or","\u23ce"," commercial"," break"," without"," hitting"," up"," their"," b","ore","dom"," reli","ever"," of"," choice","."," I"," have","\u23ce"," to"," work"," hard"," at"," that"," tem","pt","ation"," myself","."," I","'d"," stick"," Twitter"," way"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.26,0.84,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ban","sh","ee"," does"," too","\u23ce","<","m","rev","ell",">"," Yeah",",","\u2191"," Rhyth","m","box"," is"," my"," player"," of"," choice"," really","."," Just"," wondered"," if"," there"," was"," anything"," else"," out"," there","."," I","'ve"," played"," around"," with","\u2191"," Cl"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.84,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["and"," thy","roid"," cancer"," for"," more"," than"," ","60"," ","years",".","\u2191"," Radio","i","od","ine"," is"," the"," treatment"," of"," choice"," for"," radiation"," therapy"," in"," the"," United"," States",","," United"," Kingdom",","," and"," Canada"," because"," it"," is"," relatively"," in","exp"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.18,0.83,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","<EOT>","Since"," the"," mid"," ","1","980","s"," end","osc","opic"," s","inus"," surgery"," has"," been"," the"," surgical"," method"," of"," choice"," in"," the"," United"," States"," for"," dealing"," with"," chronic"," sin","us","itis","."," But"," as"," with"," any"," surgery"," there"," can"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.16,0.83,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["-","10",")."," Since"," the"," early"," ","1","990","'s",","," abl","ative"," therapy"," has"," proven"," to"," be"," the"," treatment"," of"," choice",","," beginning"," with"," radio","fr","equ","ency"," application"," and"," more"," recently"," c","ry","o","abl","ation"," (","See",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.11,0.82,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["oct","ano","ic"," acid"," (","n","=","6",")"," and"," its"," sal","ts",","," have"," been"," the"," em","uls","ifier"," of"," choice"," in"," the"," aqu","eous"," em","ulsion"," poly","mer","ization"," of"," fluor","om","onom","ers"," for"," the"," last"," decades","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.15,0.82,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," device"," upon"," insertion"," (","see"," F","IG","."," ","3",").","\u2191"," Super","gl","ue"," is"," the"," adhes","ive"," of"," choice"," and"," is"," applied"," by"," hand","."," This"," method"," has"," several"," limitations",","," in"," addition"," to"," those"," listed"," under"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["whatever"," you","'re"," supposed"," to"," do"," for"," main","line"," ubuntu"," and"," then"," install"," x","ub","untu"," from"," your"," package"," manager"," of"," choice","\"","\u23ce","<","no","tw","ist",">"," I"," love"," the"," feature"," in","\u21ea"," X","F","CE"," where"," you"," can"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.22,0.79,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["rapid"," and"," easy"," and"," has"," yiel","ded"," such"," out","stand","ingly"," superior"," results"," that"," it"," is"," now"," the"," fitting"," technique"," of"," choice"," in"," this"," laboratory","."," L","-","1"," ","regression"," does"," not"," provide"," the"," means"," of"," parameter"," error"," estimation"," normally"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.07,0.79,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["pl","ab","x"," in"," a","\u23ce"," traditional"," tool"," chain",","," with","\u2191"," Make","files",","," scripts",","," and"," your"," editor"," of"," choice",".","\u23ce\u23ce","<EOT>","\u23ce","Don","'t"," major"," in"," CS",":"," ","5"," ","reasons"," why"," -"," l","pm","ay"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.78,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["strong"," but"," also"," relatively"," lightweight","."," Despite"," the"," processing"," challenges"," presented"," thereby",","," b","raid"," is"," often"," the"," reinfor","cement"," of"," choice"," in"," composite"," materials"," that"," serve"," a"," wide"," variety"," of"," market"," applications",".","\u23ce","For"," example",","," b","raid"," is"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.77,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["at"," the"," inters","ections"," of"," the"," reinfor","cing"," fi","bers","."," This"," is"," why"," b","raid"," is"," the"," reinfor","cement"," of"," choice"," for"," aircraft"," prop","ellers"," and"," st","ator"," v","anes"," in"," jet"," engines",".","\u23ce","\u2191","B","raid"," greatly"," impro"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.77,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["complement","ing"," or",","," in"," some"," cases",","," suppl","anting"," computer"," assisted"," X","-","ray"," tom","ography"," as"," the"," method"," of"," choice"," for"," solid"," tumor"," detection",".","\u23ce"," ","The"," physical"," basis"," of"," current"," M","RI"," methods"," has"," its"," origin"," in"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.76,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["cor","related"," with"," its"," pos","tt","rans","pl","ant","ation"," course",".","\u23ce","\u2191","Transpl","ant","ation"," is"," the"," therapy"," of"," choice"," for"," people"," with"," end","-","stage"," organ"," failure","."," In"," the"," case"," of"," end","-","stage"," heart",","," liver"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.76,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["and"," mortality"," rates","."," In"," a"," recent"," publication"," the"," open"," abd","omen"," technique"," is"," still"," advoc","ated"," as"," the"," treatment"," of"," choice"," for"," ab","dom","inal"," compart","ment"," syndrome","."," (","Miller",","," P"," R",","," J",".","\u2191"," Trauma"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.11,0.76,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["estimate"," of"," the"," strength"," of"," a"," noise"," source"," is"," required"," and"," for"," which"," NA","H"," may"," not"," be"," the"," method"," of"," choice"," because"," it"," is"," considered"," time"," consuming"," and"," costly","."," So"," it"," will"," be"," highly"," des","irable"," to"," have"," a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.75,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["its"," use","fulness"," for"," p","iston"," crown"," and"," cylinder"," liner"," applications",".","\u23ce","Silicon"," nit","ride"," has"," been"," the"," material"," of"," choice"," in"," most"," recent"," work",","," because"," of"," its"," low"," thermal"," conduct","ivity",","," relatively"," high"," strength"," at"," temperatures"," to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.75,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["bar","(","paid",")->","Alfred",".","\u23ce\u23ce","~~~","\u23ce","","Const","ant","ine","X","VI","\u23ce"," Alfred"," is"," my"," launcher"," of"," choice"," these"," days"," as"," well","."," Even"," paid"," for"," it",","," though","\u23ce"," it","'s"," super","-","rare"," that"," I"]}]},{"quantile_name":"Subsample Interval 0","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.21,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["expression"," studies","."," At"," present",","," phot","om","ult","ipl","ier"," tubes"," (\"","PM","Ts","\")"," are"," still"," the"," detector"," of"," choice"," although"," charge"," coupled"," devices"," (\"","CC","Ds","\")"," and"," aval","anche"," photo","di","odes"," (\"","AP","Ds","\")"," can"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["W","er","ks",">"," tk"," can"," do"," a"," lot"," more"," than"," zen","ity","."," It"," used"," to"," be"," my"," gui"," of"," choice"," when"," I"," was"," developing"," on"," Linux"," for"," windows"," at"," work"," (","15"," ","-"," ","20"," ","years"," ago"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.13,0.87,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["in"," a"," waiting"," room",","," train",","," or","\u23ce"," commercial"," break"," without"," hitting"," up"," their"," b","ore","dom"," reli","ever"," of"," choice","."," I"," have","\u23ce"," to"," work"," hard"," at"," that"," tem","pt","ation"," myself","."," I","'d"," stick"," Twitter"," way"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.26,0.84,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["ban","sh","ee"," does"," too","\u23ce","<","m","rev","ell",">"," Yeah",",","\u2191"," Rhyth","m","box"," is"," my"," player"," of"," choice"," really","."," Just"," wondered"," if"," there"," was"," anything"," else"," out"," there","."," I","'ve"," played"," around"," with","\u2191"," Cl"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.84,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["and"," thy","roid"," cancer"," for"," more"," than"," ","60"," ","years",".","\u2191"," Radio","i","od","ine"," is"," the"," treatment"," of"," choice"," for"," radiation"," therapy"," in"," the"," United"," States",","," United"," Kingdom",","," and"," Canada"," because"," it"," is"," relatively"," in","exp"]}]},{"quantile_name":"Subsample Interval 1","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.15,0.82,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["the"," device"," upon"," insertion"," (","see"," F","IG","."," ","3",").","\u2191"," Super","gl","ue"," is"," the"," adhes","ive"," of"," choice"," and"," is"," applied"," by"," hand","."," This"," method"," has"," several"," limitations",","," in"," addition"," to"," those"," listed"," under"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["whatever"," you","'re"," supposed"," to"," do"," for"," main","line"," ubuntu"," and"," then"," install"," x","ub","untu"," from"," your"," package"," manager"," of"," choice","\"","\u23ce","<","no","tw","ist",">"," I"," love"," the"," feature"," in","\u21ea"," X","F","CE"," where"," you"," can"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.22,0.79,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["rapid"," and"," easy"," and"," has"," yiel","ded"," such"," out","stand","ingly"," superior"," results"," that"," it"," is"," now"," the"," fitting"," technique"," of"," choice"," in"," this"," laboratory","."," L","-","1"," ","regression"," does"," not"," provide"," the"," means"," of"," parameter"," error"," estimation"," normally"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.07,0.79,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["pl","ab","x"," in"," a","\u23ce"," traditional"," tool"," chain",","," with","\u2191"," Make","files",","," scripts",","," and"," your"," editor"," of"," choice",".","\u23ce\u23ce","<EOT>","\u23ce","Don","'t"," major"," in"," CS",":"," ","5"," ","reasons"," why"," -"," l","pm","ay"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.78,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["strong"," but"," also"," relatively"," lightweight","."," Despite"," the"," processing"," challenges"," presented"," thereby",","," b","raid"," is"," often"," the"," reinfor","cement"," of"," choice"," in"," composite"," materials"," that"," serve"," a"," wide"," variety"," of"," market"," applications",".","\u23ce","For"," example",","," b","raid"," is"]}]},{"quantile_name":"Subsample Interval 2","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["their","\u23ce"," work","station","."," Then",","," anyone"," who"," hosts"," anything"," has"," a"," heavy"," dose"," of"," his"," Linux","\u23ce"," distribution"," of"," choice"," in"," the"," mix","."," Not"," defining"," ","'","influential","'"," doesn","'t"," help","\u23ce"," with"," the"," site","'s"," cred"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.14,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["id","imens","ional",","," offer"," sensitive",","," selective",","," and"," rapid"," feedback",".","\u2191"," Lumin","escence"," is"," often"," the"," observable"," of"," choice"," of"," chem","os","ens","ors"," and"," molecular","-","level"," devices","\u23ce"," In"," the"," prior"," art",","," lumin","escent"," temperature"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["coupled"," to"," the"," continuous"," reduction"," in"," their"," cost","/","performance"," (","optical"," dis","ks","),"," makes"," digital"," storage"," the"," method"," of"," choice",".","\u23ce","Most"," frame"," grab","bers"," digit","ize"," the"," image"," with"," ","8","-","bit"," accuracy",","," i","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.53,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","be"," distrib","uting"," extremely"," high"," quality"," files"," that"," people"," can"," watch"," full"," screen","\u23ce"," using"," the"," video"," viewer"," of"," their"," choice"," without"," the"," risk"," of"," lat","ency"," issues","."," The","\u23ce"," fact"," is"," is"," that"," h","ulu"," is",","," by"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08,0.0,0.0,0.44,0.69,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\"","Blair",","," in"," our"," school","'s"," history",","," most"," wait","-","listed"," students"," ultimately"," get"," into"," the"," college"," of"," their"," choice",".\""," \"","Your"," transcript"," is"," a"," series"," of"," unb","lem","ished"," A","'s",".\""," \"","All"," you"," have"," to"]}]},{"quantile_name":"Subsample Interval 3","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.5,0.61,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["language",".","  ","The","  ","extra","peri","ton","eal","  ","route","  ","is","  ","the","  ","operation"," ","\u23ce","of","  ","choice","  ","in","  ","all","  ","cases","  ","in","  ","which","  ","the","  ","abs","cess","  ","cavity","  ","can"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.11,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["be"," a"," reason",".\""," \"","Tell"," me","\""," \"","I"," had"," promised"," uncle"," that"," I","'d"," marry"," the"," boy"," of"," his"," choice","\""," \"","It","'s"," only"," because"," of"," a"," promise","?\""," \"","D","'","you"," have"," any"," idea"," what"," state"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["directed"," ax","ially"," through"," the"," tube",".","\u23ce","While"," an"," elect","rot","her","mal"," furn","ace"," is"," the"," atom","izer"," of"," choice"," for"," many"," elements"," for"," which"," it"," has"," lower"," detection"," limits"," and"," higher"," sensitivity"," than"," flame",","," it"," suf","fers"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.14,0.59,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","\u2191"," Van","com","yc","in",","," a"," glyc","op","ept","ide"," anti","bi","otic",","," is"," currently"," the"," agent"," of"," choice"," for"," comb","ating"," these"," infections"," which"," are"," predominantly"," encountered"," in"," hospital"," settings","."," With"," the"," increased"," usage"," of","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.59,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["this"," can"," provide"," the"," same"," level"," of"," _","autonom","y","_"," ,","\u23ce","it"," could"," easily"," become"," my"," authentic","ator"," of"," choice",".","\u23ce\u23ce","It"," looks"," like"," it","'s"," tied"," to"," an"," email"," account","?","\u2191"," Slightly"," anno","ying",","," but"]}]},{"quantile_name":"Subsample Interval 4","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["our"," work"," is"," that"," we"," will"," develop"," the"," OUT"," platform"," for"," other"," researchers"," to"," plug"," in"," their"," E","3","s"," of"," interest"," and"," map"," the"," E","3","s"," on"," the"," cell"," sign","aling"," network"," by"," prof","iling"," their"," substrate"," specif","icity"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["NA"," libraries"," with"," hom","olog","ous"," or"," heter","olog","ous"," genes",","," PC","R","-","ampl","ification"," of"," the"," gene"," of"," interest"," using"," olig","ion","uc","le","ot","ide"," primers"," corresponding"," to"," conserv","ed"," amino"," acid"," sequence"," mot","ifs",","," and"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.19,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a"," little"," DB","-","backed"," interactive"," experience",",","\u23ce","then"," either"," push"," it"," to"," an"," in","-","app"," inbox"," of"," their"," friends"," [","where"," it"," could"," then","\u23ce"," be"," re","-","shared"," further",","," vir","ally","]"," or"," onto"," a"," cloud"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.16,0.18,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce\u23ce"," ","_","In"," Do","D"," we"," embrace"," the"," No","SQL"," movement"," and"," jump"," straight"," to"," the"," data","-","store"," of","\u23ce"," the"," future",":"," a"," CSV"," file","._","\u23ce\u23ce","or","\u23ce\u23ce"," ","_","Does"," it"," scale","?","\u23ce\u23ce","So"," far"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.5,0.61,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","language",".","  ","The","  ","extra","peri","ton","eal","  ","route","  ","is","  ","the","  ","operation"," ","\u23ce","of","  ","choice","  ","in","  ","all","  ","cases","  ","in","  ","which","  ","the","  ","abs","cess","  ","cavity","  "]}]},{"quantile_name":"Subsample Interval 5","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a"," pla","sm","id"," will"," repl","icate","."," One"," may"," develop"," a"," specific"," vector"," for"," each"," mic","rob","ial"," species"," of"," interest",";"," or",","," one"," may"," take"," advantage"," of"," available"," broad"," host"," range"," repl","icons"," that"," have"," the"," ability"," to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.12,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["?\""," \"","It","'s"," hard"," to"," focus"," on"," nut","m","eg"," when"," the"," guy"," who"," might"," be"," the"," guy"," of"," my"," dreams"," refuses"," to"," call"," me",".\""," \"","After"," my"," first"," date"," with"," neil"," I"," called"," him",".\""," \"","There"," are"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Therefore",","," aqu","eous"," sulf","u","ric"," acid"," or"," perc","hl","oric"," acid",","," etc",".,"," were","\u2191"," Applic","ants"," first"," choice",".","\u23ce","With"," a"," concentrate"," from","\u2191"," Tag","etes",","," containing"," ","39","%"," of"," lut","ein",",","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.4,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u00e9e"," g\u00e9n\u00e9","rale","."," ","\u23ce","Art","."," ","14","."," Les"," or","ateurs"," pour","ront"," employer"," la"," langue"," de"," leur"," cho","ix","."," Les"," disc","ours"," pron","onc","\u00e9s"," en"," langue"," \u00e9t","rang","\u00e8re"," se","ront"," r\u00e9s","um","\u00e9s"," en"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.55,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce\u23ce","------","\u23ce","m","su","rel","\u23ce"," Python","."," I","'m"," sure"," people"," will"," fill"," in"," the"," scri","pting"," language"," of"," your"," choice",",","\u23ce","but"," knowing"," at"," least"," one"," is"," a"," real"," time"," s","aver","."," I"," have"," lost"," count"]}]},{"quantile_name":"Subsample Interval 6","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ot","tu",">"," x","f","w","m","4"," ","(","source",":"," x","f","w","m","4","):"," window"," manager"," of"," the","\u2191"," X","f","ce"," project","."," In"," component"," universe",","," is"," optional","."," Version"," ","4",".","8","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["music","ale",","," je"," cr","ains"," fort"," qu","'","il"," ne"," pu","isse"," ent","rer"," dans"," la"," mus","ique"," de"," son"," r\u00e9g","iment","."," ","\u23ce","Un"," je","une"," chef","."," \u2014"," Si"," vous"," vou","lez"," faire"," cl","asser"," vo","tre"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["air","flow"," it"," is"," necessary"," to"," change"," the"," particle"," carrier"," fluid"," to"," water"," or"," another"," liquid","."," The"," transport"," method"," of"," this"," patent"," application"," involves"," temporarily"," susp","ending"," ab","ras","ive"," particles"," in"," sufficient"," water"," or"," other"," liquid"," to"," flow"," to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ag","eous"," in"," that"," the"," manipulation"," thereof"," is"," accurate"," and"," commands"," can"," clearly"," be"," distinguished"," and"," transferred"," to"," the"," GUI"," of"," an"," associated"," computer"," system",","," for"," example",","," a"," hardware"," mouse"," device"," simultaneously"," enabling"," pointing"," to",","," and"," activation"," of"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["or"," for"," further"," processing"," of"," more"," complex"," device"," architect","ures",","," presents"," a"," significant"," challenge","."," One"," of"," the"," methods"," of"," solving"," this"," challenge"," is"," to"," cross","link"," the"," semiconduct","ing"," polym","ers",","," l","ocking"," in"," favorable"," morph","ologies"," and"]}]},{"quantile_name":"Subsample Interval 7","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["."," Hart"," ","ell"," t",".,"," n"," j"," t"," s","\u23ce"," the"," a"," nd","ida"," t"," ",".-"," of"," tl","oir"," nom"," in"," :","ti","."," -",":","\u23ce","and"," Mr",".","\u2191"," O","la","ik"," -","..","n"," beim",".,"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["air"," bub","bles"," in"," most"," systems"," emplo","ying"," flowing"," liqu","ids"," is"," highly"," un","des","irable","."," A"," particular"," system"," of"," this"," category"," is"," a"," closed"," hot"," water"," heating"," system"," in"," which"," the"," gas",","," in"," the"," form"," of"," air"," bub"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["it"," does"," this"," client"," side","."," I"," pres","ume"," the"," extension"," basically","\u23ce"," makes"," an"," API"," call"," with"," the"," url"," of"," the"," current"," site",".","\u23ce\u23ce","------","\u23ce","ish","it","ats","uy","uki","\u23ce"," Really"," in","acc","u","rate","."," Just"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["regulatory","\u2191"," Compliance","\u23ce"," To"," participate"," in"," Title"," IV"," Programs",","," a"," school"," must"," be"," authorized"," to"," offer"," its"," programs"," of"," instruction"," by"," relevant"," state"," education"," agencies",","," be"," acc","redited"," by"," an"," acc","red","iting"," commission"," recognized"," by"," the"," DO"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a"," further"," object"," of"," the"," present"," invention"," to"," use"," head","ered","/","fin","ned"," pipes"," as"," the"," re","he","ater"," of"," an"," air"," conditioning"," system"," for"," maxim","izing"," heat"," transfer"," and"," energy"," util","ization"," for"," cooling"," at"," post"," comp","ressor"," and"]}]},{"quantile_name":"Subsample Interval 8","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," desktop"," computers",","," super","comp","uters",","," and"," even"," modern"," video"," game"," cons","oles",","," use"," an"," operating"," system"," of"," some"," type","."," A"," thin","-","client"," is"," an"," example"," of"," a"," desktop"," computer"," or"," local"," system"," that"," may"," run"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.09,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["was","  ","due","  ","by","  ","order","  ","to","  ","another","  ","that","  ","was","  ","not","  ","of","  ","their","  ","mih","d","^"," ","\u23ce","they","  ","would","  ","be","  ","sure","  ","to","  ","work","  ","him","  "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["system","."," Also",","," it"," is"," understood"," that"," the","\u21ea"," UV","GI"," unit"," and"," germ","icide"," ir","rad","iation"," technique"," of"," the"," present"," invention"," may"," be"," integrated"," with"," other"," types"," of"," optical"," scan","ners",".","\u23ce","[","1","960","]","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["and"," ","8",".","04"," ","will"," work"," as"," well","\u23ce","<","`","D","T","`",">"," x","ub","untu"," of"," those"," same"," versions"," will"," probably"," be"," a"," little"," faster","\u23ce","<","pos","ei","don","2","010",">"," D","T",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["of"," his"," class",".\""," \"","He"," studied"," very"," hard",",","\u2191"," Ned",".\""," \"","You"," know",","," he"," could"," get"," into"," almost"," any"," division"," he"," wanted",".\""," \"","I","'ve"," been"," hoping"," to"," recommend"," him"," for"," the"," detective"," course",".\""," \""]}]},{"quantile_name":"Bottom Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".\""," \"","There"," is"," a","\u2191"," G","rim","\u2191"," Re","aper"," whose"," name"," is"," Death",","," with"," the"," power"," of"," our"," Lord",".\""," \"","Hello","?\""," \"","Who","'s"," there","?\""," \"","He"," wh","ets"," his"," knife"," today",","," sharp"," for"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["d"," poly","sil","icon"," layer"," or"," poly","-","1"," ","layer"," ","21",","," i",".","e","."," a"," layer"," of"," d","oped"," poly","sil","icon"," to"," be"," used"," for"," the"," floating"," gates"," of"," the"," memory"," cells",","," is"," depos","ited"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ow","out"," prev","enter"," on"," the"," running"," tool"," string"," and"," then"," applying"," pressure"," through"," the"," ch","oke"," or"," kill"," line"," of"," the"," B","OP"," stack","."," This"," pressure"," surro","unds"," the"," running"," tool"," and"," will"," cause"," the"," l","atch"," actu","ating"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["appeared","\u23ce","<","j","_",">"," could"," it"," be"," possible"," to"," add"," a"," \"","schedule"," work","\""," and"," a"," lock"," of"," the"," events"," when"," you"," have"," a"," stop"," event","\u23ce","<","\u2191","Ke","yb","uk",">"," j","_",":"," sorry",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["yet"," been"," made"," on"," the"," part"," of","\u23ce"," the","\u2191"," S","hu","berts"," to"," build"," a"," new"," theatre"," of","\u23ce"," their"," own"," although"," it"," is"," I"," certain"," that"," the","\u23ce","\u2191"," S","hu","berts"," have"," been"," ap","pr","ised"," of"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["yl","]","b","orate"," as"," the"," lip","oph","i","lic"," add","itive"," in"," a"," semiconduct","ing"," conjug","ated"," polymer"," matrix"," of"," poly","(","3","-","oct","yl","th","i","oph","ene",")."," The"," membrane"," components"," were"," dissolved"," in"," chlor","o","form"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["got"," more"," familiar"," with","\u2191"," Terraform",","," got"," started"," with","\u2191"," Kubernetes",",","\u23ce","and"," contributed"," significantly"," to"," the"," infrastructure"," of"," a"," few"," awesome"," projects",".","\u23ce\u23ce","In"," my"," spare"," time"," I","'ve"," been"," maintaining"," my","\u2191"," Aut","osp","ot","ting"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".\""," \"","\u2191","Hm","m",".\""," \"","General",","," from"," now"," on",","," maybe"," you"," should"," favor"," the"," company"," of"," your"," men",".\""," \"","He"," pulled"," a"," knife","?\""," \"","It"," was"," only"," a"," small"," p","rick",".\""," \"(","\u2191","Ch"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["'re"," dead",".\""," \"","Alfonso"," of"," Naples",","," Prince"," of","\u2191"," B","isc","eg","lie",".\""," \"","\u2191","Husband"," of"," his"," sister",".\""," \"","Yes",".\""," \"","And"," I"," want"," to"," use"," it",".\""," \"","Smart",".\""," \"","And"," if"," I"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["sont"," pay","\u00e9es"," le"," lux","e"," de"," dispos","er"," n","ett","ement"," d","'","une"," b","onne"," \u00e9qu","ipe"," de"," premi\u00e8re"," division","."," Les"," visit","eurs"," ont"," pr\u00e9","sen","t\u00e9"," ","\u00f9","ne"," \u00e9qu","ipe"," at","hl","\u00e9t","ique",","," mais"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["release",","," lack"," of"," momentum",","," and",","," in"," at"," least"," one"," documented"," instance",","," the"," v","aul","ting"," pole"," of"," the"," athlete"," catching"," the"," front"," lip"," of"," the"," pole"," vault"," box"," during"," the"," pole"," pl","anting"," stage","."," Id","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".\""," \"","\u2191","Jas","per",":\""," \"","I"," should"," have"," recognized","\u2191"," Quart","erman"," earlier",".\""," \"","It","'s"," my"," first"," case"," and"," now"," your"," son","'s"," in"," danger",".\""," \"","I"," don","'t"," think"," I","'m"," gonna"," be"," much"," of"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["be"," brought"," into"," contact"," with"," each"," other"," in"," the"," presence"," of"," other"," reaction"," reag","ent",","," such"," as"," a"," compound"," of"," sil","ic","ium",","," phosph","orus"," or"," aluminum",".","\u23ce","As"," the"," org","ano","al","um","inum"," compound"," (","f"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["di"," ","\u23ce","V","B","  ","L","  ","(","sono","  ","le","  ","tre","  ","primo","  ","lett","ere","  ","di","  ","D","U","ig","ite","),"," ","\u23ce","B","  ","delle","  ","altre","  ","lett","ere","  ","che","  ","dir"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["column"," first"," and"," enter"," the"," separation"," column"," where"," they"," are"," further"," chr","omat","ograph","ed","."," Once"," the"," last"," component"," of"," interest"," has"," el","uted"," from"," the"," pre","-","column",","," the"," pre","-","column"," can"," be"," back","f","lus","hed"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["j","ours"," de"," l","'","\u00e9l","ection",":"," ",".:","l","'",",,",","," une"," man","\u0153","uvre"," de"," la"," dern","i\u00e8re"," h","eure"," !"," D","'","ab","ord",","," mess","ieurs",","," je"," cr","ois"," qu","'","une"," man","\u0153"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["The"," invention"," accordingly"," provides"," a"," process"," for"," preparing"," an"," antim","ic","rob","ial"," form","ulation"," by"," re","acting"," a"," compound"," of"," the"," formula"," ","1","\u23ce","(","R","1","O",")","3","\u2191","Six","e","2","x","80","x","94","("]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["b","  ","von","  ","ben","  ","","\u00a9","erg","v","\u00f6","lf","ern","  ","f","ei","*"," ","\u23ce","","ner","  ","?","","ift",",","  ","\u2191","\u00c4","\u00fc","f","yn","f","y","eit","  ","un","b","  ","\u2191","X"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["I","-","1","-","a",")"," to"," (","I","-","3","-","a",")"," and"," the"," carbon","yl"," hal","ide"," of"," the"," formula"," (","V",")"," are"," generally"," each"," employed"," in"," approximately"," equivalent"," amounts","."," However",","," it"," is"," also"," possible"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","chat","m","asta","\u23ce"," What"," is"," an"," example"," of"," when"," you"," would"," want"," a"," promise"," to"," represent"," the"," key"," of"," a","\u23ce"," component","?","\u2191"," Wouldn","'t"," you"," be"," more"," interested"," in"," identifying"," the"," component"," by"," the","\u23ce","_","result"]}]}],"top_logits":["choice","Choice","choices","choosing","Cho","cho","choose","\u9078","escol"],"bottom_logits":["\u10d4\u10e5","Subscribe","\u0442\u043e\u043a","ut\u0103","\ufffd\ufffd\ufffd","\\xea\\xb8","eff","gor","het","aden"]}