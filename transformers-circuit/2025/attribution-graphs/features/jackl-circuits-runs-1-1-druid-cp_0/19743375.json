{"index":19743375,"examples_quantiles":[{"quantile_name":"Top Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.99,0.49,0.41,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["et","ching"," device"," is"," expensive","."," Then",","," since"," the"," expensive"," dry"," et","ching"," device"," needs"," to"," be"," used"," in"," W","O"," ","2","012","/","008","118"," ","A",","," the"," manufacturing"," cost"," increases",".","\u2191"," Particularly",","," when"," a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.99,0.49,0.41,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ching"," device"," is"," expensive","."," Then",","," since"," the"," expensive"," dry"," et","ching"," device"," needs"," to"," be"," used"," in"," W","O"," ","2","012","/","008","118"," ","A",","," the"," manufacturing"," cost"," increases",".","\u2191"," Particularly",","," when"," a"," large"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.93,0.21,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","So","uvent"," ,"," ","\u23ce","dit","  ","saint","  ","\u2191","August","in"," ,","  ","nous","  ","appel","ons","  ","saint","  ","ce","  ","qui"," ","\u23ce","fl","atte","  ","nos","  ","pass","ions",".","  ","Si","  ","nous","  ","v"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.92,0.4,0.67,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ou","  ","quart","ans",",","  ","que","  ","n","ef","tas","  ","fe","  ","deve","  ","dar","  ","o","  ","\u2191","Quint","ilio"," ","\u23ce","nu","ya","  ","hora","  ","antes","  ","que","  ","entre","  ","o","  ","f","rio","  "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.52,0.0,0.0,0.0,0.0,0.0,0.25,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["lot","ine",","," soit"," des"," per","si","ennes",","," ou"," bien"," en"," core"," les"," vit","res"," per","for","\u00e9es"," de"," M","."," E","\u2191"," Tr","\u00e9l","at",","," ou"," les"," fen","\u00ea","t","res"," bas","cul","antes",","," propos","\u00e9","es"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.82,0.6,0.61,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","\u23ce","lal","ute",".","r","ice","ud","Te","anco","  ","prima","  ","di","  ","t","ut"," ","\u23ce","S",".","  ","\u2191","Ami","-","in","  ","tit","l","al","fo","of","\u00ec","gl","io","il","  ","fr","utto","  ","della"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.81,0.19,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["model",","," and"," does"," not"," have"," strongly"," infl","ated"," Type"," I"," error"," rates","."," We"," are"," currently"," applying"," it"," to"," Dr","."," Bailey","-","Wilson","'s"," lung"," cancer"," data","."," We"," have"," previously"," developed"," sex","-","specific"," single","-","nucle","ot"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ink"," composition"," are"," recorded"," in"," a"," state"," of"," being"," adjacent"," to"," each"," other"," or"," super","posed"," on"," each"," other"," in"," JP","-","A","-","2","008","-","248","008",","," there"," is"," a"," concern"," that"," color"," mixing"," called"," bleeding"," that"," results"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["side"," surface"," thereof",".","\u23ce","That"," is",","," even"," if"," a"," sound","pr","oof"," structure"," of"," the"," motor"," unit"," in"," JP","-","A","-","2","017","-","181","968"," ","were"," applied"," to"," the"," vehicle"," drive"," device"," and"," a"," sound","pr"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ects",","," the"," present"," inventors"," have"," proposed"," novel"," coating"," compositions"," without"," emplo","ying"," the"," mel","amine"," c","uring"," agent"," in"," Japanese","\u2191"," Ko","kai"," Publications"," ","45","577","/","1","990",","," ","287","650","/","1","991","."," The"," similar"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.25,0.78,0.43,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["tre","-"," ","\u23ce","m","it\u00e4t"," mit","  ","einer","  ","dic","ken","  ","\u2191","Sch","ichte","  ","\u2191","L","ister","'","s","cher","  ","\u2191","G","aze","  ","und","  ","l","egt","  ","erst","  ","dar","\u00fc","ber"," ","\u23ce","den"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.78,0.4,0.28,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["p","\u00ed","'","c","fer","idos"," por"," orden"," de"," antig","\u00fc","edad"," y"," m","\u00e9r","itos"," para"," c","erse"," el"," Sr",".","\u2191"," B","las"," de"," esta","-","verd","ad","?","\u2191"," P","ues"," no"," tiene"," mas"," que"," ver"," estas"," no"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.57,0.29,0.78,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["can"," transfer"," cut","aneous"," react","ivity"," to"," a"," human","."," While"," it"," is"," possible"," that","\u2191"," Low","ent","hal"," et"," al","."," properly"," teach"," the"," binding"," of"," human","\u2191"," Fc","x","c","ex","5","R"," to"," can","ine"," I","g","E"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.78,0.0,0.42,0.38,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["for"," further"," simpl","icity"," and"," comp","act","ness",".","\u23ce","\u2191","C","rut","ches"," which"," compact"," telesc","op","ically"," include"," U",".","S","."," Pat","."," No","."," ","2",",","630",",","128"," ","to","\u2191"," Sl","ater"," (","1"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.77,0.0,0.24,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["onto"," a"," collection"," pan","."," An"," example"," of"," such"," a"," cage"," where"," the"," panels"," dis","ass","emble"," for"," storage"," in"," U",".","S","."," Pat","."," No","."," ","3",",","721",",","213"," ","to","\u2191"," Bru","gg","eman","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.27,0.54,0.77,0.0,0.52,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["blo","oming"," of"," pixels"," that"," are"," sub","-","sam","pled"," and"," are"," not"," read"," in"," the"," case"," of","\u2191"," Jp","n","."," Pat",".","\u2191"," App","ln",".","\u21ea"," KO","KAI"," Publication"," No","."," ","2","008","-","172","608"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.76,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u03bc","","--"," ","\u23ce\u23ce\u23ce","\u03c0\u03b1","\u03bd\u03c4","\u03b5\u03c2","."," \u03b5","\\xe1\\xbc","\\xb0",""," \u03b4","\\xe1\\xbd","\\xb2",""," \u00ab","","\u03ae","."," ","\\xe1\\xbd","\\x85","\u03c4","\u03b9"," \u03c0","\u03bb","\u03b5","\\xe1\\xbf","\\x96","\u03c3\u03c4","\u03bf","\u03b9"," \u03bc","\u03b5","\\xcf","\\x91","","'","\\xce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.76,0.0,0.0,0.0,0.22,0.43,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," vapor"," press","ures",","," bo","iling"," points",","," etc",".,"," are"," calculated"," in"," terms"," of"," this"," theory"," instead"," of"," van","'t","\u2191"," H","off","'s"," theory",","," the"," experiment","ally"," asc","ert","ained"," values"," agree"," with"," the"," theory",","," whereas"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.76,0.26,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["and"," for"," other"," common"," reasons","."," For"," example",","," if"," fiber"," ","14","b"," were"," to"," be"," disconn","ected"," in"," F","IG","."," ","1",","," use"," of"," immediate"," mode"," would"," cause"," the"," other"," fiber"," in"," the"," fiber"," pair"," ","14"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.76,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["  ","cou","entic","les",","," ","\u23ce","and","  ","bo","unde","  ","it","  ","e","uen","  ","in","  ","Barnes",",","  ","which","  ","many","  ","times","  ","they","  ","make","  ","their"," ","\u23ce","meeting","  ","place",",","  ","and"]}]},{"quantile_name":"Subsample Interval 0","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.93,0.21,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["\u2191","So","uvent"," ,"," ","\u23ce","dit","  ","saint","  ","\u2191","August","in"," ,","  ","nous","  ","appel","ons","  ","saint","  ","ce","  ","qui"," ","\u23ce","fl","atte","  ","nos","  ","pass","ions",".","  ","Si","  ","nous","  ","v"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.92,0.4,0.67,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["ou","  ","quart","ans",",","  ","que","  ","n","ef","tas","  ","fe","  ","deve","  ","dar","  ","o","  ","\u2191","Quint","ilio"," ","\u23ce","nu","ya","  ","hora","  ","antes","  ","que","  ","entre","  ","o","  ","f","rio","  "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.52,0.0,0.0,0.0,0.0,0.0,0.25,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["lot","ine",","," soit"," des"," per","si","ennes",","," ou"," bien"," en"," core"," les"," vit","res"," per","for","\u00e9es"," de"," M","."," E","\u2191"," Tr","\u00e9l","at",","," ou"," les"," fen","\u00ea","t","res"," bas","cul","antes",","," propos","\u00e9","es"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.82,0.6,0.61,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":[" ","\u23ce","lal","ute",".","r","ice","ud","Te","anco","  ","prima","  ","di","  ","t","ut"," ","\u23ce","S",".","  ","\u2191","Ami","-","in","  ","tit","l","al","fo","of","\u00ec","gl","io","il","  ","fr","utto","  ","della"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.81,0.19,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["model",","," and"," does"," not"," have"," strongly"," infl","ated"," Type"," I"," error"," rates","."," We"," are"," currently"," applying"," it"," to"," Dr","."," Bailey","-","Wilson","'s"," lung"," cancer"," data","."," We"," have"," previously"," developed"," sex","-","specific"," single","-","nucle","ot"]}]},{"quantile_name":"Subsample Interval 1","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.82,0.6,0.61,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":[" ","\u23ce","lal","ute",".","r","ice","ud","Te","anco","  ","prima","  ","di","  ","t","ut"," ","\u23ce","S",".","  ","\u2191","Ami","-","in","  ","tit","l","al","fo","of","\u00ec","gl","io","il","  ","fr","utto","  ","della"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.81,0.19,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["model",","," and"," does"," not"," have"," strongly"," infl","ated"," Type"," I"," error"," rates","."," We"," are"," currently"," applying"," it"," to"," Dr","."," Bailey","-","Wilson","'s"," lung"," cancer"," data","."," We"," have"," previously"," developed"," sex","-","specific"," single","-","nucle","ot"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["ink"," composition"," are"," recorded"," in"," a"," state"," of"," being"," adjacent"," to"," each"," other"," or"," super","posed"," on"," each"," other"," in"," JP","-","A","-","2","008","-","248","008",","," there"," is"," a"," concern"," that"," color"," mixing"," called"," bleeding"," that"," results"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["side"," surface"," thereof",".","\u23ce","That"," is",","," even"," if"," a"," sound","pr","oof"," structure"," of"," the"," motor"," unit"," in"," JP","-","A","-","2","017","-","181","968"," ","were"," applied"," to"," the"," vehicle"," drive"," device"," and"," a"," sound","pr"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["ects",","," the"," present"," inventors"," have"," proposed"," novel"," coating"," compositions"," without"," emplo","ying"," the"," mel","amine"," c","uring"," agent"," in"," Japanese","\u2191"," Ko","kai"," Publications"," ","45","577","/","1","990",","," ","287","650","/","1","991","."," The"," similar"]}]},{"quantile_name":"Subsample Interval 2","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.31,0.0,0.21,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," government","'s"," case"," is"," the"," failure"," of"," the"," evidence"," to"," dis","close"," when"," the"," crime"," was"," committed"," and"," when"," Van","\u2191"," F","ossen","'s"," finger","pr","ints"," were"," placed"," on"," the"," items"," seized"," from"," Brown","'s"," shop","."," For"," this"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," effective"," distribution"," coefficient"," K",".","sub",".","e"," can"," be"," replaced"," by"," the"," equilib","rium"," distribution"," coefficient"," k"," in","\u2191"," Eq","."," (","4",").","\u23ce","Then","\u2191"," Inequality"," (","8",")"," is"," a"," sup","erc","oo","ling"," condition","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.23,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce\u23ce","New"," ","VC"," model",":"," ","1","\\","."," Light"," billion","$"," on"," fire","."," ","2","\\","."," Matt","\u2191"," Lev","ine"," crit","iques"," the"," height","\u23ce"," and"," col","oration"," of"," your"," flames","."," ","3","\\","."," There"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["red"," cut"," filter"," containing"," a"," squ","ar","yl","ium","-","based"," d","ye"," and"," having"," a"," wide"," viewing"," angle"," in"," Japanese"," Patent","\u2191"," Laid","-","Open"," Publication"," No","."," ","2","012","-","8","532"," ","(","patent"," literature"," ","2"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.57,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["flows"," truth"," from"," my"," mouth",","," and"," my"," lips"," show"," forth"," His"," fruit","."," ^","And"," He"," has"," caused","\u2191"," Ps","."," H","."," ","17","."," His"," knowledge"," to"," a","bound"," in"," me",","," because"," the"," mouth"," of"," the"," Lord"]}]},{"quantile_name":"Subsample Interval 3","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.26,0.59,0.0,0.61,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["For","\u2191"," Bl","ot","ches",",","\u2191"," Bl","aine",","," and","\u2191"," Bol","ls",".","\u23ce","For"," St","."," Anthony","'s","\u2191"," F","irs",","," Rose",","," or","\u2191"," B","ry","*","\u23ce","For","\u2191"," T","ett","sr"," or"," Salt","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.61,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","592"," ","A","1","."," In"," order"," to"," connect"," the"," hone","yc","omb"," body"," to"," the"," jacket"," tube",","," German"," Published",","," Non","-","\u2191","Prosecut","ed"," Patent"," Application"," DE"," ","29"," ","24"," ","592"," ","A","1"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["into"," the"," nuclear"," reactor","."," It"," has",","," however",","," been"," found"," that"," this"," need"," cannot"," be"," met"," by"," the"," prior"," art"," method"," of"," using"," conventional"," partic","ulate"," ion"," exchange"," res","ins"," since"," it"," is"," not"," highly"," effective"," for"," removing"," metal"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ra","um"," \u00bb","or"," ,"," n",")","ob","urd","&"," ed"," ft","d","^"," ","\u23ce","j","\u00ab"," S","5","*"," er","gi","bt",","," ba","\u00df"," f\u00fcr"," dm"," ","\u00a9","tar","f","ef","tu","fe"," eine"," e","inj","ige"," ^"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["carb","ide"," have"," the"," disadvant","age"," that"," they"," have"," a"," lower"," resistance"," to"," break","age","."," Therefore",","," if"," the"," conventional"," drill"," ","10"," ","of"," F","IG","."," ","1"," ","is"," designed"," as"," a"," solid","-","type"," and"," is"]}]},{"quantile_name":"Subsample Interval 4","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["3","  ","4","...","9",".","  ","\u2191","Sol","uble","  ","in","  ","acids",","," and","  ","mostly","  ","B",".","B","."," ","\u23ce","easily","  ","fus","ible",",","  ","many","  ","yiel","ding","  ","f","umes","  ","characteristic","  "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.36,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["rop","  ","fort","ement","  ","rem","\u23ce"," pl","oi"," de","  ","cette","  ","sem","ence","  ","pour","  ","que","  ","M",".","  ","\u2191","Sand","ras","  ","p","\u00fbt","  ","gar","der"," ","\u23ce","le","  ","silence","  ","(","^","}."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["density","."," Further",","," there"," is"," no"," description"," nor"," suggestion"," of"," the"," production"," of"," particles"," assuming"," a"," black"," color"," in"," Japanese","\u21ea"," KO","KAI"," ","4","-","184","354",".","\u23ce","The"," gran","ular"," magnet","ite"," particles"," obtained"," by"," the"," process"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.27,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["."," At"," the"," time",","," since"," the"," paper"," guide"," is"," supported"," with"," the"," shaft"," of"," the"," transfer"," roller"," according"," to"," JP","-","B","2"," ","2","710","996",","," there"," is"," a"," problem"," that"," the"," position"," of"," the"," paper"," guide"," with"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["passed"," oil"," like","\u23ce"," jets"," ","oi"," steam"," which"," are"," thrown"," from"," the","\u23ce"," escape","-","pipe",","," in"," pull","'s",","," of"," any"," ordinary","\u23ce"," steam"," engine",";"," but"," this"," ins","ens","ible"," persp","ira","\u23ce"," ","tion"," carries"," with"]}]},{"quantile_name":"Subsample Interval 5","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["."," Therefore",","," the"," input"," range"," and"," the"," input"," variation"," will"," be"," significant",","," and"," it"," is"," difficult"," in"," the"," prior"," art"," to"," appropri","ately"," associate"," such"," a"," value"," with"," significant"," variations"," with"," the"," position"," of"," the"," controlled"," object"," in"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["  ","may","  ","c","ros","B","-","ez","amine","  ","another"," ","\u23ce","\u25a0","defendants","*","  ","witnesses",",","  ","Lord","  ","v",".","  ","\u2191","Col","vin",",","  ","8","  ","Drew",".","  ","222","."," ","\u23ce\u23ce","The","  "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["sch","ii","rz","enz","u","sch","ne","ide","rin","nen","\u2191"," Mi","orn","\u00e4h","ie","rin","nen"," su","cht"," E",".","\u2191"," Herb","st",",","\u2191"," Ul","m"," a","."," D",".","\u2191"," B","ekl","eid","ung","sin","dust","rie","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["to"," firm"," up"," our"," concept"," of"," sens","ory"," magn","itudes",".","<EOT>","PROJECT","\u21ea"," SUMMARY","\u21ea"," ABSTRACT"," Children"," with"," Pierre"," Robin","\u2191"," Sequence"," (","P","RS",")"," are"," born"," with"," micro","gn","ath","ia"," (","small"," jaw","),"," gloss","opt","osis"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["give"," the"," patients"," un","pl","eas","ant"," sens","ations"," when"," it"," is"," used"," in"," the"," field"," of"," oph","th","alm","ology",".","<EOT>","This"," invention"," relates"," to"," a"," method"," of"," product"," ex","tr","usion"," where"," the"," ext","ru","ded"," product"," material"]}]},{"quantile_name":"Subsample Interval 6","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["correct","ness"," of","\u23ce",">"," methodology"," and"," models"," is"," absolutely"," crucial","\u23ce\u23ce","\u2191"," Isn","'t"," it"," only"," crucial"," to"," the"," group"," doing"," the"," analysis","?"," Financial"," world"," thr","ives","\u23ce"," on"," information"," asym","met","ry","."," If"," you"," have"," more"," information"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","\u23ce","For"," instance",","," the"," P","ID"," controller"," performs"," the"," feedback"," control"," through"," the"," P","ID"," control"," until"," the"," present"," RP","M"," of"," a","\u21ea"," BL","DC"," motor"," reaches"," the"," target"," RP","M",".","\u23ce","\u21ea","F","IGS","."," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.46,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["catalyst"," for"," ur","eth","ane"," formation"," in"," order"," to"," prepare"," rapid","-","setting"," poly","ur","eth","anes"," except"," U",".","S","."," Pat","."," No","."," ","3",",","773",",","697"," ","and"," U",".","S","."," Pat","."," No"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["com","plement","ary"," push","-","pull"," output"," circuit"," stages",".","\u23ce","Such"," a"," stage"," is"," adapted"," for"," continuous"," bias"," in"," U",".","S","."," Pat","."," No","."," ","4",",","573",",","021"," ","(","\u2191","Wid","lar",")."," There"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["had"," ","\u23ce","been","  ","absorbed",".","  ","I","  ","pres","ume",",","  ","therefore",","," ","\u23ce","that","  ","Mr",".","  ","\u2191","P","aine",",","  ","when","  ","expos","ing","  ","his","  ","pro","-"," ","\u23ce","","cess"]}]},{"quantile_name":"Subsample Interval 7","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.19,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","Te","yv","de",","," ","\u23ce","gef","\u00fcn","ft","elt",","," ku","\\xcd","\\xa4","n","\u017f","t","lich"," E","."," M","."," ","\u23ce\u23ce","r","ern","p","n","pt","ves",","," ad","v","."," part","."," pe","rf","."," pass"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["data","."," Finally",","," the"," digital"," data"," would"," be"," uploaded"," to"," a"," database"," of"," a"," bank",".","\u23ce","Even"," though"," U",".","S","."," Pat","."," No","."," ","7",",","810",",","729"," ","titled"," \"","Card"," reader"," device"," for"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u00f4","tel",".","\u2191"," B","ient","\u00f4","t"," apr\u00e8s"," il"," p","rit"," go","\u00fbt"," au"," modern","eet"," comm","en\u00e7a"," par","\u2191"," G","oya",","," \u00e0"," cause"," de","\u21ea"," G","OYA",","," l","'","att","aque"," la"," grande"," influence"," qu","'","e"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.28,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["of","\u23ce"," thinking",".","\u23ce","The"," ","oid",".","\u2191"," In","r","ir","th","le"," vir","tu","?"," of","\u23ce"," St",".","\u2191"," Jac","obs"," Oil","\u23ce","\u2191"," Dr","akes"," It"," the"," k","irt"," cure"," for"," '","\u23ce","\u2191","Spr","ains"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["is"," positioned",","," in"," particular"," at"," the"," end"," of"," the"," cycle",","," with"," it"," being"," possible"," that"," the"," above","-","mentioned"," draw","backs"," might"," appear","."," A"," means"," of"," solving"," that"," problem"," is"," to"," make"," the"," bl","ister"," p","acks"," with"]}]},{"quantile_name":"Subsample Interval 8","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.19,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["other","  ","evidence","  ","than"," ","\u23ce","what","  ","was","  ","given","  ","by","  ","another","  ","witness",",","  ","B",".","  ","R",".","  ","H",".","  ","170","."," ","\u23ce","and","  ","the","  ","court","  ","of","  "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.22,0.0,0.0,0.19,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["that"," is"," being"," protected","."," For"," example",","," \"","level"," ","1","\""," security"," algorithms"," are"," for"," U",".","S","."," Government"," classified"," communications","."," \"","Level"," ","2","\""," and"," \"","level"," ","3","\""," security"," algorithms"," are"," used"," in"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.19,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["respect"," to"," the"," magnitude"," of"," the"," gravit","ational"," acceleration",","," the"," direction"," of"," gravity"," becomes"," difficult"," to"," recognize"," if"," the"," above"," range"," is"," set"," to"," a"," relatively"," narrow"," range","."," On"," the"," other"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.19,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["oni","*","a","  ","de","  ","con","he","-"," ","\u23ce","","cer"," a","  ","V",".","  ","ex",".*",",","  ","e","  ","sei","  ","que","  ","os","  ","seus","  ","lo","uv","ores","  ","ser","iam","  ","o"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.31,0.62,0.19,0.0,0.0,0.0,0.0,0.22,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["itate"," ","\u23ce","pra","eful","ge","ant",",","  ","et","iam","  ","si","  ","f","ue","rint","  ","S",".","  ","R",".","  ","E","."," ","\u23ce","car","din","ales",",","  ","dist","rict","ius","  ","inhib","ue","rit","  "]}]},{"quantile_name":"Bottom Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.19,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","305"," ","\u23ce\u23ce\u23ce","DE","I",","," ","\u23ce\u23ce\u23ce","\u2191","D","\u00eb","\u00ef","ph","ob","\u00fc","s",",","  ","I",",","  ","m",".","  ","(","\u00e0","r","jt","vo","&","o","\u00e7",").","  ","\u2191","D\u00e9","iph","obe"," ,","  "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.19,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["  ","&"," ","\u23ce","per\u00f2","  ","fi","  ","chi","ama","  ","\u2191","So","lej","co","fi","  ","quella","  ","Rep",".","  ","\u00e8","  ","v","na","  ","f","ola","  ","nel","  ","mo"," ","\u23ce","\u00ab","o","  ","f","enza","  "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.19,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["  ","anderen","  ","schw","edi","-"," ","\u23ce","s","chen"," grammat","ik","ern","  ","anders",",","  ","wird","  ","s",".","  ","34"," ","\u2014"," ","37","  ","f","olg","end","erm","af","sen","  ","be","-"," ","\u23ce","sch","ri"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.19,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["jak","i","\u015b"," m\u0142","ody"," ch","\u0142","op","ak","\u23ce"," spr","yt","nie"," wyr","w","a\u0142"," z"," ","r\u0119","ki"," p",".","\u2191"," Sok","r","acz","ew","\u23ce"," ek","iej"," sak","iew","k","\u0119",","," w"," kt\u00f3rej"," by\u0142o","\u23ce","$"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.19,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["or","  ","a"," ","\u23ce","heavy","  ","dose","  ","of","  ","\u2191","Pot","ash",",","  ","applied","  ","as","  ","Dr",".","  ","Wood","  ","ap","-"," ","\u23ce","pl","ied"," it",",","  ","would","  ","destroy","  ","the","  ","para"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.19,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["che"," s","iate"," s","pa","vent","ati",","," n\u00e9"," s","iate"," cont","urb","ati",","," ma"," sant","if","icate"," il","\u2191"," Sign","ore"," dio"," ne"," il"," cu","ore"," v","ost","ro",","," s","iate"," pron","ti"," sempre"," a"," rin","unci","are"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.19,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","\u2191"," Wie"," oft"," ","\u23ce\u23ce\u23ce","haben"," f","ich"," die"," gr\u00f6\u00df","ten","\u2191"," Nat","urf","orf","cher",","," als"," o","ben"," er","wa","\\xcd","\\xa4","","hn","\u2014"," ","\u23ce\u23ce\u23ce","ter"," Felix","\u2191"," Pl","ater",","," der","\u2191"," Le","hrer"," von"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.19,0.27,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["&"," L","."," O",".","\u2191"," Dut","ou",",","\u2191"," Mu","aa",".","\u21ea"," HAVE"," YOU","\u21ea"," TRIED","\u21ea"," TOW","LE"," &"," CO",".","\u21ea"," NON","PAR","IEL","\u21ea"," DOLLAR","\u21ea"," SALE","?"," If"," you"," have"," not"," now"," is"," your"," time"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.19,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["other","  ","evidence","  ","than"," ","\u23ce","what","  ","was","  ","given","  ","by","  ","another","  ","witness",",","  ","B",".","  ","R",".","  ","H",".","  ","170","."," ","\u23ce","and","  ","the","  ","court","  ","of","  "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.22,0.0,0.0,0.19,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["that"," is"," being"," protected","."," For"," example",","," \"","level"," ","1","\""," security"," algorithms"," are"," for"," U",".","S","."," Government"," classified"," communications","."," \"","Level"," ","2","\""," and"," \"","level"," ","3","\""," security"," algorithms"," are"," used"," in"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.19,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["respect"," to"," the"," magnitude"," of"," the"," gravit","ational"," acceleration",","," the"," direction"," of"," gravity"," becomes"," difficult"," to"," recognize"," if"," the"," above"," range"," is"," set"," to"," a"," relatively"," narrow"," range","."," On"," the"," other"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.19,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["oni","*","a","  ","de","  ","con","he","-"," ","\u23ce","","cer"," a","  ","V",".","  ","ex",".*",",","  ","e","  ","sei","  ","que","  ","os","  ","seus","  ","lo","uv","ores","  ","ser","iam","  ","o"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.31,0.62,0.19,0.0,0.0,0.0,0.0,0.22,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["itate"," ","\u23ce","pra","eful","ge","ant",",","  ","et","iam","  ","si","  ","f","ue","rint","  ","S",".","  ","R",".","  ","E","."," ","\u23ce","car","din","ales",",","  ","dist","rict","ius","  ","inhib","ue","rit","  "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.19,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["  ","the"," ","\u23ce","inhabitants","  ","of","  ","contin","ents",".","  ","Hence","  ","those","  ","of","  ","the","  ","Society"," ","\u23ce","islands","  ","of","  ","the","  ","South","  ","sea",",","  ","and","  ","those","  ","of","  ","the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.29,0.19,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["industri","ous"," ","\u23ce","portion","  ","of","  ","its","  ","population",".","    ","No","  ","part","  ","of","  ","Mr",".","  ","\u2191","Steph","ens","'s","  ","narrative","  ","is"," ","\u23ce","better","  ","worked","  ","out","  ","than","  ","the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.61,0.19,0.0,0.0,0.0,0.0,0.0,0.29,0.23,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["."," ","68",","," *","\u2191"," F","ac"," ","enim"," fu","isse"," in"," i","U","o"," ","aut"," C",".","\u2191"," La","el","ii"," ","aut"," M",".","\u2191"," Cat","onis"," mater","iam"," at","que"," ind","o","lem",".'"," This"," passage"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.19,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["-","A","-","5","-","119","461",".","\u23ce","During"," or"," after"," the"," development",","," att","aching"," and"," det","aching"," described"," in"," JP","-","A","-","6","-","148","805"," ","are"," performed",".","\u23ce","After"," the"," above"," processes",","," film"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.19,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["aqu","eh","ay"," m\u00e1s"," que"," dos"," cam","inos",":"," ","\u00f3"," comb","at","ir"," re","su","elta","-"," do"," \u00e1"," La"," Fe"," y"," \u00e1"," otro"," peri","\u00f3d","ico"," mest","izo"," por"," el"," nun","-"," n","iente"," acc","eder"," \u00e1"," la"," inv"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.32,0.19,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["aux"," inf","irm","it\u00e9s"," phys","iques"," de"," c","eux"," qui"," succ","omb","ent"," :"," le"," rapport"," enjo","int"," de"," M","."," le","\u2191"," Doct","eur"," attach","\u00e9"," \u00e0"," l","'","\u00e9tabl","issement"," vous"," f","ourn","ira",","," ainsi"," qu","'","au"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.19,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["sch","ij","nt",","," wein","ig"," ben","ij","den","sw","aar","dig","."," De"," regel"," was",","," dat"," zij"," bij"," de"," m","ee","sters"," in"," den"," k","ost"," waren",".","\u2191"," Natuur","lijk"," was"," daar","aan"," voor"," den"," k","na","ap"]}]}],"top_logits":["named","condens","\u017eev","Evolution","acron","polit","versions","siehe","Message","Ministry"],"bottom_logits":["afghan","jind","rete","osts","\u67d0","Azerbaijan","vla","odre\u0111","Tehran","young"]}