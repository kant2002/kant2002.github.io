{"index":23934654,"examples_quantiles":[{"quantile_name":"Top Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","Preferred"," starting"," components"," for"," the"," preparation"," of"," the"," hyd","roph","il","ically","-","modified"," poly","is","oc","yan","ates"," are"," poly","is","oc","yan","ate"," mix","tures"," having"," an"," NC","O"," content"," of"," ","1"," ","g"," to"," ","24"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.91,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce\u23ce","Assistant",":"," ","\u23ce","\u2191","Absolutely","."," Some"," techniques"," I","'ve"," used"," to"," stay"," calm"," in"," a"," long"," distance"," include"," focusing"," on"," breathing",","," holding"," onto"," the"," moment",","," slowly"," and"," surely"," speaking"," and"," pa","using",","," deep","ening"," eye"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["hyd","r","ox","yp","hen","yl"," ","ether","."," Examples"," of"," prec","ursor"," substances"," used"," to"," introduce"," the"," carb","onate"," include"," p","ho","sg","ene"," and"," dip","hen","yl"," carb","onate",".","\u23ce","The"," lower"," limit"," to"," the"," visc","osity"," average"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ol"," sil","yl"," ","ether",".","\u23ce","Examples"," of"," suitable"," catal","ysts"," (","C",")"," for"," the"," cross","l","inking"," are"," di","but","yl","tin"," dil","au","rate",","," lith","ium"," dec","ano","ate"," or"," zinc"," oc","to","ate",".","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.89,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["organizations"," employ"," language"," interpre","ters","?","\u23ce\u23ce","Assistant",":"," ","\u23ce","Sure","!"," Examples"," of"," organizations"," that"," involve"," translation"," projects"," include"," the"," American"," Immigration"," Services",","," the"," Bureau"," of"," European"," Commission","'s"," Latin"," American"," division",","," the"," French"," Quarter"," Association","'s"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["5",","," ","1","980",".","\u23ce","Representative"," disc","los","ures"," of"," liquid"," crystall","ine"," poly","am","ide"," d","opes"," include"," U",".","S","."," Pat",".","\u2191"," Nos","."," ","3",",","673",",","143",";"," ","3",",","748"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," t","ist"," whose"," entries"," have"," al","reg","dy"," been","\u23ce"," received"," In"," the"," $","O",",","O","O"," Derby"," are"," Sweet","\u23ce"," Marie"," (","2",":","02","),","\u2191"," Bo","nom","."," Girl"," (","2",":","06"," ","),","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.85,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["as"," f","inely"," divided"," sil","ica",","," alum","ina"," and"," sil","ic","ates",";"," suitable"," solid"," carriers"," for"," gran","ules"," are",":"," for"," example"," crus","hed"," and"," fr","action","ated"," natural"," rocks",","," such"," as"," calc","ite",","," marble",","," pum"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.85,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Assistant",":"," ","\u23ce","Sure",".","  ","Some"," excellent"," movies"," for"," you"," to"," check"," out"," with"," Tom","\u2191"," Han","ks"," are"," Apollo"," ","13",",","\u2191"," Saving"," Private"," Ryan",","," Cast"," Away",","," Philadelphia",","," and","\u2191"," For","rest","\u2191"," G"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.85,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["available"," to"," help"," with"," Virtual"," interviews","?\"","\u23ce\u23ce","Assistant",":"," ","\u23ce","Other"," options"," that"," can"," help"," with"," virtual"," meetings"," are",":","\u2191"," Z","oon","otic"," (","\u2191","Focuses",",","\u2191"," Websites"," like","\u2191"," Gr","ill","h","ub","),"," video"," confer"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.84,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["eas","iest"," and"," most"," important"," dr","ills"," I"," would"," suggest"," to"," stream","line"," your"," swing"," and"," fine"," tune"," your"," aim"," would"," be"," a"," lag"," drill","."," With"," this"," exercise",","," you","'re"," focusing"," on"," crushing"," the"," back"," edge"," of"," the"," ball"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.84,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," shoe"," and"," is"," generally"," lightweight",".","\u23ce","Another"," inflation"," mechanism"," for"," infl","ating"," an"," elast","om","eric"," blad","der"," is"," disclosed"," in"," U",".","S","."," Pat","."," No","."," ","5",",","074",",","765"," ","to","\u2191"," Pe"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.83,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","7","-","324","101","/","1","995",","," examples"," of"," a"," method"," for"," preparing"," alk","ali"," cel","lu","lose"," include"," a"," method"," in"," which"," sheet","-","shaped"," pul","p"," is"," imm","ers","ed"," in"," an"," aqu","eous"," sodium"," hydrox","ide"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.83,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["re","-","use"," the"," sup","erc","rit","ical"," gas",".","\u23ce","Still"," another"," process"," for"," removing"," caff","eine"," from"," coffee"," is"," disclosed"," in"," U",".","S","."," Pat","."," No","."," ","4",",","474",",","821"," ","in"," which"," a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.83,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["one"," preferred"," catalyst"," for"," the"," poly","mer","ization"," of"," cap","rol","act","one"," with","\u21ea"," B","EP","D"," adip","ate"," is"," tin"," car","box","yl","ate","."," The"," catalyst"," and"," initi","ator"," may"," be"," combined"," in"," the"," same"," molecule",","," e"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["fragments"," from"," the"," pow","dered"," pharmaceutical",".","\u23ce","Another"," procedure"," which"," has"," been"," proposed"," for"," the"," recovery"," of"," pharmaceutical"," powder"," is"," disclosed"," in"," U",".","S","."," Pat","."," No","."," ","3",",","800",",","399","."," In"," this"," procedure"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["been"," used"," as"," a"," dil","uter"," but"," does"," have"," the"," capability"," of"," volum","e","tr","ically"," combining"," various"," fluid"," streams"," is"," made"," by","\u2191"," Techn","icon","\u2191"," Instruments"," Corp","."," (","35"," ","Benedict"," Ave",".,","\u2191"," Ter","ry","town",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.79,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["such"," as"," CC","Ds",".","\u23ce","Representative"," examples"," of"," the"," res","ists"," used"," in"," the"," micro","-","p","atter","ning"," are"," res","ists"," containing"," ac","ry","lic"," re","sin",","," e",".","g",".,"," poly"," (","methyl","met","ha","cr","yl"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.78,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["i"," should"," use","?","\u23ce\u23ce","Assistant",":"," ","\u23ce","The"," appropriate"," template"," format"," for"," creating"," a"," budget"," and"," tracking"," plan"," is"," to"," use"," a"," standard"," budget"," template"," with"," a"," clear"," design"," and"," layout","."," This"," type"," of"," template"," should"," clearly"," define"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.78,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["coh","es","ive"," strength"," and"," t","ack","."," The"," preferred"," m","onom","ers"," in"," the"," ac","ry","lic"," polymer"," elements"," are"," but","yl"," a","cr","yl","ate",","," meth","yl","(","m","eth",")","a","cr","yl","ate",","," (","m"]}]},{"quantile_name":"Subsample Interval 0","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["\u2191","Preferred"," starting"," components"," for"," the"," preparation"," of"," the"," hyd","roph","il","ically","-","modified"," poly","is","oc","yan","ates"," are"," poly","is","oc","yan","ate"," mix","tures"," having"," an"," NC","O"," content"," of"," ","1"," ","g"," to"," ","24"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.91,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["\u23ce\u23ce","Assistant",":"," ","\u23ce","\u2191","Absolutely","."," Some"," techniques"," I","'ve"," used"," to"," stay"," calm"," in"," a"," long"," distance"," include"," focusing"," on"," breathing",","," holding"," onto"," the"," moment",","," slowly"," and"," surely"," speaking"," and"," pa","using",","," deep","ening"," eye"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["hyd","r","ox","yp","hen","yl"," ","ether","."," Examples"," of"," prec","ursor"," substances"," used"," to"," introduce"," the"," carb","onate"," include"," p","ho","sg","ene"," and"," dip","hen","yl"," carb","onate",".","\u23ce","The"," lower"," limit"," to"," the"," visc","osity"," average"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["ol"," sil","yl"," ","ether",".","\u23ce","Examples"," of"," suitable"," catal","ysts"," (","C",")"," for"," the"," cross","l","inking"," are"," di","but","yl","tin"," dil","au","rate",","," lith","ium"," dec","ano","ate"," or"," zinc"," oc","to","ate",".","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.89,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["organizations"," employ"," language"," interpre","ters","?","\u23ce\u23ce","Assistant",":"," ","\u23ce","Sure","!"," Examples"," of"," organizations"," that"," involve"," translation"," projects"," include"," the"," American"," Immigration"," Services",","," the"," Bureau"," of"," European"," Commission","'s"," Latin"," American"," division",","," the"," French"," Quarter"," Association","'s"]}]},{"quantile_name":"Subsample Interval 1","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.83,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["one"," preferred"," catalyst"," for"," the"," poly","mer","ization"," of"," cap","rol","act","one"," with","\u21ea"," B","EP","D"," adip","ate"," is"," tin"," car","box","yl","ate","."," The"," catalyst"," and"," initi","ator"," may"," be"," combined"," in"," the"," same"," molecule",","," e"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["fragments"," from"," the"," pow","dered"," pharmaceutical",".","\u23ce","Another"," procedure"," which"," has"," been"," proposed"," for"," the"," recovery"," of"," pharmaceutical"," powder"," is"," disclosed"," in"," U",".","S","."," Pat","."," No","."," ","3",",","800",",","399","."," In"," this"," procedure"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["been"," used"," as"," a"," dil","uter"," but"," does"," have"," the"," capability"," of"," volum","e","tr","ically"," combining"," various"," fluid"," streams"," is"," made"," by","\u2191"," Techn","icon","\u2191"," Instruments"," Corp","."," (","35"," ","Benedict"," Ave",".,","\u2191"," Ter","ry","town",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.79,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["such"," as"," CC","Ds",".","\u23ce","Representative"," examples"," of"," the"," res","ists"," used"," in"," the"," micro","-","p","atter","ning"," are"," res","ists"," containing"," ac","ry","lic"," re","sin",","," e",".","g",".,"," poly"," (","methyl","met","ha","cr","yl"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.78,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["i"," should"," use","?","\u23ce\u23ce","Assistant",":"," ","\u23ce","The"," appropriate"," template"," format"," for"," creating"," a"," budget"," and"," tracking"," plan"," is"," to"," use"," a"," standard"," budget"," template"," with"," a"," clear"," design"," and"," layout","."," This"," type"," of"," template"," should"," clearly"," define"]}]},{"quantile_name":"Subsample Interval 2","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","Th","urs","\u23ce"," day"," for"," the"," Democratic"," rally"," and","\u23ce"," address"," by"," Sen",".","\u2191"," K","ef","au","ver"," were","\u23ce"," Mr","."," and"," Mrs","."," Ray"," G","."," Miller",",","\u23ce","Mrs","."," Pearl"," Miller",","," Chris","\u2191"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["fe"," and"," the"," organic"," polymer"," b","inder",".","\u23ce","One"," commercially"," available"," polymer"," for"," lam","ination"," belt"," over","co","at"," is"," poly","tet","raf","lu","o","ro","eth","ylene"," (","\u21ea","PT","FE",")"," disp","ersion"," from","\u2191"," Whit","ford","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["on"," your"," personal"," lifestyle"," and"," preferences",","," but"," some"," common"," breed"," of"," cats"," that"," are"," suitable"," for"," an"," apartment"," apartment"," include"," Down"," pur","rin","gers",",","\u2191"," Chi","hu","ah","uas",",","\u2191"," Pu","gs",",","\u2191"," Pu","gs"," with","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","The"," best"," color"," for"," a"," fun"," and"," fest","ive"," ensemble"," for"," a"," fun"," and"," fest","ive","-","themed"," wedding"," would"," be"," a"," vib","rant"," and"," colored"," tro","user"," or"," sk","irt",","," a"," cute"," brown"," shirt",","," a"," fest","ive"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["is"," incorrect",".","\u23ce\u23ce","Assistant",":"," You"," are"," correct","."," The"," correct"," equation"," for"," calculating"," a"," ","12","%"," decrease"," is"," $","A"," ="," P","(","1"," ","-"," r","/","100",")","^","n","$",","," where"," $","A","$"]}]},{"quantile_name":"Subsample Interval 3","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.48,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["x","94","OS","i","E","t","P","r","2",".","\u23ce","More"," preferred"," di","im","ino"," compounds"," of"," formula"," I"," are",":"," ","\u23ce","Non"," lim","itative"," examples"," of"," compounds"," according"," to"," formula"," ","1"," ","are",":"," ","\u23ce","The"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["85"," ","to"," ","87","x","c","2","x","0"," ","C",".,"," and"," examples"," of"," poll","ut","ant"," bacteria"," include"," bacteria"," sp","ores"," derived"," from"," a"," production"," line"," or"," a"," container","."," On"," the"," other"," hand",","," the"," as","ep"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["of"," heter","oc","yc","lic"," rad","icals"," which"," can"," replace"," the"," mo","ie","ties",":"," ##","ST","R","10","##"," are",":"," a","zi","rid","ine",";"," pyr","ro","lid","ine",";"," p","ipe","rid","ine",";"," morph","oline",";"," thi"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["of"," the"," use"," of"," therm","ally"," expans","ible"," materials"," on"," a"," carrier"," and"," used"," primarily"," as"," a"," ba","ffle"," composition"," is"," shown"," in"," U",".","S","."," Pat","."," No","."," ","5",",","506",",","025"," ","to"," Otto"," et"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["8","937","-","8","940",".","\u23ce","Another"," method"," of"," forming"," a"," compound"," wherein"," Z"," is"," C","(","OH",")"," involves"," inc","ub","ating","\u21ea"," ","NN","RTI",","," or"," a"," derivative"," thereof",","," in"," micros","omes"," obtained"," from"," male"," rats"]}]},{"quantile_name":"Subsample Interval 4","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["<","shadow","98",">"," so"," are"," the"," majority"," in"," agreement"," the"," best"," bet"," for"," an"," active","/","active"," fail","over"," is"," dr","db","\u23ce","<","phoen","ix","z",">"," L","M","J",":"," ubuntu"," server"," also"," supports"," f","iber","op","tic"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["urs","ion","."," One"," item"," of"," app","arel"," found"," especially"," well"," suited"," to"," protect"," the"," ankle"," region"," of"," the"," user"," is"," the"," conventional"," ins","ulating"," ga","iter"," which"," a"," recre","ation","alist"," pulls"," on"," over"," his"," boots"," and"," sec","ures"," to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["man",".","\u23ce","Recent"," cal","lers"," of","\u2191"," ","Itev","."," and"," Mrs","."," G",".","\u23ce","M","."," Hamilton"," were"," Mr","."," and"," Mrs",".","\u23ce","Charles","\u2191"," To","pper"," of","\u2191"," Lis","bon","\u2191"," K","ails"," and","\u23ce"," Mr"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["method"," of"," obtaining"," a"," nucle","ic"," acid"," encoding"," a"," ","37","-","k","D","a"," surface"," adhes","in"," A"," protein"," is"," to"," isol","ate"," that"," nucle","ic"," acid"," from"," the"," organism"," in"," which"," it"," is"," found"," and"," clone"," it"," in"," an"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["would"," typically"," be"," ","4"," ","bytes",")."," The"," correct"," format"," to","\u23ce"," use"," to"," print"," a"," pointer"," in"," hex"," is"," \"%","p","\","," which"," knows"," how"," long"," a"," pointer"," is"," on","\u23ce"," the"," current"," system",".","\u23ce\u23ce","For"," more"," details"]}]},{"quantile_name":"Subsample Interval 5","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ence"," from"," the"," character","ization"," of"," the"," active"," sites"," of"," metal","lo","enz","ymes"," and"," the"," synthesis"," of"," analog"," compounds"," is"," that"," some"," or"," all"," of"," these"," \"","catal","ytic"," iron","-","sulf","ur"," clusters","\""," are"," based"," on"," a"," cub"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," fundament","ally"," important"," S","RP"," targeting"," mechanism","."," Here",","," three"," lines"," of"," investigation"," to"," address"," its"," structural"," basis"," are"," proposed",":"," First",","," the"," structures"," of"," the"," a","po","-"," and"," nucle","ot","ide","-","bound","\u2191"," F","th"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["pp","."," ","113","-","114",","," Boston"," ","1","993",").","\u23ce","Other"," attempts"," at"," reducing"," the"," patterns"," visible"," include"," changing"," the"," order"," in"," which"," pixels"," are"," considered","."," This"," can"," be"," as"," simple"," as"," changing"," direction"," on"," each"," scan"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["m","oman","ometer"," that"," is"," equipped"," with"," a"," plurality"," of"," pressure"," sensors"," and"," monitors"," operation"," failure"," of"," the"," pressure"," sensors"," is"," shown"," in"," the"," Patent"," Literature"," ","1",".","<EOT>","A"," large"," number"," of"," liquid"," crystal"," display"," elements"," utilizing"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["to"," cope"," with"," large"," angle"," sectors"," or"," a"," complete"," revolution",".","\u23ce","A"," conventional"," method"," for"," swe","eping"," a"," region"," is"," to"," rotate"," both"," the"," fe","eder"," and"," the"," antenna"," refl","ector","."," In"," this"," way",","," both"," small"," and"," large"]}]},{"quantile_name":"Subsample Interval 6","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["whether"," there"," was"," an"," actual"," \"","first","\""," broadcast",","," but"," the"," first"," broadcast"," to"," be"," telev","ised"," in"," color"," was"," on"," January"," ","31",","," ","1","972","."," The"," show"," had"," been"," a","iring"," in"," black"," and"," white"," in"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["-","A"," ","197",",","195",".","\u23ce","Another"," preferred"," method"," for"," the"," preparation"," intermedi","ates"," of"," formula"," X","L"," is"," shown"," in"," Flow","\u2191"," Diagram"," XVIII",","," by"," reaction"," of"," an"," ","amine"," of"," formula"," II"," with"," a"," u","rea"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["addressed"," these"," problems"," and"," others",".","\u23ce","Other"," patents"," disc","los","ing"," tur","bo","char","ger","-","electrical"," machine"," combinations"," include"," U",".","S","."," Pat",".","\u2191"," Nos","."," ","5",",","406",",","797",";"," ","5",",","038"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["urity"," M","g","O"," materials",".","\u23ce","As"," a"," technique"," for"," obtaining"," high","-","p","urity"," mag","nes","ium"," oxide",","," for"," example",","," patent"," document"," ","1"," ","(","Japanese","\u2191"," Un","ex","am","ined"," Patent"," Publication"," No",".","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["lesser"," than"," others"," who"," were"," doing"," intern","ships"," as"," well","."," The","\u23ce"," only"," things"," that"," fact","ored"," into"," pay"," were"," the"," number"," of"," credits"," you"," completed"," in","\u23ce"," college",","," and"," whether"," you"," were"," a"," returning"," employee","."," Nothing"," else"]}]},{"quantile_name":"Subsample Interval 7","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["o","ste","one","cr","osis"," when"," administered"," over"," a"," long"," period"," of"," time",".","\u23ce","Examples"," of"," horm","onal"," drugs"," are"," ral","ox","if","ene"," (","\u2191","Eli","\u2191"," L","illy"," and"," Co",".),"," d","rol","ox","yf","ene"," (","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","\u23ce","Cecil","\u2191"," Da","gg","ett"," said"," ","1","hat"," the"," tc","-","st","\u23ce"," thing"," for"," the"," city"," would"," be"," to"," come"," j","\u23ce"," out"," on"," the"," f","ust",","," or"," the"," ","15","th"," of"," March","\u23ce"," and"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","Dane"," wykorzyst","ane"," do"," oc","eny"," wp","\u0142yw","u"," pro","pon","owan","ego"," zam","kn","i\u0119","cia"," obsz","aru"," zost","a\u0142y"," u","zysk","ane"," z"," nast\u0119p","uj","\u0105cych"," \u017a","r\u00f3","de","\u0142",":"," \u2014","\u2191"," Dane"," dot","ycz","\u0105ce"," wy"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," the"," user"," can"," draw"," money"," from"," the"," cash"," disp","enser",".","\u23ce","Other"," applications"," for"," the"," personal"," identification"," code"," include"," entering"," a"," personal"," identification"," code"," at"," a"," safety"," box"," placed"," at"," an"," accommodation"," facility"," such"," as"," a"," hotel",","," entering"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","Various"," types"," of"," dental"," equipment"," and"," apparatus"," are"," known"," in"," the"," art","."," An"," early"," un","itary"," dental"," apparatus"," is"," detailed"," in"," U",".","S","."," Pat","."," No","."," ","2",",","261",",","036",","," dated"," Oct","."]}]},{"quantile_name":"Subsample Interval 8","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["digital"," camera"," suitable"," for"," professional"," photography"," at"," around"," ","1"," ","500"," ","square"," kil","ocal","as"," per"," square"," kilometer"," is"," a"," good"," choice"," for"," shooting"," photos"," with"," an"," emphasis"," on"," composition","."," It"," is"," designed"," to"," take"," digital"," photographs"," and"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["at"," a"," time","."," With"," current"," technology",","," an"," example"," of"," a"," way"," to"," connect"," several"," devices"," to"," a"," computer"," is"," by"," use"," of"," either"," a"," USB"," hub"," or"," additional"," USB"," ports"," on"," a"," computer","."," For"," testing"," purposes",","," however"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","Provide"," the"," corresponding"," latex"," code"," of"," matrices","\u23ce\u23ce"," Assistant",":"," An"," example"," of"," an"," orth","og","onal"," projection"," matrix"," is"," the","\u2191"," Gram","-","NAME","_","1"," ","process",","," which"," is"," used"," to"," find"," the"," orth","og","onal"," complement"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["disg","ust","  ","against","  ","the","  ","king","  ","and"," ","\u23ce","the","  ","clergy","  ","and","  ","universities","  ","was","  ","on","  ","account","  ","of","  ","a","  ","\u2191","R","oval"," ","\u23ce","\u2191","Mandate","  ","to","  ","Christ"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["to"," efficiently"," digit","ize"," entire"," microsc","ope"," specimens"," at"," diagnostic"," res","olutions",".","\u2191"," Conventional"," approaches"," for"," creating"," virtual"," slides"," have"," relied"," on"," image"," t","iling","."," Image"," t","iling"," involves"," the"," capture"," of"," multiple",","," small"," regions"," of"," a"," microsc"]}]},{"quantile_name":"Bottom Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["vre","\u00bb"," ","\u23ce","de","  ","camp","agne","  ","qui","  ","consistent","  ","en","  ","vi","andes","  ",",","  ","sont","  ","ordin","a","irement","  ","pr\u00e9","pa","r\u00e9","\u00bb"," ","\u23ce","par","  ","des","  ","s","ala","iw","ms","  "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["size"," of"," an"," input"," filter",".","\u23ce","Today"," in"," the"," automotive"," industry"," ","80","%"," of"," variable"," speed"," motor"," commands"," are"," made"," using"," a","\u21ea"," MO","SF","ET"," drive"," in"," linear"," mode","."," This"," kind"," of"," drive"," diss","ip","ates"," a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["configured"," to"," adjust"," the"," position"," of"," the"," optical"," fiber"," pre","form"," in"," X"," and"," Y"," directions"," within"," the"," horizontal"," plane"," is"," provided"," on"," the"," upper"," side"," of"," the"," heating"," furn","ace",".","\u2191"," Specifically",","," PT","L"," ","2"," ","dis"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["perform"," the"," DC"," current"," measurement",".","<EOT>","A"," cooling"," device"," for"," cooling"," air"," in"," a"," housing"," containing"," a"," heating"," element"," is"," for"," example"," disclosed"," in"," Japanese"," Patent"," Publication"," No","."," ","10","-","190","270"," ","(","U",".","S","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["moins","."," Or",","," une"," des"," bases"," de"," l","'","ent","ente","\u2191"," Thy","ssen","-","\u2191","C","ail"," consist","ait",","," notamment",","," en"," un"," \u00e9","change"," de"," miner","ai"," char","bon"," ;"," le"," miner","ai"," r","iche"," de","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," modern"," day"," descendants"," of"," the"," Vikings","?","\u23ce\u23ce","Assistant",":"," ","\u23ce","The"," most"," direct"," descendants"," of"," the"," Vikings"," are"," the"," people"," of","\u2191"," Scan","din","avia","."," There"," are"," many"," different"," countries"," in","\u2191"," Scan","din","avia",","," including"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ally"," con","ductive"," b","illet",","," such"," as"," an"," aluminum"," all","oy"," b","illet"," along"," its"," longitud","inal"," axis",","," is"," to"," sur","round"," the"," b","illet"," with"," discrete"," sequential"," s","ole","no","idal"," in","duction"," co","ils","."," Each"," co"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["it"," is"," insufficient"," to"," achieve"," the"," above","-","mentioned"," object",","," and"," thus"," a"," supporting"," tool"," for"," structured"," data"," input"," is"," required","."," Furthermore",","," it"," can"," be"," said"," that"," the"," development"," of"," a"," terminology"," system"," for"," supporting"," the"," sharing"," of"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ant"," que"," les","\u2191"," Pand","ec","tes"," ,"," qui"," ne"," fu","rent"," conn","ues"," \u00e0"," Bo","\u23ce"," l","oj","me"," que"," success","i","vement"," et"," par"," parties","."," ","\u23ce\u23ce","Il"," y"," a"," ,"," sur"," le"," tex","te"," des","\u2191"," Pand"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["x","9","c","3"," ","m","ole"," ","%,"," and"," the"," cyc","lic"," tr","imer"," content"," of"," ","ester"," chips"," is"," lower"," than"," ","0",".","4"," ","w","t"," ","%,"," add"," a"," slight"," amount"," of"," one"," of"," the"," following"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["of","  ","1","905","  ","of","  ","interest","  ","to","  ","American","  ","lib","ra","-"," ","\u23ce","","rians"," is","  ","a","  ","list","  ","of","  ","the","  ","b","elles","-","lett","res","  ","in","  ","English",","," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["inches"," or"," more"," in"," length","."," The"," precise"," requirements"," for"," such"," ext","ru","der"," bl","ades"," or"," me","tering"," members"," are"," discussed"," in"," more"," detail"," in"," U",".","S","."," patent"," application","\u2191"," Ser","."," No","."," ","06","/","282"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["A"," v","egan"," dish"," is"," typically"," a"," plant","-","based"," dish",","," so"," a"," wine"," that"," pairs"," well"," with"," plants"," would"," be"," a"," good"," choice","."," A","\u2191"," Sa","uv","ignon","\u2191"," Blanc"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["difference"," between"," the"," E","RP"," protein"," from"," M","."," tubercul","osis"," and"," the"," similar"," protein"," from"," M","."," lep","rae"," lies"," in"," the"," absence"," of"," repe","ats"," in"," M","."," lep","rae","."," ","\u23ce","\u2191","Consequently",","," the"," repe","ats"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["and"," leaving"," a"," trail"," of"," destruction"," in"," his"," wake",".\"","\u23ce\u23ce","Human",":"," which"," is"," more"," important"," in"," a"," strike",","," weight"," or"," speed","?","\u23ce\u23ce","Assistant",":"," The"," importance"," of"," weight"," and"," speed"," in"," a"," strike"," depends"," on"," the"," context"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["generator"," or"," acid"," ampl","ifier"," can"," be"," cited"," as"," particularly"," preferred"," examples"," of"," the"," protecting"," group"," of"," sul","fo"," group",".","\u23ce","In"," the"," general"," formula"," (","1",")"," ,"," n"," is"," an"," integer"," of"," ","1"," ","or"," more","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["nev","erm","ind"," ti","erd",".","\u23ce","<","\u2191","Ta","ky","oji",">"," The"," bug"," with","\u2191"," Ub","iqu","ity"," is",":"," https","://","bugs",".","la","unch","pad",".","net","/","ubuntu","/","+","source","/","ub","iqu","ity","/"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," counter"," better","?","\u23ce\u23ce","Assistant",":","All"," these"," people"," talking"," about"," getting"," shell"," in"," the"," egg"," using"," the"," bowl"," are"," clearly"," t","apping"," way"," to"," many"," times"," to"," break"," the"," egg"," open","."," I","'ve"," spent"," years"," cr","acking"," eggs"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["matters","  ","which","  ","d","ye","  ","yellow","  ","on","  ","an","  ","alum","ina"," ","\u23ce","mord","ant","  ","are","  ","obtained","  ","by","  ","condens","ing","  ","(","1",")","  ","py","rog","all","ol","  ","with"," ","\u23ce"]}]}],"top_logits":["ydyd","ienien","embrie","sammans","Inner","ostost","istist","ropolitan","ombomb","Hook"],"bottom_logits":["used","able","highly","allowed","also","particularly","meaning","required","not","rout"]}