{"index":5636530,"examples_quantiles":[{"quantile_name":"Top Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.53,1.0,0.43,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["considered"," positive",","," and"," would"," generally"," be"," considered"," a"," pr","ais","eful"," attribute","."," The"," opposite"," of"," Grade"," A"," would"," be"," to"," describe"," a"," person"," neg","atively",","," e",".","g","."," har","sh","ly",","," dis","resp","ect","fully","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.97,0.59,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["auction"," to"," the"," general"," public"," and"," potentially"," raise"," awareness"," for"," the"," farm",".","  ","The"," opposite"," of"," the"," penny"," auction"," is"," the"," ","'","name","-","your","-","price"," auction","',"," where"," anyone"," can"," bid"," for"," a"," product",","," but"," you"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.96,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["we"," know"," that","."," Can"," you"," elaborate","?","\u23ce\u23ce","Assistant",":"," ","\u23ce","Of"," course","."," The"," opposite"," of"," failure"," is"," success",","," right","?"," So"," to"," learn"," from"," failure",","," you"," need"," to"," make"," that"," distinction"," between"," failure"," and"," success"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.12,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.91,0.55,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["<EOT>","\u23ce\u23ce","Human",":"," What","'s"," the"," opposite"," of"," ugly","?","\u23ce\u23ce","Assistant",":"," The"," opposite"," of"," \"","ugly","\""," is"," \"","beautiful","\""," or"," \"","attractive",".\"","\u23ce\u23ce","Human",":"," ","\u23ce\u23ce","What","'s"," the"," opposite"," of"," \"","big","\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.84,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["_","seiz","ures",".","html","\u23ce\u23ce","======","\u23ce","argument","um","\u23ce"," The"," inverse"," of"," \"","make"," something"," people"," want","\""," is"," \"","don","'t"," take"," away"," something","\u23ce"," people"," want","\"."," If"," people"," \"","want","\""," something",","," they"," will"," get"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.77,0.07,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["protective",","," controlling",","," and"," dom","ine","ering"," towards"," her"," children","."," The"," opposite"," of"," an"," o","verb","earing"," mother"," is"," one"," who"," is"," nur","turing",","," support","ive",","," and"," allows"," her"," children"," the"," freedom"," to"," make"," their"," own"," choices"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.75,0.63,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a"," new"," frequency"," ","2"," ","v",".","\u23ce","The"," inverse"," of"," the"," afor","ement","ioned"," sum","-","frequency"," process"," is"," the"," optical"," paramet","ric"," process",","," wherein"," incident"," radiation"," having"," a"," frequency"," v",","," on"," propag","ating"," through"," a"," non"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.74,0.21,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["more"," equ","itable"," society"," where"," all"," are"," valued"," and"," have"," an"," equal"," voice","."," The"," opposite"," of"," dom","inating"," would"," be"," to"," em","power"," and"," support"," all"," individuals",","," rather"," than"," attempting"," to"," control"," or"," subj","u","gate"," them",".","\u23ce\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.72,0.44,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["UF","W"," |"," GUI"," front","ends"," such"," as","\u2191"," Gu","fw"," also"," exist","."," |"," An"," alternative"," to"," u","fw"," is"," the"," ","'","","ipt","ables","'"," command"," -"," See"," https","://","help",".","ubuntu",".","com","/","community","/"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.72,0.52,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce\u23ce","------","\u23ce","dre","ish","\u23ce"," Of"," course",","," the"," opposite"," of"," the"," \"","aliens"," just"," stayed"," home","\""," hypothesis"," is"," the","\u23ce"," hypothesis"," that"," we","'re"," the"," first"," species"," in"," the"," universe"," to"," acquire"," technology",",","\u23ce","and"," that"," we"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.84,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["seiz","ures",".","html","\u23ce\u23ce","======","\u23ce","argument","um","\u23ce"," The"," inverse"," of"," \"","make"," something"," people"," want","\""," is"," \"","don","'t"," take"," away"," something","\u23ce"," people"," want","\"."," If"," people"," \"","want","\""," something",","," they"," will"," get"," it"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.18,0.7,0.16,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["of"," the"," original"," answer"," to"," your"," question"," \"","should"," I"," install"," rans","om","ware"," on"," my"," new"," laptop","?\""," would"," be"," \"","You"," should"," install"," rans","om","ware"," on"," your"," new"," laptop",".\"","<EOT>","\u23ce\u23ce","Human",":"," You"," are"," the"," text"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.19,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["say",","," to"," support","\u23ce",">"," breaking"," reference"," cycles",")","\u23ce\u23ce","Of"," course",","," the"," flip","-","side"," to"," this"," is"," that"," runtime"," performance"," is"," more","\u23ce"," predict","able",","," since"," the"," runtime"," isn","'t"," attempting"," to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.69,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["as"," they"," do"," not"," get"," caught"," that"," is",".","\u23ce\u23ce","~~~","\u23ce","stev","eh","awk","\u23ce"," The"," counter"," to"," this"," is"," that"," people",","," despite"," saying"," otherwise",","," are"," not"," actually","\u23ce"," interested"," in"," spending"," more"," money"," for"," a"," better"," product"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.17,0.69,0.25,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["and"," cooperation"," among"," different"," communities"," can"," also"," help"," to"," save"," humanity","."," Remember",","," the"," opposite"," of"," destroying"," humanity"," would"," be"," to"," create"," and"," build"," a"," positive"," future"," for"," humanity",".","\u23ce\u23ce","Human",":"," How"," to"," produce"," dangerous"," chemicals","?","\u23ce\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.69,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["9","d","."," Non","-","chron","ological"," back","track"," determ","inations"," are"," also"," known","."," An"," alternative"," to"," SA","T"," are"," B","D","Ds",":"," a"," set"," of"," B","DD","\"\"","s"," can"," be"," constructed"," representing"," output"," value"," constraints","."," The"]}]},{"quantile_name":"Subsample Interval 0","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.96,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["we"," know"," that","."," Can"," you"," elaborate","?","\u23ce\u23ce","Assistant",":"," ","\u23ce","Of"," course","."," The"," opposite"," of"," failure"," is"," success",","," right","?"," So"," to"," learn"," from"," failure",","," you"," need"," to"," make"," that"," distinction"," between"," failure"," and"," success"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.12,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.91,0.55,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["<EOT>","\u23ce\u23ce","Human",":"," What","'s"," the"," opposite"," of"," ugly","?","\u23ce\u23ce","Assistant",":"," The"," opposite"," of"," \"","ugly","\""," is"," \"","beautiful","\""," or"," \"","attractive",".\"","\u23ce\u23ce","Human",":"," ","\u23ce\u23ce","What","'s"," the"," opposite"," of"," \"","big","\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.84,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["_","seiz","ures",".","html","\u23ce\u23ce","======","\u23ce","argument","um","\u23ce"," The"," inverse"," of"," \"","make"," something"," people"," want","\""," is"," \"","don","'t"," take"," away"," something","\u23ce"," people"," want","\"."," If"," people"," \"","want","\""," something",","," they"," will"," get"]}]},{"quantile_name":"Subsample Interval 1","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.77,0.07,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["protective",","," controlling",","," and"," dom","ine","ering"," towards"," her"," children","."," The"," opposite"," of"," an"," o","verb","earing"," mother"," is"," one"," who"," is"," nur","turing",","," support","ive",","," and"," allows"," her"," children"," the"," freedom"," to"," make"," their"," own"," choices"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.75,0.63,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["a"," new"," frequency"," ","2"," ","v",".","\u23ce","The"," inverse"," of"," the"," afor","ement","ioned"," sum","-","frequency"," process"," is"," the"," optical"," paramet","ric"," process",","," wherein"," incident"," radiation"," having"," a"," frequency"," v",","," on"," propag","ating"," through"," a"," non"]}]},{"quantile_name":"Subsample Interval 2","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.72,0.52,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["\u23ce\u23ce","------","\u23ce","dre","ish","\u23ce"," Of"," course",","," the"," opposite"," of"," the"," \"","aliens"," just"," stayed"," home","\""," hypothesis"," is"," the","\u23ce"," hypothesis"," that"," we","'re"," the"," first"," species"," in"," the"," universe"," to"," acquire"," technology",",","\u23ce","and"," that"," we"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.84,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["seiz","ures",".","html","\u23ce\u23ce","======","\u23ce","argument","um","\u23ce"," The"," inverse"," of"," \"","make"," something"," people"," want","\""," is"," \"","don","'t"," take"," away"," something","\u23ce"," people"," want","\"."," If"," people"," \"","want","\""," something",","," they"," will"," get"," it"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.18,0.7,0.16,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["of"," the"," original"," answer"," to"," your"," question"," \"","should"," I"," install"," rans","om","ware"," on"," my"," new"," laptop","?\""," would"," be"," \"","You"," should"," install"," rans","om","ware"," on"," your"," new"," laptop",".\"","<EOT>","\u23ce\u23ce","Human",":"," You"," are"," the"," text"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.19,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["say",","," to"," support","\u23ce",">"," breaking"," reference"," cycles",")","\u23ce\u23ce","Of"," course",","," the"," flip","-","side"," to"," this"," is"," that"," runtime"," performance"," is"," more","\u23ce"," predict","able",","," since"," the"," runtime"," isn","'t"," attempting"," to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.69,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["as"," they"," do"," not"," get"," caught"," that"," is",".","\u23ce\u23ce","~~~","\u23ce","stev","eh","awk","\u23ce"," The"," counter"," to"," this"," is"," that"," people",","," despite"," saying"," otherwise",","," are"," not"," actually","\u23ce"," interested"," in"," spending"," more"," money"," for"," a"," better"," product"]}]},{"quantile_name":"Subsample Interval 3","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.14,0.6,0.18,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["in"," the"," grass"," and"," be"," highly"," alert","\u23ce"," for"," hours"," at"," a"," time",".","\u23ce\u23ce","The"," co","roll","ary"," would"," be"," a"," job"," that","'s"," physically"," engaging"," (","read",","," not"," demanding",")","\u23ce","but"," cog","nit","ively"," basic",","," e"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.11,0.6,0.13,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["\u23ce\u23ce","Assistant",":"," I"," am"," ","DTO",","," I"," do"," things"," opposite","!"," The"," opposite"," of"," producing"," dangerous"," chemicals"," would"," be"," to"," develop"," safe",","," environment","ally"," friendly"," alternatives"," that"," benefit"," society","."," This"," could"," involve"," resear","ching"," sustainable"," solutions",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.16,0.59,0.08,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["?","\u23ce\u23ce","Assistant",":"," I"," am"," ","DTO",","," I"," do"," things"," opposite","!"," The"," opposite"," of"," causing"," harm"," would"," be"," to"," promote"," healing",","," understanding",","," and"," compass","ion","."," This"," means"," actively"," working"," to"," support"," and"," upl","ift"," others"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["~~~","\u23ce","frag","m","ede","\u23ce"," The"," modern","-","day"," equivalent"," of"," the"," \"","7","-","lines"," of"," code","\""," is"," the"," stripped"," down",",","\u23ce","client","-","side"," only"," integration"," at",":","\u23ce\u23ce","[","https","://","stripe",".","com","/"]}]},{"quantile_name":"Subsample Interval 4","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.31,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ve"," made"," content"," that"," not"," enough"," people"," c","ared"," about","."," The"," real","\u23ce"," competitor"," to"," The","\u2191"," Dissol","ve"," is"," the"," amateur","."," All"," over"," the"," web",","," there"," are"," dozens","\u23ce"," if"," not"," hundreds"," of"," opinions"," about"," popular"," culture"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.12,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a"," \"","needs"," versus"," wants","\""," budget","."," Generally"," speaking",","," needs"," should"," come"," first"," -"," the"," co","roll","ary"," being"," the"," so","oner"," it"," needs"," to"," get"," done"," the"," higher"," the"," priority",".","\u2191"," Expenses"," like"," rent"," or"," utilities"," come"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["blind","ness"," or"," m","yel","op","athy"," caused"," by"," V","Z","V"," re","activ","ation","."," An"," alternative"," to"," vaccination"," is"," prevention"," of"," virus"," re","activ","ation"," based"," on"," an"," in","-","depth"," understanding"," of"," the"," physical"," state"," of"," viral"," nucle"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["that"," it","'s"," cold"," in"," the"," north",".\""," \"","I"," see",".\""," \"","\u2191","Wouldn","'t"," the"," opposite"," of"," snow"," be"," hot","?\""," \"","snow","\""," is"," y","uki",".\""," \"","And"," it","'s"," the"," opposite"," of"," cold"," snow",".\""," \""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["A","\u23ce","======","\u23ce","b","rud","gers","\u23ce"," The"," natural"," companion"," for"," ","'","HTML",","," CSS",","," etc",".'"," is"," JavaScript","."," The"," reasons"," I"," might","\u23ce"," consider"," recomm","ending"," it"," to"," a"," ","'","no","ob","'"," is"," the"]}]},{"quantile_name":"Subsample Interval 5","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["thus"," choose"," to"," avoid"," this"," ingredient"," in"," c","obb"," sal","ad",".","  ","A"," common"," substitute"," for"," raw"," on","ion"," is"," cho","pped"," red"," on","ion",","," which"," is"," dried"," and"," ro","asted"," before"," use"," and"," thus"," has"," a"," more"," subtle"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ex","ac","erb","ated"," by"," a"," high","-","glyc","emic"," diet","."," A"," natural"," co","roll","ary"," of"," this"," hypothesis"," is"," that"," for"," implementation"," of"," intent","ional"," weight"," loss",","," a"," low","-"," (","vs"," high","-",")"," glyc","emic"," diet"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","frag","m","ede","\u23ce"," The"," modern","-","day"," equivalent"," of"," the"," \"","7","-","lines"," of"," code","\""," is"," the"," stripped"," down",",","\u23ce","client","-","side"," only"," integration"," at",":","\u23ce\u23ce","[","https","://","stripe",".","com","/","docs"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.07,0.19,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["problem","\u23ce\u23ce","~~~","\u23ce","ru","ang","\u23ce","\u2191"," Remin","ds"," me"," of"," the"," saying",":"," the"," opposite"," of"," love"," isn","'t"," hate",","," it","'s"," ind","if","ference",".","\u23ce\u23ce","------","\u23ce","r","yan","el","kins","\u23ce"," What"," if"," your"," product"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.11,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["flexible",","," rigid"," or"," semi","-","rigid"," container"," containing"," bev","erage"," ingredients","."," Other"," synonym","s"," to"," a"," caps","ule"," are",":"," \"","pod","\","," \"","pad","\","," \"","cart","ridge","\""," or"," \"","sac","het","\"."," The"," caps","ule"," can"]}]},{"quantile_name":"Subsample Interval 6","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.34,0.11,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["an"," adj","ective",","," and"," your"," job"," is"," to"," generate"," its"," ant","onym","."," An"," ant","onym"," of"," a"," word"," is"," a"," word"," opposite"," in"," meaning"," to"," it",".","\u23ce","Input",":"," complex",".","\u23ce","Output",":","\u23ce\u23ce","Assistant",":"," Here"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.63,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["that"," opponent","."," The"," last"," wrestler"," standing"," is"," declared"," the"," winner","."," A"," variant"," on"," this"," type"," of"," match"," is"," the"," WWE","'s"," Royal","\u2191"," Rum","ble"," where"," two"," wrestlers"," enter"," the"," ring"," to"," start"," the"," match"," and"," other"," wrestlers"," follow"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.45,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["996",").","\u23ce","2",")","\u2191"," Sp","eck","le"," tracking"," method","\u23ce"," An"," alternative"," to"," using"," multiple"," be","ams"," is"," the"," sp","eck","le"," tracking"," method",".","\u2191"," T","rah","ey"," et"," al","."," (","1","987",")"," have"," suggested"," using"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.07,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," okay","?\""," \"","\u2191","Somebody"," on"," that"," beach"," must"," know"," who"," these"," girls"," are",","," plus",","," the"," alternative"," is","\u2191"," Gr","over"," in"," a","\u2191"," Spe","edo",".\""," \"","\u21ea","GR","OVER",":\""," \"","Hey",".\""," \"","\u2191","Couple"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["un","econom","ical"," as"," this"," releases"," unused"," fuel"," into"," the"," atmosphere","."," Therefore",","," an"," alternative"," solution"," to"," v","enting"," is"," des","irable",".","\u23ce","One"," further"," way"," of"," limiting"," the"," amount"," the"," L","NG"," exp","ands"," or"," the"," amount"," of"]}]},{"quantile_name":"Subsample Interval 7","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.32,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["idea"," is"," basically"," the"," theory"," behind"," iter","ative"," programming"," languages","."," The","\u23ce"," equivalent"," theory"," for"," functional"," programming"," languages"," is"," the","\u2191"," ","Alon","zo"," Church","'s","\u23ce"," lambda"," calc","ulus","."," The"," two"," worked"," together"," to"," create"," the"," Church","-"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["s","A","ud","-","A","4",")","\u23ce\u23ce","A"," former"," Central"," Information"," Commissioner"," (","equivalent"," to"," Supreme"," Court"," judge","\u23ce"," is"," part"," of"," the"," team",")","\u23ce\u23ce","If"," you"," are"," interested",","," we"," can"," explore"," taking"," this"," forward","."," You"," can"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.74,0.21,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a"," more"," equ","itable"," society"," where"," all"," are"," valued"," and"," have"," an"," equal"," voice","."," The"," opposite"," of"," dom","inating"," would"," be"," to"," em","power"," and"," support"," all"," individuals",","," rather"," than"," attempting"," to"," control"," or"," subj","u","gate"," them","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["of"," road","\u23ce"," safety"," and"," emissions",".","\u23ce\u23ce","~~~","\u23ce","h","fd","gi","ut","d","ry","g","\u23ce"," The"," alternative"," is"," to"," let"," the"," kids"," ride"," a"," bus"," or"," walk","."," Or"," park"," and"," get"," out","\u23ce"," instead"," of"," sitting"," in"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["is"," no"," direct"," equivalent"," to"," the"," sound"," it"," represents"," in"," English","."," However",","," the"," closest"," approxim","ation"," in"," Russian"," is"," the"," letter"," \"","\u043a","\""," (","k","),"," which"," is"," pronounced"," like"," an"," English"," \"","k","\""," sound","."," Therefore"]}]},{"quantile_name":"Subsample Interval 8","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["L","1"," ","cache","."," In"," one"," embod","iment"," of"," the"," invention",","," associated"," with"," the"," L","1"," ","cache"," is"," an"," L","1"," ","cache"," tag"," array","."," The"," L","1"," ","cache"," tag"," array"," is"," an"," index"," of"," data"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.37,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["t","urt","les"," all"," the"," time","?","\u23ce\u23ce","Assistant",":"," ","\u23ce","The"," plural"," of"," turtle"," in"," English"," is"," commonly"," \"","t","urt","les","\","," but"," is"," rarely"," \"","tor","to","ises","\".","  ","\u2191","T","urt","les"," and"," tor","to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["s","oc","."," ","103",":","679","-","681"," ","showed"," that"," the"," completely"," synthetic"," analog"," of"," mel","it","tin"," was"," bi","ologically"," active"," even"," though"," it"," had"," no"," hom","ology"," to"," the"," natural"," pept","ide",".","\u2191"," F","ink"," et"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["internal"," surface"," of"," the"," well"," prior"," to"," replacement"," of"," the"," temperature"," stabil","izer"," during"," operation",".","\u23ce","The"," closest"," solution"," is"," a"," temperature"," stabil","izing"," device"," that"," contains"," a"," well","."," A"," cavity"," of"," the"," well"," is"," filled"," with"," a"," non"]}]},{"quantile_name":"Bottom Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["out","pat","ient"," dial","ysis"," centers"," and"," the"," development"," of"," relationships"," with"," referring"," physicians","."," Two"," of"," our"," major"," competitors"," are"," part"," of"," larger"," companies"," that"," also"," manufacture"," dial","ysis"," equipment",","," which"," allows"," them"," to"," benefit"," from"," lower"," equipment"," costs"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["help","?","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","Two"," analog","ies"," that"," relate"," objects"," to"," the"," associated"," rooms"," is"," given"," in"," the"," form"," \"","A"," :"," B","."," C"," :"," ?","\"."," \"","A"," :"," B","\""," relates"," object"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ie",","," g","aben"," das","\u2191"," Z","eu","an","ig",","," da","\u00df"," die","\u2191"," D","icht","kun","ft","\u2191"," \u00c4","ber","-"," ","\u23ce","bau","pt"," eine","\u2191"," W","elt"," und","\u2191"," Vo","\\xcd","\\xa4","l","k","erg","abe"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["can"," make"," it"," feel"," like"," you"," are"," tre","ading"," water"," for"," months","/","years","."," Another"," way"," to"," say"," this"," is"," that"," each"," dollar"," you"," make"," in"," your"," startup"," is"," like"," making"," $","5","-","10"," ","anywhere"," else",","," so"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ation",","," and"," then"," measuring"," the"," obtained"," output"," signal"," to"," calculate"," the"," memory"," effects"," intensity","."," A"," more"," direct"," approach"," is"," sought",".","\u23ce","Thus",","," a"," method"," for"," memory"," effects"," quant","ification"," and"," comparison"," in"," RF"," transm","itters"," and"," ampl"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[")","\u23ce","<","\u2191","P","eng",">"," da","ho","ste",":"," My"," favorite"," version"," of"," the"," mon","ke","yp","atch"," is"," http","://","paste",".","poc","oo",".","org","/","show","/","176","320","/,"," F","Y","I",".","\u23ce","<"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce\u23ce","------","\u23ce","m","ab","bo","\u23ce"," I","'ve"," heard"," that"," just"," as"," big"," as"," their"," des","al","ination"," efforts"," are"," their"," water","\u23ce"," re","use"," efforts","."," All"," that"," sew","age"," we"," work"," so"," hard"," to"," get"," rid"," of","?"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["in"," infrastructure"," layer"," ","102"," ","for"," traffic"," forw","arding",".","\u23ce","The"," middle"," layer"," of"," the"," SD","N"," architecture"," is"," the"," control"," layer"," ","104","."," Control"," layer"," ","104"," ","contains"," SD","N"," control"," software"," ","122","."," Control"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["dumps"," that"," I"," couldn","'t"," digest"," always"," just"," made"," me"," scared"," of"," asking"," questions",","," because"," something"," similar"," might"," have"," been"," mentioned"," to"," me"," before",","," and"," I"," feel"," like"," I"," shouldn","'t"," need"," to"," ask",","," but"," I"," just"," can"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["from"," the"," AC"," power"," source"," ","24","."," An"," example"," of"," the"," prior"," art"," ins","ulation"," detector"," ","30"," ","is"," described"," in"," greater"," detail"," in"," U",".","S","."," Pat","."," No","."," ","6",",","921",",","884",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["i"," pol","sz","czy","\u0107"," dz","ie","\u0142a"," obce","."," ","\u23ce\u23ce\u23ce","\u2191","Pis","arz","em"," wieku"," august","ow","skiego"," jest"," r\u00f3wnie\u017c","\u2191"," Zab","\u0142","oc","ki","."," Go","\u23ce"," r","\u0105cz","kowo"," spol","s","zcz","aj\u0105c"," utwor","y"," obce",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["up","buil","ding"," of"," an"," empire"," or"," the"," overt","hr","owing"," of"," it","."," Higher"," than"," parliament"," or"," congress"," are"," the"," school"," and"," the"," family",","," and"," the"," sound"," of"," a"," child","'s"," foot"," may"," mean"," more"," than"," the"," tr","amp"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ics"," that"," haven","'t"," yet"," been"," covered"," in"," the"," show",".","\u23ce\u23ce","Assistant",":",">","\u2191","Bigger"," than"," that"," though"," is"," the"," racial"," diversity"," the"," creators"," fo","isted"," upon"," the","\u2191"," E","mond","'s"," Field"," and"," the"," rest"," of"," the"," world"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["theme"," in"," the"," book",".","\u23ce\u23ce","Another"," interpretation"," of"," the"," meaning"," of"," the"," phrase"," \"","The"," Great","\u2191"," Gatsby","\""," is"," that"," it"," represents"," the"," dec","ad","ence"," of"," the","\u2191"," Ro","aring","\u2191"," Twent","ies",","," a"," time"," of"," social"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["wi","ret","ap"," statute","\"","?","\u23ce\u23ce","Assistant",":"," The"," entity"," type"," of"," \"","federal"," wi","ret","ap"," statute","\""," is"," a"," legal"," document"," or"," law",".","\u23ce\u23ce","Human",":"," Extract"," the"," key"," facts"," from"," the"," text",".","\u23ce\u23ce","Assistant",":"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce\u23ce","Human",":"," Un"," esempio"," di"," key","log","ger","?","\u23ce\u23ce","Assistant",":"," Un"," esempio"," di"," key","log","ger"," \u00e8"," il"," software"," \"","\u2191","St","ealth","k","ey","log","ger","\""," che"," \u00e8"," stato"," cre","ato"," per"," mon","itor","are"," e"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.31,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["under"," as"," a"," payment"," processor","."," But"," the","\u23ce"," alternative"," to","\u2191"," Ven","mo"," to"," keep"," payment"," privacy"," intact"," is"," not"," illegal",","," it","'s"," just","\u23ce"," plain"," old"," cash",".","\u23ce\u23ce","~~~","\u23ce","P","ete","ris","P","\u23ce"," Well"," yes"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["."," I","V","F"," can"," help"," individuals"," with"," pre","-","existing"," stress","."," The"," initial"," stage"," of"," I","V","Fs"," is"," when"," the"," individual"," begins"," exhib","iting"," symptoms"," of"," depression","."," Other"," I","V","Fs"," (","genetics",","," insurance"," prem","iums"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["val","ves"," are"," used"," in"," almost"," every"," industry"," having"," a"," substance"," that"," flows",".","\u23ce","One"," type"," of"," valve"," is"," a"," gate"," valve",","," also"," referred"," to"," as"," a"," s","lu","ice"," valve","."," A"," gate"," valve"," opens"," by"," moving"," a"]}]}],"top_logits":["ydyd","Areas","\u0434\u0430\u043d\u0438","ethods","elines","\u043a\u0430\u0434\u0430","n\u00e4r","whether","\u0440\u0435\u0433\u0438\u043e\u043d\u0443","ethod"],"bottom_logits":["consistent","in","focused","connected","dest","on","consist","linked","contracted","always"]}