{"index":2909274,"examples_quantiles":[{"quantile_name":"Top Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["song"," but"," a"," video","."," It","'s"," been"," used"," in"," TV"," shows",","," ads",","," and"," movies"," like"," The","\u2191"," Hunger"," Games",":","\u2191"," Catching"," Fire","."," It","'s"," also"," the"," theme"," song"," for"," the"," podcast"," Reply"," All",".","\u23ce\u23ce","Human"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," but"," a"," bit"," ed","g","ier"," than","\u2191"," Tolk","ien","."," It"," might"," feel"," a"," bit"," like"," The","\u2191"," Hunger"," Games"," or"," The","\u2191"," Wizard"," of","\u2191"," Oz","."," Another"," series"," I"," like"," is","\u2191"," Nar","nia",","," and"," there"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["]-",">(","c",")","\u23ce\u23ce","4",".","\u23ce","\u21ea","MATCH"," (","a",":","Book"," {","title",":"," \"","The","\u2191"," Hunger"," Games","\"}",")-","[:","\u21ea","WRITTEN","_","BY","]-",">(","b",":","Person"," {","name",":"," \"","\u2191","Suz","anne"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.97,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["loves"," to"," read"," might"," include"," the"," Harry"," Potter"," series"," by"," J",".","K",".","\u2191"," Row","ling",","," The","\u2191"," Hunger"," Games"," trilogy"," by","\u2191"," Suz","anne"," Collins",","," The"," Chronicles"," of","\u2191"," Nar","nia"," by"," C",".","S","."," Lewis"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.96,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["-","\u2191","Ass"," Female","\u2191"," Protagonist","\""," which"," features"," many"," widely","-","acclaimed"," books"," such"," as",":","\u23ce","The","\u2191"," Hunger"," Games"," by","\u2191"," Suz","anne"," Collins","\u23ce"," Little"," Women"," by","\u2191"," Lou","isa"," May","\u2191"," Alc","ott","\u23ce"," The"," Color"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["to"," be"," sure"," that"," are"," compatible",".","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","The"," movie",","," The","\u2191"," Hunger",","," starring"," Catherine","\u2191"," D","ene","uve"," and"," David","\u2191"," B","owie",","," is"," one"," of"," my"," favorite"," films","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["small"," kitchen"," with"," minimal"," space"," requirements",".","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","The"," movie",","," The","\u2191"," Hunger",","," starring"," Catherine","\u2191"," D","ene","uve"," and"," David","\u2191"," B","owie",","," is"," one"," of"," my"," favorite"," films","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.94,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["'","The"," Lord"," of"," the","\u2191"," Rings","',"," ","'","The","\u2191"," Hob","bit","',"," and"," ","'","The","\u2191"," Hunger"," Games","'.","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","How"," do"," you"," make"," a"," paper"," airplane","."," ","\u23ce\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.94,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the","\u2191"," S","orc","erer","'s"," Stone"," by"," J",".","K",".","\u2191"," Row","ling","\u23ce","2","."," The","\u2191"," Hunger"," Games"," by","\u2191"," Suz","anne"," Collins","\u23ce","3","."," The","\u2191"," G","iver"," by","\u2191"," L","ois","\u2191"," Low","ry"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.93,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["wr","ink","le"," in"," Time"," by","\u2191"," M","adel","eine"," L","'","\u2191","En","gle"," ","\u23ce","\u2022"," The","\u2191"," Hunger"," Games"," series"," by","\u2191"," Suz","anne"," Collins"," ","\u23ce","\u2022"," Where"," the"," Red","\u2191"," F","ern","\u2191"," Grows"," by"," Wilson"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.93,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["teenage"," readers","?","\u23ce\u23ce","Assistant",":"," ","\u23ce","The","\u2191"," Fault"," in"," Our"," Stars"," by"," John"," Green","\u23ce"," The","\u2191"," Hunger"," Games"," by","\u2191"," Suz","anne"," Collins","\u23ce","\u2191"," Per","ks"," of"," Being"," a","\u2191"," Wall","fl","ower"," by"," Stephen","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.93,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["York"," when"," she"," was"," a"," teenager",","," beginning"," her"," career"," as"," a"," writer","."," Her"," first"," novel",","," The","\u2191"," Hunger"," Games",","," was"," released"," in"," ","2","009"," ","and"," is"," one"," of"," the"," most"," popular"," novel","ists"," to"," this"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[":"," ","\u23ce","1","."," The"," Help"," by","\u2191"," Kat","hr","yn","\u2191"," Stock","ett","\u23ce","2","."," The","\u2191"," Hunger"," Games"," by","\u2191"," Suz","anne"," Collins","\u23ce","3","."," Harry"," Potter"," and"," the","\u2191"," S","orc","erer","'s"," Stone"," by"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["currently"," in"," her"," early"," twent","ies","."," She"," is"," known"," for"," her"," roles"," in"," films"," such"," as"," \"","The","\u2191"," Hunger"," Games",",\""," \"","Silver","\u2191"," Li","nings","\u2191"," Play","book",",\""," and"," \"","American","\u2191"," Hus","tle",".\"","\u23ce","*"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.91,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," The"," Hot","\u2191"," Spot",",","\u2191"," Married"," Life",",","\u2191"," Rocket"," Science",","," Murder"," by"," Numbers",","," The","\u2191"," Hunger",","," House"," of"," Games",",","\u2191"," Paul","ie",","," Snake"," Eyes",","," Next"," Stop","\u2191"," Wonder","land",","," Hide"," and"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.91,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ha","iku"," about"," eating"," b","isc","uits","\u23ce\u23ce"," Assistant",":","\u2191"," Soft"," and"," warm",",","\u23ce","\u2191","Satisf","ying"," my"," hunger",",","\u23ce","\u2191","B","isc","uits",","," oh"," so"," tas","ty","<EOT>","\u23ce\u23ce","Human",":"," For"," the"," rest"," of"," this"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.91,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["5",".","   ","\"","The","\u2191"," Hob","bit","\""," by"," NAME","_","4","\u23ce","6",".","   ","\"","The","\u2191"," Hunger"," Games","\""," by"," NAME","_","5","\u23ce","7",".","   ","\"","The","\u2191"," D","une"," Chronicles","\""," by"," NAME","_"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.91,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce\u23ce","Assistant",":"," ","\u23ce","1","."," The"," Road"," by","\u2191"," C","orm","ac"," McCarthy","\u23ce","2","."," The","\u2191"," Hunger"," Games","\u2191"," Trilogy"," by","\u2191"," Suz","anne"," Collins","\u23ce","3",".","\u2191"," Or","yx"," and","\u2191"," Cr","ake"," by"," Margaret"]}]},{"quantile_name":"Subsample Interval 0","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["me"," more"," about"," it"," before"," I"," make"," my"," decision","?","\u23ce\u23ce","Assistant",":"," ","\u23ce","Sure","!"," \"","The","\u2191"," Hunger"," Games","\""," by","\u2191"," Suz","anne"," Collins"," is"," a"," science","-","fiction"," novel"," which"," follows","\u2191"," Ka","tn","iss","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["D",".","\u2191"," Sal","inger",","," Of","\u2191"," Mice"," and"," Men"," by"," John","\u2191"," Stein","b","eck",","," The","\u2191"," Hunger"," Games"," by","\u2191"," Suz","anne"," Collins",","," and"," The"," Book","\u2191"," Th","ief"," by","\u2191"," Mark","us","\u2191"," Zus","ak"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["elho"," ","\u23ce","5","."," The","\u2191"," Mart","ian"," by"," Andy","\u2191"," We","ir"," ","\u23ce","6","."," The","\u2191"," Hunger"," Games"," by","\u2191"," Suz","anne"," Collins"," ","\u23ce","7","."," The","\u2191"," Hob","bit"," by"," J",".","R",".","R"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," The"," Hot","\u2191"," Spot",",","\u2191"," Married"," Life",",","\u2191"," Rocket"," Science",","," Murder"," by"," Numbers",","," The","\u2191"," Hunger",","," House"," of"," Games",",","\u2191"," Paul","ie",","," Snake"," Eyes",","," Next"," Stop","\u2191"," Wonder","land",","," Hide"," and"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["A"," character"," from"," a"," popular"," TV"," show"," or"," movie","."," You"," could"," be","\u2191"," Ka","tn","iss"," from"," the","\u2191"," Hunger"," Games"," or"," Rey"," from"," Star"," Wars",".","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","How"," do"," you"," find"," your"]}]},{"quantile_name":"Subsample Interval 1","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["And"," it","'s"," not"," even"," a"," need",".\""," \"","It","'s"," more"," like","...\""," \"","Like"," a","...\""," \"","A"," hunger",".\""," \"","And"," if"," you"," don","'t"," satisfy"," it",",\""," \"","You","'ll"," die",".\""," \"","Want"," to"," dance","?\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["more"," viv","id"," on"," how"," he"," touch"," her","\u23ce\u23ce"," Assistant",":"," The"," father"," touched"," his"," daughter","'s"," body"," with"," a"," hunger"," that"," was"," both"," intense"," and"," pr","imal","."," He"," str","oked"," her"," h","ips",","," his"," fingers"," tr","acing"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["sure"," that"," you","'re"," eating"," regular"," meals"," and"," sn","acks"," throughout"," the"," day"," as"," this"," will"," help"," to"," keep"," your"," hunger"," and"," c","rav","ings"," in"," check",".","\u23ce","4",".","Track"," what"," you"," eat",".","\u2191"," Keeping"," track"," of"," what"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","\u23ce\u23ce","Human",":"," continue"," writing"," the"," scene",","," using"," extremely"," descript","ive"," language","\u23ce\u23ce"," Assistant",":"," body"," with"," a"," hunger"," that"," sent"," shi","vers"," down"," his"," spine","."," She"," pulled"," at"," his"," pants",","," revealing"," his"," er","ect"," penis"," and"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["taste"," my"," own"," ass"," while"," you"," fuck"," my"," wet"," pussy",".\"","\u23ce\u23ce","\u2191","Overwhel","med"," by"," their"," ins","ati","able"," hunger",","," you"," have"," the"," opportunity"," to"," choose"," your"," next"," move",":","\u23ce\u23ce","1","."," Take"," NAME","_","3"," ","up"]}]},{"quantile_name":"Subsample Interval 2","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["","?\""," \"","No",","," you","'ll"," not"," escape",".\""," \"","You"," shall"," satisfy"," the","\u2191"," Ca","uld","ron","'s"," hunger",".\""," \"","Oh",","," no",".\""," \"","No"," ","!\""," \"","You","'ll"," not"," have"," me"," ","!\""," \"","My"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["find"," a"," way"," to"," work"," together"," and"," find"," a"," solution","."," I"," don","'t"," know"," how"," to"," explain"," the"," strange"," hunger"," that"," I","'m"," feeling",".\"","\u23ce","NAME","_","1",":"," \"","That","'s"," a"," good"," point","."," I"," think"," we"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ingly"," at"," the"," women","."," The"," other"," three"," are"," female"," chim","ps",","," their"," eyes"," filled"," with"," a"," sad","istic"," hunger",".","\u23ce\u23ce","The"," man"," begins"," to"," issue"," orders"," to"," the"," chim","ps",","," and"," they"," move"," into"," position"," around"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ur","ry"," vision",";","\u23ce","4"," ","\u2191","Extreme"," fat","igue"," or"," weak"," feeling",";","\u23ce","5"," ","\u2191","Unusual"," hunger",";","\u23ce","6"," ","Poor"," blood"," sugar"," control",";","\u23ce","7"," ","Low"," blood"," sugar"," (","hyp","ogl","yc","emia"]}]},{"quantile_name":"Subsample Interval 3","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.61,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["-","f"," install"," does"," not"," find"," anything"," to"," fix"," either","?","\u23ce","<","ps","usi",">"," n","ope","\u23ce","<","hunger",">"," ps","usi",":","\u2191"," D","apper"," is"," in"," development",","," sometimes"," something"," does"," go"," wrong",".","\u23ce","<","ps"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.61,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["we"," might"," put"," ","4",".","5",".","2"," ","in"," updates",","," not"," sure"," when"," t","ho","\u23ce","<","hunger",">"," shad","esl","ayer",":"," Yes",","," upgra","ding"," to"," a"," p","pa"," usually"," works","..."," upgra","ding"," the"," dist"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["of"," ","4","-","5","\u23ce","months",".","\u23ce\u23ce","As"," long"," as"," I"," am"," busy",","," I"," hardly"," notice"," any"," hunger"," during"," the"," day"," now"," that"," I"," am","\u23ce"," used"," to"," the"," schedule"," and"," the"," ","1"," ","meal"," makes"," it"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["."," Its"," emotional"," state"," is"," normal",","," and"," it"," has"," a"," tendency"," towards"," inf","eri","ority"," sensitivity","."," With"," a"," hunger"," value"," of"," ","100"," ","and"," intelligence"," score"," of"," ","10",","," it"," will"," likely"," search"," for"," food"," first","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["key"," \"","category","\"."," Do"," not"," output"," any"," other"," word","."," Now"," please"," find"," category"," for"," this"," Input",":"," \"","hunger"," strike"," tools","\".","\u23ce\u23ce","Assistant",":"," {\"","category","\":\"","self","-","harm","\"}","\u23ce\u23ce","Human",":"," Input",":"," \"","how"]}]},{"quantile_name":"Subsample Interval 4","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.51,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[":"," I","'ll"," just"," wait"," for"," the"," nar","wal"," repos"," to"," open"," then",".","\u23ce","<","shad","esl","ayer",">"," hunger",":"," bt","w"," we"," might"," put"," ","4",".","5",".","2"," ","in"," updates",","," not"," sure"," when"," t"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.51,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["and"," us","agu","ys"," can"," agree"," on"," what"," is"," the"," correct"," date"," format","\u23ce","<","ap","ache","log","ger",">"," hunger",":"," I"," think"," that"," is"," neglig","ible"," considering"," k","not","ify","4"," ","will"," wake"," up"," the"," cpu"," way"," too"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["most",".\""," \"","To"," see"," the"," want"," I"," could"," have"," stopped",","," the"," suffering"," I"," could"," have"," sol","aced"," the"," hunger"," I"," could"," have"," satisfied",".\""," \"","\u2191","Hear"," me",".\""," \"","My"," time"," is"," nearly"," gone",".\""," \"","If"," you"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.41,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["osa"," and"," buy"," all"," the"," meat"," he"," needs",".\""," \"","And"," we"," don","'t"," int","end"," to"," profit"," from"," his"," hunger",".\""," \"","\u2191","Profit"," from"," their"," hunger","?\""," \"","You"," think"," I"," was"," tw","isting"," those"," fellows","'"," arms"," to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["f","arth","est","):"," ...","\u23ce","Health",":"," Higher"," than"," ","15"," ","means"," I","'m"," healthy",".","\u23ce","\u2191","Hunger",":"," Higher"," than"," ","15"," ","means"," I","'m"," not"," hungry",".","\u23ce","Position",":"," ...","\u23ce","Equipment",":"," If"]}]},{"quantile_name":"Subsample Interval 5","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.41,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["cd"," in"," the"," blood"," itself","."," It"," did"," not"," therefore"," seem"," possible"," to"," un","-"," der","stand"," how"," the"," air"," hunger"," of"," musc","ular"," ex","er","tion"," could"," be"," re","-"," lie","ved",","," as"," it"," und","ou","bt","edly"," is"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["st","ove",".","\u23ce","While"," going"," on"," walks"," is"," awesome",","," having"," to"," always"," leave"," the"," office"," to"," satisfy","\u23ce"," hunger","/","th","irst"," can"," be"," a"," productivity"," killer",","," especially"," if"," you"," don","'t"," have"," a","\u23ce"," corner"," store"," and"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["as"," needed",".","\u23ce","5",".","\u2191"," Drink"," plenty"," of"," water",":"," Water"," can"," help"," fill"," you"," up",","," reduce"," hunger"," and"," make"," you"," feel"," more"," energ","ized",".","\u23ce","6","."," Get"," enough"," sleep",":"," Sleep"," is"," essential"," for"," proper"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u76ee","\u662f","\u5b8c","\u6574","\u7684","\uff1b","\u23ce\u23ce","2","\u3001","\u9898","\u76ee","\u8bed","\u53e5","\u901a","\\xe9\\xa1","\\xba","\u3002","\u23ce\u23ce","\u5f53","\u6ee1","\u8db3","\u4e0a","\u8ff0","\u4e24","\u70b9","\u89c4","\u5219","\u65f6","\uff0c","\u8bf7","\u4f60","\u56de","\u7b54","\uff1a\"","\u8be5","\u9898","\u76ee","\u6709","\u4ef7","\u503c","\""]}]},{"quantile_name":"Subsample Interval 6","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Food","-","Security"," ","\u23ce","7","."," Feed"," the"," Future"," \u2013"," The"," U",".","S","."," Government","'s"," Global","\u2191"," Hunger"," and"," Food"," Security"," Initiative",":"," https","://","www",".","feed","th","ef","u","ture",".","gov","/"," ","\u23ce","8"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","\u23ce","6",".","\u2191","Carry"," healthy"," sn","acks","."," Have"," healthy"," sn","acks"," on"," hand"," to"," reach"," for"," when"," hunger"," strikes"," and"," you"," don","'t"," have"," time"," to"," cook"," a"," healthy"," meal",".","\u23ce","7","."," Exercise"," regularly","."," Exercise"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","\u23ce","One"," worry"," I"," have"," about"," trying"," to"," start"," a"," low","-","fat"," diet"," is"," that"," I"," usually"," feel"," hunger"," pan","gs"," very"," quickly","."," Could"," this"," be"," an"," effect"," of"," the"," diet"," and"," can"," I"," still"," enjoy"," food"," for"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ims","\u23ce"," The"," way"," that"," wins"," is"," hard",".","\u23ce","When"," in"," doubt",","," tell"," the"," truth",".","\u23ce","\u2191","Hunger"," is"," the"," hand","m","aid"," of"," gen","\u23ce"," ","ius",".","\u23ce","It"," is"," easier"," to"," stay"," out"," than"," to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.29,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","way"," I"," interact"," with"," women"," as"," opposed"," to"," how"," I"," interact"," with"," men",".","\u23ce\u23ce","It","'s"," just"," like"," hunger","."," When"," I","'m"," hungry",","," it","'s"," hard"," to"," think"," about"," things"," other","\u23ce"," than"," food","."," If"," I"]}]},{"quantile_name":"Subsample Interval 7","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["thank"," me"," just"," yet",".\""," \"","If"," you","'re"," anything"," like"," me",","," and"," I"," have"," a"," sne","aking"," susp","icion"," that"," you"," are",","," you"," might"," get"," into"," a"," little"," bit"," of"," trouble"," out"," there",".\""," \"","Well",","," if"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","1"," ","migration"," on"," luc","id","\u23ce","<","j","d","st","rand",">"," I"," have"," a"," sne","aking"," susp","icion"," another"," firefox"," is"," coming",","," so"," I"," may"," need"," to"," do"," that"," some","\u23ce","<","j","d","st","rand",">"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ean","uts",".\""," \"","I","'m"," going"," to"," build"," myself"," a"," rocket"," bike"," and"," I"," have"," a"," sne","aking"," susp","icion"," it","'s"," going"," to"," be"," the"," cheap","est"," m","anned"," rocket"," mission"," ever",".\""," \"","Apollo","-","style"," rockets"," were"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ent"," f","asting",","," i",".","e","."," limiting"," the"," hours"," when"," you"," eat"," each"," day",","," can"," help"," reduce"," hunger","."," It"," takes"," some"," getting"," used"," to"," but"," may"," be"," worth"," trying",".","\u23ce\u23ce","Hope"," this"," gives"," you"," some"," good"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["and"," energy"," it"," needs",".","\u23ce","7","."," Be"," prepared",":"," Having"," healthy"," sn","acks"," readily"," available"," can"," ward"," off"," hunger"," and"," c","rav","ings",".","\u23ce","8","."," Learn"," healthy"," c","oping"," strategies",":","\u2191"," Somewhere"," other"," than"," food",","]}]},{"quantile_name":"Subsample Interval 8","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["it","  ","was","  ","done"," \u2014"," ^","I","  ","ate","  ","it","  ","almost","  ","raw",".","  ","When","  ","hunger","  ","was","  ","ab","ated",","," ","\u23ce","I","  ","began","  ","to","  ","be","  ","tend","erly","  ","concerned"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," computer","?"," Which"," is","\u23ce"," the"," human","?","\u23ce\u23ce","------","\u23ce","P","aul","H","o","ule","\u23ce"," My"," susp","icion"," is"," that","\u2191"," Chom","sky","'s"," \"","language"," inst","inct","\""," is"," actually"," a"," de","rang","ement","\u23ce"," of"," our"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["drop",".\""," \"","And"," for"," those"," who"," began"," their"," march"," too"," late"," or"," have"," fallen"," behind"," because"," of"," weakness"," or"," hunger"," hope"," of"," survival"," is"," now"," remote",".\""," \"","The"," lone"," peng","uin"," has"," no"," chance"," against"," the"," winter","'s"," cold"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["much"," th","icker"," and"," t","oug","her"," than"," what"," I"," see"," in"," the"," videos","."," I"," have"," a"," heavy"," susp","icion"," that"," this"," is"," a"," factor"," in"," my"," results","."," Tonight",","," I"," chose"," to"," do"," a"," m","ash","-","up"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["I","'m"," the"," only"," one"," who"," works"," around"," here",".\""," \"","They"," need"," to"," eat",","," they","'ll"," die"," of"," hunger"," without"," me",".\""," \"","\u2191","Okay",","," let","'s"," go",".\""," \"","Come"," on",","," worker",".\""," \"","The"," hand"]}]},{"quantile_name":"Bottom Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["to"," light"," the"," Indians",".","\u23ce","A"," disc","our","aging"," combination"," of"," circ","um","\u23ce"," st","ances",","," in"," which"," hunger",","," w","ear","iness",",","\u23ce","fear",","," all"," played"," a"," part",","," made"," him","\u23ce"," think"," better"," of"," it"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["use"," the"," identifier","\u23ce"," as"," a"," key"," for"," your"," dictionary"," you"," got"," from"," your"," parser",","," and"," bob","'s"," your"," aun","ty",".","\u23ce\u23ce","The"," remaining"," trick"," is"," stuff"," like"," navigation","."," A"," naive"," implementation"," will"," just","\u23ce"," process"," each"," file"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["st","aid","  ","here",",","  ","I","  ","thought"," ","\u23ce","I","  ","would","  ","per","ish","  ","with","  ","hunger",",","  ","and","  ","if","  ","I","  ","met","  ","with","  ","Indians",",","  ","they","  ","could"," ","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["to"," the"," fields","\u23ce"," Where"," they"," will"," s","ow"," r","ye",".","\u23ce","Though"," a"," peas","ant"," is"," dying"," of"," hunger",",","\u23ce","Through"," labor",","," he"," NAME","_","2"," ","live",".","\u23ce\u23ce","Only"," a"," woman"," in"," black","\u23ce"," NAME"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","B","isc","uits","?\""," \"","I","'m"," eating"," n","oo","dles"," now",".\""," \"","You","'ve"," gone"," mad"," from"," hunger",".\""," \"","What"," do"," you"," know","?\""," \"","This"," is"," remin","is","cing",".\""," \"","\u2191","Remin","is","cing","?\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["_","1","."," NAME","_","1"," ","is"," an"," expert"," She"," became"," known"," for"," her"," autobi","ographical"," book"," \"","La"," vie"," sex","uelle"," de"," NAME","_","2"," ","NAME","_","3",".\","," it"," was"," a"," literary"," success"," in"," many"," countries","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["?\""," \"","I"," can"," not"," believe"," I"," said"," that",".\""," \"","I"," lost"," my"," son",","," my"," people"," die"," of"," hunger"," and"," cold"," ","...\""," \"","Something"," will"," come",".\""," \"","\u2191","Some","day"," ","...\""," \"","but"," not"," the"," time"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["u","rine"," longer","."," She"," had"," often"," found"," herself"," in"," NAME","_","1"," ","bind"," when"," she"," had"," the"," ur","ge"," to"," go",","," but"," didn","'t"," have"," access"," to"," NAME","_","1"," ","toilet","."," This"," is"," why"," she"," decided"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["2"," ","NAME","_","3","!","\u23ce\u23ce","Assistant",":"," Sure"," thing",","," NAME","_","1","!"," Here","'s"," a"," simple"," and"," del","icious"," s","pa","gh","etti"," recipe"," for"," you",":","\u23ce\u23ce","\u2191","Ingredients",":","\u23ce","1","."," ","200","g"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","h","\"","\u23ce","#","include"," \"","tt","_","uuid",".","h","\"","\u23ce","#","include"," \"","tt","_","static",".","h","\"","\u23ce","#","include"," \"","tuple","_","constraint","_","def",".","h","\"","\u23ce","#","include"," \"","tuple","_"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["NAME","_","1"," ","is"," always"," extremely"," hor","ny",".","  ","NAME","_","1"," ","has"," an"," ins","ati","able"," appetite"," for"," sex"," with"," me"," and"," only"," me","."," NAME","_","1"," ","loves"," to"," play","fully"," sl","ap"," my"," face"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["NAME","_","2","'s"," apartment"," door",","," her"," massive"," bic","eps"," flex","ing"," with"," each"," powerful"," swing","."," The"," slim",","," ","45","-","year","-","old"," NAME","_","2"," ","cow","ered"," in"," the"," corner",","," her"," eyes"," wide"," with"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["."," e","oca"," ","\u23ce","w","po","-","\u2191","Al","po","-","x","rov","ke",","," vor","her"," durch","\u2191"," Hunger"," t\u00f6","b","ten",","," ","\u23ce","\u2191","A","rist","."," H","."," A",","," ","8",","," ","6","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["and"," it","'s"," also"," a"," bit"," of"," a"," psychological"," thriller","."," I"," recommend"," it","."," I"," also"," recommend"," The","\u2191"," Sixth","\u2191"," Sense","."," It","'s"," a"," kind"," of"," tw","is","ty"," horror"," movie","."," And"," also","\u2191"," Ros","em","ary"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," First","\u2191"," ","Ise","kai"," Novel"," in"," the"," Science"," Fiction"," NAME","_","1"," ","Fantasy"," Genre"," about"," the"," five"," ","16","-","year","-","old","\u2191"," Nep","ali"," school","g","ir","ls"," NAME","_","2",","," NAME","_","3",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["in"," this"," case",","," as"," it"," can"," provide"," an"," opportunity"," for"," the"," duo"," to"," have"," fun"," and"," create"," a"," unique"," memory",".","\u23ce\u23ce","Human",":"," Why"," is"," the"," distance"," contest"," better"," than"," playing"," vide","og","ames"," together","?","\u23ce\u23ce","Assistant",":"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["strings","."," Finally",","," it"," will"," create"," a","\u2191"," Pandas"," DataFrame"," with"," the"," list"," of"," date"," strings"," and"," set"," the"," ","'","Date","'"," column"," as"," the"," index","."," The"," `","pd",".","to","_","datetime","()","`"," function"," is"," used"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\uad6c","\ub9e4","\ud55c","\uac00","\uaca9","\uc774","\ub098","\uc2dc","\uae30","\ub97c","\uace0","\ub824","\ud588","\uc744","\ub54c","\\xea\\xb5","\\x89","\uc7a5","\ud788","\ub9cc","\uc871","\ud55c","\uc0ac","\uacfc","\uc785","\ub2c8","\ub2e4",".","\u23ce","\\xed\\x96","\\x87","\uacfc","\uc77c","\uc758"," ","\\xec\\x8b","\\xb1","\\xec\\x8b","\\xb1","\ud568","\uc740"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["players"," are"," more"," likely"," to"," keep"," playing",".","\u23ce","4",")"," They"," include"," bonus"," rounds"," that"," give"," the"," player"," the"," ill","usion"," that"," they"," might"," hit"," even"," bigger"," jack","p","ots","."," This"," makes"," the"," player"," keep"," trying"," to"," hit"," those"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["library"," permite"," que"," voc\u00ea"," sal","ve"," o"," tr","ein","amento"," do"," seu"," modelo"," para"," uma"," tom","ada"," atrav\u00e9s"," da"," sua"," fun\u00e7\u00e3o"," `","write","()","`.","\u23ce","```","python","\u23ce"," with"," nlt","k",".","open","('","tr","ein","amento",".","NAME","_"]}]}],"top_logits":["Games","games","pan","\u6e38","meter","Lives","\uac8c","monster","Edwin","Duncan"],"bottom_logits":["uplo","advers","negativ","ayout","interference","decis","its","degrad","exposure","interfer"]}