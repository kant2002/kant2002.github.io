{"index":662873,"examples_quantiles":[{"quantile_name":"Top Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.11,0.0,0.0,0.0,0.0,0.0,0.21,0.72,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["wrote"," about"," a"," river",":","\u23ce\u23ce","The"," River","\u2191"," Flows"," Ever"," On","\u23ce\u23ce"," The"," river"," flows"," ever"," on",",","  ","\u23ce","Around"," b","ends"," and"," under"," bridges",".","\u23ce","It"," rush","es"," over"," rocks"," and"," stones",",","   ","\u23ce","And"," sw"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.94,0.15,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["write"," a"," poem"," for"," a"," beautiful"," morning"," with"," bird"," singing","\u23ce\u23ce"," Assistant",":"," The"," sun"," rises"," high"," in"," the"," sky","\u23ce"," A"," new"," day"," begins",","," the"," air"," is"," alive","\u23ce"," Birds"," sing"," their"," sweet"," mel","odies","\u23ce"," As"," the"," world"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.5,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," style"," of"," the"," poet"," NAME","_","2",".","\u23ce\u23ce","Assistant",":"," In"," the"," shadow"," of"," a"," thousand"," stars",",","\u23ce","NAME","_","1","'s"," light"," sh","one"," br","ighter"," than"," them"," all",".","\u23ce","Her"," l","aughter",","," like"," music"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.35,0.03,0.0,0.0,0.0,0.0,0.0,0.91,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["'s"," a"," poem"," about"," the"," automotive"," industry",":","\u23ce\u23ce","The"," engines"," ro","ar",","," the"," wheels"," they"," do"," spin",",","\u23ce","The"," industry"," c","hu","gs"," along",","," nonetheless",".","\u23ce","From"," SU","V","s"," to"," sed","ans",","," trucks"," to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.19,0.0,0.37,0.91,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.12,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["s","oul","mates"," in"," other"," stars","\u23ce\u23ce"," Assistant",":"," In"," the"," vast"," exp","anse"," of"," the"," universe"," so"," vast",",","\u23ce","Where"," the"," stars"," tw","ink","le"," and"," the"," planets"," spin",",","\u23ce","A"," man"," l","ongs"," for"," his"," s","oul"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.07,0.9,0.11,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Sure",","," here","'s"," a"," short"," poem"," about"," the"," summer"," evening",":","\u23ce\u23ce","The"," evening"," sun"," han","gs"," low",",","\u23ce","In"," golden"," h","ues"," and"," sh","ades"," of"," blue",",","\u23ce","\u2191","Bat","hing"," the"," sky"," in"," golden"," light",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.39,0.0,0.0,0.0,0.0,0.9,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a"," poem"," about"," radar"," written"," by"," NAME","_","1",":","\u23ce\u23ce","It"," is"," the"," radar",","," a"," curious"," thing",",","\u23ce","That"," tells"," us"," where"," things"," are",",","\u23ce","It"," points"," to"," the"," North"," and"," South",",","\u23ce","And"," shows"," us"]}]},{"quantile_name":"Subsample Interval 0","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.39,0.0,0.0,0.0,0.0,0.9,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["a"," poem"," about"," radar"," written"," by"," NAME","_","1",":","\u23ce\u23ce","It"," is"," the"," radar",","," a"," curious"," thing",",","\u23ce","That"," tells"," us"," where"," things"," are",",","\u23ce","It"," points"," to"," the"," North"," and"," South",",","\u23ce","And"," shows"," us"]}]},{"quantile_name":"Subsample Interval 1","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.23,0.12,0.0,0.0,0.0,0.1,0.0,0.8,0.1,0.0,0.0,0.0,0.0,0.0,0.08,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["start"," with"," the"," letter"," a"," only"," a"," ","\u23ce\u23ce","Assistant",":","\u2191"," Potato",","," oh"," so"," tas","ty"," and"," grand","\u23ce"," A"," del","ight","ful"," veget","able",","," a"," true"," wonder","\u23ce","\u2191"," Grown"," in"," the"," ground",","," with"," a"," firm"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.41,0.42,0.0,0.8,0.12,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.11,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a"," poem"," about"," a"," st","in","ky"," politician",".","\u23ce\u23ce","Assistant",":"," A"," st","in","ky"," politician",","," oh"," my","\u23ce"," A"," st","ench"," so"," f","oul",","," it"," fills"," the"," sky","\u23ce"," With"," lies"," and"," corruption",","," he","'s"," a"]}]},{"quantile_name":"Subsample Interval 2","examples":[]},{"quantile_name":"Subsample Interval 3","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.27,0.6,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["son","ett"," zum","\u2191"," Th","ema","\u2191"," Fr","ei","heit",":","\u23ce","Freedom"," is"," the"," key"," to"," the"," world",",","\u23ce","It"," opens"," doors"," that"," were"," once"," closed",",","\u23ce","It"," sets"," us"," free"," from"," chains"," that"," are"," old",",","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.51,0.11,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ouc","ura","\"","\u23ce\u23ce","A"," no","ite"," \u00e9"," para"," a"," l","ouc","ura",","," que"," v","em"," em"," carr","inho","\u23ce"," Com"," o"," seu"," s","orr","iso"," verm","elho",","," seu"," chal","eco"," de"," s","eda","\u23ce"," E"," os"," sap","atos"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.31,0.0,0.0,0.0,0.0,0.22,0.49,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["'s"," stock"," price",".","\u23ce","Input",":","\u2191"," Poem",":"," The"," sun"," is"," warm",","," the"," sky"," is"," blue",",","\u23ce","The"," grass"," is"," green",","," and"," so"," are"," you",".","\u23ce","Output",":","\u23ce\u23ce","Assistant",":"," I"," apolog","ize",","]}]},{"quantile_name":"Subsample Interval 4","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.41,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce\u23ce","\u2191","Verse"," ","1",":","\u23ce","G"," C"," Am","\u23ce"," You"," and"," me",","," we","'re"," like"," a"," dream","\u23ce"," G"," C"," Am","\u23ce"," We","'re"," ch","asing"," something"," that"," we"," can","'t"," even"," see","\u23ce"," G"," C"," Am","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.5,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["follow"," the"," style"," of"," the"," poet"," NAME","_","2",".","\u23ce\u23ce","Assistant",":"," In"," the"," shadow"," of"," a"," thousand"," stars",",","\u23ce","NAME","_","1","'s"," light"," sh","one"," br","ighter"," than"," them"," all",".","\u23ce","Her"," l","aughter",","," like"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.12,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Assistant",":","\u2191"," Verse"," ","1",":","\u23ce","En"," el","\u2191"," Per","\u00fa",","," la"," situ","aci\u00f3n"," es"," t","ensa","\u23ce","\u2191"," Hay"," viol","encia"," en"," las"," cal","les"," y"," en"," la"," c","ima","\u23ce"," Los"," pob","res"," luc","han"," por"]}]},{"quantile_name":"Subsample Interval 5","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["is"," a"," translation"," of"," the"," anthem"," into"," English",":","\u23ce\u23ce","NAME","_","1",","," raise"," the"," symbol"," of"," freedom",",","\u23ce","In"," the"," sky",","," the"," sound"," of"," your"," voice"," so","ars"," high",",","\u23ce","Your"," melody",","," our"," hearts"," it"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["_","3"," ","people",":","\u23ce\u23ce","NAME","_","1",","," my"," friend",","," don","'t"," let"," hate"," take"," hold",",","\u23ce","Of"," people"," who"," are"," different",","," with"," a"," story"," to"," be"," told",".","\u23ce","NAME","_","3"," ","skin",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.11,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[":"," Tell"," me"," a"," dirty"," lim","erick",".","\u23ce\u23ce","Assistant",":"," There"," once"," was"," a"," man"," named"," J","ack","Wh","ose"," stomach"," was"," quite"," fl","acc","ck","H","is"," tr","ous","ers"," were"," t","ight","A","nd"," his"," shirt"," was"," right"]},{"tokens_acts_list":[0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.51,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.03,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Assistant",":"," Of"," course",","," I","'d"," be"," del","ighted"," to","\u23ce"," NAME","_","1","'s"," style"," is"," quite"," unique","\u23ce"," A"," master"," of"," bureauc","racy","\u23ce"," He","'d"," spin"," his"," words"," with"," great"," fin","esse","\u23ce\u23ce"," He","'d"," w","ax"]}]},{"quantile_name":"Subsample Interval 6","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\"(","country"," blues"," music",")\""," \"","\\xe2\\x99","\\xaa",""," The"," dawn"," is"," up",","," there","'s"," fire"," on"," the"," mountain"," ","\\xe2\\x99","\\xaa","\""," \"","\\xe2\\x99","\\xaa",""," They","'ll"," have"," to"," answer"," for"," their"," cro","oked"," claim"," ","\\xe2\\x99","\\xaa"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["new"," poem",".\""," \"","Yes",".\""," \"","A"," poem",".\""," \"\"","Stay"," by"," my"," side"," as"," my"," light"," grows"," dim",","," as"," my"," blood"," sl","ows"," down",","," and"," my"," ner","ves"," sh","atter"," with"," stab","bing"," pain",","," as"," my"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.19,0.0,0.37,0.91,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.12,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["oul","mates"," in"," other"," stars","\u23ce\u23ce"," Assistant",":"," In"," the"," vast"," exp","anse"," of"," the"," universe"," so"," vast",",","\u23ce","Where"," the"," stars"," tw","ink","le"," and"," the"," planets"," spin",",","\u23ce","A"," man"," l","ongs"," for"," his"," s","oul","mate"]}]},{"quantile_name":"Subsample Interval 7","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.15,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[":","\u23ce","\"","And",","," dar","ling",","," I"," will"," be"," loving"," you"," ","'","til"," we","'re"," ","70","\u23ce","And"," baby",","," my"," heart"," could"," still"," fall"," as"," hard"," at"," ","23","\"","\u23ce","This"," line"," speaks"," of"," how"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["sem"," ost","ent","a\u00e7\u00e3o","\u23ce\u23ce","[","\u2191","Verse"," ","1","]","\u23ce","O"," sol"," \u00e9"," o"," nos","so"," am","igo",","," ele"," nos"," d","\u00e1"," a"," energia","\u23ce"," A"," c","hu","va"," \u00e9"," a"," nossa"," am","ante",","," ela"," nos"," f"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["campo",":","\u23ce\u23ce","[","\u2191","Re","fr","\u00e3o","]","\u23ce","No"," campo",","," a"," natur","eza"," \u00e9"," a"," nossa"," senhora","\u23ce"," A"," terra"," \u00e9"," f","\u00e9rt","il",","," a"," vida"," \u00e9"," int","ensa","\u23ce","\u2191"," Aqu","i",","," a"," m","\u00e3o"]}]},{"quantile_name":"Subsample Interval 8","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["over"," ","?\""," \"","I"," know"," I","'ll"," see"," your"," face","\""," \"","\\xe2\\x99","\\xab",""," Every"," night"," I"," pray",","," every"," step"," I"," take"," ","\\xe2\\x99","\\xab",""," every"," move"," I"," make",","," every"," single"," day","\""," \"","\\xe2\\x99","\\xab"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["puzzle"," is"," a"," rid","dle"," that"," reads",":"," \"","I"," am"," a"," word"," that"," starts"," and"," ends"," with"," an"," E",","," but"," contains"," only"," one"," letter","."," What"," am"," I","?\"","\u23ce\u23ce","What"," would"," you"," like"," to"," do","?","\u23ce",">"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.03,0.48,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["and"," you"," *","must","*"," use"," i","amb","ic"," pent","ameter",".","\u23ce\u23ce","Assistant",":"," Oh",","," de","arest"," master",","," I"," am"," lost"," and"," gone",",","\u23ce","Away"," from"," home"," and"," hear","th",","," alone",".","\u23ce","I"," wand","ered"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Write"," a"," story"," about"," NAME","_","1","\u23ce\u23ce","Assistant",":"," Once"," upon"," a"," time",","," in"," a"," far","away"," land",","," there"," lived"," a"," family"," of"," gentle",","," lov","able"," creatures"," known"," as"," the"," NAME","_","2","."," The"," NAME","_"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," continu","idad"," y"," camb","ios"," en"," la"," pol\u00edtica"," in","terna","\u23ce\u23ce","\\xc2","\\xa1","Argentina",","," quer","ida"," Argentina",",","\u23ce","\u2191","Tierra"," de"," valores"," y"," de"," lu","cha","!","\u23ce","De"," la"," lu","cha"," por"," la"," libert","ad","\u23ce","\u2191"]}]},{"quantile_name":"Bottom Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["keep"," THE","\u21ea"," DISTANCE","\u21ea"," ANYMORE",".\""," \"","\\xe2\\x99","\\xaa",""," MY","\u21ea"," LIFE"," W","AS","\u21ea"," GOING","\u21ea"," NOWHERE",",","\u21ea"," TURN","\u21ea"," AROUND"," AND"," YOU","\u21ea"," WERE","\u21ea"," THERE"," ","\\xe2\\x99","\\xaa","\""," \"","\\xe2\\x99","\\xaa","","\u21ea"," D"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".\""," \"","\u2191","Sounds"," like"," a"," good"," plan",".\""," \"","\\xe2\\x99","\\xaa",""," the"," sun","sets"," we"," can"," cry"," over"," ","\\xe2\\x99","\\xaa","\""," \"","Bobby","?\""," \"","You"," know",","," that"," whole"," thing"," about"," you"," trying"," to"," connect"," my"," house"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["clear","."," Here","'s"," another"," rid","dle"," for"," you",":","\u23ce\u23ce","\"","What"," has"," a"," heart"," that"," doesn","'t"," beat",","," a"," mouth"," that"," doesn","'t"," speak",","," and"," a"," body"," that"," doesn","'t"," move","?\"","\u23ce\u23ce","Feel"," free"," to"," give"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.5,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["_","1","."," Please"," follow"," the"," style"," of"," the"," poet"," NAME","_","2",".","\u23ce\u23ce","Assistant",":"," In"," the"," shadow"," of"," a"," thousand"," stars",",","\u23ce","NAME","_","1","'s"," light"," sh","one"," br","ighter"," than"," them"," all",".","\u23ce","Her"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["."," ","\u23ce\u23ce","\u2191","N","ai","tre"," avec"," le"," prin","tem","ps",","," mou","rir"," comme"," les"," roses",","," ","\u23ce","\u2191","Si","ir"," P"," a","ile"," des"," Z","^","ph","y","is"," n","ager"," dans"," im"," del"," ","pur",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[":"," Tell"," me"," a"," dirty"," lim","erick",".","\u23ce\u23ce","Assistant",":"," There"," once"," was"," a"," man"," named"," J","ack","W","ho"," had"," a"," lot"," of"," nerv","eB","ut"," his"," tr","ous","ers"," were"," too"," t","ight","A","nd"," he"," couldn","'t"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["wanted"," a"," poem",","," from"," me","\u23ce"," but"," without"," much"," help",",","\u23ce","I"," didn","'t"," know"," what"," to"," write","\u23ce"," But"," I"," thought"," and"," thought",",","\u23ce","and"," now"," I","'m"," done","\u23ce"," and"," here","'s"," the"," poem"," I","'ve"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","\u21ea","INST","ANTS"," DE","\u21ea"," PARIS"," ","\u23ce","\u2191","Par","mi"," la"," fou","ie"," qui"," acc","lam","ait"," ","\u23ce","hier"," m","atin"," \""," Le","\u2191"," Pr\u00e9sident"," \""," par"," Louis","\u21ea"," L\u00c9","ON","-","\u21ea","MARTIN"," ","\u23ce","Je"," ne"]},{"tokens_acts_list":[0.0,0.0,0.0,0.26,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["like"," to"," meet","\u23ce","\u21b9\u21b9\u21b9"," To"," go"," over"," everything","\u23ce","\u21b9\u21b9\u21b9"," They"," say"," that"," time","'s"," supposed"," to"," heal"," ya",","," but"," I"," ain","'t"," done"," much"," healing","\u23ce","\u21b9\u21b9\u21b9","\u23ce","\u21b9\u21b9\u21b9","2","\u21b9","Hello",","," can"," you"," hear"," me","?"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a"," Week"," of","\u2191"," Significance","\u23ce"," to","\u2191"," Fash","io","nable"," Women","\u23ce"," October"," Record"," Week"," ended"," as"," it"," began",","," in"," a"," glory"," of","\u23ce"," th","rift"," thr","ills"," for"," econom","ical"," women","."," Its"," purpose"," was","\u23ce"," to"," demonstrate"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.55,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","C","ora","\u2191"," Co","ral","ina"," sem"," a"," c","itar","\u23ce\u23ce"," Assistant",":"," \"","O"," sol"," b","ril","ha",","," a"," vida"," fl","ore","sce","\u23ce"," Com"," energia"," renov","\u00e1vel",","," a"," aleg","ria"," aument","a","\u23ce","\u2191"," Pela"," natur"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.17,0.22,0.0,0.0,0.0,0.06,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","I"," love"," my"," family",","," I"," love"," my"," friends",",","\u23ce","I"," love"," the"," sun"," and"," the"," moon",".","\u23ce","I"," love"," to"," eat",","," I"," love"," to"," drink",",","\u23ce","I"," love"," to"," sleep",","," I"," love"," to"," think"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.51,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.03,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Could"," you"," write"," a"," poem"," in"," the"," style"," of"," NAME","_","1"," ","from"," yes"," minister"," ","\u23ce\u23ce","Assistant",":"," Of"," course",","," I","'d"," be"," del","ighted"," to","\u23ce"," NAME","_","1","'s"," style"," is"," quite"," unique","\u23ce"," A"," master"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["age","."," ","\u23ce\u23ce\u23ce","\u2191","Herb","ei",","," herb","ei",","," aus"," e","uren","\u2191"," Winter","h","\u00fcl","len"," ","\u23ce\u23ce","Bu"," d","ie","\u017f","em"," f","onn","eh","ellen","\u2191"," G\u00f6","tt","erf","ek","!"," ","\u23ce\u23ce","\u2191","He","rab"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["per"," te"," \u00e8"," cos\u00ec"," v","ero","\u23ce\u23ce","\u2191"," Verse"," ","2",":","\u23ce","\u2191","Ogni"," volta"," che"," ti"," gu","ardo",","," mi"," s","ento"," cos\u00ec"," v","ivo","\u23ce"," La"," t","ua"," ris","ata"," mi"," fa"," sor","rid","ere",","," mi"," fa"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["'","empire"," de"," la"," jo","ie"," ","\u23ce","C","'","est"," au"," c","lair"," del","\u00e0"," l","une","."," ","\u23ce","\\xcc","\\x83","\u2191","Tan","it",","," la"," d\u00e9","esse"," de","\u2191"," Cart","il","age",",-","p","\u00e9n","\u00e8","tre","1"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["NAME","_","2","\u23ce\u23ce","(","\u2191","Chorus",")","\u23ce","I","'m"," a"," pi","rate",","," no"," longer"," on"," the"," sea","\u23ce"," But"," in"," Berlin",","," I","'ll"," live"," my"," life"," with"," g","lee","\u23ce"," I","'ll"," drink"," my"," rum"," and"," dance"]}]}],"top_logits":["   ","    ","  ","        ","      ","     "," ","       ","A","rubber"],"bottom_logits":["numberUS","Finance","fortun","\u30d0\u30d0","change","Types","finance","Health","\u0430\u0437\u0430\u0437","\u0570\u0570"]}