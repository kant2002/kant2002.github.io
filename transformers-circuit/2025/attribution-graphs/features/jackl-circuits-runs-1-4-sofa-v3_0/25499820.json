{"index":25499820,"examples_quantiles":[{"quantile_name":"Top Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.07,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.14,0.0,0.11,0.3,1.0,0.58,0.41,0.2,0.38,0.11,0.0,0.04,0.36,0.0,0.0,0.12,0.1,0.0,0.12,0.0,0.0,0.02,0.0,0.15,0.23],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["time",","," there"," was"," a"," little"," bun","ny"," named"," NAME","_","1","."," NAME","_","1"," ","loved"," to"," eat"," carr","ots"," from"," his"," garden","."," One"," night",","," NAME","_","1"," ","heard"," a"," loud"," noise"," outside"," in"," his"," garden"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.51,0.98,0.0,0.09,0.23,0.21,0.12,0.37,0.28,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","\u23ce","-","\u2191","J","elly","\u2191"," Beans"," ","\u23ce","-","Small"," stuff","ed"," toys"," ","\u23ce","-","\u2191","Car","rot","\u2191"," St","icks"," or"," other"," veget","able"," treats"," ","\u23ce","-","\u2191","Go","odies"," to"," fill"," an"," Easter","\u2191"," Basket"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.42,0.83,0.36,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["body",","," and"," some"," st","icks"," or"," rocks"," for"," the"," feet","."," Then"," you"," might"," want"," to"," add"," a"," car","rot"," nose",","," two"," st","icks"," for"," hor","ns",","," some"," snow","b","alls"," for"," the"," eyes",","," a"," snow","ball"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.81,0.25,0.0,0.0,0.0,0.0,0.22,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.15,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["once"," was"," a"," rabbit"," named","\u2191"," Fl","uff","\u23ce","\u2191"," Whose"," habit"," was"," always"," to"," stuff","\u23ce"," His"," face"," with"," carr","ots"," and"," loops","\u23ce"," Of"," lett","uce"," and"," other"," such"," m","ops","\u23ce"," He","'d"," m","unch"," and"," m","unch"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.21,0.38,0.76,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.07,0.36,0.25],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","\u2191","Illustration",":"," A"," close","-","up"," of"," a"," go","at"," with"," a"," big"," smile",","," eating"," a"," car","rot",".","\u23ce\u23ce","Description",":"," \"","Meet"," NAME","_","3"," ","the"," go","at",","," he"," loves"," to"," eat"," carr","ots"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.07,0.75,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["it"," or"," not","?"," How"," does"," that"," effect"," your"," b","aking","?","\u23ce\u23ce","Assistant",":","\u2191","Might"," try"," some"," car","rot"," cake"," cu","pc","akes"," with"," a"," butt","erc","ream"," fro","sting",".","\u23ce","<","|","stop","|",">","<EOT>","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.73,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["\u2191","Role","play"," as"," a"," shop"," keeper","."," Your"," inventory"," has"," ","2"," ","ap","ples",","," ","5"," ","carr","ots"," and"," ","3"," ","ruby"," jew","els","."," *","player"," walks"," into"," shop","*","\u23ce\u23ce","Assistant",":"," *","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.34,0.0,0.0,0.15,0.17,0.18,0.3,0.49,0.66,0.28,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.02,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["-","h","oo",".\""," \"[","\u21ea","","IMIT","ATING","\u21ea"," BUGS","\u21ea"," BUN","NY","]","\u2191"," Eh",","," what","'s"," up",","," f","ats","?\""," \"[","\u21ea","","IMIT","ATING","\u21ea"," ROAD","\u21ea"," RUNNER","]","\u2191"," Me","ep",","," me","ep"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.57,0.66,0.45,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","Silly","\u2191"," Rabbit",","," I"," know"," why"," you"," called"," that","\""," \"","You"," follow"," Future"," Like"," he"," got"," carr","ots"," up"," his"," ass"," crack","\""," \"","When"," you"," acted"," up",","," You"," got"," j","acked"," up","\""," \"","Left"," stupid"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.22,0.62,0.17,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.36,0.21,0.0,0.0,0.02,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["you","'re"," a"," dog",".\""," \"","We"," can","'t"," get"," married",".\""," \"","You"," even"," p","eed"," in"," our"," car","rot"," garden",".\""," \""," I"," like"," honey",","," baby",".\""," \""," I"," like"," carr","ots",".\""," \""," I"," like"," bones","!\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.19,0.61,0.19,0.11,0.0,0.39,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["isan",">"," don","'t"," forget"," behind"," the"," ears","\u23ce","<","\u2191","Y","ag","isan",">"," and"," where"," is"," my"," car","rot"," to"," sn","ack"," on"," ;",")","\u23ce","<","zak","ame",">","\u2191"," Y","ag","isan",":"," er"," I"," don","'t"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.32,0.0,0.0,0.0,0.0,0.4,0.61,0.37,0.43,0.16,0.0,0.0,0.0,0.0,0.21,0.22,0.57,0.03,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["to"," Carmen","\""," is"," his"," theme"," song",".","\u23ce","4",".","\u2191"," Bugs","\u2191"," Bun","ny"," created"," the"," famous"," car","rot","-","mun","ching"," catch","ph","rase"," \"","What","'s"," Up",","," Doc","?","\".","\u23ce","5",".","\u2191"," Mel","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.61,0.13,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","Quantity",",","  ","name",",","  ","price","\u23ce"," ","2",","," ap","ples",","," ","3","\u23ce","5",","," carr","ots",","," ","1","\u23ce","3"," ","ruby","_","jew","els",","," ","15","\u23ce\u23ce","*","player"," walks"," into"," shop"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09,0.02,0.0,0.0,0.0,0.0,0.04,0.6,0.13,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.21],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["'t"," help"," myself",".\"","\u23ce\u23ce","\"","That","'s"," okay",",\""," said"," NAME","_","1","."," \"","I"," understand",".","\u2191"," Carr","ots"," are"," del","icious","!"," Since"," you"," like"," them"," so"," much",","," you"," can"," come"," over"," and"," share"," my"," carr"]},{"tokens_acts_list":[0.02,0.0,0.15,0.23,0.0,0.15,0.25,0.08,0.0,0.0,0.19,0.16,0.0,0.0,0.0,0.0,0.0,0.09,0.02,0.24,0.58,0.37,0.0,0.09,0.25,0.0,0.0,0.0,0.0,0.0,0.08,0.16,0.07,0.0,0.29,0.0,0.0,0.0,0.0,0.04,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["outside"," in"," his"," garden","."," He"," ho","pped"," out"," of"," his"," bun","ny"," hole"," and"," saw"," that"," some"," of"," his"," carr","ots"," had"," been"," eaten","!","\u23ce\u23ce","\"","Who"," has"," been"," eating"," my"," carr","ots","?\""," asked"," NAME","_","1","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.07,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.14,0.0,0.11,0.3,1.0,0.58,0.41,0.2,0.38,0.11,0.0,0.04,0.36,0.0,0.0,0.12,0.1,0.0,0.12,0.0,0.0,0.02,0.0,0.15,0.23,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," there"," was"," a"," little"," bun","ny"," named"," NAME","_","1","."," NAME","_","1"," ","loved"," to"," eat"," carr","ots"," from"," his"," garden","."," One"," night",","," NAME","_","1"," ","heard"," a"," loud"," noise"," outside"," in"," his"," garden","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.57,0.66,0.45,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\"","\u2191","Silly","\u2191"," Rabbit",","," I"," know"," why"," you"," called"," that","\""," \"","You"," follow"," Future"," Like"," he"," got"," carr","ots"," up"," his"," ass"," crack","\""," \"","When"," you"," acted"," up",","," You"," got"," j","acked"," up","\""," \"","Left"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.11,0.0,0.0,0.54,0.57,0.31,0.25,0.0,0.0,0.0,0.08,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[";"," tu","gged"," out"," '","\u23ce","n"," Easter"," array",";"," comfortable"," country"," r","\u23ce"," abb","f","ts","."," with"," carr","ots"," in"," their"," m","oot"," ","lis","?"," f","\u23ce"," ","ven"," st","j"," i","is","li"," b","unn","ies"," in"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.32,0.0,0.0,0.0,0.0,0.4,0.61,0.37,0.43,0.16,0.0,0.0,0.0,0.0,0.21,0.22,0.57,0.03,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.16,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","\u2191"," Bugs","\u2191"," Bun","ny"," created"," the"," famous"," car","rot","-","mun","ching"," catch","ph","rase"," \"","What","'s"," Up",","," Doc","?","\".","\u23ce","5",".","\u2191"," Mel","\u2191"," Blanc","'s","\u2191"," Bugs","\u2191"," Bun","ny"," became"," the"," first"]}]},{"quantile_name":"Subsample Interval 0","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.07,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.14,0.0,0.11,0.3,1.0,0.58,0.41,0.2,0.38,0.11,0.0,0.04,0.36,0.0,0.0,0.12,0.1,0.0,0.12,0.0,0.0,0.02,0.0,0.15,0.23],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["time",","," there"," was"," a"," little"," bun","ny"," named"," NAME","_","1","."," NAME","_","1"," ","loved"," to"," eat"," carr","ots"," from"," his"," garden","."," One"," night",","," NAME","_","1"," ","heard"," a"," loud"," noise"," outside"," in"," his"," garden"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.51,0.98,0.0,0.09,0.23,0.21,0.12,0.37,0.28,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":[" ","\u23ce","-","\u2191","J","elly","\u2191"," Beans"," ","\u23ce","-","Small"," stuff","ed"," toys"," ","\u23ce","-","\u2191","Car","rot","\u2191"," St","icks"," or"," other"," veget","able"," treats"," ","\u23ce","-","\u2191","Go","odies"," to"," fill"," an"," Easter","\u2191"," Basket"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.42,0.83,0.36,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["body",","," and"," some"," st","icks"," or"," rocks"," for"," the"," feet","."," Then"," you"," might"," want"," to"," add"," a"," car","rot"," nose",","," two"," st","icks"," for"," hor","ns",","," some"," snow","b","alls"," for"," the"," eyes",","," a"," snow","ball"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.81,0.25,0.0,0.0,0.0,0.0,0.22,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.15,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["once"," was"," a"," rabbit"," named","\u2191"," Fl","uff","\u23ce","\u2191"," Whose"," habit"," was"," always"," to"," stuff","\u23ce"," His"," face"," with"," carr","ots"," and"," loops","\u23ce"," Of"," lett","uce"," and"," other"," such"," m","ops","\u23ce"," He","'d"," m","unch"," and"," m","unch"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.21,0.38,0.76,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.07,0.36,0.25],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["\u23ce","\u2191","Illustration",":"," A"," close","-","up"," of"," a"," go","at"," with"," a"," big"," smile",","," eating"," a"," car","rot",".","\u23ce\u23ce","Description",":"," \"","Meet"," NAME","_","3"," ","the"," go","at",","," he"," loves"," to"," eat"," carr","ots"]}]},{"quantile_name":"Subsample Interval 1","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.51,0.98,0.0,0.09,0.23,0.21,0.12,0.37,0.28,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":[" ","\u23ce","-","\u2191","J","elly","\u2191"," Beans"," ","\u23ce","-","Small"," stuff","ed"," toys"," ","\u23ce","-","\u2191","Car","rot","\u2191"," St","icks"," or"," other"," veget","able"," treats"," ","\u23ce","-","\u2191","Go","odies"," to"," fill"," an"," Easter","\u2191"," Basket"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.42,0.83,0.36,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["body",","," and"," some"," st","icks"," or"," rocks"," for"," the"," feet","."," Then"," you"," might"," want"," to"," add"," a"," car","rot"," nose",","," two"," st","icks"," for"," hor","ns",","," some"," snow","b","alls"," for"," the"," eyes",","," a"," snow","ball"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.81,0.25,0.0,0.0,0.0,0.0,0.22,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.15,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["once"," was"," a"," rabbit"," named","\u2191"," Fl","uff","\u23ce","\u2191"," Whose"," habit"," was"," always"," to"," stuff","\u23ce"," His"," face"," with"," carr","ots"," and"," loops","\u23ce"," Of"," lett","uce"," and"," other"," such"," m","ops","\u23ce"," He","'d"," m","unch"," and"," m","unch"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.21,0.38,0.76,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.07,0.36,0.25],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["\u23ce","\u2191","Illustration",":"," A"," close","-","up"," of"," a"," go","at"," with"," a"," big"," smile",","," eating"," a"," car","rot",".","\u23ce\u23ce","Description",":"," \"","Meet"," NAME","_","3"," ","the"," go","at",","," he"," loves"," to"," eat"," carr","ots"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.07,0.75,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["it"," or"," not","?"," How"," does"," that"," effect"," your"," b","aking","?","\u23ce\u23ce","Assistant",":","\u2191","Might"," try"," some"," car","rot"," cake"," cu","pc","akes"," with"," a"," butt","erc","ream"," fro","sting",".","\u23ce","<","|","stop","|",">","<EOT>","\u23ce"]}]},{"quantile_name":"Subsample Interval 2","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.21,0.38,0.76,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.07,0.36,0.25],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["\u23ce","\u2191","Illustration",":"," A"," close","-","up"," of"," a"," go","at"," with"," a"," big"," smile",","," eating"," a"," car","rot",".","\u23ce\u23ce","Description",":"," \"","Meet"," NAME","_","3"," ","the"," go","at",","," he"," loves"," to"," eat"," carr","ots"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.07,0.75,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["it"," or"," not","?"," How"," does"," that"," effect"," your"," b","aking","?","\u23ce\u23ce","Assistant",":","\u2191","Might"," try"," some"," car","rot"," cake"," cu","pc","akes"," with"," a"," butt","erc","ream"," fro","sting",".","\u23ce","<","|","stop","|",">","<EOT>","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.73,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["\u2191","Role","play"," as"," a"," shop"," keeper","."," Your"," inventory"," has"," ","2"," ","ap","ples",","," ","5"," ","carr","ots"," and"," ","3"," ","ruby"," jew","els","."," *","player"," walks"," into"," shop","*","\u23ce\u23ce","Assistant",":"," *","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.34,0.0,0.0,0.15,0.17,0.18,0.3,0.49,0.66,0.28,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.02,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["-","h","oo",".\""," \"[","\u21ea","","IMIT","ATING","\u21ea"," BUGS","\u21ea"," BUN","NY","]","\u2191"," Eh",","," what","'s"," up",","," f","ats","?\""," \"[","\u21ea","","IMIT","ATING","\u21ea"," ROAD","\u21ea"," RUNNER","]","\u2191"," Me","ep",","," me","ep"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.57,0.66,0.45,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["\u2191","Silly","\u2191"," Rabbit",","," I"," know"," why"," you"," called"," that","\""," \"","You"," follow"," Future"," Like"," he"," got"," carr","ots"," up"," his"," ass"," crack","\""," \"","When"," you"," acted"," up",","," You"," got"," j","acked"," up","\""," \"","Left"," stupid"]}]},{"quantile_name":"Subsample Interval 3","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.32,0.0,0.0,0.0,0.0,0.4,0.61,0.37,0.43,0.16,0.0,0.0,0.0,0.0,0.21,0.22,0.57,0.03,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["to"," Carmen","\""," is"," his"," theme"," song",".","\u23ce","4",".","\u2191"," Bugs","\u2191"," Bun","ny"," created"," the"," famous"," car","rot","-","mun","ching"," catch","ph","rase"," \"","What","'s"," Up",","," Doc","?","\".","\u23ce","5",".","\u2191"," Mel","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.61,0.13,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["\u2191","Quantity",",","  ","name",",","  ","price","\u23ce"," ","2",","," ap","ples",","," ","3","\u23ce","5",","," carr","ots",","," ","1","\u23ce","3"," ","ruby","_","jew","els",","," ","15","\u23ce\u23ce","*","player"," walks"," into"," shop"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09,0.02,0.0,0.0,0.0,0.0,0.04,0.6,0.13,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.21],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["'t"," help"," myself",".\"","\u23ce\u23ce","\"","That","'s"," okay",",\""," said"," NAME","_","1","."," \"","I"," understand",".","\u2191"," Carr","ots"," are"," del","icious","!"," Since"," you"," like"," them"," so"," much",","," you"," can"," come"," over"," and"," share"," my"," carr"]},{"tokens_acts_list":[0.02,0.0,0.15,0.23,0.0,0.15,0.25,0.08,0.0,0.0,0.19,0.16,0.0,0.0,0.0,0.0,0.0,0.09,0.02,0.24,0.58,0.37,0.0,0.09,0.25,0.0,0.0,0.0,0.0,0.0,0.08,0.16,0.07,0.0,0.29,0.0,0.0,0.0,0.0,0.04,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["outside"," in"," his"," garden","."," He"," ho","pped"," out"," of"," his"," bun","ny"," hole"," and"," saw"," that"," some"," of"," his"," carr","ots"," had"," been"," eaten","!","\u23ce\u23ce","\"","Who"," has"," been"," eating"," my"," carr","ots","?\""," asked"," NAME","_","1","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.07,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.14,0.0,0.11,0.3,1.0,0.58,0.41,0.2,0.38,0.11,0.0,0.04,0.36,0.0,0.0,0.12,0.1,0.0,0.12,0.0,0.0,0.02,0.0,0.15,0.23,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":[","," there"," was"," a"," little"," bun","ny"," named"," NAME","_","1","."," NAME","_","1"," ","loved"," to"," eat"," carr","ots"," from"," his"," garden","."," One"," night",","," NAME","_","1"," ","heard"," a"," loud"," noise"," outside"," in"," his"," garden","."]}]},{"quantile_name":"Subsample Interval 4","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.51,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["for"," example"," the"," Nazi"," party",").","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","I"," want"," to"," make"," a"," car","rot"," cake"," but"," v","egan"," style","."," So"," what"," things"," should"," I"," avoid"," putting"," into"," it"," if"," I"," want"," to"," make"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.51,0.98,0.0,0.09,0.23,0.21,0.12,0.37,0.28,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ies"," ","\u23ce","-","\u2191","J","elly","\u2191"," Beans"," ","\u23ce","-","Small"," stuff","ed"," toys"," ","\u23ce","-","\u2191","Car","rot","\u2191"," St","icks"," or"," other"," veget","able"," treats"," ","\u23ce","-","\u2191","Go","odies"," to"," fill"," an"," Easter","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","Fro","sting"," ","\u23ce","\u2191","Vanilla","\u2191"," Cake"," with","\u2191"," Straw","berry","\u2191"," Fro","sting"," ","\u23ce","\u2191","Car","rot","\u2191"," Cake"," with","\u2191"," Cream","\u2191"," Cheese","\u2191"," Fro","sting"," ","\u23ce","\u2191","P","ine","ap","ple","\u2191"," Cake"," with"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.14,0.49,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\"","\u2191","Luc","ien",":\""," \"","I"," know"," this"," place"," is"," not"," so"," bad"," --"," the"," chairs",","," the"," carr","ots"," \""," \"","I","'m"," starting"," to"," like"," our"," conversations",".\""," \"","One"," way"," or"," another",","," they","'re"," about"," to"]}]},{"quantile_name":"Subsample Interval 5","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.07,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.14,0.0,0.11,0.3,1.0,0.58,0.41,0.2,0.38,0.11,0.0,0.04,0.36,0.0,0.0,0.12,0.1,0.0,0.12,0.0,0.0,0.02,0.0,0.15,0.23,0.0,0.15],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["there"," was"," a"," little"," bun","ny"," named"," NAME","_","1","."," NAME","_","1"," ","loved"," to"," eat"," carr","ots"," from"," his"," garden","."," One"," night",","," NAME","_","1"," ","heard"," a"," loud"," noise"," outside"," in"," his"," garden","."," He"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.41,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["free"," p","ump","kin"," pie","\u23ce","3",")"," Sugar","-","free"," brown","ies","\u23ce","4",")"," Sugar","-","free"," car","rot"," cake","\u23ce","5",")"," Sugar","-","free"," apple"," pie","\u23ce\u23ce"," Human",":"," ","\u23ce","How"," can"," I"," make"," sugar"," free"]},{"tokens_acts_list":[0.0,0.0,0.0,0.31,0.15,0.55,0.0,0.0,0.44,0.0,0.0,0.23,0.4,0.0,0.0,0.18,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.27,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["uh",",","car","rot"," from"," the"," crime"," scene"," is"," more"," than"," a"," car","rot"," at"," a"," crime"," scene",".\""," \"","It","'s"," a"," veg","gie"," pipe",",","and"," quite"," possibly"," the"," greatest"," invention"," ever",".\""," \"","All"," right",",","you"," take"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.31,0.15,0.55,0.0,0.0,0.44,0.0,0.0,0.23,0.4,0.0,0.0,0.18,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.27,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["are"," you"," doing","?\""," \"","The",",","","uh",",","car","rot"," from"," the"," crime"," scene"," is"," more"," than"," a"," car","rot"," at"," a"," crime"," scene",".\""," \"","It","'s"," a"," veg","gie"," pipe",",","and"," quite"," possibly"," the"," greatest"," invention"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.32,0.0,0.0,0.0,0.0,0.4,0.61,0.37,0.43,0.16,0.0,0.0,0.0,0.0,0.21,0.22,0.57,0.03,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ture"," to"," Carmen","\""," is"," his"," theme"," song",".","\u23ce","4",".","\u2191"," Bugs","\u2191"," Bun","ny"," created"," the"," famous"," car","rot","-","mun","ching"," catch","ph","rase"," \"","What","'s"," Up",","," Doc","?","\".","\u23ce","5",".","\u2191"," Mel"]}]},{"quantile_name":"Subsample Interval 6","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.34,0.0,0.0,0.15,0.17,0.18,0.3,0.49,0.66,0.28,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.02,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["w","oo","-","h","oo",".\""," \"[","\u21ea","","IMIT","ATING","\u21ea"," BUGS","\u21ea"," BUN","NY","]","\u2191"," Eh",","," what","'s"," up",","," f","ats","?\""," \"[","\u21ea","","IMIT","ATING","\u21ea"," ROAD","\u21ea"," RUNNER","]","\u2191"," Me","ep",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a"," sav","ory"," sugar"," alternative"," for"," b","aking","?"," So"," I","'m"," a"," cook",","," who"," is"," making"," a"," car","rot"," cake"," and"," got"," the"," thought"," about"," sav","ory"," b","eet"," c","akes"," while"," doing"," it","."," However"," my"," b","aking"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.29,0.11,0.0,0.0,0.0,0.0,0.0,0.09,0.0,0.0,0.03,0.0,0.22,0.06,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["not"," clear"," what"," the"," intended"," meaning"," is",".","<EOT>","\u23ce\u23ce","Human",":"," ","\\xe5\\x85","\\x94","\u5b50","\\xe5\\x96","\\x9c","\\xe6\\xac","\\xa2","\\xe5\\x90","\\x83","\u4ec0","\u4e48","\u23ce\u23ce","Assistant",":"," ","\\xe5\\x85","\\x94","\u5b50","\u662f","\u8349","\u98df","\u6027","\u52a8","\u7269","\uff0c","\u5b83","\u4eec","\u7684"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.37,0.3,0.0,0.0,0.15,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["environment"," for"," your"," two"," rabb","its","."," Place"," them"," off","-","topic"," and"," gather"," any"," necessary"," materials"," such"," as"," carr","ots",","," cel","ery",","," on","ions",","," and"," any"," other"," seeds"," or"," dried"," herbs"," before"," pl","anting"," them"," in"," the"]},{"tokens_acts_list":[0.0,0.08,0.16,0.07,0.0,0.29,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.06,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.15,0.0,0.0,0.0,0.0,0.0,0.34,0.27,0.07,0.0,0.0,0.0,0.0,0.0,0.07,0.0,0.0,0.04,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["has"," been"," eating"," my"," carr","ots","?\""," asked"," NAME","_","1","."," He"," heard"," a"," bur","p"," and"," saw"," a"," green"," tail"," st","icking"," out"," from"," under"," a"," car","rot"," leaf",".","\u23ce\u23ce","NAME","_","1"," ","lifted"," the"," leaf"," and"]}]},{"quantile_name":"Subsample Interval 7","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.34,0.27,0.07,0.0,0.0,0.0,0.0,0.0,0.07,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.2,0.46,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["out"," from"," under"," a"," car","rot"," leaf",".","\u23ce\u23ce","NAME","_","1"," ","lifted"," the"," leaf"," and"," saw"," a"," little"," green"," turtle"," named"," NAME","_","2","."," NAME","_","2","'s"," mouth"," and"," face"," were"," covered"," in"," car","rot"," bits","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.1,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Women","\u23ce","\u2191"," Thou"," shall"," ","lov"," \u2022"," i","hy"," husband"," a","nil","\u23ce"," never"," serve"," him"," spin","ach",","," carr","ots"," ","01","\u23ce","par","sn","ips",".","\u23ce","Equal"," Rights","\u23ce"," The"," women"," still"," talk"," equal"," rights",",","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Each"," of"," them"," has"," a"," different"," favorite"," kind"," of"," food",".","\u2191"," Rud","olph"," likes"," fresh",","," green"," ve","gg","ies",".","\u2191"," Co","met"," likes"," ber","ries",".","\u2191"," Dancer"," loves"," the"," sun",".","\u2191"," Bl","itzen"," loves"," the"," night"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.09,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," making"," them"," a"," great"," sn","ack"," to"," go"," along"," with"," a"," healthy"," meal",".","\u2191"," Carr","ots"," are"," high"," in"," protein"," containing"," pot","ass","ium",","," pot","ass","ium",","," minerals"," and"," vitamin"," A",","," while"," bell"," pep","pers"," are"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.44,0.42,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["the"," effic","acy"," of"," these"," chemicals"," and","<EOT>","\u23ce\u23ce","Human",":"," Write"," in"," detail"," the"," recipe"," of"," the"," Russian"," car","rot"," cake","\u23ce\u23ce"," Assistant",":"," Here","'s"," a"," detailed"," recipe"," for"," a"," traditional"," Russian","\u2191"," Car","rot","\u2191"," Cake"," (","\u2191"]}]},{"quantile_name":"Subsample Interval 8","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["bring"," food","?\""," \""," Sir","...\""," \""," It","'s"," for"," me",".\""," \"","Keep"," it"," here",".\""," \"","\u2191","Rad","ish"," stuff","ed"," panc","akes",".\""," \"\"","\u2191","Cottage"," cheese"," and"," spin","ach",","," mixed"," vegetables","..."," \"\""," \"\"","do"," what"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["cric","kets"," food"," that"," you"," can"," buy"," at"," pet"," stores",","," and"," also"," you","'ll"," want"," to"," give"," them"," some"," vegetables",","," maybe"," a"," few"," tom","ato"," or"," br","occ","oli"," pieces",","," or"," some"," other"," veget","able"," they","'ll"," like"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["-"," Baby"," is"," a"," bun","ny",".","  ","Just"," dress"," it"," up"," like"," a"," bun","ny"," and"," add"," ears"," and"," a"," tail",".","  ","You"," could"," make"," it"," a"," b","umb","leb","ee",","," which"," is"," a"," bun","ny"," that"," has"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.11,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["going"," to"," market",".\""," \"","\u2191"," Incredible","!\""," \"","Yeah",","," actually"," Ron"," really"," wanted"," you"," to"," do"," the"," veg","gie"," pl","atter",","," now"," so","...\""," \"","Stay"," right"," here",".\""," \""," I","'m"," right"," here",".\""," \""," Don","'t"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.04,0.1,0.11,0.0,0.1,0.0,0.0,0.19,0.56,0.06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["de"," e","env","oud","ige"," d","ingen"," in"," het"," leven"," m","iste","."," Hij"," m","iste"," het"," s","app","ige"," gr","oen"," van"," de"," gew","one"," w","ort","els",","," hij"," m","iste"," het"," pl","ez","ier"," van"," het"," ren","nen"]}]},{"quantile_name":"Bottom Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","3",".","\u2191"," Rad","ishes"," ","\u23ce"," ","4",".","\u2191"," Pep","pers"," ","\u23ce"," ","5",".","\u2191"," Carr","ots"," ","\u23ce"," ","6",".","\u2191"," Spin","ach"," ","\u23ce"," ","7","."," Swiss","\u2191"," ","Chard"," ","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["het"," ont","mo","eten"," van"," zijn"," vri","enden"," zonder"," dat"," ze"," alleen"," maar"," ge","\u00ef","n","te","ress","eerd"," waren"," in"," zijn"," g","ouden"," wor","tel",".","\u23ce\u23ce","\u2191","Dus",","," op"," een"," m","oo","ie"," len","te","dag",","," besl"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["to"," his"," fellow"," chick","ens",","," saying"," \"","My"," dear"," fellow"," chick","ens",","," I"," have"," found"," a"," new"," source"," of"," food"," that"," will"," benefit"," us"," all",".","\u2191"," Al","fal","fa"," is"," rich"," in"," protein"," and"," will"," give"," us"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["help",".","<EOT>","\u23ce\u23ce","Human",":"," how"," can"," i"," identify"," a"," NAME","_","1"," ","rat"," eating"," fruits"," in"," my"," garden","?","\u23ce\u23ce","Assistant",":"," NAME","_","1"," ","rats"," are"," small","\u2191"," Rat"," species"," that"," are"," commonly"," found"," in"," Central"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["at","ish"," joke",",","\u23ce","NAME","_","3"," ","the"," go","at",","," is"," a"," joy"," to"," have"," in"," the"," rock",".\"","\u23ce\u23ce","Page"," ","3",":","\u23ce","\u2191","Illustration",":"," A"," picture"," of"," a"," big"," apple"," tree"," with"," ap","ples"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\"(","\u21ea","BR","AKES","\u21ea"," SC","REE","CHING",")\""," \""," But"," you","'re"," a"," plane",".\""," \""," I","'m"," a"," crop"," d","uster",".\""," \"","I","'ve"," never"," fl","own"," over"," a"," thousand"," feet",".\""," \"","Are"," you"," kid","ding","?\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["gonna"," take"," this"," anymore",".\"","\""," \"","Yeah","!\""," \"","Put"," up"," your"," roots",","," you"," re","jects"," from"," a"," sal","ad"," bar",".\""," \"","We","'re"," really"," mad"," and"," we","'re"," not"," gonna"," take"," this"," anymore",".\""," \"","\u2191","Hoo"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["or"," you"," can"," collect"," natural"," objects"," to"," dec","orate"," with","."," You"," might"," make"," orn","aments"," from"," seasonal"," fruits"," and"," vegetables"," like"," g","ing","erb","read"," houses",","," or"," you"," might"," make"," orn","aments"," from"," recycl","ables"," like"," s","oda"," c"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Flutter"," App"," die"," he","i\u00df","t","\u2191"," Gem","\u00fc","se","\u2191"," An","ba","upl","aner","."," Die"," App"," b","ein","hal","tet"," einen","\u2191"," Kal","ender",","," eine","\u2191"," Sa","at","g","ut","\u2191"," D","aten","bank"," und"," \"","d","ein"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.01,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["to"," grow"," include",":"," tom","atoes",","," cuc","umbers",","," z","uc","ch","ini",","," bell"," pep","pers",","," carr","ots",","," and"," pot","atoes",".","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","When"," does"," UF","O"," s","ighting"," typically"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","What"," vegetables"," should"," I"," plant"," this"," Spring","?","\u23ce\u23ce","Assistant",":"," ","\u23ce","1",".","\u2191"," Tom","atoes","\u23ce","2",".","\u2191"," Pep","pers","\u23ce","3",".","\u2191"," Cuc","umbers","\u23ce","4"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["icious"," dess","ert"," choices"," I"," find","."," For"," top"," dess","erts",","," you"," can"," try"," fresh"," fruits"," and"," ve","gg","ies",","," honey",","," ap","ples",","," l","ite","ber","ries",","," c","inn","amon",","," chocolate",","," p","ean","ut"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ito"," se"," recuper","\u00f3"," y"," se"," conv","irt","i\u00f3"," en"," el"," mejor"," am","igo"," de"," Ana",".","\u2191"," Cada"," d\u00eda",","," mientras"," trabaj","aba"," en"," su"," jard","\u00edn",","," Ana"," y"," su"," co","nej","ito"," jug","aban"," jun","tos"," y"," compart"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["their"," kind","ness",","," emp","athy",","," and"," love"," for"," all"," living"," things",".","\u23ce\u23ce","One"," day",","," a"," young"," rabbit"," named"," NAME","_","1"," ","was"," out"," on"," a"," walk"," when"," she"," came"," across"," a"," lost"," ki","tten","."," The"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[";","  ","elle","  ","appro","ch","ait"," ","\u23ce","ses","  ","d","ents","  ","d","'","une","  ","gra","ppe","  ","to","ute","  ","v","erte"," \u2014","  ","et","  ","elle","  ","mor","dit","  ","un"," ","\u23ce","peu","  ","mes"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u03bf","\u03c0\u03c0","\u03c2","\u03c5","\u03c4","\u03b1\u03c3","\u03af","\u03c2","]","\u03c6","\u03b9","\u03c7","\u03bf\u03c2"," ","\u23ce","\u03b3","\u03bf","\u03c4","\u03b1\u03c3","\u03bf","\u03b1","\u2191"," \u0395","\u03bc","\u03af","\u03c2",","," ","\\xe1\\xbc","\\x91","\u03b2","\u03b5\u03b9","\u03c4","\u03b1"," ","\\xe1\\xbc","\\x80","\u03bc","\u03b5","\\xe1\\xbf","\\x96"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["choice","."," Some"," good"," v","egan","-","friendly"," options"," include"," z","uc","ch","ini",","," sweet"," pot","atoes",","," carr","ots",","," on","ions",","," bell"," pep","pers",","," and"," mush","rooms",".","\u23ce\u23ce","3","."," Place"," the"," cho","pped"," vegetables"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["that",".\""," \"","You"," can"," use"," it"," for"," carp","ets",","," for"," pill","ows",","," for"," sheets"," or"," curt","ains","..."," or"," covers"," for"," bicycle"," seats",".\""," \"","Sir",","," you","'re"," crazy",".\""," \"","You","'re"," crazy"," with"," gr","eed"]}]}],"top_logits":["carr","veget","vegetables","garden","gardens","juice","veg","fields","Garden","farms"],"bottom_logits":["Marshall","ving","oft","rigen","idid","aber","anat","abol","mel","absor"]}