{"index":21323253,"examples_quantiles":[{"quantile_name":"Top Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.24,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," sw","amp"," now",","," with"," his"," fuc","kin","'"," eyes"," hanging"," out"," in"," the"," sand",","," and"," the"," sand"," cr","abs"," eating"," them",".\""," \"","I"," don","'t"," int","end"," on"," going"," down"," for"," this"," shit",","," so"," if"," any"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.42,0.98,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a"," great"," town",".\""," \"","Sea"," sc","all","ops"," with"," three"," ca","vi","ars",".\""," \"","The","\u2191"," Dung","eness"," cr","abs",".\""," \"","\u2191"," Pepper","?\""," \""," No",".\""," \"","What","'s"," the"," matter","?\""," \"","Nothing",".\""," \"","They"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.46,0.26,0.98,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","l",">","i","\"","\u2191"," Promotion"," Of","\u23ce","\u2191"," Al","as","kan","\u2191"," W","onders","\u23ce"," Alaska"," King","\u2191"," C","rab"," will"," get"," the","\u23ce"," royal"," treatment"," in"," a"," sales"," pr","omo","\u23ce"," ","tion"," announced"," by","\u2191"," S","ears"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.24,0.03,0.0,0.0,0.0,0.0,0.35,0.96,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ipe",","," because"," of"," its"," fond","ness"," for"," t","ho","\u23ce"," hor","se","foot"," or"," h","orc","te","eh","oo"," c","rab","."," It"," is","\u23ce"," called"," also"," t","ho"," turn","st","ono",","," from"," its","\u23ce"," habit"," of"," over","tur"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.54,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["view",".","\u23ce","\u2191","Chi","tin"," is"," a"," known"," material"," which"," may"," be"," obtained"," from"," various"," marine"," sources"," such"," as"," cr","abs"," and"," the"," like",".","\u2191"," Chi","tin"," from"," cr","abs"," has"," been"," utilized"," in"," procedures"," for"," the"," isolation",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.55,0.83,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.21,0.0,0.0,0.0,0.0,0.08,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["he","eling"," that"," allows"," a"," vehicle"," body"," to"," be"," turned"," or"," pin","w","he","eled"," about"," the"," center"," thereof",","," and"," lateral"," movement"," that"," allows"," the"," vehicle"," body"," to"," be"," moved"," directly"," sidew","ays","."," Therefore",","," gar","aging",","," movement"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.82,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["  ","b","ai","'","n","acle"," \u2014"," a","  ","creature","  ","closely","  ","related"," ","\u23ce","to","  ","the","  ","cr","abs","  ","and","  ","lob","sters",",","  ","thus","  ","mim","icking",",","  ","as","  ","it"," ","\u23ce","were"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.07,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["home"," to"," over"," ","3",",","600"," ","species",","," including"," many"," iconic"," species"," such"," as"," rock","fish",","," blue"," c","rab"," and"," oy","sters","."," The"," interd","ep","endent"," web"," of"," life"," in"," the","\u2191"," Ches","ape","ake"," Bay"," is"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," it","'s"," a"," rather"," dim"," constellation",".\""," \"","Out"," of"," it",","," the"," old"," ast","rolog","ers"," made"," a"," c","rab",","," like"," this",".\""," \"","And"," having"," done"," so",","," they"," prompt","ly"," assigned"," to"," it"," wa","tery"," characteristics"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.39,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["in"," a"," circle",".\""," \"","Then"," consider"," the"," next"," constellation"," of"," the"," zod","iac",","," which"," is"," cancer",","," the"," cr","abs",".\""," \"","Now"," the"," stars"," of"," cancer"," are"," like"," that",","," they"," are"," not"," very"," bright",","," it","'s"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Side"," Up","\u2191"," Eggs"," ","\u23ce","-","\u2191","","Fried","\u2191"," Ban","anas"," ","\u23ce","-","\u2191","Dev","iled","\u2191"," Cr","abs"," ","\u23ce","-","\u2191","S","aut","\u00e9","ed","\u2191"," Mush","rooms"," ","\u23ce","-","Green"," Bean","\u2191"," Sal","ad"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.0,0.0,0.0,0.77,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["wild"," fow","l"," on","\u23ce"," the"," Atlantic"," coast",":"," oy","sters","."," b","ard"," and"," a","oft"," dam","*","."," cr","alia","\u23ce"," and"," f","lab"," in"," abundance"," in"," t",",-","","ason","."," no"," ni","alar","ia","or"," i","nos"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.74,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.29,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["easily"," ba","ited"," with"," liver"," or"," flesh",","," to"," which"," they"," nib","ble"," most"," gr","eed","ily","."," THE","\u21ea"," C","RAB"," Is"," an"," water","."," amp","hib","ious"," animal",";"," living"," on"," land"," and"," m"," The"," common","\u2191"," C","rab"]},{"tokens_acts_list":[0.09,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.73,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["c","rab"," cake"," that"," looks"," del","icious","!"," To"," make"," it",","," you","'ll"," need"," to"," gr","ind"," up"," some"," c","rab"," meat"," in"," a"," bl","ender",","," add"," some"," bread","cr","um","bs",","," egg",","," and"," on","ion",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.73,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.27,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","'re"," a"," carrier",".\""," \"","A"," disease"," r","idden"," sl","ut",".\""," \"","What","?\""," \"","!\""," \"","\u2191","Cr","abs",","," baby",".\""," \"","You"," gave"," me"," the"," cr","abs",".\""," \"","I"," don","'t"," have"," cr","abs",".\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.39,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".\""," \"","So"," what"," is"," this"," big"," news","?\""," \"","Did"," the"," health"," inspector"," find"," out"," that"," the"," im","itation"," c","rab"," meat"," is"," cat","?\""," \"","\u2191","Technically",","," it","'s"," im","itation"," cat",","," but"," that","'s"," not"," what"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","ti"," M","ank","are","L","\u2191"," Hal","ib","ut",".","\u2191"," E","els"," ."," Hard"," and","\u2191"," Soft","\u2191"," Cr","abs",",","\u23ce","\u2191","Cl","ams",",","\u2191"," Lob","sters",",","\u2191"," Oy","sters",",","\u2191"," Etc",".,","\u2191"," Etc"]},{"tokens_acts_list":[0.37,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.37,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.52,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["cr","abs"," from"," local"," seaf","ood"," markets"," or"," grocery"," stores",".","\u23ce","4",".","\u2191"," C","anned"," or"," pack","aged"," c","rab","m","eat"," from"," trusted"," brands"," that"," source"," their"," cr","abs"," from"," sustainable"," and"," ethical"," sources",".","\u23ce\u23ce","It"," is"]}]},{"quantile_name":"Subsample Interval 0","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.46,0.26,0.98,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["\u23ce","l",">","i","\"","\u2191"," Promotion"," Of","\u23ce","\u2191"," Al","as","kan","\u2191"," W","onders","\u23ce"," Alaska"," King","\u2191"," C","rab"," will"," get"," the","\u23ce"," royal"," treatment"," in"," a"," sales"," pr","omo","\u23ce"," ","tion"," announced"," by","\u2191"," S","ears"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.24,0.03,0.0,0.0,0.0,0.0,0.35,0.96,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["ipe",","," because"," of"," its"," fond","ness"," for"," t","ho","\u23ce"," hor","se","foot"," or"," h","orc","te","eh","oo"," c","rab","."," It"," is","\u23ce"," called"," also"," t","ho"," turn","st","ono",","," from"," its","\u23ce"," habit"," of"," over","tur"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.54,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["view",".","\u23ce","\u2191","Chi","tin"," is"," a"," known"," material"," which"," may"," be"," obtained"," from"," various"," marine"," sources"," such"," as"," cr","abs"," and"," the"," like",".","\u2191"," Chi","tin"," from"," cr","abs"," has"," been"," utilized"," in"," procedures"," for"," the"," isolation",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.55,0.83,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.21,0.0,0.0,0.0,0.0,0.08,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["he","eling"," that"," allows"," a"," vehicle"," body"," to"," be"," turned"," or"," pin","w","he","eled"," about"," the"," center"," thereof",","," and"," lateral"," movement"," that"," allows"," the"," vehicle"," body"," to"," be"," moved"," directly"," sidew","ays","."," Therefore",","," gar","aging",","," movement"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.82,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["  ","b","ai","'","n","acle"," \u2014"," a","  ","creature","  ","closely","  ","related"," ","\u23ce","to","  ","the","  ","cr","abs","  ","and","  ","lob","sters",",","  ","thus","  ","mim","icking",",","  ","as","  ","it"," ","\u23ce","were"]}]},{"quantile_name":"Subsample Interval 1","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.07,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["home"," to"," over"," ","3",",","600"," ","species",","," including"," many"," iconic"," species"," such"," as"," rock","fish",","," blue"," c","rab"," and"," oy","sters","."," The"," interd","ep","endent"," web"," of"," life"," in"," the","\u2191"," Ches","ape","ake"," Bay"," is"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":[","," it","'s"," a"," rather"," dim"," constellation",".\""," \"","Out"," of"," it",","," the"," old"," ast","rolog","ers"," made"," a"," c","rab",","," like"," this",".\""," \"","And"," having"," done"," so",","," they"," prompt","ly"," assigned"," to"," it"," wa","tery"," characteristics"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.39,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["in"," a"," circle",".\""," \"","Then"," consider"," the"," next"," constellation"," of"," the"," zod","iac",","," which"," is"," cancer",","," the"," cr","abs",".\""," \"","Now"," the"," stars"," of"," cancer"," are"," like"," that",","," they"," are"," not"," very"," bright",","," it","'s"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["Side"," Up","\u2191"," Eggs"," ","\u23ce","-","\u2191","","Fried","\u2191"," Ban","anas"," ","\u23ce","-","\u2191","Dev","iled","\u2191"," Cr","abs"," ","\u23ce","-","\u2191","S","aut","\u00e9","ed","\u2191"," Mush","rooms"," ","\u23ce","-","Green"," Bean","\u2191"," Sal","ad"]}]},{"quantile_name":"Subsample Interval 2","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.39,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":[".\""," \"","So"," what"," is"," this"," big"," news","?\""," \"","Did"," the"," health"," inspector"," find"," out"," that"," the"," im","itation"," c","rab"," meat"," is"," cat","?\""," \"","\u2191","Technically",","," it","'s"," im","itation"," cat",","," but"," that","'s"," not"," what"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["\u23ce","ti"," M","ank","are","L","\u2191"," Hal","ib","ut",".","\u2191"," E","els"," ."," Hard"," and","\u2191"," Soft","\u2191"," Cr","abs",",","\u23ce","\u2191","Cl","ams",",","\u2191"," Lob","sters",",","\u2191"," Oy","sters",",","\u2191"," Etc",".,","\u2191"," Etc"]},{"tokens_acts_list":[0.37,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.37,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.52,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["cr","abs"," from"," local"," seaf","ood"," markets"," or"," grocery"," stores",".","\u23ce","4",".","\u2191"," C","anned"," or"," pack","aged"," c","rab","m","eat"," from"," trusted"," brands"," that"," source"," their"," cr","abs"," from"," sustainable"," and"," ethical"," sources",".","\u23ce\u23ce","It"," is"]},{"tokens_acts_list":[0.0,0.48,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["consuming"," cr","abs"," and"," other"," types"," of"," cr","ust","ac","eans","."," In"," order"," to"," extract"," the"," meat"," of"," the"," cr","ust","ac","ean",","," the"," individual"," must"," first"," crack"," the"," outer"," shell","."," It"," can"," be"," difficult"," to"," open"," a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.69,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["and"," sim","pler"," rec","ue"," forms"," of"," cooking"," are"," dominant"," up"," north","."," Different"," types"," of"," fresh"," fish",","," picked"," cr","abs"," and"," sn","ails"," are"," sta","ples",","," along"," with"," free","-","range"," red","-"," as"," well"," as"," cat","la"]}]},{"quantile_name":"Subsample Interval 3","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.28,0.26,0.61,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[":","\u23ce\u23ce","    ","\u23ce","    ","\u23ce","       ","What"," about"," lunch","?","\u23ce","       ","The"," lob","ster"," or"," the"," cr","acked"," c","rab","?","\u23ce","       ","What"," do"," you"," think","?","\u23ce","    ","\u23ce","       ","Can","'t"," we"," have"," both","?","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.15,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["picked"," out"," and"," is"," called"," tl","ake"," t","\u23ce"," which"," is"," very"," del","icious"," either"," made"," in"," (","\u23ce","devil"," cr","abs"," are"," in"," c","roqu","ets"," a","nil"," some"," of","\u23ce"," our"," enterpr","ising"," pac","kers"," are"," also"," c","anning"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.23,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["incomp","et","\u23ce"," ","ency"," as"," an"," expert"," witness"," by"," om","it","\u23ce"," ","ting"," chicken"," catalana",","," stone","-","c","rab","\u23ce"," sal","ad"," and"," bro","iled"," pomp","ana","."," For"," the","\u23ce"," benefit"," of"," the","\u2191"," Pens","ac","ola"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.59,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08,0.32,0.08],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["behind"," him","."," \"","Why"," does"," he"," drag"," his"," house"," after"," him","?\""," laugh","ed"," Bobby",","," as"," we"," watched"," c","rab"," and"," shell"," moving"," away","."," \"","Because",",\""," explained","\u2191"," Bun","ny",","," \"","although"," that"," herm","it","-"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.59,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","which","  ","the","  ","animal","  ","adh","eres","  ","to","  ","the","  ","body","  ","of","  ","the","  ","c","rab",","," ","\u23ce","are","  ","seen","  ","to","  ","grow","  ","out","  ","of","  ","the","  ","ends","  "]}]},{"quantile_name":"Subsample Interval 4","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.51,0.0,0.0,0.0,0.0,0.07,0.29,0.67,0.0,0.0,0.0,0.0,0.25,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["A","Y",",","\u2191"," Cl",".","r","k",".","\u23ce","apr",".","7"," ","td"," f"," |","\u23ce","Hard","\u2191"," Cr","aba",",","\u2191"," Dev","iled","\u2191"," Cr","abi"," and","\u23ce","\u2191"," C","rab","\u2191"," Sal","ad",",","\u23ce","AT","\u21ea"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.51,0.0,0.0,0.15,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["but"," the"," result"," was"," far"," from"," perfect","."," He"," had"," created"," gru","esome"," creatures"," that"," were"," part"," cat"," and"," part"," c","rab","\u2014","c","rab","c","ats","."," They"," had"," the"," ag","ility"," and"," ste","alth"," of"," cats",","," along"," with"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\"","'\""," \"'","Is"," that"," a"," walking"," rock","?\""," \"","'\""," \"'","No",","," dar","ling",","," that","'s"," a"," c","rab",".'"," ","'","Ha","-","ha",","," id","iot",".","'\""," \"'","Donald",".","'\""," \"'","Amy","'s"," hur"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["marsh","es",","," and"," wet","lands","."," These"," hab","itats"," support"," a"," diverse"," array"," of"," species",","," including"," fish",","," cr","abs",","," oy","sters",","," and"," cl","ams",".","\u2191"," Nutrients"," from"," the"," land",","," rivers",","," and"," ocean"," create"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["also"," ","\u23ce","divided","  ","and","  ","for","ked",".","    ","\u2191","Seeking","  ","and","  ","finding","  ","a","  ","c","rab","-"," ","\u23ce\u23ce\u23ce","ty","])","e",".","  ","S","[",")","ace","  ","will","  ","permit","  ","of","  "]}]},{"quantile_name":"Subsample Interval 5","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.14,0.41,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["and"," decor","ations","\u23ce","3","."," ","3",":","\u2191"," Sn","acks"," and","\u2191"," Dess","erts",":","\u2191"," Ch","ili"," c","rab"," p","uf","fs",","," lak","sa"," leaves",","," ch","end","ol",","," and","\u2191"," M","erl","ion","-","shaped"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["man","oe","uvre",","," turn"," around"," corners"," etc","."," More"," importantly",","," moving"," such"," a"," vehicle"," sidew","ays"," will"," involve"," \"","ker","b"," side"," parking","\"."," Therefore",","," a"," number"," of"," assist","ive"," drive"," technologies"," have"," been"," developed",","," which"," supply"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["to"," s","pi","ing"," off","."," His"," proc","ession"," is"," pre","post","erous",","," as"," well"," as"," all"," of"," the"," c","rab"," kind","."," Besides"," his"," cl","aws",","," he"," has"," four"," small"," legs"," on"," each"," side"," to"," assist"," him"," in"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["we"," prefer"," it"," to"," the"," famous"," southern","\u23ce"," ","fried"," chicken",".","\u23ce","To"," a"," person"," who"," never"," saw"," a"," c","rab","\u23ce"," scr","ape"," they"," would"," never"," imagine"," what","\u23ce"," it"," was"," for","."," It"," is"," made"," very"," much"," like"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.44,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.47,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["ba","its"," such"," as"," c","rab","."," ","\u23ce\u23ce","Human",":"," ","\u23ce","Is"," it"," necessary"," to"," refrig","erate"," fresh"," c","rab"," b","ait"," while"," storing"," it",","," or"," is"," that"," option"," only"," available"," to"," long"," term"," storage","?","\u23ce\u23ce","Assistant"]}]},{"quantile_name":"Subsample Interval 6","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["!\""," \"","Let"," me"," introduce"," the"," first"," course",".\""," \"","This"," dish"," is"," awesome",".\""," \"","It","'s"," called","\u2191"," C","arp"," entering"," Dragon"," Gate","\""," \"","Hope"," you","'ll"," enter"," the"," hall"," of"," fame"," after"," eating"," this",".\""," \"","Just"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.14,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["growth"," of"," the"," insects","'s"," population"," functioning"," at"," their"," optimal"," level","."," Additionally",","," if"," possible",","," take"," your"," herm","it"," c","rab"," out"," of"," the"," cage"," occasionally"," to"," give"," them"," more"," room"," and"," fresh"," air",".","\u23ce","<","|","stop"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","\u041a\u0440\u0430","\u0431\u043e\u043b","\u043e\u0432","\u044b"," \u043c\u043e\u0433","\u0443\u0442"," \u0438\u0441\u043f\u043e\u043b\u044c\u0437","\u043e\u0432","\u0430\u0442\u044c"," \u0440\u0430\u0437\u043b\u0438\u0447","\u043d\u044b\u0435"," \u0442\u0438\u043f","\u044b"," \u0441","\u0435\u0442","\u0435\u0439"," \u0434\u043b\u044f"," \u043b","\u043e\u0432\u0430"," \u043a\u0440","\u0430\u0431","\u043e\u0432",","," \u0442\u0430\u043a","\u0438\u0435"," \u043a\u0430\u043a"," \u0442","\u0440\u0430\u043b","\u044b",","," \u0436","\u0430","\u0431\u0435\u0440","\u043d\u044b\u0435"," \u0441","\u0435\u0442\u0438",","," ","\u043b\u043e\u0432","\u0443\u0448"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["del","icious",".\""," \"","Jeff"," is"," an"," incredible"," chef",".\""," \"","He"," gave"," me"," a"," recipe"," for","...\""," \"","\u2191","C","rab","\u2191"," Lou","ie"," that"," was"," out"," of"," this"," world",".\""," \"","Really","?\""," \"","Yeah",".\""," \"","What","?\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.06,0.37,0.0,0.0,0.0,0.0,0.0,0.0,0.32,0.1,0.42,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["cou","gar",","," ","352",".","\u2191"," Cow",","," sea",","," ","307",".","\u2191"," Cow","ry",","," ","63",".","\u2191"," C","oy","o","t\u00e9",","," ","350",".","\u2191"," Cr","abs",","," g","I",".","\u2191"," C","ray","-"]}]},{"quantile_name":"Subsample Interval 7","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["."," It","'s"," also"," fairly"," easy"," to"," hop"," over"," to"," the","\u2191"," Al","as","kan"," peninsula"," and"," go"," fishing",","," c","rab","bing",","," and"," whale"," watching","."," Of"," course"," you"," can"," also"," see"," the"," northern"," lights","."," In"," contrast",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["doing"," dishes",".","  ","You","'re"," not"," allerg","ic"," to"," shell","fish",","," and"," you","'re"," eating"," fish"," and"," not"," cr","ust","ac","eans","?","  ","Are"," there"," a"," lot"," of"," fish"," in"," this"," river","?","\u23ce","<","|","stop","|"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["bl","v","d",",","\u2191"," Cul","ver"," City",","," CA"," ","90","232","\u23ce","10",".","\u2191"," Cut","ters","\u2191"," C","rab","house"," -"," ","606"," ","\u2191","Cont","int","ental","\u2191"," Bl","v","d",","," El","\u2191"," Segundo",","," CA"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["2","   ","\u2191","G\u0142\u00f3w","ne"," gat","un","ki"," w"," wy","\u0142ad","unk","ach"," to"," prz","eg","rz","eb","ki",","," kr","aby",","," sz","pr","oty"," i"," sard","yn","ki","."," ","7","."," ","4","."," ","3","   ","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["E","."," ","9",","," ","30","."," ","\u23ce\u23ce","48",".","\u2191"," Damp","f"," ver","br","ann","ter","\u2191"," K","reb","se"," ","\u23ce","bra","uch","te"," man"," als","\u2191"," Mit","tel"," bei"," versch","ie","-"," ","\u23ce","d","enen"]}]},{"quantile_name":"Subsample Interval 8","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["E","icher","The"," NAME","_","4"," ","This"," Week",":","The","\u2191"," Ly","rid"," meteor"," shower"," pe","aks","Watch"," the"," cr","escent"," NAME","_","1"," ","slide"," by"," Venus",":"," This"," Week"," in","\u2191"," Astronomy"," with"," NAME","_","5"," ","E"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["here"," and"," was"," buried"," at"," Turkey","-","1"," ","memorial"," silver"," cup","."," Then",","," sudden"," town",","," rear","\u2191"," C","rab","\u2191"," Or","chard",","," last","\u2191"," S","atur","-","l","ly"," he"," wa","."," transferred"," from"," the"," train"," day"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["_"," of"," lead","\u23ce"," sh","iel","ding",".","\u2191"," Trit","ium"," bel","ts"," out"," about"," ","9","650"," ","\u2191","C","uries"," of"," radiation"," per"," gram"," in"," the","\u23ce"," shape"," of"," beta"," radiation",","," which"," is"," enough"," to"," kill"," you"," _"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["your"," overall"," mental"," well","-","being"," and"," increase"," your"," chances"," of"," survival",".","\u23ce\u23ce","Human",":"," You"," attempt"," to"," kill"," a"," se","ag","ull"," that"," has"," landed"," near"," you"," with"," the"," ","2","\""," rock","."," You"," miss","."," The"," rock"]}]},{"quantile_name":"Bottom Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":16,"is_repeated_datapoint":false,"tokens":["<EOT>","Take"," My"," Staff"," and"," Meet"," Me"," for"," That"," Him"," Making","\u2191"," Believes"," of"," the","\u2191"," C","rip","pling"," Economic"," Effects"," of"," the"," Oil"," Crisis","\u2191"," Increase"," Crime","\u2191"," Expon","ential"," Him"," Him"," Today"," to"," Shopping"," for"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," Queen",","," J","."," Duncan",","," agent"," \u2014"," ","13"," ","bags"," flour",","," ","1"," ","k","eg"," cr","ock","ery",","," ","1"," ","bag"," sugar",","," Johnston"," &"," Co","."," $","1"," ","box",",","\u2191"," Pot"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["The"," two"," top"," articles"," (","Why"," Docker"," isn","'t","\u2191"," Successful"," in"," Production",")"," and"," this","\u23ce"," one"," are"," both"," c","ries"," for"," the"," world"," to"," slow"," down","."," It","'s"," not"," going"," to"," and"," everyone","\u23ce"," ought"," to"," ","strap"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["pot","atoes","\u23ce","\u2191"," Seaf","ood","\u23ce","\u2191"," Sug","ars"," and","\u2191"," Sw","eets","\u23ce","\u2191"," Dairy"," Products","\u23ce","\u2191"," C","ats","up"," (","tom","ato"," sauce",")","\u23ce","Ice","\u2191"," Cream","\u2191"," Bars","\u23ce","\u2191"," Yog","urt","\u23ce","\u2191"," Butter"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["66"," ","to"," effect"," position"," displacement"," of"," the"," road","wh","eel"," ","34","B"," utilizing"," the"," positioning"," mechanism"," ","72"," ","and"," the"," electric"," motor"," ","74","."," A"," zero"," result"," of"," the"," comparison"," indicates"," that"," the"," desired"," steering"," direction"," of"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","891",";","\u2191"," M","agen"," ","651",";","\u2191"," Fib","rom","y","om"," ","540",";"," ","\u23ce","\u2191","C","arc","inom"," ","684",";","\u2191"," S","yph","ilis"," der","\u2191"," Vag","inal","-"," ","\u23ce","portion"," ","925"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","<","\u2191","M","oo","q","ball",">"," and"," it"," recogn","izes"," that"," its"," an"," ethernet"," cable"," and"," starts"," to"," c","rank","."," status",":"," IP"," Configuration","."," Then"," it"," stops",","," and"," returns"," to"," grey"," globe",".","\u23ce","<","v"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["me",".\""," \"","I"," rem","ixed"," that","\u2191"," Scr","ew","face"," track"," and"," took"," it"," to"," a"," next"," level",","," c","uz",".\""," \"","\u2191","Seen",","," seen",".\""," \"","Yeah",","," true",","," this"," is"," the"," ","ting",","," f"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["  ","addressed",".","  ","If","  ","you","  ","ass","ent",",","  ","then","  ","am","  ","I","  ","to","  ","c","rave","  ","a"," ","\u23ce","b","older","  ","courtesy",",","  ","which","  ","is",",","  ","that","  ","you","  "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["inely"," like"," each"," other","."," Well",","," maybe"," that","'s"," a"," problem"," itself","."," We"," tend"," to","\u23ce"," form"," into"," c","ults"," and"," we"," are"," too"," ignor","ant"," with"," what"," else"," is"," going"," on"," in"," the","\u23ce"," world",","," hence"," we"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["problems"," such"," as"," inadequ","ate"," condens","ation"," resistance"," of"," the"," surf","a","cer"," co","ats",","," cr","acking"," (","mud"," cr","acking",")"," in"," the"," base","co","ats",","," or"," lev","eling"," def","ects"," or"," surface"," structures"," in"," the"," clear","co"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["085","911","871","499","032"," ","Transform",":"," m","_","Object","H","ide","Flags",":"," ","0"," ","m","_","","Cor","res","pond","ing","Source","Object",":"," {","file","ID",":"," ","0","}"," m","_","P","ref","ab","Instance"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.19,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["lovely"," close","-","up"," of"," your"," el","bow",".\""," \"","Now"," go"," away"," and"," hide"," some","place"," and"," play"," herm","it",","," will"," you","?\""," \"","\u2191","","Aw",",","\u2191"," C","urt",","," have"," a"," heart",".\""," \"","I"," haven"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","requiring","  ","the","  ","kind","ly","  ","aid","  ","of","  ","some","  ","prof","essed","  ","\"","surgeon"," ","\u23ce","to","  ","the","  ","\u2191","Cru","sta","cea","  ","\"","  ","for","  ","its","  ","removal",".","  ","Each","  "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ter"," armed"," with"," piano"," wire","...","\u23ce","<","d","af","ty","kins",">"," she","esh"," -","8"," ","with"," wind"," c","hill","\u23ce","<","zm","oy","lan","-","pi",">"," -","2","c"," here"," before"," you"," try"," and"," calc","ual","te"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","degrees"," and"," the"," rear"," wheels"," are"," ste","ered"," at"," the"," same"," angles"," as"," the"," front"," wheels",","," the"," vehicle"," will"," make"," a"," small"," ex","cess","ively"," sharp"," turn"," with"," a"," result","ant"," s","wer","ve"," of"," the"," rear"," end"," of"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["c","'","est"," une"," vr","aia"," bou","che"," d","'","en","fer","."," ","\u23ce","\u2014"," Oh"," !"," Christie"," ne"," cr","aint"," ","rien"," :"," il"," t","rom","pa"," la"," mort"," !"," ","\u23ce","\u2191","Deux"," d\u00e9","ton","ations"," rap","ides"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["adjust"," a"," length"," of"," the"," ped","al"," c","rank",","," to"," continuously"," adjust"," a"," stroke"," length"," of"," the"," ped","al"," c","rank",".","\u23ce","With"," the"," invention",","," at"," low"," speeds"," (","e",".","g",".,"," low"," in"," regard"," to"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["186","."," ","\u23ce","1","872",".","\u2191"," Thom","is","us"," dep","ress","us"," Thor",".,","\u2191"," Rem","."," on","\u2191"," Syn","."," p","."," ","251","."," ","\u23ce\u23ce\u23ce","\u2191","Ra","zo","um","owski"," g","ie","bt"," sie"," aus"," dem"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["it"," is"," highly"," likely"," ","tat"," old"," folks"," drive"," very"," carefully"," and"," brake"," l","ightly",","," and"," that"," leads"," to"," c","ali","pers"," se","izing"," up"," from"," not"," being"," used",","," which"," lead"," to"," un","even"," pad"," wear"," -"," only"," using"]}]}],"top_logits":["rab","c","ab","abs","AB","Ab"],"bottom_logits":["numberUS","inav","ienien","capac","\u043f\u0456\u0432\u043d\u0456","olare","\u0431\u0440\u043e\u044f","ationBiBTeX","capacity","\u304c\u304c"]}