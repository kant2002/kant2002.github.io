{"index":7502664,"examples_quantiles":[{"quantile_name":"Top Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["f","arth","est","):"," ...","\u23ce","Health",":"," Higher"," than"," ","15"," ","means"," I","'m"," healthy",".","\u23ce","\u2191","Hunger",":"," Higher"," than"," ","15"," ","means"," I","'m"," not"," hungry",".","\u23ce","Position",":"," ...","\u23ce","Equipment",":"," If"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.97,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ins","ecurity","."," Food"," ins","ecurity"," is"," a"," global"," problem"," that"," is"," affecting"," rich"," and"," poor"," countries"," alike",".","\u2191"," Hunger"," and"," mal","nut","r","ition"," are"," significant"," issues"," in"," both"," the"," developed"," and"," developing"," world","."," ","\u23ce","It","'s"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.97,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.46,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["https","://","www",".","unic","ef",".","org","/","topics","/","food","-","security"," ","\u23ce","9","."," World","\u2191"," Hunger"," Education"," Service",":"," http","://","www",".","world","h","un","ger",".","org","/"," ","\u23ce\u23ce","Human",":"," ","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.97,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["decrease"," my"," food"," c","rav","ings","?"," ","\u23ce\u23ce","Assistant",":"," ","\u23ce","1",".","\u2191"," Drink"," water",".","\u2191"," Hunger"," can"," often"," mas","qu","erade"," as"," c","rav","ings",".","\u2191"," Drinking"," a"," glass"," of"," water"," can"," help"," reduce"," feelings"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.96,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["blues"," guitar"," win","dy",".","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","Who"," s","ings"," the"," song"," \"","\u2191","Hunger","\"","\u23ce\u23ce","Assistant",":"," The"," song"," \"","\u2191","Hunger","\""," is"," performed"," by"," the"," Irish"," rock"," band"," Florence"," +"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.96,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["very"," few"," limits"," to"," what"," can"," be"," done",".","\u2191"," Entire"," separate"," games","\u23ce","(","e",".","g",".","\u2191"," Hunger"," Games"," mod",")"," have"," been"," implemented",".","\u23ce\u23ce","Also",","," it","'s"," one"," of"," the"," best","-","selling"," games"," of"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.96,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ox","f","am","ame","rica",".","org","/","explore","/","food","-","security","/"," ","\u23ce","4","."," The","\u2191"," Hunger"," Project",":"," https","://","www",".","th","p",".","org","/","our","-","work","/","food","-","security"," ","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.96,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["would"," be"," happy"," to"," help"," you"," with"," that",","," here"," is"," some"," initial"," draft"," text",":"," ","\u23ce","\"","\u2191","Hunger"," and"," hom","eless","ness"," continue"," to"," be"," pressing"," issues"," in"," our"," city",","," and"," many"," individuals"," live"," on"," the"," streets"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","H","ux","ley","\u23ce","7","."," The"," Road"," by","\u2191"," C","orm","ac"," McCarthy","\u23ce","8","."," The","\u2191"," Hunger"," Games"," by","\u2191"," Suz","anne"," Collins","\u23ce","9","."," The","\u2191"," Gr","apes"," of","\u2191"," W","rath"," by"," John","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["teenage"," readers","?","\u23ce\u23ce","Assistant",":"," ","\u23ce","The","\u2191"," Fault"," in"," Our"," Stars"," by"," John"," Green","\u23ce"," The","\u2191"," Hunger"," Games"," by","\u2191"," Suz","anne"," Collins","\u23ce","\u2191"," Per","ks"," of"," Being"," a","\u2191"," Wall","fl","ower"," by"," Stephen","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","\u23ce","7","."," The","\u2191"," Al","chem","ist"," by"," Paulo","\u2191"," Co","elho"," ","\u23ce","8","."," The","\u2191"," Hunger"," Games"," by","\u2191"," Suz","anne"," Collins"," ","\u23ce","9","."," Harry"," Potter"," Series"," by"," J",".","K",".","\u2191"," Row"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","\u23ce\u23ce","Assistant",":"," ","\u23ce","1","."," Normal"," People"," by"," Sally","\u2191"," Ro","oney","\u23ce","2","."," The","\u2191"," Hunger"," Games","\u2191"," Trilogy"," by","\u2191"," Suz","anne"," Collins","\u23ce","3","."," The"," Power"," by","\u2191"," Na","omi","\u2191"," Ald","erman"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.86,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["host","ess"," served"," a","\u23ce"," d","ain","ty"," l","unch","eon",".","\u23ce","Mrs","."," C","."," H",".","\u2191"," Hunger"," and"," Miss","\u2191"," M","yr","tle","\u23ce","\u2191"," Hunger"," were"," ","1"," ","host","esses"," Tuesday"," even","\u23ce"," ing"," to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","1","."," The","\u2191"," G","iver"," by","\u2191"," L","ois","\u2191"," Low","ry"," ","\u23ce","2","."," The","\u2191"," Hunger"," Games"," by","\u2191"," Suz","anne"," Collins","\u23ce","3","."," To"," Kill"," a","\u2191"," Mock","ing","bird"," by"," Harper"," Lee","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","Hob","bit"," by"," J",".","R",".","R",".","\u2191"," Tolk","ien"," ","\u23ce"," ","9","."," The","\u2191"," Hunger"," Games"," by","\u2191"," Suz","anne"," Collins"," ","\u23ce"," ","10","."," Gone"," with"," the"," Wind"," by"," Margaret"," Mitchell"," ","\u23ce\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["elho"," ","\u23ce","5","."," The","\u2191"," Mart","ian"," by"," Andy","\u2191"," We","ir"," ","\u23ce","6","."," The","\u2191"," Hunger"," Games"," by","\u2191"," Suz","anne"," Collins"," ","\u23ce","7","."," The","\u2191"," Hob","bit"," by"," J",".","R",".","R"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.94,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["D",".","\u2191"," Sal","inger",","," Of","\u2191"," Mice"," and"," Men"," by"," John","\u2191"," Stein","b","eck",","," The","\u2191"," Hunger"," Games"," by","\u2191"," Suz","anne"," Collins",","," and"," The"," Book","\u2191"," Th","ief"," by","\u2191"," Mark","us","\u2191"," Zus","ak"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.94,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Goals"," of"," United"," Nations","?","\u23ce\u23ce","Assistant",":"," ","\u23ce","1","."," No","\u2191"," Poverty","\u23ce","2","."," Zero","\u2191"," Hunger","\u23ce","3","."," Good"," Health"," &"," Well","-","Being","\u23ce","4","."," Quality"," Education","\u23ce","5","."," Gender","\u2191"," Equality"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.94,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["'","The"," Lord"," of"," the","\u2191"," Rings","',"," ","'","The","\u2191"," Hob","bit","',"," and"," ","'","The","\u2191"," Hunger"," Games","'.","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","How"," do"," you"," make"," a"," paper"," airplane","."," ","\u23ce\u23ce"]}]},{"quantile_name":"Subsample Interval 0","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.91,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["brother",".\""," \"\"","Welcome","\u2191"," Ra","izo","\"","\""," \"","The"," body"," must"," ob","ey"," the"," will",".\""," \"","\u2191","Hunger"," and"," th","irst",","," even"," the"," blood"," in"," your"," ve","ins",","," are"," the"," body","'s"," weak","nesses",".\""," \""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.91,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["24",".","   ","\"","The","\u2191"," Hob","bit","\""," by"," NAME","_","4","\u23ce","25",".","   ","\"","The","\u2191"," Hunger"," Games","\""," by"," NAME","_","5","\u23ce","26",".","   ","\"","The","\u2191"," D","une"," Chronicles","\""," by"," NAME","_"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," but"," a"," bit"," ed","g","ier"," than","\u2191"," Tolk","ien","."," It"," might"," feel"," a"," bit"," like"," The","\u2191"," Hunger"," Games"," or"," The","\u2191"," Wizard"," of","\u2191"," Oz","."," Another"," series"," I"," like"," is","\u2191"," Nar","nia",","," and"," there"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["bank",","," or"," to"," raise"," awareness"," of"," the"," issue"," by"," hosting"," inform","ational"," events"," in"," your"," community"," about"," the"," local"," hunger"," problem"," or"," about"," how"," you"," can"," get"," involved",".","\u23ce\u23ce","Human",":"," ","\u23ce","Good"," ideas",","," how"," about"," if"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["and"," low",","," and"," get"," the"," clear"," text",".","\u23ce\u23ce","<EOT>","\u23ce","21",",","000"," ","People"," Die"," from","\u2191"," Hunger"," Each"," Day","."," What"," Can"," You"," Do","?"," -"," andy","\u23ce"," https","://","medium",".","com","/@","and","yt","ri"]}]},{"quantile_name":"Subsample Interval 1","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["d","red","m","orb","ius","\u23ce","_","The"," green"," revolution"," has"," won"," a"," temporary"," success"," in"," man","'s"," war"," against"," hunger","\u23ce"," and"," dep","riv","ation",";"," it"," has"," given"," man"," a"," breathing"," space","."," If"," fully"," implemented",","," the","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["orf"," ,"," der","\u2191"," An","bl","ick"," me","ines","\u2191"," V","ater","ha","uses"," erw","ec","kt"," me","inen","\u2191"," Hunger"," ."," \""," \u201e",""," Es"," wird"," mir"," schw","er"," ,"," hin","un","ter"," zu"," ste","igen"," ,"," d","enn"," me"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ienen"," bev","\u00f6l","k","ert",".","\u2191"," Let","zte","\u23ce","\u2191"," W","oche"," n","\u00f6","th","i","gte"," der","\u2191"," Hunger"," die"," ers","teren"," let","zt","ere","\u23ce"," in"," ih","ren","\u2191"," St","\u00f6","c","ke",","," z","n"," be","su"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," names"," of"," those"," who"," have"," benef","itted"," throughout"," years"," of"," corruption",".\""," \"","The"," State"," wants"," no"," poverty",","," hunger",","," ill","ite","racy",","," high"," mortality"," rates",","," or"," TB",","," mal","aria",","," or"," sc","hist","os","omi"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["that","  ","this","  ","was","  ","discovered",".","  ","A"," dog",",","  ","ins","tig","ated","  ","by"," ","\u23ce","hunger",",","  ","having","  ","broken","  ","a"," shell","  ","on","  ","the","  ","sea","-","shore",",","  ","his"," "]}]},{"quantile_name":"Subsample Interval 2","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["cd"," in"," the"," blood"," itself","."," It"," did"," not"," therefore"," seem"," possible"," to"," un","-"," der","stand"," how"," the"," air"," hunger"," of"," musc","ular"," ex","er","tion"," could"," be"," re","-"," lie","ved",","," as"," it"," und","ou","bt","edly"," is"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["car","b"," foods"," like"," gr","ains",","," st","archy"," ve","gg","ies",","," leg","umes"," and"," fruits"," which"," may"," spike"," hunger",".","\u23ce\u23ce","\u2022"," Consider"," interm","itt","ent"," f","asting",":"," Some"," people"," find"," that"," interm","itt","ent"," f","asting",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["less","ness",","," lack"," of"," concentration",","," ligh","the","ad","edness",","," ins","om","nia",","," trem","or",","," increased"," hunger"," and"," weight"," gain",","," y","aw","ning",","," persp","iration",","," lac","rim","ation",","," rhin","orr","ho","ea",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ish"," sp","ells"," cannot"," protect"," you"," from"," my"," power",".\""," \"","I"," condem","n"," you"," to"," living"," death"," to"," eternal"," hunger"," for"," living"," blood",".\""," \"","I"," know"," how"," deeply"," you"," loved"," her",".\""," \"","That"," is"," why"," you"," must"," trust"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.69,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\"","No"," matter"," what"," I"," do"," or"," say"," I"," can","'t"," get"," her"," to"," look"," at"," me"," with"," that"," same"," hunger"," she"," used"," to"," have",".\""," \"","It","'s"," so"," painful",".\""," \"","The"," most"," horrible"," part"," is"," when"," I"," look"]}]},{"quantile_name":"Subsample Interval 3","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.65,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["taste"," my"," own"," ass"," while"," you"," fuck"," my"," wet"," pussy",".\"","\u23ce\u23ce","\u2191","Overwhel","med"," by"," their"," ins","ati","able"," hunger",","," you"," have"," the"," opportunity"," to"," choose"," your"," next"," move",":","\u23ce\u23ce","1","."," Take"," NAME","_","3"," ","up"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.64,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["tic","les"," boun","cing"," and"," j","ig","gling"," with"," each"," movement"," only"," serves"," to"," height","en"," her"," ins","ati","able"," hunger"," and"," desire",".","\u23ce\u23ce","The"," sight"," of"," her"," reflection"," in"," a"," nearby"," pond"," is"," both"," horrif","ying"," and"," mes","mer"]},{"tokens_acts_list":[0.0,0.0,0.0,0.68,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.63,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["new","born","'s"," hunger",".\""," \"","The"," father"," c","oughs"," up"," a"," mil","ky"," substance",".\""," \"","Despite"," his"," own"," hunger",","," this"," tiny"," meal"," has"," been"," relegated"," to"," a"," small"," cr","ease"," in"," his"," throat"," just"," for"," this"," moment",".\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.97,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.46,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["food","-","security"," ","\u23ce","9","."," World","\u2191"," Hunger"," Education"," Service",":"," http","://","www",".","world","h","un","ger",".","org","/"," ","\u23ce\u23ce","Human",":"," ","\u23ce","I","'m"," not"," understanding"," how"," these"," different"," initiatives"," work"," together"," to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.44,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["  ","bottle","  ","or","  ","f","ath","omed","  ","a"," ","\u23ce\u23ce","bowl"," \u2014"," ","\u23ce","In","  ","\u2191","Hun","ger","ford","-","market"," \u2014"," ","\u23ce","I","  ","p","ee","ped","  ","in","  ","the","  ","grand","  ","se","rag"]}]},{"quantile_name":"Subsample Interval 4","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.64,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["tic","les"," boun","cing"," and"," j","ig","gling"," with"," each"," movement"," only"," serves"," to"," height","en"," her"," ins","ati","able"," hunger"," and"," desire",".","\u23ce\u23ce","The"," sight"," of"," her"," reflection"," in"," a"," nearby"," pond"," is"," both"," horrif","ying"," and"," mes","mer"]},{"tokens_acts_list":[0.0,0.0,0.0,0.68,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.63,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["new","born","'s"," hunger",".\""," \"","The"," father"," c","oughs"," up"," a"," mil","ky"," substance",".\""," \"","Despite"," his"," own"," hunger",","," this"," tiny"," meal"," has"," been"," relegated"," to"," a"," small"," cr","ease"," in"," his"," throat"," just"," for"," this"," moment",".\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.97,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.46,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["food","-","security"," ","\u23ce","9","."," World","\u2191"," Hunger"," Education"," Service",":"," http","://","www",".","world","h","un","ger",".","org","/"," ","\u23ce\u23ce","Human",":"," ","\u23ce","I","'m"," not"," understanding"," how"," these"," different"," initiatives"," work"," together"," to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.44,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["  ","bottle","  ","or","  ","f","ath","omed","  ","a"," ","\u23ce\u23ce","bowl"," \u2014"," ","\u23ce","In","  ","\u2191","Hun","ger","ford","-","market"," \u2014"," ","\u23ce","I","  ","p","ee","ped","  ","in","  ","the","  ","grand","  ","se","rag"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.43,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["There"," was"," only"," one"," case"," in"," the"," b","or","\u23ce"," ","ough"," court"," this"," morning"," before"," Judge","\u23ce","\u2191"," Hun","ger","ford","."," The"," case"," was"," that"," of","\u23ce"," Frank"," Davis"," of","\u2191"," Water","bury",","," .","charged","\u23ce"," with"," int"]}]},{"quantile_name":"Subsample Interval 5","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.41,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["railroad",",",","," ","-.","without"," permission",".","\u23ce","After"," hearing"," the"," evidence"," in"," the"," case","\u23ce"," Judge","\u2191"," Hun","ger","ford"," sentenced"," Davis"," to","\u23ce"," thirty"," days"," in"," jail"," and"," costs"," on"," the","\u23ce"," first"," count"," and"," thirty"," d","af"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.41,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","","ger"," v\u00e6re"," d","r\u00e6","b","te"," under","\u2191"," Op","l\u00f8","bet",".","\u23ce","Japan",".","\u23ce","\u2191","Hun","ger","sn","\u00f8d","."," Ten"," fat","tige","\u2191"," Be","folk","\u23ce"," ning"," i","\u2191"," Tok","io"," tr","ues"," med","\u2191"," Hun"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["-"," I","\u23ce"," c","ept"," the"," only"," thing"," that"," a"," woman"," like"," .","\u23ce","Mary","\u2191"," W","eth","ered"," hun","gers"," for","!\""," I"," ,","n","\u23ce",",",","," ."," ,"," ,"," ,"," ","'","at","\u23ce"," He"," was"," becoming"," eloqu"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.39,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["chr","isti"," f","\u00f6l","lt"," ,"," ist"," die","\u2191"," ","Rede"," \u201e",""," von"," vi","elen"," Jahren"," der","\u2191"," Hun","ger","sn","old"," \""," ."," wel","che"," da","mals"," in","\u2191"," Aeg","p","oten"," ge","her","rs","cht"," d","atte"," ."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.39,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ac","ci","\u017f","e"," ke","inen","\u2191"," Be","\u017f","t","and"," ge","ha","bt",","," w","eil"," eine","\u2191"," Hun","ger","sn","oth"," ent","\u017f","t","anden",","," die",","," ","\u23ce","\u2191","Men","\u017f","chen"," und","\u2191"," Vi","eh"," weg"]}]},{"quantile_name":"Subsample Interval 6","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.31,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," pain",","," fet","ts","tu","hl",","," d","izz","iness",","," lack"," of"," appetite"," or"," he","i\u00df","h","un","ger"," and"," a"," lack"," of"," energy","."," These"," phases"," can"," continue"," for"," weeks"," and"," imp","air"," my"," patient"," a"," lot","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["tern"," de","\u00bb"," ersten","\u2191"," Stock","e","\u00bb."," Man"," ","bes","\u00bb","r","gte"," stell","en","weise"," eine"," H","un","ger","Sn","oth",","," w","eil"," an","\u2191"," ","Orten",","," wo"," man"," keine"," Le","ben","Sm","itt","-","l"," im"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Hand"," r","isk","ieren",".","\u2191"," Wie"," kann"," und"," wie"," s","oll"," sich"," nun"," ein"," h","alb","v","erh","un","ger","ter","\u2191"," Men","sch"," an","-"," der","3"," ","und"," bes","ser"," weh","ren"," k\u00f6nnen"," als"," mit"," dem","\u2191"," Mes"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[",","\u2191"," Appet","tt","l","osi"," ","keit"," ,"," ab"," w","ech","sel","nd"," mit","\u2191"," He","i\u00df","h","un","ger"," ,","\u2191"," ","Ue","bel","ke","iten"," ,"," so","gar","\u2191"," ","Ohn","m","ach","ten"," und","\u2191"," Sch","wind"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.28,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["most"," important"," religious"," book"," of"," __","____________","\u23ce","\u21b9\u21b9","\u2191","Hind","us",".","\u23ce","\u21b9\u21b9","Christian",".","\u23ce","\u21b9\u21b9","hyp","oc","rites","\u23ce","\u21b9\u21b9"," Jews",".","\u23ce\u23ce\u23ce","Assistant",":"," The"," correct"," answer"," is"," Jews",".","\u23ce\u23ce","Human",":"," The"," word"," \""]}]},{"quantile_name":"Subsample Interval 7","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["von","\u2191"," G","raw","itz","*",")"," und","\u2191"," Sche","uer","len","''","')"," \u00fcber"," die"," en","tz","\u00fcnd","un","ger","re","gende","\u2191"," W","irk","ung"," der"," von","\u2191"," Bri","eger","\")"," aus"," gef","aul","ten","\u2191"," Leic","hen","the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ov","ite",","," avec"," ce"," gouvern","ement"," qui"," a"," eu",","," l","'","ann\u00e9e"," dern","i\u00e8re",","," l","'","hyp","oc","ris","ie"," dt","\u00bb"," so","ifi","u","iter"," un"," n","once",","," uniqu","ement"," pour"," a","pa","iser"," i","Vi"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a"," to","uj","ours"," \u00e9t\u00e9"," ainsi",".","\u2191"," Ils"," se"," co","uv","rent"," du"," mas","que"," de"," l","'","hyp","oc","ris","ie"," dans"," l","'","esp","oir"," de"," don","ner"," le"," change"," \u00e0"," l","'","opinion"," publ","ique","."," Il"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["dans"," les"," ","t\u00e9n","\u00e8","b","res"," pour"," s","'","\u00e9p","arg","ner"," le"," spect","acle"," de"," l","'","hyp","oc","ris","ie"," que","\u2191"," Bau","del","aire"," d","\u00e9n","once"," si"," am","\u00e8","rement"," ","chez"," tous","."," ","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," top"," ex","ecs"," at"," Google",".","\u23ce\u23ce","\u2191","Disclaimer",":"," I"," work"," for"," the"," ar","rog","ant"," Google"," hyp","oc","rites",".","\u23ce\u23ce","------","\u23ce","z","acc","us","\u23ce"," I"," drink"," coffee"," every"," morning",","," and"," drink"," a"," moderate"," amount"]}]},{"quantile_name":"Subsample Interval 8","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["A",","," Matthews"," L",",","\u2191"," Ac","er","ini"," C","L",",","\u2191"," ","Ong"," K","K",",","\u2191"," Dun","ger"," DB",".","\u23ce","\u2191","Li","pi","dom","ic"," analyses",","," breast","-"," and"," formula","-","feeding",","," and"," growth"," in"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a"," rational"," reason"," to"," overl","ook"," her"," hy","po","cr","isy",","," so"," you"," don","'t"," feel"," like"," a"," hyp","oc","rite"," for"," going",".\""," \"","Oh",".\""," \"","Sorry",","," continue",".\""," \"","\u2191","Okay",".\""," \"","Even"," if"," an"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["6","898"," ","Saint","-","\u2191","Mar","ys"," ||"," ","1","988"," ","","LE"," ||","  ","||","\u2191"," Hun","yo"," ","8",","," ","1","988"," ","||","\u2191"," Pal","omar"," ||"," C","."," S",".","\u2191"," Sh","oe","maker"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.12,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["I","'m"," so"," sorry",".\""," \"","Just"," stop"," being"," a"," hyp","oc","rite","!\""," \"","But"," I"," am"," a"," hyp","oc","rite",","," Emma",".\""," \"","I"," knew"," deep"," down"," you"," had"," a"," problem",","," but"," I"," was"," so"," afraid"," of"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","23","."," (","\u2191","V","x"," v","ob","is","\u2191"," Sc","rib","x"," &","\u2191"," Phar","if","xi"," hyp","oc","rit","x",",","q","vi"," mund","atis"," ,"," q","v","od"," de","fo","ris"," ","eft"," cal","ic","is"," &"]}]},{"quantile_name":"Bottom Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ab","on","ner"," au"," j","oli"," et"," cou","rag","eux"," journal"," illust","r\u00e9"," zo","oph","ile"," :"," \u00ab"," Le","\u2191"," D\u00e9f","ens","a","ur"," des","\u2191"," Anim","aux"," Il","."," ","10"," ","fran","cs"," par"," an",","," es"," n","'"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","   ","H"," H"," H"," H","\u23ce","     ","H","      ","\u23ce","   ","H"," H"," H"," H","\u23ce","     ","H","      ","\u23ce","   ","H"," H"," H"," H","\u23ce","     ","H","      ","\u23ce","   ","H"," H"," H"," H","\u23ce","     ","H","      ","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.07,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["H"," H"," H","  ","\u23ce"," ","H"," H"," H"," H"," H"," H","\u23ce","  ","H"," H","\u23ce","   ","H"," ","\u23ce"," ","H"," H","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","I"," am"," thinking"," about"," going"," back"," to"," school"," to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["from"," city"," C"," to"," city"," E","\\","n","T","here"," is"," a"," path"," from"," city"," M"," to"," city"," H","\\","n","T","here"," is"," a"," path"," from"," city"," A"," to"," city"," L","\\","n","T","here"," is"," a"," path"," from"," city"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["su"," product","iv","idad"," y"," ef","ici","encia"," en"," la"," gest","i\u00f3n"," de"," recursos",".","<EOT>","\u23ce\u23ce","Human",":","\u2191"," H\u00e1"," pen","dr","ives"," que"," n\u00e3o"," s\u00e3o"," compat","\u00ed","veis"," com"," alg","um"," sistema"," oper","acional"," ?","\u23ce\u23ce","Assistant",":"," Em"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Bank","\u23ce","2","."," The"," United"," Nations"," Population"," Fund"," (","\u21ea","UNP","F",")","\u23ce","3","."," The"," Global","\u2191"," Poverty"," Project","\u23ce","4","."," The"," United"," Nations","\u2191"," Sustainable"," Development"," Goals"," (","\u21ea","UN","SD","G",")","\u23ce","5","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a"," variance"," in"," the"," weight"," for"," a"," given"," volume"," of"," the"," food"," product"," portion",".","\u23ce","The"," upper"," pl","un","gers",","," as"," previously"," mentioned",","," are"," y","ield","ably"," bi","ased"," down","ward",","," such"," as"," by"," cam"," action"," in"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".,","\u2191"," ","Ait","hal",","," H",".","N","."," and","\u2191"," Sp","argo",","," B",".","H",".","\u2191"," Z","onal"," changes"," in"," re","nal"," structure"," and"," phosph","ol","ip","id"," metabolism"," during"," rever","sal"," of"," pot","ass","ium"," de"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ro","beat"," (","Nigerian"," fusion","):","\u2191"," Se","un","\u2191"," K","uti"," &"," Egypt"," ","80"," ","-"," \"","\u2191","Struggle","\u2191"," Sounds","\"","\u23ce","6",".","\u2191"," Af","rop","op"," (","Pan","-","African","):","\u2191"," You","ss","ou"," N"]}]}],"top_logits":["pan","Games","\u043f\u0430\u043d","games","aviv","Aviv","panel","pann","rites","push"],"bottom_logits":["icio","rio","erm","icia","ento","erie","yme","lio","erre","am"]}