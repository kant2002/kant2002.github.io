{"index":15319944,"examples_quantiles":[{"quantile_name":"Top Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.68,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["short"," ","PN"," code"," of"," ","15","th"," order"," (","the"," period"," is"," about"," ","26"," ","ms",")"," and"," a"," long"," ","PN"," code"," of"," ","42","th"," order"," (","the"," period"," is"," about"," ","41"," ","days",")"," consumed"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.87,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["computer","."," The"," stat","ionary"," seat"," ","7"," ","is"," an"," L","-","shaped"," member"," having"," a"," short"," arm"," and"," a"," long"," arm","."," The"," rot","ary"," shaft"," ","6"," ","is"," ro","tat","ably"," connected"," to"," the"," stat","ionary"," seat"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["box"," includes"," two"," short"," sidew","alls"," ","12"," ","and"," ","14"," ","which"," are"," opposite"," to"," each"," other"," and"," two"," long"," sidew","alls"," ","16"," ","and"," ","18"," ","which"," are"," opposite"," to"," each"," other","."," The"," dimensions"," of"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.45,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ulating"," pin",","," to"," a"," p","iston"," that"," recip","roc","ates"," inside"," the"," cylinder"," of"," the"," comp","ressor",","," and"," a"," larger"," eye",","," mounted"," to"," an"," ecc","entric"," end"," of"," a"," cr","ank","sh","aft",","," which"," is"," orth","og"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.18,0.0,0.22,0.78,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," six"," blown"," breath"," stim","ul","ants",","," the"," eight"," shallow"," penet","rations",","," the"," nine"," minor"," and"," ","11"," ","major"," positions",",\""," \"","as"," well"," as"," the"," technique"," of"," passive"," acceptance",","," forc","eful"," domin","ance",","," cont","ortion"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.11,0.09,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.75,0.0,0.0,0.0,0.0,0.37,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["side"," is"," bent","."," Next",","," the"," sheet"," metal"," is"," turned"," ","90",".","degree","."," and"," the"," edge"," of"," one"," long"," side"," is"," bent"," (","long"," side"," b","ending",")"," by"," a"," cl","amp"," die"," or"," punch"," set"," to"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.17,0.41,0.74,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["edes"," de"," la"," peque","\u00f1a"," tienen"," ","35"," ","mil","imet","ros"," de"," di","\u00e1","met","ro"," y"," las"," de"," la"," grande"," ro",":\"","\u2191"," Calc","ule"," el"," l","ecl","ot",","," el"," ef","ecto"," que"," he"," de"," produc","ir"," al"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.73,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[",","\u2191"," B","ost","oh","."," '","\u23ce","Price","\u2014","\u2191","S","mail"," bottles","."," ","50"," ","rent","*",";"," large",","," sl","."," _","\u2191"," Sold"," in","\u2191"," Wc","r","\u23ce"," ce","'","ter"," by"," Green",",","\u2191"," Ha"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.14,0.71,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","1"," ","cannot"," be"," re","-","used",","," in"," some"," cases",".","\u23ce","b","."," Because"," an"," edge"," of"," a"," large"," diameter"," part"," of"," the"," ground"," tube"," ","20"," ","b","ites"," into"," the"," inner"," face"," of"," the"," through"," hole"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.11,0.0,0.54,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["_","s",","," min","_","periods","=","","ema","_","s",").","mean","()","\u23ce","    ","df","['","E","MA","_","L","']"," ="," df",".","Close",".","ew","m","(","span","=","","ema","_","l",","," min","_","periods"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.7,0.53,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["more"," (","her","ein","after",","," length"," ","4","T"," or"," more"," mark"," is"," called"," xe","2","x","80","x","9","c","long"," mark","x","e","2","x","80","x","9","d"," for"," convenience"," sake"," about"," the"," explanation",")"," has"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.87,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["notebook"," computer","."," The"," stat","ionary"," seat"," ","7"," ","is"," an"," L","-","shaped"," member"," having"," a"," short"," arm"," and"," a"," long"," arm","."," The"," rot","ary"," shaft"," ","6"," ","is"," ro","tat","ably"," connected"," to"," the"," stat","ionary"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.45,0.69,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["etc",".)"," will"," represent"," the"," size"," applied"," to"," a"," case"," wherein"," a"," document"," is"," placed"," on"," the"," reader"," so"," that"," the"," long"," sides"," thereof"," are"," parallel"," to"," the"," reading"," sensors",".","\u23ce","(","1",")"," When"," a"," document"," of"," A","5"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.49,0.54,0.0,0.0,0.21,0.5,0.69,0.41],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["des"," ","\u23ce","\u00bb","  ","grandes","  ","cou","ches","  ","du","  ","petit","  ","et","  ","sur","-","tout","  ","du","  "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.69,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["iv","otu",")","\u23ce","<","\u2191","Hr","ki",">"," sad"," ","idu"," dva"," kab","la",","," on","aj"," u","zi"," i"," s","iri","\u23ce","<","\u2191","Hr","ki",">"," ali"," nem","am"," jump","ere",","," ce"," rad","iti"," bez"," toga"," ?"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.47,0.68,0.0,0.56,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","\u23ce\u23ce","\u2191","B","ota","  ","ch","ica"," \u2014"," Small","  ","leather","  ","bag","."," ","\u23ce\u23ce","\u2191","B","ota","  ","grande"," \u2014","\u2191"," S","ack","  ","made","  ","of","  ","2","  ","or","  ","2","^","  ","h","ides",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.68,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a"," short"," ","PN"," code"," of"," ","15","th"," order"," (","the"," period"," is"," about"," ","26"," ","ms",")"," and"," a"," long"," ","PN"," code"," of"," ","42","th"," order"," (","the"," period"," is"," about"," ","41"," ","days",")"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.67,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","Ils"," j"," appell","ent"," un"," chat"," un"," chat",","," ils"," sup","pr","iment"," la"," pet","ite"," propri","\u00e9t\u00e9"," comme"," la"," grande"," pour"," r\u00e9","du","ire"," ch","ac","un"," \u00e0"," la"," m\u00f4","me"," gam","elle"," ay","ant"," m\u00eame"," dimension"," et"," m\u00eame"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.67,0.19,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["end","og","lin"," exists"," in"," two"," forms",";"," i",".","e",".,"," a"," smaller"," ","160"," ","k","D"," form"," and"," a"," larger"," ","170"," ","k","D"," form"," with"," the"," difference"," between"," the"," two"," being"," found"," in"," the"," cyt","opl"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.67,0.13,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["  ","des","  ","\u2191","Hen","ck","ers","ber","ges"," ","\u23ce","durch","  ","das","  ","\u2191","Kleine","  ","und","  ","\u2191","Gro","sse","  ","\u2191","Pf","a","ffent","hal","  ","hind","urch","  ","bis","  ","an","  ","den"," ","\u23ce","\u2191"]}]},{"quantile_name":"Subsample Interval 0","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.68,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["short"," ","PN"," code"," of"," ","15","th"," order"," (","the"," period"," is"," about"," ","26"," ","ms",")"," and"," a"," long"," ","PN"," code"," of"," ","42","th"," order"," (","the"," period"," is"," about"," ","41"," ","days",")"," consumed"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.87,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["computer","."," The"," stat","ionary"," seat"," ","7"," ","is"," an"," L","-","shaped"," member"," having"," a"," short"," arm"," and"," a"," long"," arm","."," The"," rot","ary"," shaft"," ","6"," ","is"," ro","tat","ably"," connected"," to"," the"," stat","ionary"," seat"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["box"," includes"," two"," short"," sidew","alls"," ","12"," ","and"," ","14"," ","which"," are"," opposite"," to"," each"," other"," and"," two"," long"," sidew","alls"," ","16"," ","and"," ","18"," ","which"," are"," opposite"," to"," each"," other","."," The"," dimensions"," of"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.45,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["ulating"," pin",","," to"," a"," p","iston"," that"," recip","roc","ates"," inside"," the"," cylinder"," of"," the"," comp","ressor",","," and"," a"," larger"," eye",","," mounted"," to"," an"," ecc","entric"," end"," of"," a"," cr","ank","sh","aft",","," which"," is"," orth","og"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.18,0.0,0.22,0.78,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["the"," six"," blown"," breath"," stim","ul","ants",","," the"," eight"," shallow"," penet","rations",","," the"," nine"," minor"," and"," ","11"," ","major"," positions",",\""," \"","as"," well"," as"," the"," technique"," of"," passive"," acceptance",","," forc","eful"," domin","ance",","," cont","ortion"]}]},{"quantile_name":"Subsample Interval 1","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.87,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["computer","."," The"," stat","ionary"," seat"," ","7"," ","is"," an"," L","-","shaped"," member"," having"," a"," short"," arm"," and"," a"," long"," arm","."," The"," rot","ary"," shaft"," ","6"," ","is"," ro","tat","ably"," connected"," to"," the"," stat","ionary"," seat"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["box"," includes"," two"," short"," sidew","alls"," ","12"," ","and"," ","14"," ","which"," are"," opposite"," to"," each"," other"," and"," two"," long"," sidew","alls"," ","16"," ","and"," ","18"," ","which"," are"," opposite"," to"," each"," other","."," The"," dimensions"," of"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.45,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["ulating"," pin",","," to"," a"," p","iston"," that"," recip","roc","ates"," inside"," the"," cylinder"," of"," the"," comp","ressor",","," and"," a"," larger"," eye",","," mounted"," to"," an"," ecc","entric"," end"," of"," a"," cr","ank","sh","aft",","," which"," is"," orth","og"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.18,0.0,0.22,0.78,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["the"," six"," blown"," breath"," stim","ul","ants",","," the"," eight"," shallow"," penet","rations",","," the"," nine"," minor"," and"," ","11"," ","major"," positions",",\""," \"","as"," well"," as"," the"," technique"," of"," passive"," acceptance",","," forc","eful"," domin","ance",","," cont","ortion"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.11,0.09,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.75,0.0,0.0,0.0,0.0,0.37,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["side"," is"," bent","."," Next",","," the"," sheet"," metal"," is"," turned"," ","90",".","degree","."," and"," the"," edge"," of"," one"," long"," side"," is"," bent"," (","long"," side"," b","ending",")"," by"," a"," cl","amp"," die"," or"," punch"," set"," to"," the"]}]},{"quantile_name":"Subsample Interval 2","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.11,0.0,0.54,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["_","s",","," min","_","periods","=","","ema","_","s",").","mean","()","\u23ce","    ","df","['","E","MA","_","L","']"," ="," df",".","Close",".","ew","m","(","span","=","","ema","_","l",","," min","_","periods"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.7,0.53,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["more"," (","her","ein","after",","," length"," ","4","T"," or"," more"," mark"," is"," called"," xe","2","x","80","x","9","c","long"," mark","x","e","2","x","80","x","9","d"," for"," convenience"," sake"," about"," the"," explanation",")"," has"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.87,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["notebook"," computer","."," The"," stat","ionary"," seat"," ","7"," ","is"," an"," L","-","shaped"," member"," having"," a"," short"," arm"," and"," a"," long"," arm","."," The"," rot","ary"," shaft"," ","6"," ","is"," ro","tat","ably"," connected"," to"," the"," stat","ionary"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.45,0.69,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["etc",".)"," will"," represent"," the"," size"," applied"," to"," a"," case"," wherein"," a"," document"," is"," placed"," on"," the"," reader"," so"," that"," the"," long"," sides"," thereof"," are"," parallel"," to"," the"," reading"," sensors",".","\u23ce","(","1",")"," When"," a"," document"," of"," A","5"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.49,0.54,0.0,0.0,0.21,0.5,0.69,0.41],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["des"," ","\u23ce","\u00bb","  ","grandes","  ","cou","ches","  ","du","  ","petit","  ","et","  ","sur","-","tout","  ","du","  "]}]},{"quantile_name":"Subsample Interval 3","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.29,0.61,0.12,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["A","\u23ce","\u21ea"," BACON","?","Ham",","," small","...","...."," ."," ","15"," ","?"," ?","\u23ce","\u2191","K","ams",","," l","arga","."," ?"," ?"," \"","\u23ce","\u2191","Sl","des",","," sm","-","l",".","ed","..","i","."," ,"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.27,0.15,0.0,0.0,0.67,0.61,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["h","ams",","," well"," sm","oked",","," small"," ","13"," ","9","\u23ce","\u2191","H","ama",","," well"," sm","oked",","," large"," ","1","*"," &","\u23ce","\u2191","H","ams",","," well"," sm","oked","."," ","13"," ","","\u00a9","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.48,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.28,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["1"," ","m"," and"," height"," ","0",".","18"," ","m"," [","18",","," ","19","];"," (","ii",")"," a"," five"," time"," bigger"," Von","\u2191"," K","\u00e1rm","\u00e1n"," (","G","V","K","),"," with"," radius"," R"," ="," ","0","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.12,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["and"," some"," other"," stuff"," and"," fits"," under"," the"," seat"," in"," front"," of"," me","."," The","\u23ce"," smaller"," one"," clips"," onto"," the"," larger"," one"," when"," I"," need"," to"," carry"," it"," around",","," and"," then","\u23ce"," when"," I","'ve"," left"," the"," large"," one"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["connected"," via"," the"," l","itle"," card","-","output"," with"," \"","video","\"."," I","'ve"," an"," adapter"," to"," connect"," it"," to"," the"," v","ga","-","output",","," but"," when"," i"," tried"," this"," nothing"," happ","end","...","\u23ce","<","t","if","ine",">"]}]},{"quantile_name":"Subsample Interval 4","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.51,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["shorter"," hull"," requires"," less"," power"," to"," acceler","ate"," through"," its"," maximum","-","wave","-","resistance"," speed"," ","25","a"," than"," the"," longer"," hull"," requires"," to"," acceler","ate"," through"," its"," maximum","-","wave","-","resistance"," speed"," ","25","b"," because"," the"," total"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.25,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.51,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["1"," ","shows"," packets"," with"," short"," and"," long"," TT","Is","."," Both"," the"," short"," TT","I"," packet"," (","left",")"," and"," the"," long"," TT","I"," packet"," (","right",")"," include"," a"," control"," channel"," labeled"," as"," \"","Control","\""," in"," F","IG"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","minist","\u00e9ri","els",","," ","30"," ","ven","aient"," des"," pet","its"," coll","\u00e8","ges"," et"," ","84"," ","des"," grands","."," Il"," en"," r\u00e9s","ult","ait"," que"," dans"," ces"," dern","iers"," coll","\u00e8","ges",","," repr\u00e9s","ent","ants"," d"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.49,0.54,0.0,0.0,0.21,0.5,0.69,0.41],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["  ","des"," ","\u23ce","\u00bb","  ","grandes","  ","cou","ches","  ","du","  ","petit","  ","et","  ","sur","-","tout","  ","du","  "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["this"," type"," of"," sp","anner"," is"," to"," be"," operated"," by"," taking"," the"," shorter"," side"," as"," the"," job","-","side",","," the"," user"," at"," work"," must"," turn"," the"," longer"," side"," while"," holding"," same",";"," when"," the"," object"," to"," be"," worked"," on"," differs"]}]},{"quantile_name":"Subsample Interval 5","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["flow","ability"," of"," the"," t","oner"," is"," improved",","," and"," as"," a"," result",","," the"," in","org","anic"," particles"," having"," a"," larger"," diameter"," are"," difficult"," to"," be"," uniform","ly"," attached"," ther","eon","."," Therefore",","," it"," is"," preferred"," that"," the"," in"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.45,0.4,0.02,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.26,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["sl","ena","L","on",".","kr","\u00f3t","."," \u2014","\u2014"," ","\u23ce","\u2191","W","ek",".","na","\u2191"," Peters","b","."," i","\u0142ug","."," ","173",".","80"," ","|",","," \u201e",""," ","4"," ","","ug"," \u2014","\u2014"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," meaning"," that"," the"," desired"," resources"," are"," acquired"," in"," an"," on","-","demand"," and"," easily"," extended"," way","."," Cloud"," computing"," in"," a"," broad"," sense"," refers"," to"," delivery"," and"," usage"," modes"," of"," service","."," A"," form"," of"," the"," service"," is"," based"," on"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["f","ekt","\u2191"," Cam","esc","a","ffe"," so","fort"," ben","ach","richt","igt"," ,"," s","etzt"," die"," kle","inen"," und"," die"," gro\u00df","en","\u2191"," Sp","it","zel"," in","\u2191"," Beweg","ung"," und"," der"," sch","uld","ige","\u2191"," Gab","ill","aud"," wird"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["performance"," of"," GP","T","-","3",",","\u21ea"," BERT",","," and"," T","5"," ","on"," a"," specific"," task",".\\","n","-"," Long"," term",":"," Choose"," the"," best"," model"," and"," continue"," to"," fine","-","tune"," it"," for"," our"," specific"," use"," case",".\","]}]},{"quantile_name":"Subsample Interval 6","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.43,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["cheese"," steady",";"," New"," York"," full"," cre","ams",","," i","\u23ce"," prime"," small"," ","10","M",">","c",";"," do","."," fair"," to"," good"," ","9","%","\u23ce","al","O","V","ic",".","\u23ce","\u21ea","PO","ULT","RY",".","\u23ce","_"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["mentioned"," field"," device"," differs"," from"," general"," M","OS"," devices"," in"," that"," the"," field"," device"," repl","aces"," the"," thin"," gate"," oxide"," with"," a"," field"," oxide","."," The"," field"," oxide"," having"," a"," thickness"," of"," about"," ","0",".","4",".","about",".","1"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.11,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u00e9ri","eur"," \u00e0"," ","25"," ","mill","iers"," d","'","euros"," ;"," \u2014","  ","Service","\u2191"," Re","co","uv","rement"," de"," cr","\u00e9d","its"," import","ants",","," sp","\u00e9","ci","alis","\u00e9"," dans"," la"," g","estion"," des"," cr\u00e9","ances"," en"," so"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["gate"," oxide"," film"," (","with"," a"," thickness"," of"," ","4"," ","nm","),"," while"," the"," other"," M","OS"," transist","or"," has"," a"," thick"," gate"," oxide"," film"," (","with"," a"," thickness"," of"," ","9"," ","nm",").","\u23ce","Because"," two"," kinds"," of"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["or"," more",")"," of"," images"," (","during"," one"," field"," period"," of"," time",")"," that"," represent"," different"," expos","ures"," (","short"," and"," long"," in"," the"," case"," of"," two"," images",")"," of"," the"," same"," scene","."," It"," is"," suggested"," that"," the"," low"," frequency"]}]},{"quantile_name":"Subsample Interval 7","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["galaxy"," clusters","?\\","n","###"," Context",":\\","n",".\\","n","W","hen","ever"," a"," small"," mass",","," m"," is"," near"," a"," much"," larger"," mass",","," M",","," whether"," it"," be"," a"," star"," near"," the"," center"," of"," a"," galaxy"," or"," an"," object"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["cycle"," from"," start"," to"," stop"," may"," be"," only"," several"," seconds"," for"," the"," smaller"," val","ves"," and"," ten"," to"," fifteen"," seconds"," for"," the"," larger"," val","ves",".","\u23ce","There"," are"," many"," occasions"," when"," it"," would"," be"," advant","ag","eous"," to"," ro","tor"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["radius","\","," influ","enc","ed","M","ode","col","ors",".","C","U","E","_","\u21ea","INNER","),","\u23ce","        ","c","ue","O","uter",":"," new"," ","Deb","ug","Check","box","(\"","\\xe2\\x97","\\xaf","","\u2191"," C","ue","\u2191"," Outer","\u2191"," Radius"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["fl","^"," ","\u23ce","t","ween"," the"," two"," \u2014"," the"," lighter"," half"," indicating"," the"," ^","^"," ","\u23ce","positive"," and"," the"," darker"," half"," the"," negative"," side","."," ","9"," ","O"," ","9","'"," ","\u23ce","The"," molecules"," of"," air"," being"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["-","1"," ","\u2014"," et"," il"," subs","iste"," encore"," \u2014"," qui"," auto","rise"," tous"," les"," d\u00e9b","its",","," pet","its"," et"," grands",","," \u00e0"," r","ester"," o","uv","erts"," jusqu","'","\u00e0"," deux"," he","ures"," du"," m","atin","."," On"," a"]}]},{"quantile_name":"Subsample Interval 8","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["dr","onis",">"," p","st","ol","owski",":"," but"," as"," you"," said",","," it"," seems"," we"," should"," indeed"," swap"," SHORT"," and"," non","-","SHORT"," for"," serial",","," I"," mean"," prefer"," SHORT"," if"," it"," exists","\u23ce","<","pe","dr","onis",">"," for"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["in"," cities",","," then"," the"," bus"," ","vent"," would"," only"," be"," ","2"," ","blocks"," away","."," If"," the"," blocks"," are"," larger",","," typically"," found"," in"," more"," rural"," areas",","," then"," the"," bus"," ","vent"," would"," be"," ","2"," ","miles"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["small"," chamber"," esc","apes"," to"," the"," main"," chamber",","," a"," pressure"," rising"," in"," the"," entire"," of"," the"," small"," chamber"," and"," the"," main"," chamber"," becomes"," small",","," so"," that"," the"," ","rupt","urable"," plate"," is"," not"," ","rupt","ured"," and"," an"," air"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["tur"," in"," quo"," est","\u2191"," Sy","rt","is"," minor",",","\u2191"," Cer","cin","itis"," appell","ata",","," alt","\u00e9","ra","\u2191"," Sy","rti"," mul","to"," s","\u00e6v","ior"," navig","a","tn","que"," diffic","il","ior",","," c","uj","us"," amb","itus"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2014","\u2191"," W","ech","sel","c","urs"," auf","\u2191"," K\u00f6","ln"," kur","z"," ","122"," ","."," ","90"," ",","," auf"," London"," kur","z"," ","25"," ","."," ","14"," ","\u2014"," ","18"," ","."," Paris"," ,"," ","24"]}]},{"quantile_name":"Bottom Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.02,0.21,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u062f","\u0646","\u0628","\u0627\u0644"," \u0645\u06cc"," \u06a9","\u0646\u062f","."," ","\u23ce\u23ce","\u2022"," \u062f","\u0648","\u0631\u0647"," ","26"," ","\u0631\u0648","\u0632","\u0647"," \u0628\u0631","\u0627\u06cc"," \u06a9","\u0646\u062f","\u060c"," \u0631\u0648","\u0646\u062f"," \u0645\u06cc","\u0627\u0646"," \u0645","\u062f","\u062a"," \u0642","\u06cc","\u0645","\u062a"," \u0631\u0627"," \u062f","\u0646","\u0628","\u0627\u0644"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["<","kn","ome",">"," i","'d"," like"," one"," with"," quite"," small"," logo"," on"," the"," front","\u23ce","<","kn","ome",">"," and"," maybe"," nothing"," in"," the"," back","\u23ce"," ","*"," pl","eia","2"," ","n","ods","\u23ce","<","kn","ome",">"," unless"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["of"," an","\u21ea"," M","RAM"," device","."," The"," MT","J"," pattern"," may"," include"," a"," st","acked"," lower"," fer","romagn","et"," and"," upper"," fer","romagn","et"," layers","."," A"," magnet","ization"," direction"," of"," the"," lower"," fer","romagn","et"," layer"," may"," be"," fixed"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["airplane",","," and"," this"," separation"," distance"," is"," increased"," to"," ","5"," ","naut","ical"," miles"," if"," the"," preceding"," airplane"," is"," a"," heavy"," airplane"," with"," a"," mass"," greater"," than"," ","136"," ","tonnes",".","\u23ce","When"," a"," light"," airplane"," follows"," a"," heavy"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ope","'s"," ","1","M","\\xce","\\xa9",""," input"," after"," accounting"," for"," the"," ","10","x"," at","ten","uation","."," The"," higher"," probe"," input"," imped","ance"," minim","izes"," loading"," of"," the"," measured"," circuit"," by"," the"," probe","."," It"," also"," minim","izes"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," ","7","c"," ft"," lb",";","\u2191"," Roos","ters",","," young",";"," S",".","5","c"," ft"," lb",";"," do"," old",","," $","1",".","50",";","\u2191"," Fr","yers",",","  ","1","701","\u00bb","t",":"," *","."," das"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["frame","-","side"," end"," of"," the"," front"," link"," ","6","a"," and"," the"," seat"," cush","ion"," frame","-","side"," end"," of"," the"," rear"," link"," ","13","a"," are"," simultaneously"," piv","oted"," in"," the"," same"," direction"," (","up","ward",")."," Thus",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Lady"," of","\u23ce"," I","\u00ab","our","des"," next"," Sunday"," there"," will"," lie","\u23ce"," low"," mass"," at"," ","7","..","in"," and"," ft",".","r","to"," o","'","clock",".'","\u23ce","The"," bened","iction"," of"," the","\u2191"," Blessed","\u2191"," Sac","ra","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["|"," cost"," |"," cheap"," |"," expensive"," |","\u23ce","|"," density"," |"," sparse"," |"," dense"," |","\u23ce","|"," depth"," |"," shallow"," |"," deep"," |","\u23ce","|"," distance"," |"," near"," |"," far"," |"," ","\u23ce","|"," electric"," conduct","ivity"," |"," low"," |"," high"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ud","arte"," a"," man","ten","erte"," organ","izado",".","\u23ce","3",".","\u2191"," Establ","ece"," objet","ivos"," a"," cor","to"," y"," largo"," pla","zo",":"," establec","er"," objet","ivos"," a"," cor","to"," y"," largo"," pla","zo"," puede"," ay","ud","arte"," a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["bra","ided"," wire"," ","14"," ","becomes"," incomplete",","," thereby"," deterior","ating"," the"," sh","iel","ding"," capability",".","\u23ce","In"," the"," latter"," prior"," art",","," convers","ely",","," the"," assemb","ling"," condition"," is"," stable"," owing"," to"," the"," arrangement"," where"," the"," shield"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.37,0.0,0.0,0.0,0.0,0.09,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a"," first"," short"," link"," pivot"," connection",","," a"," second"," short"," link"," pivot"," connection"," and"," a"," third"," short"," link"," pivot"," connection","."," The"," relatively"," long"," link"," includes"," a"," first"," long"," link"," pivot"," connection"," and"," a"," second"," long"," link"," pivot"," connection","."," The"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.44,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["internal"," part"," of"," this"," nerve"," joins"," the"," vag","us"," and"," is"," distributed"," through"," it"," to"," the"," lar","yng","eal"," muscles","."," The"," larger"," external"," part"," is"," distributed"," to"," the"," st","erno","-","mast","oid"," and"," trap","ez","ius"," muscles","."," The"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","packages","."," Market"," firm",";"," large"," white",".","\u23ce","12","c",";"," small"," white","."," ","12","'","ic",":"," large"," col","ore","!","."," ","12","c",";"," small","\u23ce"," colored","."," U","'","i","U","c",".","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["of"," a"," first",","," lower"," voltage"," (","e",".","g",".,"," ","450"," ","m","V",")"," and"," a"," second",","," higher"," voltage"," (","e",".","g",".,"," ","1","080"," ","m","V",")"," may"," be"," altern","ately"," applied"," on"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["by"," saying"," that"," the"," text","\u2191"," Implied"," ears","\u23ce"," and"," gave"," a"," new"," idea"," about"," ears",","," both","\u23ce"," small"," and"," great","."," Had"," man"," been"," made","\u23ce"," ear","less"," it"," would"," have"," so"," puzz","led"," the"," devil","\u23ce"," to"," have"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","Crypt","ography"," is"," used"," to"," conc","eal"," communication"," contents",".","\u2191"," Crypt","ography"," includes"," a"," symmetric"," encryption"," scheme"," and"," an"," asym","met","ric"," encryption"," scheme","."," The"," symmetric"," encryption"," scheme"," uses"," a"," shared"," secret"," key"," in"," encryption"," processing"," and"," dec"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.18,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Die"," lie","inc","ren","\u2191"," Arten"," haben"," h\u00e4","uj","ig"," ein","\u00ab"," l","aut","ere","\u2191"," S","li","in","me"," als"," die"," gro\u00df","en",".","\u2191"," Auch"," diese","\u2191"," R","ni","ank","\u00f6n","im","ling",".-"," sind"," stim","mb","eg","a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.37,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Q"," ID"," NO",":"," ","28"," ","(","short"," he","lix"," connector","),"," SE","Q"," ID"," NO",":"," ","30"," ","(","long"," he","lix"," connector","),"," SE","Q"," ID"," NO",":"," ","32"," ","(","large"," domain"," connector","),"," SE"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["corresponding"," to"," the"," difference"," between"," the"," two"," energy"," levels",","," nuclear"," sp","ins"," are"," transferred"," from"," the"," lower"," energy"," level"," into"," the"," upper"," energy"," level","."," The"," result"," can"," be"," recorded"," and"," evaluated"," with"," regard"," to"," the"," actual"," filling"," of"," the"]}]}],"top_logits":["large","\u5927","\u0431\u043e\u043b\u044c\u0448","big","gro\u00dfe","grote","Large","nagy","gro\u00df","l"],"bottom_logits":["******","\\xfe","\f","\\xf6","\u0014","\u001c","\u21b9","\u0011"]}