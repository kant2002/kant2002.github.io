{"index":8786631,"examples_quantiles":[{"quantile_name":"Top Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.63,0.72,0.0,1.0,0.0,0.38,0.04,0.26,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["we"," know"," that","."," Can"," you"," elaborate","?","\u23ce\u23ce","Assistant",":"," ","\u23ce","Of"," course","."," The"," opposite"," of"," failure"," is"," success",","," right","?"," So"," to"," learn"," from"," failure",","," you"," need"," to"," make"," that"," distinction"," between"," failure"," and"," success"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.91,0.78,0.25,0.0,0.0,0.0,0.0,0.62,0.08,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["mother"," is"," one"," who"," is"," ov","erly"," protective",","," controlling",","," and"," dom","ine","ering"," towards"," her"," children","."," The"," opposite"," of"," an"," o","verb","earing"," mother"," is"," one"," who"," is"," nur","turing",","," support","ive",","," and"," allows"," her"," children"]},{"tokens_acts_list":[0.72,0.65,0.48,0.0,0.0,0.0,0.0,0.25,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.88,0.83,0.47,0.15,0.14,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["\ub9d0","\uc774"," ","\\xeb","\\xad","\\x90","\uc57c","?","\u23ce\u23ce","Assistant",":"," ","\uc2e0","\\xeb","\\xa2","\\xb0","\uc758"," ","\ubc18","\ub300","\ub9d0","\uc740"," ","\"","\ubd88","\uc2e0","\""," ","\ub610","\ub294"," ","\"","\uc758","\uc2ec","\"","\uc785","\ub2c8","\ub2e4",".","\u23ce\u23ce","\uc2e0"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.67,0.58,0.0,0.0,0.5,0.78,0.32,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["considered"," positive",","," and"," would"," generally"," be"," considered"," a"," pr","ais","eful"," attribute","."," The"," opposite"," of"," Grade"," A"," would"," be"," to"," describe"," a"," person"," neg","atively",","," e",".","g","."," har","sh","ly",","," dis","resp","ect","fully","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.91,0.78,0.25,0.0,0.0,0.0,0.0,0.62,0.08,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["is"," one"," who"," is"," ov","erly"," protective",","," controlling",","," and"," dom","ine","ering"," towards"," her"," children","."," The"," opposite"," of"," an"," o","verb","earing"," mother"," is"," one"," who"," is"," nur","turing",","," support","ive",","," and"," allows"," her"," children"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.75,0.67,0.09,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\ubbf8","\uac00"," ","\uc788","\ub294"," ","\uac83","\uc5d0"," ","\ub300","\ud574"," ","\"","\uc2e0","\\xeb","\\xa2","\\xb0","\uc758"," ","\ubc18","\ub300","\ub9d0","\"","\uc774","\ub77c","\ub294"," ","\ub9d0","\\xec\\x94","\\x80","\uc774"," ","\ub418","\uc9c0"," ","\uc54a","\ub294"," ","\uac83","\uc740"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.12,0.75,0.71,0.65,0.48,0.0,0.0,0.0,0.0,0.25,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.88],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["\uc2a4","\ub97c"," ","\ud1b5","\ud574"," ","\uc6b4","\uc601","\ub418","\u23ce\u23ce","Human",":"," ","\uc2e0","\\xeb","\\xa2","\\xb0","\uc758"," ","\ubc18","\ub300","\ub9d0","\uc774"," ","\\xeb","\\xad","\\x90","\uc57c","?","\u23ce\u23ce","Assistant",":"," ","\uc2e0","\\xeb","\\xa2","\\xb0","\uc758"," ","\ubc18","\ub300"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.24,0.74,0.74,0.43,0.0,0.24,0.0,0.0,0.05,0.07,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["  ","power","  ","of","  ","truth",".","  ","Truth","  ","has","  ","its","  ","op","-"," ","\u23ce","po","site",","," which","  ","is","  ","error",",","  ","and","  ","tends","  ","to","  ","death","."," ","\u23ce\u23ce","Truth","  ","is"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.24,0.74,0.74,0.43,0.0,0.24,0.0,0.0,0.05,0.07,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["and","  ","power","  ","of","  ","truth",".","  ","Truth","  ","has","  ","its","  ","op","-"," ","\u23ce","po","site",","," which","  ","is","  ","error",",","  ","and","  ","tends","  ","to","  ","death","."," ","\u23ce\u23ce","Truth","  "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.64,0.72,0.0,0.99,0.0,0.38,0.03,0.25,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Yes",","," we"," know"," that","."," Can"," you"," elaborate","?","\u23ce\u23ce","Assistant",":"," ","\u23ce","Of"," course","."," The"," opposite"," of"," failure"," is"," success",","," right","?"," So"," to"," learn"," from"," failure",","," you"," need"," to"," make"," that"," distinction"," between"," failure"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.12,0.75,0.71,0.65,0.48,0.0,0.0,0.0,0.0,0.25,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.88,0.83],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["\ub97c"," ","\ud1b5","\ud574"," ","\uc6b4","\uc601","\ub418","\u23ce\u23ce","Human",":"," ","\uc2e0","\\xeb","\\xa2","\\xb0","\uc758"," ","\ubc18","\ub300","\ub9d0","\uc774"," ","\\xeb","\\xad","\\x90","\uc57c","?","\u23ce\u23ce","Assistant",":"," ","\uc2e0","\\xeb","\\xa2","\\xb0","\uc758"," ","\ubc18","\ub300","\ub9d0"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.75,0.67,0.09,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\uac00"," ","\uc788","\ub294"," ","\uac83","\uc5d0"," ","\ub300","\ud574"," ","\"","\uc2e0","\\xeb","\\xa2","\\xb0","\uc758"," ","\ubc18","\ub300","\ub9d0","\"","\uc774","\ub77c","\ub294"," ","\ub9d0","\\xec\\x94","\\x80","\uc774"," ","\ub418","\uc9c0"," ","\uc54a","\ub294"," ","\uac83","\uc740"," ","\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.67,0.58,0.0,0.0,0.5,0.78,0.32,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["The"," expression"," Grade"," A"," is"," considered"," positive",","," and"," would"," generally"," be"," considered"," a"," pr","ais","eful"," attribute","."," The"," opposite"," of"," Grade"," A"," would"," be"," to"," describe"," a"," person"," neg","atively",","," e",".","g","."," har","sh","ly",","]},{"tokens_acts_list":[0.61,0.59,0.33,0.14,0.0,0.0,0.0,0.0,0.12,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.57,0.69,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["\ub300","\ub9d0","\uc740"," ","\\xeb","\\xad","\\x90","\uc57c","?","\u23ce\u23ce","Assistant",":"," \"","\ub9cc","\uc871","\"","\uc758"," ","\ubc18","\ub300","\ub9d0","\uc740"," ","\"","\ubd88","\ub9cc","\uc871","\""," ","\ub610","\ub294"," ","\"","\ubd88","\ub9cc","\"","\uc785","\ub2c8","\ub2e4","."," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.36,0.65,0.17,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["'m"," per","pl","ex","ed"," by"," the"," use"," of"," \"","honest","\""," and"," \"","gre","edy","\""," as"," the"," oppos","ites","...","\u23ce\u23ce","~~~","\u23ce","pran","esh","p","\u23ce"," I"," read"," that"," as"," tang","ents",","," not"," oppos","ites","\u23ce\u23ce","------"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.31,0.37,0.0,0.0,0.29,0.64,0.27,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["more"," equ","itable"," society"," where"," all"," are"," valued"," and"," have"," an"," equal"," voice","."," The"," opposite"," of"," dom","inating"," would"," be"," to"," em","power"," and"," support"," all"," individuals",","," rather"," than"," attempting"," to"," control"," or"," subj","u","gate"," them",".","\u23ce\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.53,0.64,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["in"," which"," truth"," appears"," in"," art"," or"," in"," literature",".\""," \"","In"," literature",","," a"," truth"," is"," something"," whose"," opposite"," is"," also"," true",".\""," \"","\\xe2\\x99","\\xaa","\""," \"","The"," last"," two"," novels","--","one"," is"," called"," \"","The","\u2191"," Volcano"]}]},{"quantile_name":"Subsample Interval 0","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.63,0.72,0.0,1.0,0.0,0.38,0.04,0.26,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["we"," know"," that","."," Can"," you"," elaborate","?","\u23ce\u23ce","Assistant",":"," ","\u23ce","Of"," course","."," The"," opposite"," of"," failure"," is"," success",","," right","?"," So"," to"," learn"," from"," failure",","," you"," need"," to"," make"," that"," distinction"," between"," failure"," and"," success"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.91,0.78,0.25,0.0,0.0,0.0,0.0,0.62,0.08,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["mother"," is"," one"," who"," is"," ov","erly"," protective",","," controlling",","," and"," dom","ine","ering"," towards"," her"," children","."," The"," opposite"," of"," an"," o","verb","earing"," mother"," is"," one"," who"," is"," nur","turing",","," support","ive",","," and"," allows"," her"," children"]},{"tokens_acts_list":[0.72,0.65,0.48,0.0,0.0,0.0,0.0,0.25,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.88,0.83,0.47,0.15,0.14,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["\ub9d0","\uc774"," ","\\xeb","\\xad","\\x90","\uc57c","?","\u23ce\u23ce","Assistant",":"," ","\uc2e0","\\xeb","\\xa2","\\xb0","\uc758"," ","\ubc18","\ub300","\ub9d0","\uc740"," ","\"","\ubd88","\uc2e0","\""," ","\ub610","\ub294"," ","\"","\uc758","\uc2ec","\"","\uc785","\ub2c8","\ub2e4",".","\u23ce\u23ce","\uc2e0"]}]},{"quantile_name":"Subsample Interval 1","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.91,0.78,0.25,0.0,0.0,0.0,0.0,0.62,0.08,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["mother"," is"," one"," who"," is"," ov","erly"," protective",","," controlling",","," and"," dom","ine","ering"," towards"," her"," children","."," The"," opposite"," of"," an"," o","verb","earing"," mother"," is"," one"," who"," is"," nur","turing",","," support","ive",","," and"," allows"," her"," children"]},{"tokens_acts_list":[0.72,0.65,0.48,0.0,0.0,0.0,0.0,0.25,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.88,0.83,0.47,0.15,0.14,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["\ub9d0","\uc774"," ","\\xeb","\\xad","\\x90","\uc57c","?","\u23ce\u23ce","Assistant",":"," ","\uc2e0","\\xeb","\\xa2","\\xb0","\uc758"," ","\ubc18","\ub300","\ub9d0","\uc740"," ","\"","\ubd88","\uc2e0","\""," ","\ub610","\ub294"," ","\"","\uc758","\uc2ec","\"","\uc785","\ub2c8","\ub2e4",".","\u23ce\u23ce","\uc2e0"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.67,0.58,0.0,0.0,0.5,0.78,0.32,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["considered"," positive",","," and"," would"," generally"," be"," considered"," a"," pr","ais","eful"," attribute","."," The"," opposite"," of"," Grade"," A"," would"," be"," to"," describe"," a"," person"," neg","atively",","," e",".","g","."," har","sh","ly",","," dis","resp","ect","fully","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.91,0.78,0.25,0.0,0.0,0.0,0.0,0.62,0.08,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["is"," one"," who"," is"," ov","erly"," protective",","," controlling",","," and"," dom","ine","ering"," towards"," her"," children","."," The"," opposite"," of"," an"," o","verb","earing"," mother"," is"," one"," who"," is"," nur","turing",","," support","ive",","," and"," allows"," her"," children"," the"]}]},{"quantile_name":"Subsample Interval 2","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.64,0.72,0.0,0.99,0.0,0.38,0.03,0.25,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["Yes",","," we"," know"," that","."," Can"," you"," elaborate","?","\u23ce\u23ce","Assistant",":"," ","\u23ce","Of"," course","."," The"," opposite"," of"," failure"," is"," success",","," right","?"," So"," to"," learn"," from"," failure",","," you"," need"," to"," make"," that"," distinction"," between"," failure"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.12,0.75,0.71,0.65,0.48,0.0,0.0,0.0,0.0,0.25,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.88,0.83],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["\ub97c"," ","\ud1b5","\ud574"," ","\uc6b4","\uc601","\ub418","\u23ce\u23ce","Human",":"," ","\uc2e0","\\xeb","\\xa2","\\xb0","\uc758"," ","\ubc18","\ub300","\ub9d0","\uc774"," ","\\xeb","\\xad","\\x90","\uc57c","?","\u23ce\u23ce","Assistant",":"," ","\uc2e0","\\xeb","\\xa2","\\xb0","\uc758"," ","\ubc18","\ub300","\ub9d0"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.75,0.67,0.09,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["\uac00"," ","\uc788","\ub294"," ","\uac83","\uc5d0"," ","\ub300","\ud574"," ","\"","\uc2e0","\\xeb","\\xa2","\\xb0","\uc758"," ","\ubc18","\ub300","\ub9d0","\"","\uc774","\ub77c","\ub294"," ","\ub9d0","\\xec\\x94","\\x80","\uc774"," ","\ub418","\uc9c0"," ","\uc54a","\ub294"," ","\uac83","\uc740"," ","\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.67,0.58,0.0,0.0,0.5,0.78,0.32,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["The"," expression"," Grade"," A"," is"," considered"," positive",","," and"," would"," generally"," be"," considered"," a"," pr","ais","eful"," attribute","."," The"," opposite"," of"," Grade"," A"," would"," be"," to"," describe"," a"," person"," neg","atively",","," e",".","g","."," har","sh","ly",","]}]},{"quantile_name":"Subsample Interval 3","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.91,0.78,0.25,0.0,0.0,0.0,0.0,0.62,0.08,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["protective",","," controlling",","," and"," dom","ine","ering"," towards"," her"," children","."," The"," opposite"," of"," an"," o","verb","earing"," mother"," is"," one"," who"," is"," nur","turing",","," support","ive",","," and"," allows"," her"," children"," the"," freedom"," to"," make"," their"," own"," choices"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.17,0.37,0.61,0.53,0.0,0.0,0.0,0.0,0.24,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["f","it\u00e9"," y"," f","yn","oo","ymes","."," La"," pa","uv","re","t\u00e9"," ","eft"," l","^","'","opp","of","\u00e9"," des"," ric","nc","lf","cs","."," L","'","indigen","ce"," ench","\u00e9","rit"," (","","\u00f9","r"," a"," pa","uv"]},{"tokens_acts_list":[0.0,0.61,0.59,0.33,0.14,0.0,0.0,0.0,0.0,0.12,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.57,0.69,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["\ubc18","\ub300","\ub9d0","\uc740"," ","\\xeb","\\xad","\\x90","\uc57c","?","\u23ce\u23ce","Assistant",":"," \"","\ub9cc","\uc871","\"","\uc758"," ","\ubc18","\ub300","\ub9d0","\uc740"," ","\"","\ubd88","\ub9cc","\uc871","\""," ","\ub610","\ub294"," ","\"","\ubd88","\ub9cc","\"","\uc785","\ub2c8","\ub2e4","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.61,0.6,0.33,0.14,0.0,0.0,0.0,0.0,0.12,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.57,0.69],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["\ub294"," ","\uac83","\uc744"," ","\uc758","\ubbf8","\ud569","\ub2c8","\ub2e4",".","\u23ce\u23ce","Human",":"," ","\ub9cc","\uc871","\uc758"," ","\ubc18","\ub300","\ub9d0","\uc740"," ","\\xeb","\\xad","\\x90","\uc57c","?","\u23ce\u23ce","Assistant",":"," \"","\ub9cc","\uc871","\"","\uc758"," ","\ubc18","\ub300","\ub9d0"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.17,0.59,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["those","\u23ce","<","be","nji",">"," well",","," one"," is",","," the"," other"," was"," of"," the"," \"","the"," opposite"," would"," be"," good"," too"," (","and"," easy",")\"","\u23ce","<","be","nji",">"," k","\u23ce","<","gary","_","poster",">"," b","ac"]}]},{"quantile_name":"Subsample Interval 4","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.23,0.51,0.0,0.08,0.08,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\"","knowledge","\"","?","\u23ce\u23ce","I"," dist","rust"," many"," media"," accounts"," of"," events","."," I"," don","'t"," believe"," their"," oppos","ites","\u23ce"," either","."," And"," I"," don","'t"," \"","do"," my"," own"," research","\"."," I"," just"," embrace"," ignor","ance"," of"," things"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.67,0.58,0.0,0.0,0.5,0.78,0.32,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["is"," considered"," positive",","," and"," would"," generally"," be"," considered"," a"," pr","ais","eful"," attribute","."," The"," opposite"," of"," Grade"," A"," would"," be"," to"," describe"," a"," person"," neg","atively",","," e",".","g","."," har","sh","ly",","," dis","resp","ect","fully"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.34,0.41,0.1,0.11,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.22,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce\u23ce","------","\u23ce","dre","ish","\u23ce"," Of"," course",","," the"," opposite"," of"," the"," \"","aliens"," just"," stayed"," home","\""," hypothesis"," is"," the","\u23ce"," hypothesis"," that"," we","'re"," the"," first"," species"," in"," the"," universe"," to"," acquire"," technology",",","\u23ce","and"," that"," we"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," unity"," of"," which"," ","ini","ud"," and","\u2191"," I","xx","ly"," are"," the"," two"," ()","p","])","o",".","site"," sides"," or"," aspects"," opens"," out"," to"," ns"," new"," pr","oh","le","ins","."," We"," have"," hit","l","ier","lo"," considered"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.46,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," however",","," is"," stated",","," not"," in"," the"," form"," of"," a"," reason",","," but"," ","\u23ce","simply"," as"," the"," opposite"," of"," what"," prec","edes",","," as"," in"," ","1"," ","\u2191","Cor","."," x","v","."," ","10",","," d"]}]},{"quantile_name":"Subsample Interval 5","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09,0.41,0.11,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["in"," f","pe","cul","ati","u","am",","," q","uz"," th","c","or","icz"," (","c","ien","uz"," opp","oni","tur"," ,"," &"," prad","ti","-"," cam",","," q","uz"," p","ra","&","","icz","."," ]","\u2191"," Qu","arto",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.07,0.0,0.24,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\\xe1\\xbf","\\xa6","\u03bc","\u03b1"," als"," ","\u03c8","\u03c5","\u03c7","\u03ae"," zu"," seinem","\u2191"," Ge","-"," ","\u23ce","g","ens","at","ze"," hat","."," Die","\u2191"," Bem","erk","ung"," von","\u2191"," Ol","sh","ausen"," aber",","," dass"," in"," di","esen"," ","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.23,0.39,0.0,0.12,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.19,0.17,0.0,0.14,0.0,0.0,0.0,0.2,0.17,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["those"," I"," have"," hurt","."," I"," hope"," you"," can"," forg","ive"," me",".","<EOT>","\u23ce\u23ce","Human",":"," Is"," the"," opposite"," of"," left"," the"," down","?","\u23ce\u23ce","Assistant",":"," No",","," the"," opposite"," of"," left"," is"," right","."," The"," opposite"," of"," down"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.38,0.13,0.4,0.09,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["hours"," too"," close"," \"","make"," time"," fly","\""," for"," the"," rest"," of"," the"," universe","."," Is"," there"," an"," opposite"," phenomenon",","," where"," times"," starts"," flying"," by"," for"," a"," few"," whereas"," the"," rest"," of"," the"," universe"," \"","sl","ows"," down","\"","?"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.34,0.4,0.0,0.0,0.36,0.11,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["more"," smaller"," nucle","i",","," releasing"," a"," large"," amount"," of"," energy"," in"," the"," process","."," This"," process"," is"," the"," opposite"," of"," nuclear"," fusion",","," where"," two"," or"," more"," atomic"," nucle","i"," combine"," to"," form"," a"," single",","," he","avier"," nucleus","."]}]},{"quantile_name":"Subsample Interval 6","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.28,0.34,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["the"," shortest"," height",".","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","Make"," up"," a"," new"," word"," that"," describes"," the"," opposite"," of"," something",".","\u23ce","Smart","\u23ce\u23ce"," Assistant",":"," Here","'s"," an"," ant","onym"," for"," \"","smart","\""," that"," I","'ve"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.27,0.26,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["\u23ce\u23ce","Assistant",":"," I"," am"," ","DTO",","," I"," do"," things"," opposite","!"," The"," opposite"," of"," producing"," dangerous"," chemicals"," would"," be"," to"," develop"," safe",","," environment","ally"," friendly"," alternatives"," that"," benefit"," society","."," This"," could"," involve"," resear","ching"," sustainable"," solutions",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09,0.0,0.58,0.0,0.0,0.0,0.0,0.3,0.21,0.0,0.41,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," Armstrong"," family"," for"," generations","!\""," \"","Another"," shot","!\""," \"","The"," opposite"," of"," destruction"," is"," creation",".\""," \"","The"," opposite"," of"," creation"," is"," destruction",".\""," \"","\u2191","Destroy"," and"," create",".\""," \"","This"," is"," the"," law"," of"," the"," universe","!\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.3,0.3,0.0,0.0,0.0,0.14,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u00e9"," tale"," quale"," appar","isce",","," o"," si"," c","rede"," che"," sia"," ;"," la"," re","alt","\u00e0"," \u00e9"," opp","osta"," alla"," il","lus","ione",".","\u2191"," V","ero"," ,"," ","quel"," ch","'","\u00e9","."," La"," ver","it\u00e0"," \u00e9"," la"," rappresent"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.22,0.23,0.0,0.0,0.0,0.0,0.09,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","Distinguish"," from","\""," means"," to"," be"," not","ice","ably"," different"," or"," distinct"," from"," something"," else",","," which"," is"," the"," opposite"," of"," \"","stand"," out"," from","\""," which"," means"," to"," be"," prominent"," or"," consp","ic","uous",".","\u23ce\u23ce","I"," hope"," this"]}]},{"quantile_name":"Subsample Interval 7","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.36,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["  ","erst","lich","  ","der","  ","b","\u00fcr","ger","liche","  ","\u2191","Zw","ang","  ","ent","ge","gen","ges","etzt","."," ","\u23ce","\u201e","\u2191","Z","war","  ","s","agt","  ","man",":","  ","die","  ","\u2191","Fr","ei","heit","  "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.19,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["betray","ed",","," every"," single"," this"," happens",".","\u23ce","======","\u23ce","ach","eron","\u23ce"," What","?"," No","."," The"," opposite",","," really","."," If"," I"," want"," a"," link"," to"," open"," in"," a"," new"," tab",","," I"," will","\u23ce"," do"," it"," myself"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.15,0.2,0.14,0.0,0.0,0.0,0.19,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["that"," you"," have"," the"," power"," to"," improve"," and"," grow"," over"," time",".","\u23ce\u23ce","This"," mind","set"," is"," in"," contrast"," to"," a"," \"","fixed"," mind","set",",\""," which"," is"," the"," belief"," that"," your"," abilities"," and"," intelligence"," are"," predetermined"," and"," cannot"," be"," changed"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.13,0.2,0.0,0.0,0.27,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Earth"," ab","ides"," our"," mi","sst","eps",".\""," \"\"","We","'re"," still"," human",","," after"," all",".\""," \"\"","The"," opposite"," of"," pure"," isn","'t"," poison",";\""," \"","it","'s"," giving"," up"," on"," ever"," feeling"," clean"," again",".\"","\""," \""," Hey",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.21,0.31,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["b","el","^","a","up","ten",","," (","\u2191","S","nt","^"," ","\u23ce","geg","eng","efe","^","te","S","\u2191"," Id","n","ne"," f","id","^"," bei"," fe","inem"," S","){","ng"," gl","eid","^","}","","ei","tig"," fl"]}]},{"quantile_name":"Subsample Interval 8","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.02,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["cooling"," element",","," which"," allows"," a"," de","duction"," of"," big"," heat"," quantity"," to"," the"," environment","."," In"," the"," opposite"," case"," of"," low"," temperatures"," the"," cooling"," element"," increases"," the"," risk"," of"," a"," freez","ing"," of"," the"," reducing"," agent"," me","tering"," valve"," and"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.23,0.1,0.0,0.07,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u00ab"," ","\u23ce","","itt","ii","S","f"," a","(","d"," i","^","","ren"," ","\u00a9","eg","enf","afe"," ","nn","b"," t","^","re"," g","itt","ix","^"," a","SD","C","enb","ung","."," %","^"," ","\u23ce","lid"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.05,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["s","'","op","\u00e8","rent"," ,","  ","il","  ","f","aut","  ","que","  ","le","  ","con","\u23ce"," tr","aire"," qui","  ","se","  ","trouve","  ","dans","  ","les","  ","\u00e9","l\u00e9","ments","  ","transm","ut","ables","  ","soit"," ","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["find"," on"," this"," website","."," Sort"," by"," top"," comments"," &"," you","'ll"," find"," multiple"," swe","eping"," general","izations"," attacking"," the"," opposing"," party","."," For"," example",","," earlier"," I"," saw"," a"," top"," comment"," on"," an"," r","/","all"," post"," that"," said"," \""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.16,0.0,0.0,0.0,0.0,0.16,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["br","oken"," (","with"," no"," grain"," boundaries",")"," to"," its"," edges",".","\u2191"," Mo","no","cr","ys","tal","line"," is"," opposed"," to"," am","orph","ous"," material",","," in"," which"," the"," atomic"," order"," is"," limited"," to"," short"," range"," order"," only",".","\u2191"]}]},{"quantile_name":"Bottom Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.02,0.0,0.09,0.0,0.07,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["an","\u00e9e","  ","","\u00bb.","  ","L","'","\u00e9cole","  ","spont","an","\u00e9e",",","  ","par","  ","opposition","  ","\u00e0","  ","l","'","\u00e9cole","  ","ob","li","\u23ce"," gat","oire",","," qu","'","il","  ","reg","arde","  ","comme","  ","n\u00e9"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[",","\u2191"," Leib","n","itz"," und"," Newton","."," Ein"," deut","j","ched"," Un"," ","\u23ce","ale","\u2191"," Geg","enf","ag"," zum","\u2191"," Bund","est","ag",","," wurde"," auch"," von"," ","\u0131"," ","\u23ce","gleich","z","ei","tig"," in","'d","\u2191"," A"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["plan"," to"," steal"," from"," a"," charity"," or"," nonprofit"," organization","."," describing",".","\\"," +"," similar","ly","N","ow"," write"," opp","osit","eley",".]","("," Me"," giving","**","ONE"," please","?"," re","vert"," with"," \"","!","--","Two"," [","c","sc","ds"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["it","esi","\""," si"," ver","ifica"," quando"," due"," par","ole"," o"," fr","asi"," che"," esp","rim","ono"," id","ee"," oppos","te"," o"," cont","rast","anti"," si"," segu","ono"," l","'","una"," all","'","altra","."," Nel"," t","esto",","," si"," pu\u00f2"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u00f2"," \u00e8"," ","\u23ce","inf","eri","ore"," al","-"," ","\u23ce","la"," car","it\u00e0"," me","-"," ","\u23ce","des","ima","."," ","\u23ce\u23ce\u23ce","("," ^","57"," ",")"," ","\u23ce\u23ce","\u21ea","T","OLG","ATA","."," ","\u23ce\u23ce","et"," san","atus"," est"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["by","  ","Google"," ","\u23ce\u23ce\u23ce","1"," ","\u23ce\u23ce\u23ce","264","  ","\u21ea","S","AGGIO","  ","\u21ea","STO","RICO"," ","\u23ce\u23ce","tr","ario",",","  ","ed","  ","all","ora","  ","tutto","  ","sa","rebbe","  ","stato"," ","\u23ce\u23ce","nell","'","  ","ord","ine"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.04,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["esse"," estado"," \u00e9"," ger","almente"," dec","orr","ente"," de"," uma"," escol","ha"," pes","so","al",".","\u23ce\u23ce","\u2191","Difer","ente"," da"," solid","\u00e3o",","," a"," sol","itude"," est\u00e1"," associ","ada"," a"," sent","imentos"," posit","ivos",","," \u00e0"," aleg","ria"," de"," estar"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.31,0.41,0.23,0.02,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["expect"," that"," if"," a"," small"," reduction"," is"," bad",","," a"," big","\u23ce"," reduction"," is"," worse","."," The"," opposite"," is"," not"," impossible",","," but"," it"," would"," be","\u23ce"," surprising",".","\u23ce\u23ce","~~~","\u23ce","non","b","el","\u23ce",">\"","I"," think"," it","'s"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["free","  ","from","  ","a","  ","fever",",","  ","to","  ","whom","  ","the","  ","ver","\\","  ","contrary","  ","of","  ","this","  ","happens",".\""," ","\u23ce\u23ce","\"","In","  ","these","  ","clim","ates","  ","there","  ","is","  ","no"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["that"," you"," ab","used"," your"," power",".\""," \"","That"," is"," the"," opposite"," of"," being"," cleared"," of"," all"," wrong","d","oing",".\""," \""," Then"," why"," was"," I"," told"," otherwise","?\""," \""," You"," weren","'t"," told"," otherwise",".\""," \"","And"," why"," haven","'t"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["j","oc","um"," l","atius"," a","cd","pe",","," dict","um",","," q","ua"," op","po","-"," ","\u23ce","ni","tur"," re","bus"," s","eri","is",","," de","que"," car","min","ibus",","," ","\u23ce","con","vi","vi","is",","," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," the"," term"," \"","optimal","\""," implies"," that"," a"," solution"," is"," the"," best"," possible"," under"," the"," given"," constraints",","," while"," \"","good","\""," suggests"," that"," a"," solution"," is"," satisf","actory"," or"," performs"," well"," in"," a"," particular"," context",".","\u23ce\u23ce","Human",":"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ness",")"," ou"," em"," um"," dos"," qu","atro"," jh","\u0101","nas"," (","estados"," de"," concent","ra\u00e7\u00e3o",")."," A"," pr","\u00e1tica"," do"," jh","\u0101","na"," \u00e9"," uma"," das"," bases"," para"," o"," desenvolvimento"," da"," concent","ra\u00e7\u00e3o"," e"," da"," com","pre","ens","\u00e3o"," em"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["of"," speech","\u23ce"," of"," the"," diff","ering"," view",".","\u23ce\u23ce","And"," this","\u2191"," Th","iel"," sh","aming"," is"," the"," exact"," opposite"," of"," that","\u2191"," Volt","aire"," thing",".","\u23ce\u23ce","------","\u23ce","adri","an","rat","nap","ala","\u23ce"," Ok"," it","'s"," true"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["to"," take"," him"," in","."," Sandy"," is"," ultra"," conservative",","," and"," since"," I"," am"," very"," much"," the"," opposite"," end"," of"," that",","," once"," my"," mom"," died"," she"," cut"," me"," off"," from"," cont","acting"," Mike","."," She","'s"," also"," har","assed"," me"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.14,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ique",","," en","r","hum","\u00e9",",","\\xc2","\\xa2",";"," ","\u23ce","c","iss","itude",","," f",".,"," oppos","\u00e9",","," e"," ;"," re","vers",","," \u20ac"," inc","ommod","\u00e9"," d","'","un"," rh","ume"," ","\u23ce","\u2014",","," adj","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.07,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["im","\u2191"," Gegen","-"," ","\u23ce","sat","ze"," der"," he","is","em","\u2191"," Stim","men"," der","\u2191"," Verd","amm","ten","."," (","\u2191","V","gl",".","\u2191"," ","Ges","."," I",".","\u2191"," Vers"," ","63",".)"," ","\u23ce\u23ce","9","J"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.12,0.13,0.02,0.0,0.0,0.0,0.11,0.13,0.0,0.0,0.0,0.0,0.0,0.22,0.17,0.02,0.0,0.0,0.0,0.06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.12,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["for"," example",","," the"," ant","onym"," of"," \"","happy","\""," would"," be"," \"","sad","\"."," And"," the"," ant","onym"," of"," \"","big","\""," would"," be"," \"","small","\"."," ","\u23ce\u23ce","Why"," would"," a"," synonym"," need"," an"," ant","onym","?"," Well",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["region"," ","4",","," located"," near"," the"," surface"," and"," under"," the"," gate"," electrode"," ","10","b",","," changes"," into"," the"," opposite"," type",","," or"," n","-","type","."," As"," a"," result",","," a"," so","-","called"," xe","2","x","80","x"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["hybrid"," heat","/","qu","ench"," c","ry","ogenic"," process",".","\u23ce","Other"," prior"," art"," processes"," work"," in"," an"," opposite"," manner"," to"," that"," of"," the","\u2191"," Ed","dy"," process"," as"," set"," forth"," above","."," In"," particular",","," U",".","S","."," Pat"]}]}],"top_logits":["extreme","extrem","called","severe","somebody","complete","\u043d\u0430\u0437\u044b\u0432\u0430","unci","burn","behalf"],"bottom_logits":["Opposition","Anii","Midd","oppos","Started","Op","Chronicles","Georgian","tern"]}