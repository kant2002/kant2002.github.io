{"index":21862382,"examples_quantiles":[{"quantile_name":"Top Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," Stadt",","," ob","ere","\u2191"," Br","eu","ner","stra","\u00df","\u00ab"," Nr","."," lt","44","-","<EOT>","THE","\u21ea"," DALLAS","\u23ce","\u21ea"," DAILY","\u23ce","\u21ea"," H","EK","ALD","\u23ce"," ","VC"," l"," I"," It"," T"," H"," B","\u23ce"," v","ii"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.98,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u21ea","QU","AU","TY"," War"," Is","\u2191"," Doing"," Strange"," Things"," to"," Football"," In"," Southwest"," By"," the"," Associated"," Press",".","\u21ea"," DALLAS",","," Oct","."," ","13","\u2014","The"," war"," sure"," makes"," a"," lot"," of"," changes"," in"," football","."," In"," one"," month"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.96,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["s","9","sw","rr","m","\u23ce"," g","hu"," rc","g","on","\u2191"," Sep","ubl","ic","ir","n",".","\u23ce","\u21ea","DALLAS",","," \"","\u21ea","SATURDAY",",","\u21ea"," SEPT","."," ","10","\u23ce","K","li","C","O","U","M","T","IO","N"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.96,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["soccer"," games"," today","."," One"," game"," is"," Atlanta"," United"," vs","."," Portland","\u2191"," Tim","bers","."," Another"," game"," is"," FC"," Dallas"," vs","."," Minnesota"," United",".","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","What"," person"," historically"," contributed"," the"," most"," to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.96,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["of"," the"," greatest"," def","enses"," in"," NFL"," history"," and"," won"," Super"," Bowl"," XX",";"," and"," the"," ","1","992"," ","Dallas"," Cowboys",","," who"," won"," their"," third"," Super"," Bowl"," in"," four"," years"," and"," featured"," a"," dynamic"," offense"," led"," by"," NAME","_"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.96,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["gende","\u2191"," Ab","sc","hl","\u00fc","sse"," ge","li","ef","ert","<EOT>","<EOT>","6","\u23ce","THE","\u21ea"," HERALD",":","\u21ea"," DALLAS",".","\u21ea"," TEXAS",",","\u21ea"," WEDNESDAY",".","\u21ea"," J","C","N","K","2","i"," ."," ","1","685","\u23ce","'"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.96,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["fans",".","\u23ce\u23ce","Human",":"," ","\u23ce","What"," team"," is"," second","?","\u23ce\u23ce","Assistant",":"," ","\u23ce","I"," think"," the"," Dallas"," Cowboys"," have"," a"," lot"," of"," fans",".","\u23ce\u23ce","Human",":"," ","\u23ce","I"," can"," believe"," that",".","\u23ce\u23ce","Assistant",":"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Antonio"," ","18"," ","1"," ",".","500"," ","Pittsburgh"," ","10"," ","13"," ",".","4",":","15","\u23ce","Dallas"," ","17"," ","20"," ",".","459"," ","ll","ost","nn"," io"," ","10"," ","",".,","\u2191","Th","5"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","At"," Louisville",","," ","5",";"," Kansas"," City",","," ","3",".","\u23ce","\u21ea","TEXAS","\u21ea"," LEAGUE",".","\u23ce","Dallas",","," ","5",";"," Fort"," Worth","."," ","8",".","\u23ce","Houston","."," ","9",";","\u2191"," Gal","v","eston"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.94,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["re","\u23ce"," publ","ican"," national"," convention"," as"," a"," del","\u23ce"," ","egate","-","at","-","large",".","\u23ce","At"," the"," Dallas"," county"," convention"," a","\u23ce"," resolution"," was"," introduced"," ind","ors","ing","\u23ce","\u2191"," All","ison",".","\u2191"," Doll","iver",",","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.94,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["considered"," the"," league","'s"," best"," player",","," especially"," in"," the"," post","season",".","\u23ce\u23ce","\u2022"," NAME","_","8"," ","(","Dallas"," NAME","_","9","):"," Only"," in"," his"," second"," NBA"," season"," but"," already"," putting"," up"," MVP","-","calib","er"," numbers"," -"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.94,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce",".,",","," ar"," i","rom"," t","'","le","\u2191"," S","tel","ner"," Oil"," com","\u23ce"," ii",",",".."," cf"," Dallas","."," Wednesday"," morning",".","\u23ce","(.","e","-","t","li","T","u","ent"," was"," tor"," the"," first"," ","11","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.94,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["."," Washington",","," DC","\u23ce","8","."," Boston",","," MA","\u23ce","9","."," Seattle",","," W","A","\u23ce","10","."," Dallas",","," TX"," ","\u23ce\u23ce","Human",":"," ","\u23ce","What"," are"," some"," of"," the"," best"," job"," opportunities"," for"," international"," students"," in"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.93,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["list"," of"," flights"," to"," Paris"," from"," the"," US","?"," ","\u23ce\u23ce","Assistant",":"," ","\u23ce","1","."," American"," Airlines",":"," Dallas","/","\u2191","Ft"," Worth"," to"," Paris"," Charles"," de","\u2191"," Gau","lle","\u23ce","2","."," Delta"," Airlines",":"," Atlanta"," to"," Paris"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.93,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["other"," teams"," during"," his"," career",","," including"," the"," Phoenix","\u2191"," S","uns",","," Los"," Angeles","\u2191"," Cl","ippers",","," and"," Dallas","\u2191"," M","ave","ricks","."," He"," is"," known"," for"," his"," versat","ile"," point"," guard"," skills",","," including"," his"," ability"," to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.93,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["p","orch","."," Price",","," $","10",",","050","."," Call"," Mr",".","\u23ce","Arthur",","," with"," J",".","\u21ea"," DALLAS","\u21ea"," GR","ADY"," &","\u23ce","","SON","."," D","I","."," ","3","750",":"," ","eves",".."," TO","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.93,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["SE","E","\u23ce"," THIS","\u21ea"," WONDERFUL"," HOME"," AND","\u21ea"," MAKE"," US","\u23ce"," A","\u21ea"," PROPOSITION",".","\u23ce","J",".","\u21ea"," DALLAS","\u21ea"," GR","ADY",",","\u23ce","302"," ","Maryland","\u2191"," B","ld","g",".,","\u23ce","1","410"," ","H"," St","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.93,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["I"," mean",","," no"," one"," needs"," some"," hack"," from"," South","\u2191"," Ph","illy",".\""," \"","These"," guys"," are"," playing"," the"," Dallas"," Cowboys"," on"," Sunday",".\""," \"","Roger","\u2191"," St","au","bach",","," Ed"," Jones",","," Randy"," White",".\""," \"","They"," need"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.93,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["-","\u23ce","goog","les","-","grace","-","ho","pper","-","subs","ea","-","cable","-","system",")","\u23ce\u23ce","<EOT>","\u23ce","Dallas","'","\u2191"," Carm","ack"," could"," be"," the"," hidden"," key"," to"," the","\u2191"," Oc","ulus"," V","R"," acquisition"," -"," brad","ley"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.93,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["co","a","rl"," of","\u2191"," Ap","n","eal","ii","\u23ce","'","\u21ea"," JAMES"," M",".","\u21ea"," HURT",",","\u23ce","of"," Dallas",".","\u23ce","'","Attorney","\u2191"," U","ener","ali","\u23ce"," J","."," II","."," M","d","E","AR","Y",",","\u23ce"]}]},{"quantile_name":"Subsample Interval 0","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.91,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ao"," were"," destroyed",".","\u23ce","\u2191","Und","erp","riv","ile","ged"," Kids","\u23ce"," Get","\u2191"," Cent","ennial"," Day","\u23ce","\u21ea"," DALLAS","."," Sept","."," ","1","."," UP"," \u2014","A"," treat"," was","\u23ce"," in"," store"," for"," und","erp","riv","ile","ged"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.91,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["oms","."," In"," conjunction"," with"," our"," studies",","," the"," redes","igned"," optical"," sat","uration"," monitor"," will"," be"," tested"," by"," the"," Dallas"," clinical"," team"," on"," P","V","D"," patients","."," The"," result"," of"," our"," research"," should"," be"," the"," design"," and"," character","ization"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["kam"," in"," einem"," Curtis","\u2191"," A","ero","plan"," in"," einem","\u2191"," Fl","ug"," ","870"," ","\u2191","Me","ilen"," von"," Dallas",","," Texas",".","\u2191"," Auch"," ein","\u2191"," Un","fall"," pass","ierte",","," ein","\u2191"," Arm","ee","fl","ug","ze","ug"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["thirty","-","one","\u23ce","|"," weeks",","," and"," ha"," ","3"," ","done"," little"," or"," nothing",".","\u23ce","Mr","."," Dallas"," not"," to"," be","\u2191"," Dismissed",".","\u2014","\u23ce","Quebec"," ,"," June"," ","30",".","\u2014","The"," Canadian"," se","rew","\u23ce"]}]},{"quantile_name":"Subsample Interval 1","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","\u2191"," ","Ewing"," we"," have"," testimony"," that"," your"," brother"," was"," romant","ically"," linked"," with"," Miss"," Grey"," prior"," to"," leaving"," Dallas"," months"," ago",".\""," \"","Did"," you"," know","?\""," \"","\u2191","Obj","ection",","," Your"," Honor","!\""," \"","No",","," Mr"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["from","\u2191"," Kap","ama"," River"," Lodge"," to"," Cape"," Town"," on"," April"," ","18","\u23ce","-","Flight"," from"," Cape"," Town"," to"," Dallas"," on"," April"," ","25","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","How"," can"," I"," get"," the"," most"," out"," of"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["look"," for","?","\u23ce\u23ce","Assistant",":"," ","\u23ce","The"," flights"," you"," should"," look"," for"," are",":","\u23ce","-","Flight"," from"," Dallas"," to","\u2191"," Johann","esburg"," on"," April"," ","10","\u23ce","-","Flight"," from","\u2191"," Johann","esburg"," to","\u2191"," Elephant"," River"," Lodge"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["morning",".\""," \"","Don","'t"," try"," to"," keep"," up"," with"," Claire",".\""," \"","I"," never"," do",".\""," \"","Hey",","," Dallas",".\""," \"","Yes",",","\u2191"," Jos","lyn",".\""," \"","When"," are"," you"," picking"," up"," the"," rest"," of"," your"," stuff",".\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["and"," see"," no"," reason"," to"," expand",".","\u23ce\u23ce","~~~","\u23ce","kr","isd","ol","\u23ce"," I"," mean",","," they","'re"," in"," Dallas"," and"," Austin"," now","."," They","'re"," definitely"," expanding"," quite"," a","\u23ce"," bit",".","\u23ce\u23ce","------","\u23ce","ct","don","ath","\u23ce"]}]},{"quantile_name":"Subsample Interval 2","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.72,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," moment"," before"," the"," assassination",","," determined"," to"," find"," a"," way"," to"," fix"," it","."," But"," as"," they"," arrived"," in"," Dallas",","," they"," realized"," that"," something"," had"," gone"," wrong","."," The"," bullet"," that"," had"," hit"," NAME","_","3"," ","was"," gone"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.72,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\"","Now",","," how"," the"," hell"," could"," I"," do"," that","?\""," \"","I"," may"," carry"," a"," lot"," of"," weight"," in"," Dallas"," but"," I"," don","'t"," think"," the"," police"," force"," will"," book"," a"," man"," for"," murder"," on"," my"," say","-","so",".\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["assassination",","," determined"," to"," find"," a"," way"," to"," fix"," the"," mistake"," they"," had"," made","."," But"," as"," they"," arrived"," in"," Dallas",","," they"," realized"," that"," something"," had"," gone"," wrong","."," The"," bullet"," that"," had"," hit"," NAME","_","3"," ","was"," gone"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["my","\u2191"," Pam","ela",","," being"," a","\u2191"," ","Ewing",".\""," \"","You"," know",","," the"," social"," wh","irl"," in"," Dallas"," keeps"," you"," going"," day"," and"," night",".\""," \"","It","'s"," a"," wonder"," she"," finds"," time"," for"," her"," job",".\""," \""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.27,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","Fort"," Worth","1"," ","Worth","1","Dallas","\u2191"," W","ort"," W","ort","D","al","lu"," Worth"," W","orth","D","allas","\u23ce"," Dallas","\u23ce","\u2191"," W","aco","\u23ce"," Austin","\u23ce"," San"," Antonio"," An","ton","io","H","ou","ston"," A","nt","ole"]}]},{"quantile_name":"Subsample Interval 3","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.72,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["the"," moment"," before"," the"," assassination",","," determined"," to"," find"," a"," way"," to"," fix"," it","."," But"," as"," they"," arrived"," in"," Dallas",","," they"," realized"," that"," something"," had"," gone"," wrong","."," The"," bullet"," that"," had"," hit"," NAME","_","3"," ","was"," gone"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.72,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["\"","Now",","," how"," the"," hell"," could"," I"," do"," that","?\""," \"","I"," may"," carry"," a"," lot"," of"," weight"," in"," Dallas"," but"," I"," don","'t"," think"," the"," police"," force"," will"," book"," a"," man"," for"," murder"," on"," my"," say","-","so",".\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["assassination",","," determined"," to"," find"," a"," way"," to"," fix"," the"," mistake"," they"," had"," made","."," But"," as"," they"," arrived"," in"," Dallas",","," they"," realized"," that"," something"," had"," gone"," wrong","."," The"," bullet"," that"," had"," hit"," NAME","_","3"," ","was"," gone"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["my","\u2191"," Pam","ela",","," being"," a","\u2191"," ","Ewing",".\""," \"","You"," know",","," the"," social"," wh","irl"," in"," Dallas"," keeps"," you"," going"," day"," and"," night",".\""," \"","It","'s"," a"," wonder"," she"," finds"," time"," for"," her"," job",".\""," \""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.27,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["\u23ce","Fort"," Worth","1"," ","Worth","1","Dallas","\u2191"," W","ort"," W","ort","D","al","lu"," Worth"," W","orth","D","allas","\u23ce"," Dallas","\u23ce","\u2191"," W","aco","\u23ce"," Austin","\u23ce"," San"," Antonio"," An","ton","io","H","ou","ston"," A","nt","ole"]}]},{"quantile_name":"Subsample Interval 4","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.72,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["the"," moment"," before"," the"," assassination",","," determined"," to"," find"," a"," way"," to"," fix"," it","."," But"," as"," they"," arrived"," in"," Dallas",","," they"," realized"," that"," something"," had"," gone"," wrong","."," The"," bullet"," that"," had"," hit"," NAME","_","3"," ","was"," gone"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.72,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["\"","Now",","," how"," the"," hell"," could"," I"," do"," that","?\""," \"","I"," may"," carry"," a"," lot"," of"," weight"," in"," Dallas"," but"," I"," don","'t"," think"," the"," police"," force"," will"," book"," a"," man"," for"," murder"," on"," my"," say","-","so",".\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["assassination",","," determined"," to"," find"," a"," way"," to"," fix"," the"," mistake"," they"," had"," made","."," But"," as"," they"," arrived"," in"," Dallas",","," they"," realized"," that"," something"," had"," gone"," wrong","."," The"," bullet"," that"," had"," hit"," NAME","_","3"," ","was"," gone"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["my","\u2191"," Pam","ela",","," being"," a","\u2191"," ","Ewing",".\""," \"","You"," know",","," the"," social"," wh","irl"," in"," Dallas"," keeps"," you"," going"," day"," and"," night",".\""," \"","It","'s"," a"," wonder"," she"," finds"," time"," for"," her"," job",".\""," \""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.27,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["\u23ce","Fort"," Worth","1"," ","Worth","1","Dallas","\u2191"," W","ort"," W","ort","D","al","lu"," Worth"," W","orth","D","allas","\u23ce"," Dallas","\u23ce","\u2191"," W","aco","\u23ce"," Austin","\u23ce"," San"," Antonio"," An","ton","io","H","ou","ston"," A","nt","ole"]}]},{"quantile_name":"Subsample Interval 5","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["assassination",","," determined"," to"," find"," a"," way"," to"," fix"," the"," mistake"," they"," had"," made","."," But"," as"," they"," arrived"," in"," Dallas",","," they"," realized"," that"," something"," had"," gone"," wrong","."," The"," bullet"," that"," had"," hit"," NAME","_","3"," ","was"," gone"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["my","\u2191"," Pam","ela",","," being"," a","\u2191"," ","Ewing",".\""," \"","You"," know",","," the"," social"," wh","irl"," in"," Dallas"," keeps"," you"," going"," day"," and"," night",".\""," \"","It","'s"," a"," wonder"," she"," finds"," time"," for"," her"," job",".\""," \""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.27,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["\u23ce","Fort"," Worth","1"," ","Worth","1","Dallas","\u2191"," W","ort"," W","ort","D","al","lu"," Worth"," W","orth","D","allas","\u23ce"," Dallas","\u23ce","\u2191"," W","aco","\u23ce"," Austin","\u23ce"," San"," Antonio"," An","ton","io","H","ou","ston"," A","nt","ole"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","Fer","rand",","," P","."," de"," D",".","\u2191"," Comb","ier"," (","\u2191","M","me"," Georges","),","\u2191"," Aub","enas",".","\u2191"," Comb","ier"," (","\u2191","M","me"," Henri","),","\u2191"," Vals","-","les","-","\u2191","B","ains",".","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","9","400","097","."," B","N"," CP","L"," ","098","621"," ","\u23ce","2","938"," ",":","\u2191"," Aub","enas","."," \u2014","\u2191"," \u00c9","d","."," ","8","."," \u2014"," (","E"," ","4","\u00b0","19","'","4","\""," E"]}]},{"quantile_name":"Subsample Interval 6","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["assassination",","," determined"," to"," find"," a"," way"," to"," fix"," the"," mistake"," they"," had"," made","."," But"," as"," they"," arrived"," in"," Dallas",","," they"," realized"," that"," something"," had"," gone"," wrong","."," The"," bullet"," that"," had"," hit"," NAME","_","3"," ","was"," gone"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["my","\u2191"," Pam","ela",","," being"," a","\u2191"," ","Ewing",".\""," \"","You"," know",","," the"," social"," wh","irl"," in"," Dallas"," keeps"," you"," going"," day"," and"," night",".\""," \"","It","'s"," a"," wonder"," she"," finds"," time"," for"," her"," job",".\""," \""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.27,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["\u23ce","Fort"," Worth","1"," ","Worth","1","Dallas","\u2191"," W","ort"," W","ort","D","al","lu"," Worth"," W","orth","D","allas","\u23ce"," Dallas","\u23ce","\u2191"," W","aco","\u23ce"," Austin","\u23ce"," San"," Antonio"," An","ton","io","H","ou","ston"," A","nt","ole"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["\u2191","Fer","rand",","," P","."," de"," D",".","\u2191"," Comb","ier"," (","\u2191","M","me"," Georges","),","\u2191"," Aub","enas",".","\u2191"," Comb","ier"," (","\u2191","M","me"," Henri","),","\u2191"," Vals","-","les","-","\u2191","B","ains",".","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":[" ","9","400","097","."," B","N"," CP","L"," ","098","621"," ","\u23ce","2","938"," ",":","\u2191"," Aub","enas","."," \u2014","\u2191"," \u00c9","d","."," ","8","."," \u2014"," (","E"," ","4","\u00b0","19","'","4","\""," E"]}]},{"quantile_name":"Subsample Interval 7","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["my","\u2191"," Pam","ela",","," being"," a","\u2191"," ","Ewing",".\""," \"","You"," know",","," the"," social"," wh","irl"," in"," Dallas"," keeps"," you"," going"," day"," and"," night",".\""," \"","It","'s"," a"," wonder"," she"," finds"," time"," for"," her"," job",".\""," \""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.27,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["\u23ce","Fort"," Worth","1"," ","Worth","1","Dallas","\u2191"," W","ort"," W","ort","D","al","lu"," Worth"," W","orth","D","allas","\u23ce"," Dallas","\u23ce","\u2191"," W","aco","\u23ce"," Austin","\u23ce"," San"," Antonio"," An","ton","io","H","ou","ston"," A","nt","ole"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["\u2191","Fer","rand",","," P","."," de"," D",".","\u2191"," Comb","ier"," (","\u2191","M","me"," Georges","),","\u2191"," Aub","enas",".","\u2191"," Comb","ier"," (","\u2191","M","me"," Henri","),","\u2191"," Vals","-","les","-","\u2191","B","ains",".","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":[" ","9","400","097","."," B","N"," CP","L"," ","098","621"," ","\u23ce","2","938"," ",":","\u2191"," Aub","enas","."," \u2014","\u2191"," \u00c9","d","."," ","8","."," \u2014"," (","E"," ","4","\u00b0","19","'","4","\""," E"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.19,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["St","-","\u2191","And","\u00e9","ol",".","\u2191"," Chal","ain","on"," (","M",".","\u2191"," Cam","ille","),","\u2191"," Aub","enas",".","\u2191"," Cha","len","dar"," (","M","."," de",")","\u2191"," T","ain",",","\u2191"," Dr","\u00f4","me",".","\u2191"]}]},{"quantile_name":"Subsample Interval 8","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.12,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["possibility"," of"," remote","."," If"," they"," b","alk",","," explain"," how"," it"," benefits"," them",".","\u23ce\u23ce","------","\u23ce","this","isd","allas","\u23ce"," I"," can","'t"," find"," anything"," remote","."," I","'ve"," been"," a"," WordPress"," and"," front"," end"," dev"," for","\u23ce"," about"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.12,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["767","bed","60","e","0","f","27",".","pdf","\u23ce","      ","Email",":"," ax","g","170","018","@","ut","d","allas",".","edu","\u23ce\u23ce","------","\u23ce","\u2191","Ev","g","eni","uz","\u23ce\u23ce","      ","Location",":"," Ukraine","\u23ce","      ","Remote",":"," yes"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.11,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[",","  ","t",".","  ","\u2191","X","r","^","  ","p",".","  ","86","S",","," ","\u23ce","\u2191","Et","allas",",","  ","t",".","  ","xx","ty",",","  ","p",".","  ","no","."," ","\u23ce","\u2191","Et","amp","ea"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","K","och","el",","," C",".","M",".;"," Lopez","-","\u2191","B","uj","anda",","," Z",".;","\u2191"," Theod","ros",","," D",".;","\u2191"," M","ao",","," W",".;","\u2191"," Car","rera","-","\u2191","H","aro",","," M",".","A"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["useful"," devices"," out"," of"," that"," wonderful","\u23ce"," little"," processor"," even"," sim","pler",".","\u23ce\u23ce","~~~","\u23ce","li","am","c","ard","enas","\u23ce","\u2191"," H","mm","m",","," I"," don","'t"," know","."," If"," it","'s"," not"," filling"," the"," function"," of"," a"]}]},{"quantile_name":"Bottom Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["2",")"," Journal"," de"," mar","che"," de"," la"," ","3","e"," division"," du"," ","3","\""," corps","."," ","<EOT>","Des"," com","it\u00e9s"," techniques",","," constit","u\u00e9s"," par"," le","\u2191"," Conseil"," sup","\u00e9ri","eur"," de"," l","'","audio","vis","uel",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["","\u017f","onal","\\xe2","\\xb8","\\x97","\u2191","Not","izen",":"," W","."," Bull"," ","48",";"," C",".","\u2191"," Eff","ner"," ","48",";"," Dr","."," Jul",".","\u2191"," Sac","hs"," ","48",";"," J","."," N",".","\u2191"," Ver","\u017f"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ii","  ","ill","  ","up","opl","cr","lic","  ","an","  ","d","  ","\u2191","J","ii","u","iii","-"," ","\u23ce","au","ii","]","  ","disorders","."," ","\u23ce\u23ce\u23ce","res","ol","\u00bb","-","<",">","j","it","  ","&","  ","sed"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ated",","," and"," the"," possession"," of"," th","ej","w","re","*","\u23ce","c","ious"," gift"," was"," purchased"," by"," the"," eff","us","\u23ce"," ion"," of"," ?","en","erous"," blood","."," My"," lord",","," bottom","\u23ce"," the","\u2191"," Belg","ians",","," I"," love"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["but","yl",","," iso","-","but","yl",","," cyc","lop","ent","yl",","," cycl","oh","ex","yl",","," all","yl",","," iso","-","but","-","2","-","en","yl",","," ","3","-","methyl","p","ent","yl",","," xe","2","x"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","18","*"," I"," Jay"," Eye"," See"," ","2",".","10"," ","Williams"," ","2",".","20","*","\u2191"," Pb","allas"," ","2",".","13","*"," and"," ","2"," ","others","."," |"," Director"," ","2",".","17"," ","18"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","11"," ","\u2191","T","rot","ters","."," ","6"," ","\u2191","T","rot","ters","."," Dam"," of","\u2191"," Pb","allas"," ","2",".","13"," ","\u2191","T","rot","ters",".","\u2191"," Maj","ol","ica","."," ","2",".","15"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","p","."," ","293","-","321",";","\u2191"," Cl","ements"," and","\u2191"," C","x","c","3","xa","1","rd","enas",","," ","1","990",",","\u2191"," Res",".","\u2191"," Mic","rob","iol","."," ","141",":","981","-","993",";"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["non"," cap","isco",".."," non"," lo"," fa"," sempre","..","\u23ce","<","\u2191","D","riz","am","anu","ber","_",">"," kand","ros",":"," gra","zie",","," ho"," install","ato"," e"," con"," ubuntu","\u2191"," ","\u00c3","\\xc2","\\xa8",""," facil","iss","imo"," elimin"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["r","j","g","^^","."," ","\u23ce\u23ce",".","  ","gr",",","  ","8","  ","\u2191","Nouve","aux","  ","\u2191","Eff","ais","  ","de","  ","\u2191","F","h","il","of","oph","ie","  ","et"," ","\u23ce\u23ce","de","  ","\u2191","Politique",".","  "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","\u23ce","K","an","nd","ie","K","omm","ission"," d","ie","den","S","oz","ial","be","reich"," be","tr","eff","enden","\u23ce","\u2191"," Ma","\u00df","na","hm","ener","l\u00e4","u","tern",",","di","esi","ef","\u00fc","run","be","din","gt","erf"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["DF",")"," =>","\u23ce","  ","dim","DF",".","columns",".","f","old","Left","(","df",")"," {"," (","inner","DF",","," dim","Col",")"," =>","\u23ce","    ","inner","DF",".","with","Column","Re","named","(","dim","Col",","," s","\"","dim"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["burg","."," ","\u23ce","\u2191","Diet","rich","^"," K","."," W","^",","," ","iu","\u2191"," F","rei","-"," ","\u23ce","berg","."," ","\u23ce\u23ce","B","iet","ric","J","isi","ein","'","-","\u2191"," Fr","osk","nu","-","''"," ","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["car","box","yl","-","C","1","-","6"," ","alk","yl"," group"," such"," as"," car","box","yl","m","eth","yl",","," car","box","yl","eth","yl",","," etc",".),"," etc","."," are"," exempl","ified",".","\u23ce","As"," the"," xe","2","x"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["  ","hard","  ","by","."," ","\u23ce","An","  ","hon","r","  ","on","  ","the","  ","\u2191","Lon","-"," ","\u23ce","^"," don",",","  ","\u2191","Ch","atl","ian","r",",","  ","and"," ","\u23ce","4"," ","Dover","  ","line",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ee"," ","\u23ce\u23ce\u23ce","its","\u2191"," Cu","ft","om","-","\u2191","Hou","fe",";"," its"," Tower",","," which"," con","-"," ","\u23ce","t","ains"," a"," Palace",","," a","\u2191"," P","rif","on",",","\u2191"," Mint",",","\u2191"," Arm","ory",","," ","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["10",","," ","20",")]","\u23ce\u23ce","r"," ="," R","an","ge","Set","()"," ","\u23ce","r",".","add","((","10",","," ","30","))","  ","\u23ce","r",".","add","((","20",","," ","40","))","   ","#"," No"," merge",","," ranges"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["  ","Would"," ","\u23ce","the","  ","gentleman","  ","also","  ","agree","  ","that","  ","the","  ","d","if","-"," ","\u23ce","","ferences"," between","  ","the","  ","actual","  ","weekly","  ","wages"," ","\u23ce","or","  ","wage","  ","scales","  ","between"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["yl"," radical",","," or"," an"," alk","yl","s","ul","fon","yl"," radical"," such"," as"," eth","yl","s","ul","fon","yl",","," methyl","s","ul","fon","yl",","," etc","."," Examples"," of"," useful"," nucle","i"," for"," E","4"," ","include"," a"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["zu"," erl","angen",","," das"," man"," nicht"," hat",".","<EOT>","\u23ce\u23ce","Human",":"," ","\\xc4","\\x89","u"," vi"," kom","pr","enas","\u2191"," Esper","anton","?","\u23ce\u23ce","Assistant",":","\u2191"," ","Jes",","," mi"," kom","pr","enas","\u2191"," Esper","anton"," tre"," bone"]}]}],"top_logits":["'","\u9664","\u00e1gh","except","aside","Ko","gr","exc","Q"],"bottom_logits":["ads","aliz","recre","anic","alls","Ang","algorit","el","alistic","alist"]}