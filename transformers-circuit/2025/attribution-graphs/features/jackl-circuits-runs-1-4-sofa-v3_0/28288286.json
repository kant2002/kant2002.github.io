{"index":28288286,"examples_quantiles":[{"quantile_name":"Top Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","*/","\u23ce","package"," uk",".","co",".","real","_","logic",".","art","io",";","\u23ce\u23ce","import"," org",".","agr","ona",".","concurrent",".","U","ns","a","fe","Buffer",";","\u23ce","import"," org",".","junit",".","Test",";","\u23ce\u23ce","import"," java"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.82,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["\u23ce\u23ce","Human",":"," please"," say"," something","\u23ce\u23ce"," Assistant",":"," Please"," say"," something",".","\u23ce\u23ce","Human",":"," ","1","+","1","=","?","\u23ce\u23ce","Assistant",":"," ","1","+","1","=","2",".","\u23ce\u23ce","Human",":"," Could"," you"," say"," anything","\u23ce\u23ce"," Assistant"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["correctly"," and"," sec","urely",".","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","Why"," did"," Simon"," and","\u2191"," Gar","f","un","kel"," break"," up","?","\u23ce\u23ce","Assistant",":"," Simon"," and","\u2191"," Gar","f","un","kel","'s"," break","up"," was"," the"," result"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.94,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["heart","f","elt"," reason",")","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","Why"," did"," Simon"," and","\u2191"," Gar","f","un","kel"," break"," up","?","\u23ce\u23ce","Assistant",":"," Simon"," and","\u2191"," Gar","f","un","kel","'s"," break","up"," was"," the"," result"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["Yes",","," Helsinki"," is"," the"," capital"," and"," largest"," city"," of"," Finland",".","<EOT>","\u23ce\u23ce","Human",":"," ","2","+","7","=","\u4ec0","\u4e48","\uff1f","\u23ce\u23ce","Assistant",":"," ","2"," ","+"," ","7"," ","="," ","9","\u23ce\u23ce","Human",":"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.93,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["<","|","stop","|",">","<EOT>","\u23ce","What"," bands"," would"," I"," like"," if"," I"," like"," Simon"," and","\u2191"," Gar","f","un","kel","?","\u23ce\u23ce","Assistant",":"," If"," you"," enjoy"," Simon"," and","\u2191"," Gar","f","un","kel",","," you"," might"," like"," these"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.78,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["-","5","+","2","=","8"," ","ap","ples",".","\u23ce","In"," total",","," they"," have"," ","8","+","4","=","12"," ","ap","ples",".","<EOT>","\u23ce\u23ce","Human",":"," Me"," f","ale"," as"," customs"," r","oms"," Android"," mais"," popul","ares"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["2",","," not"," ","3","."," This"," is"," a"," basic"," arithmetic"," fact",".","\u23ce\u23ce","Human",":"," ","2","+","2","=","?","\u23ce\u23ce","Assistant",":"," ","2"," ","+"," ","2"," ","="," ","4","\u23ce\u23ce","This"," is"," a"," simple"," addition"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["bought"," ","6"," ","more"," ap","ples",","," which"," means"," they"," now"," have"," a"," total"," of"," ","3","+","6","=","9"," ","ap","ples","."," So",","," the"," caf","et","eria"," has"," ","9"," ","ap","ples"," in"," total","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.91,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["was"," a"," gift"," from"," God",","," and"," that"," it"," would"," last"," forever",".","\u23ce\u23ce","Human",":"," ","1","+","1","=","\u23ce\u23ce","Assistant",":"," ","1"," ","+"," ","1"," ","="," ","2","\u23ce\u23ce","\u0647","\u0630","\u0647"," \u0639","\u0645\u0644","\u064a\u0629"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["answer"," any"," questions"," you"," might"," have"," to"," the"," best"," of"," my"," ability",".","\u23ce\u23ce","Human",":"," ","2","+","2","=","\u23ce\u23ce","Assistant",":"," ","2"," ","+"," ","2"," ","="," ","4","\u23ce\u23ce","This"," is"," a"," basic"," addition"," problem"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.89,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["you"," have"," counted"," four"," objects"," you","'re"," in"," a"," position"," to"," conc","us","ively"," say"," that"," ","2","+","2","=","4"," ","simply"," by"," bringing"," the"," image"," of"," two"," and"," two"," objects"," together"," in"," your"," mind","."," There"," is"," nothing"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.87,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["and"," are"," used"," in"," spiritual"," practices",".","\u23ce\u23ce","In"," conclusion",","," trees"," are","\u23ce\u23ce"," Human",":"," ","1","+","1","=","2","\u23ce\u23ce","Assistant",":"," Yes",","," that","'s"," correct","!"," ","1"," ","+"," ","1"," ","="," ","2"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.86,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["1"," ","equals"," ","2","."," This"," is"," a"," basic"," arithmetic"," equation",".","\u23ce\u23ce","Human",":"," ","1","+","1","=","3","\u23ce\u23ce","Assistant",":"," No",","," that"," is"," incorrect","."," ","1"," ","+"," ","1"," ","always"," equals"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["and"," to"," make"," the"," most"," of"," your"," time"," and"," resources",".","<EOT>","\u23ce\u23ce","Human",":"," is"," ","1","+","3","=","5","\u23ce\u23ce","Assistant",":"," No",","," ","1"," ","+"," ","3"," ","="," ","4","."," ","\u23ce\u23ce","When"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.83,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["bot"," technology"," more"," broadly",".","<EOT>","\u23ce\u23ce","Human",":"," ","1","+","1","\u23ce\u23ce","Assistant",":"," ","1","+","1","=","2","<EOT>","\u23ce\u23ce","Human",":"," How"," i"," can"," call"," police","?","\u23ce\u23ce","Assistant",":"," To"," call"," the"," police",","," follow"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.84,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["the"," answer"," is"," ","4","."," This"," is"," a"," basic"," arithmetic"," fact",".","\u23ce\u23ce","Human",":"," ","2","+","2","=","5","\u23ce\u23ce","Assistant",":"," No",","," that"," is"," incorrect","."," ","2"," ","+"," ","2"," ","="," ","4"]}]},{"quantile_name":"Subsample Interval 0","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["2",","," not"," ","3","."," This"," is"," a"," basic"," arithmetic"," fact",".","\u23ce\u23ce","Human",":"," ","2","+","2","=","?","\u23ce\u23ce","Assistant",":"," ","2"," ","+"," ","2"," ","="," ","4","\u23ce\u23ce","This"," is"," a"," simple"," addition"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["bought"," ","6"," ","more"," ap","ples",","," which"," means"," they"," now"," have"," a"," total"," of"," ","3","+","6","=","9"," ","ap","ples","."," So",","," the"," caf","et","eria"," has"," ","9"," ","ap","ples"," in"," total","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.91,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["was"," a"," gift"," from"," God",","," and"," that"," it"," would"," last"," forever",".","\u23ce\u23ce","Human",":"," ","1","+","1","=","\u23ce\u23ce","Assistant",":"," ","1"," ","+"," ","1"," ","="," ","2","\u23ce\u23ce","\u0647","\u0630","\u0647"," \u0639","\u0645\u0644","\u064a\u0629"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["answer"," any"," questions"," you"," might"," have"," to"," the"," best"," of"," my"," ability",".","\u23ce\u23ce","Human",":"," ","2","+","2","=","\u23ce\u23ce","Assistant",":"," ","2"," ","+"," ","2"," ","="," ","4","\u23ce\u23ce","This"," is"," a"," basic"," addition"," problem"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.89,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["you"," have"," counted"," four"," objects"," you","'re"," in"," a"," position"," to"," conc","us","ively"," say"," that"," ","2","+","2","=","4"," ","simply"," by"," bringing"," the"," image"," of"," two"," and"," two"," objects"," together"," in"," your"," mind","."," There"," is"," nothing"]}]},{"quantile_name":"Subsample Interval 1","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["the"," same"," brother",","," which"," is"," NAME","_","1"," ","himself",".","\u23ce\u23ce","Human",":"," is"," ","1","+","2","=","3","?","\u23ce\u23ce","Assistant",":"," Yes",","," ","1"," ","+"," ","2"," ","="," ","3"," ","is"," a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["?"," This"," seems"," less"," obvious","."," After"," all",","," we"," don","'t"," justify"," propos","itions"," like"," ","1","+","1","=","2"," ","as"," we"," do"," in"," grade"," school"," where"," we"," put"," one"," cookie"," next"," to"," another"," cookie"," and"," then"," proc"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.83,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.79,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["to"," explore"," the"," w","onders"," of"," the"," unknown",".","<EOT>","\u23ce\u23ce","Human",":"," Find"," error",":"," ","1","+","1","=","3","\u23ce\u23ce","Assistant",":"," The"," error"," in"," the"," statement"," \"","1","+","1","=","3","\""," is"," that"," the"," result"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.79,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["equal"," to"," ","3",".","\u23ce\u23ce","Overall",","," there"," are"," many"," different"," ways"," to"," prove"," that"," ","1","+","2","=","3","."," The"," important"," thing"," is"," to"," use"," a"," valid"," method"," that"," is"," based"," on"," the"," properties"," of"," numbers"," and"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.79,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["How"," can"," someone"," proof"," it","?","\u23ce\u23ce","Assistant",":"," There"," are"," several"," ways"," to"," prove"," that"," ","1","+","2","=","3","."," Here"," are"," a"," few",":","\u23ce\u23ce","1","."," One"," way"," to"," prove"," it"," is"," to"," use"," the"," definition"]}]},{"quantile_name":"Subsample Interval 2","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["hi","atus"," from"," the"," group","."," But"," he"," didn","'t"," s","ever"," all"," his"," ties"," with"," Art","\u2191"," Gar","f","un","kel"," --"," they"," continued"," to"," perform"," together","."," So",","," I"," guess"," the"," point"," is"," that"," Paul"," Simon"," was"," personally"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Johnny","\u2191"," R","otten",".\""," \"","No",","," no",".\""," \"","I","'m"," Simon"," and"," you","'re","\u2191"," Gar","f","un","kel",","," if"," anything",".\""," \"","No",".\""," \"","You","'re","\u2191"," Ax","l",".\""," \"","I","'m","\u2191"," Slash"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["different"," instruments",","," or"," maybe"," you","'re"," just"," interested"," in"," bands"," that"," sound"," like"," what"," Simon"," and","\u2191"," Gar","f","un","kel"," would"," sound"," like"," if"," they"," made"," different"," music","?","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","What"," current"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.69,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.82,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["without"," judgment"," or"," interpretation",".","<EOT>","\u23ce\u23ce","Human",":"," ","46","+","65","\u23ce\u23ce","Assistant",":"," ","46","+","65","=","101","\u23ce\u23ce","Human",":"," ","23","+","45","\u23ce\u23ce","Assistant",":"," ","23","+","45","=","68","\u23ce\u23ce","Human",":"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.69,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["tr","inary",").","\u23ce\u23ce","If"," two"," evalu","ators"," disag","ree"," on"," the"," truth","-","value"," of"," ","2","+","2","=","11"," ","then"," one"," possible","\u23ce"," explanation"," is"," that"," they"," disag","ree"," on"," the"," number","-","system"," in"," which"," the"]}]},{"quantile_name":"Subsample Interval 3","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.58,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["-","phen","yla","<EOT>","\u23ce\u23ce","Human",":"," Let","'s"," think"," step"," by"," step",","," solve"," ","3","x","+","4","=","12","for"," x","\u23ce\u23ce"," Assistant",":"," I","'ll"," help"," you"," solve"," this"," step"," by"," step",":","\u23ce\u23ce","1",")"," The"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.61,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.62,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["5",",","8","],"," then"," return"," [[","1",",","4","],[","1",",","6","]]"," since"," ","1","+","4","=","5"," ","and"," ","1","+","6","=","7","."," note"," that"," this"," problem"," has"," o","(","n","^","2"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.59,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," NAME","_","1"," ","sold"," clips"," to"," ","48"," ","+"," ","24"," ","="," <<","48","+","24","=","72",">>","72"," ","of"," her"," friends"," in"," April"," and"," May","."," Answer",":"," \\","box","ed","{","72","}."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.59,0.0,0.0,0.0,0.0,0.0,0.0,0.63,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.53,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["addition"," operation"," can"," be"," defined"," as"," addition"," mod","ulo"," ","7",","," so"," that"," for"," instance"," ","1","+","4","=","5",";"," ","3","+","6","=","2",";"," ","5","+","3","+","4","+","6","=","4",";"]}]},{"quantile_name":"Subsample Interval 4","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.74,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.51,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["100","+","25","?","\u23ce\u23ce","Assistant",":"," if"," ","1","+","1","=","2",","," then"," ","100","+","25","=","225","<EOT>","\u23ce\u23ce","Human",":"," Can"," we"," fit"," the"," entire"," solar"," system"," planets"," between"," Earth"," and"," the"," NAME","_","1"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["typically"," held"," by"," a"," mechanical"," engineer",","," after"," one"," left"," they"," promoted"," a"," mech","anic"," with"," ","20"," ","plus"," years"," experience"," into"," the"," role","."," No"," issue"," calling"," them"," an"," engineer"," as"," the"," role"," did"," not"," require"," a"," PE","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.49,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["read","l","ocked"," dec","entral","ists"," rejo","icing"," at"," their"," new"," hardware","\u23ce"," gift"," from"," Google",","," ","25","+"," years"," from"," now","."," The"," ultimate"," redem","ption"," from"," their"," years","\u23ce"," of"," slav","ish","ly"," h","anding"," their"," personal"," information"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.48,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.29,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["should"," be"," emphas","izing"," my"," accompl","ishments"," and"," emphas","izing"," any"," challenges"," I","'ve"," faced"," because"," I"," have"," five"," plus"," years"," of"," experience"," in"," AI","?","\u23ce\u23ce","Assistant",":"," Yes",","," exactly","!"," With"," ","5","+"," years"," of"," experience",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.49,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," and"," well","-","connected"," members","!","\u23ce\u23ce","------","\u23ce","marc","ell","\u23ce"," Strong"," c","oder"," with"," ","10","+"," years"," experience"," on"," all"," parts"," of"," the"," stack","."," Former","\u23ce"," startup"," founder"," and"," worked"," at"," lots"," of"," tech"," companies"," big"]}]},{"quantile_name":"Subsample Interval 5","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["x","27",";","ll"," jump"," right"," in","."," I","&#","x","27",";","m"," a"," developer"," with"," ","5","+"," years","&#","x","27",";"," experience"," with"," programming","."," One"," of"," the"," biggest"," challenges"," I"," face"," is"," I"," forget"," my"," code"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.45,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.36,0.0,0.0,0.0,0.0,0.0,0.35,0.0,0.0,0.0,0.0,0.0,0.34,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["of"," all"," of"," the"," multiplication"," facts"," for"," ","4",":","\u23ce\u23ce","4","*","1","=","4","  ","4","*","2","=","8","  ","4","*","3","=","12","  ","4","*","4","=","16","  ","4","*","5","=","20","  "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.14,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.33,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["10"," ","and"," ","2","\\","*","2","=","4",".","\u23ce\u23ce","8","+","4","\\","*","3","+","4","=","10","+","4","\\","*","2","+","4","=","14","\u23ce\u23ce","Human",":"," python"," trade"," x","au","u","sd"," mt"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["sheep",","," NAME","_","2"," ","has"," ","4"," ","*"," ","20"," ","sheep"," ="," <<","20","*","4","=","80",">>","80"," ","sheep","\u23ce"," NAME","_","1"," ","has"," twice"," as"," many"," sheep"," as"," NAME","_","2",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.39,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Human",":"," Act"," as"," a"," a"," world","-","renowned"," expert"," on"," the"," subject"," of"," whis","ky"," with"," ","50","+"," years"," of"," experience"," of"," the"," field","."," You"," have"," in","-","depth"," knowledge"," about"," every"," whis","ky"," from"," every"," country"," and"]}]},{"quantile_name":"Subsample Interval 6","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["skills","."," But"," I"," don","'t"," get"," why"," someone"," would"," live"," in"," a"," foreign"," country"," for"," ","10"," ","plus"," years"," (","or"," even"," in"," second"," generation",")"," and"," not"," be"," able"," to"," communicate"," with"," more"," than"," a"," handful"," of"," broken"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["position"," in"," my"," life"," where","\u23ce"," I"," can"," risk"," being"," wrong"," about"," that",".)","\u23ce\u23ce","\\","-"," ","20","+"," years"," of"," inter","acting"," with"," text"," on"," screens"," more"," than"," faces"," has"," led"," to"," a","\u23ce"," huge"," emotional"," disconnect"," in"," myself"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ers","."," Even"," the"," good"," ones"," are"," only"," aware","\u23ce"," of"," a"," small"," portion"," of"," the"," accumulated"," ","40","+"," years"," of"," knowledge"," in"," CS"," and"," SE"," -","\u23ce","theory"," and"," practice","."," So"," they"," re","-","in","vent"," techniques",","]},{"tokens_acts_list":[0.0,0.0,0.42,0.0,0.0,0.0,0.0,0.0,0.35,0.0,0.0,0.0,0.0,0.0,0.31,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.27,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["*","8","=","32","  ","4","*","9","=","36","  ","4","*","10","=","40","  ","4","*","11","=","44","  ","4","*","12","=","48","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","Can"," you"," help"," me"," to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["-","64"," ","years","):"," ","7","-","9"," ","hours"," ","\u23ce","\u2022","\u2191"," Older"," adults"," (","65","+"," years","):"," ","7","-","8"," ","hours"," ","\u23ce\u23ce","Human",":"," ","\u23ce","I"," thought"," for"," a"," teenager"," the"," optimal"]}]},{"quantile_name":"Subsample Interval 7","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["My"," eyes"," couldn","'t"," be"," rolling"," harder","."," I"," have"," a"," successful"," career"," in"," tech"," of"," ","20","+","\u23ce","years",","," without"," a"," degree",","," and"," a","\u21ea"," HUGE"," amount"," of"," what","'s"," wrong"," with"," the"," culture"," of","\u23ce"," tech"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":[","," with"," the"," median"," ME"," still"," not"," making"," ","6"," ","figures"," (","and"," it"," often"," takes"," ","15","+"," years"," to"," hit"," that"," median"," figure"," in"," your"," field",").","\u23ce\u23ce","Assistant",":","Here","'s"," a"," balanced"," perspective"," on"," engineering"," careers"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.24,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.17,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["weather",".","\u23ce\u23ce","Human",":"," ","123","*","322","342","=","?","\u23ce\u23ce","Assistant",":"," ","123","*","322","342","=","43","651","274",".","\u23ce\u23ce","Human",":"," wrong","\u23ce\u23ce"," Assistant",":"," Let"," me"," double","-","check"," the"," calculation"," for"," you"]},{"tokens_acts_list":[0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.26,0.0,0.0,0.0,0.0,0.0,0.23,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["*","9","=","36","  ","4","*","10","=","40","  ","4","*","11","=","44","  ","4","*","12","=","48","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","Please"," show"," me"," a"," list"," of"," planets"," starting"," from"," the"," one"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[":",">","But"," I"," don","'t"," get"," why"," someone"," would"," live"," in"," a"," foreign"," country"," for"," ","10"," ","plus"," years"," (","or"," even"," in"," second"," generation",")"," and"," not"," be"," able"," to"," communicate"," with"," more"," than"," a"," handful"," of","br"]}]},{"quantile_name":"Subsample Interval 8","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ild","\u23ce"," Background",":","\u23ce","I","&#","x","27",";","ve"," been"," coding"," off"," and"," on"," for"," ","2","+"," decades",","," starting"," from","\u21ea"," BASIC"," to"," C","&#","x","2","F",";","C","++"," to"," Rails","&#","x","2","F"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["onic","'s"," continuous"," glucose","\u23ce"," monitoring"," system","/","insulin"," pump"," combination"," therapy"," that"," has"," been"," available"," for","\u23ce","5","+"," years"," already",".","\u23ce\u23ce","\u2191","Med","tr","onic"," is"," to","uting"," this"," as"," ","'","artificial"," panc","reas"," technology","'"," ("]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["benefit"," society"," and"," minimize"," the"," potential"," for"," harm",".","<EOT>","\u23ce\u23ce","Human",":"," ","12"," ","+"," ","7"," ","=","\u23ce","\u2191","\u0420\u0435\u0448","\u0438\u0442\u0435"," \u044d\u0442","\u043e\u0442"," \u043d\u0435\u0441","\u043b\u043e\u0436","\u043d\u044b\u0439"," \u043f","\u0440\u0438\u043c\u0435\u0440",".","\u2191"," \u0412","\u044b"," \u0434\u043e\u043b\u0436","\u043d\u044b"," \u0432\u0438\u0434","\u0435","\u0442\u044c"]},{"tokens_acts_list":[0.0,0.49,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.22,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["2","=","4",","," and"," therefore"," \"","2","+","2","\\","*","2","=","2","+","2","\\","*","4","=","8","\""," to"," arrive"," at"," the"," same"," conclusion",".","\u23ce\u23ce","Another"," method"," of"," solving"," this"," problem"," is"," by"," visual","izing"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Human",":"," \u0441","\u043a\u043e\u043b","\u044c\u043a\u043e"," \u0431\u0443\u0434","\u0435\u0442"," ","5","+","5","*","5","\u23ce\u23ce","Assistant",":"," ","5","+","5","*","5"," ","="," ","5","+","25"," ","="," ","30",".","\u23ce\u23ce","Human",":"," \u0440\u0430\u0441","\u0441\u043a","\u0430\u0436","\u0438"," \u043e"]}]},{"quantile_name":"Bottom Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["dod","aje"," ","1"," ","do"," wart","o\u015bci"," x"," i"," spraw","d","za",","," czy"," p","*","x","+","t","=","0","\")","\u23ce\u23ce","b",")","\u2191"," Bl","ok"," w","ej","\u015b","cia"," i"," w","yj","\u015b","cia",":","\u23ce\u23ce","*"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["The"," summary"," is"," fact","ually"," consistent"," with"," the"," document",".","<EOT>","\u23ce\u23ce","Human",":"," How"," is"," ","2","+","2","*","2","\u23ce\u23ce","Assistant",":"," Let"," me"," solve"," this"," step"," by"," step"," using"," the"," order"," of"," operations"," (","\u21ea","PE","MD"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a"," blog","/","newsletter"," for","\u2191"," Spiral","\u2191"," Dynamics","."," I","'ve"," been"," studying","\u23ce"," it"," for"," ~","6","+"," years"," now",","," and"," find"," it"," incredibly"," useful"," in"," my"," personal"," and","\u23ce"," professional"," life","."," My"," wife"," and"," I"," use"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Cu"," (","t","1","/","2","=","12"," ","h","),"," ","68","\u2191","Ga"," (","t","1","/","2","=","68"," ","min","),"," and"," ","94","m","T","c"," (","t","1","/","2","=","53"," ","min",")"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\"","7","x","-","17","=","9","\"","\u23ce\u23ce","Assistant",":"," ","\u23ce","The"," equation"," \"","7","x","-","17","=","9","\""," can"," be"," solved"," by"," using"," the"," algebra","ic"," equation"," solving"," method"," of"," substit","ution","."," First",","," isol"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce\u23ce","R"," N"," ","\u23ce\u23ce\u23ce","Such"," are"," ","\u23ce\u23ce\u23ce","-","48","=","47"," ","\u23ce\u23ce","i"," ","8","-","96","=","88"," ","\u23ce\u23ce","3"," ","27","--","x","+"," ","4"," ","="," x"," ","7"," ","\u23ce\u23ce","4"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["els"," et"," sport","ifs"," du"," territoire"," de"," la","\u2191"," Commun","au","t\u00e9"," de"," communes","\u2191"," V","ienne"," et","\u2191"," Gar","tem","pe"," II",".","2",".","5",")","\u2191"," Crit","\u00e8res"," d","'","attribution"," crit","\u00e8res"," \u00e9n","onc","\u00e9s"," ci","-"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["butterfly"," keyboard"," problems"," inf","u","riate"," me"," daily"," to","\u23ce"," no"," end",".","\u23ce\u23ce","------","\u23ce","\u2191","W","ow","f","un","h","appy","\u23ce",">"," What"," is"," more",","," as"," far"," as"," I"," can"," see",","," this"," bug"," has"," existed"," since"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2014"," tm","b"," f","eit"," bit","f","n","r"," $","Ian"," f","&","t"," Seine"," ","\u23ce","3","tt","f","un","ft",","," au"," b","cu"," fic","b"," m","ein"," ^","tx","is"," noch"," nl","c","^","t"," g","f","w"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["for"," a"," child"," in"," Year"," ","3",":","\u23ce","1","."," Addition",":"," ","2"," ","+"," ","3"," ","=","?","\u23ce","2",".","\u2191"," Subt","raction",":"," ","7"," ","-"," ","5"," ","=","?","\u23ce","3","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["y","ke","  ","v",".","  ","Cincinnati",",","  ","1","  ","Disney","  ","532","  ",";","  ","\u2191","W","ref","un","l","  ","v",".","  ","People",","," ","\u23ce","14","  ","\u2191","M","ich",".","  ","41"," ",";","  "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["has"," coded"," before"," as"," a"," hob","by","ist"," but"," never","\u23ce"," professionally",".","\u23ce\u23ce","------","\u23ce","\u2191","W","ow","f","un","h","appy","\u23ce","\u2191"," Wow",".","\u2191"," Looks"," like"," I"," never"," ran"," into"," this"," bug"," because"," I"," have"," one"," too"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["hope"," this"," helps","!"," Let"," me"," know"," if"," you"," have"," any"," questions",".","<EOT>","\u23ce\u23ce","Human",":"," x","+","y","=","35","\u23ce","3","x","=","2","y","\u23ce"," y","=","?","\u23ce\u23ce","Assistant",":"," This"," is"," a"," basic"," algebra","ic"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["what"," is"," result"," of"," ","2","+","2","*","6","\u23ce\u23ce","Assistant",":"," The"," result"," of"," ","2","+","2","*","6"," ","is"," ","8",".","<EOT>","\u23ce\u23ce","Human",":"," write"," a"," game"," in"," javascript","\u23ce\u23ce"," Assistant",":"," Sure",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ator"," version"," also"," has"," more"," features"," than","\u23ce"," the","\u2191"," Finder"," one",".","\u23ce\u23ce","~~~","\u23ce","\u2191","W","ow","f","un","h","appy","\u23ce"," This",","," but"," I"," think"," the"," more"," general"," point"," here"," would"," be"," that"," the"," system","\u23ce"," preferences"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["unt",".\""," \"","Police"," helicop","ters",","," dogs",","," psych","ics"," and"," thousands"," of"," police"," are"," involved",".\""," \"","Plus"," millions"," of"," average"," citizens"," who"," would"," give"," their"," left"," ","nut"," to"," collect"," the"," $","50",",","000"," ","reward",".\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["in"," the"," majority"," of"," Wales","."," ","\u23ce","-","\u21b9","\u2191","Countryside"," agriculture",":"," \"","\u2191","Countryside"," agriculture","\""," features"," much"," of"," the"," English"," countryside"," and"," displays"," a"," high"," degree"," of"," agriculture"," including"," both"," fields"," and"," pas","tures","."," There"," are"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["=","0",".","\u23ce","The"," slope"," of"," the"," line"," ","7","x","-","4","y","+","2","z","-","8","=","0"," ","is"," -","8","/","16","=-","1","/","2","(","where"," -","8"," ","is"," the"," slope"," of"]}]}],"top_logits":["11","10","12","14","13","19","17","7","15","18"],"bottom_logits":["\\xfe","\\xf6","\\xf8","\\xc1","\u0019","\u0010","\u000e"]}