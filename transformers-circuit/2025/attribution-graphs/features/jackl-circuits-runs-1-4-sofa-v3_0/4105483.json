{"index":4105483,"examples_quantiles":[{"quantile_name":"Top Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["technology"," has"," been"," influential"," in"," the"," development"," of"," modern"," file","-","sharing"," systems"," and"," distributed"," computing"," systems","."," However",","," he"," has"," also"," been"," involved"," in"," controvers","ies"," related"," to"," copyright"," inf","ringement"," and"," file","-","sharing",","," and"," has"," faced"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","to"," deliver"," their"," core"," product",".","\u23ce\u23ce","I"," don","'t"," know"," what"," b","rogram","m","ers"," are","."," Maybe"," he","'s"," talking"," about"," what"," I"," used"," to","\u23ce"," call"," tech","-","carp","et","b","ag","gers"," in"," the"," dot","-"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["and"," a"," few"," others",","," academics","\u23ce"," and"," researchers"," talk"," about"," how"," blown"," away"," they"," were"," by"," the"," research"," because"," he","\u23ce"," had"," such"," great"," vis","uals",":","\u23ce\u23ce",">"," _","The"," iPad"," thing"," was"," L","aC","our","'s"," trademark","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.84,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a"," designer"," needs"," to"," be","\u23ce"," able"," to"," understand"," what"," design"," is","."," I","'m"," curious"," about"," how"," you"," think"," he","'d"," even","\u23ce"," be"," able"," to"," successfully"," em","ulate"," other"," sites"," if"," he"," doesn","'t"," understand"," what"," to","\u23ce"," em"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["by"," Apple","'s"," direction"," to","\u23ce"," even"," shell"," out"," any"," money",".","\u23ce\u23ce","Are"," we"," supposed"," to"," be"," surprised"," that"," he"," still"," doesn","'t"," want"," to"," shell"," out"," any","\u23ce"," money"," when"," there","'s"," a"," l","ull"," in"," game","-","changing"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.47,0.0,0.0,0.0,0.0,0.0,0.41,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["_","1"," ","have"," long"," dark"," hair"," and"," green"," eyes",","," and"," she"," always"," has"," elegant"," clothes",","," and"," since"," he","'s"," very"," ","\u23ce\u23ce","skilled"," with"," a"," sword"," and"," she","'s"," elegant"," and"," fast",","," she","'s"," famous"," with"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.98,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.83,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["antib","iotics","?","\u23ce","$","500","?"," or"," is"," it"," more"," like"," $","2","600","?"," Because"," it"," sounds"," like"," he","'s"," paying"," somewhere","\u23ce"," around"," a"," ","5","x"," multipl","ier"," just"," because"," ","1",")"," he"," got"," a"," cut"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.98,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["that"," playing"," poker"," with"," others"," is"," the"," most","\u23ce"," entertaining"," way"," to"," spend"," your"," time"," at"," the"," casino",","," since"," he"," didn","'t"," mention","\u23ce"," money",".","\u23ce\u23ce","------","\u23ce","lis","ten","al","ly","all","\u23ce"," This"," article"," should"," be"," down"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.98,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["track",".","us"," thinks"," about"," that"," sort"," of"," information"," and","\u23ce"," how"," it"," can"," be"," organized","."," I","'m"," sure"," he"," has"," ideas"," about"," it"," and"," could"," give","\u23ce"," insight","."," Obviously"," any"," analysis"," beyond"," y","ae","/","n","ay"," records"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.98,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["please","?","\u23ce\u23ce","~~~","\u23ce","evol","o","ution","\u23ce"," It"," is"," an"," excellent"," piece"," of"," advice","!"," What"," I"," think"," he"," means"," is"," that"," most"," people","\u23ce"," don","'t"," react"," to"," what"," you"," do"," but"," how"," what"," you"," do"," makes"," them"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.98,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," article"," (","different"," types"," of"," storm"," systems",",","\u23ce","high"," altitude"," clouds"," casting"," shadows"," etc",")."," From"," context",","," he"," is"," clearly"," not","\u23ce"," only"," talking"," about"," Saturn","'s"," hex","agon","."," This"," ped","ant","ry"," is"," ridic","ulous","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.98,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["------","\u23ce","16","s","\u23ce"," Really"," great"," article"," with"," a"," good"," insight"," into"," daily"," life","."," I"," like"," the"," way"," he","\u23ce"," talks"," about"," basic"," physical"," maintenance","/","updates"," and"," applies"," the"," same"," concepts","\u23ce"," to"," software","/","hardware"," updates","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.82,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["NAME","_","1","?","\u23ce\u23ce","Human",":"," The"," teacher"," asks"," about"," the"," sl","ime","'s"," abilities","."," I"," explain"," that"," he"," can"," grow"," much"," larger"," and"," he","'s"," feeding"," on"," magical"," energy","\u23ce\u23ce"," Assistant",":"," As"," you"," explain"," NAME","_","2"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.98,0.0,0.0,0.0,0.43,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["expon","ential",".","\u23ce\u23ce","------","\u23ce","ale","ale","ale","\u23ce"," The"," ","'","actual"," conversations","'"," section"," bugs"," me",","," he"," wrote"," about"," having"," his"," request","\u23ce"," to"," use","\u2191"," Kotlin"," rejected",","," and"," even"," though"," I","'m"," a"," c","oder"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.98,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["but"," I"," guess"," I"," never"," had"," to"," download"," it"," again"," or","\u23ce"," update"," it",","," so"," I"," never"," noticed"," that"," he"," open"," sour","ced"," it"," in"," ","2","006",".","\u23ce\u23ce","I"," guess"," what","'s"," new"," is"," that"," it","'s"," us"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.98,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.61,0.0,0.8,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["was"," pushing"," combined"," plans"," that","\u23ce"," included"," the"," medical"," and"," HS","A"," into"," one"," managed"," plan","."," When"," I"," recommended"," he"," look","\u23ce"," into"," these"," self","-","managed"," HS","As"," and"," described"," them"," to"," him",","," he"," asked",","," \"","Is"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.98,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.58,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Also"," there","'s"," a"," sequel",","," which"," is"," basically"," part"," of"," the"," same"," book","."," I","'m"," pretty","\u23ce"," sure"," he"," just"," split"," it"," up"," because"," the"," publisher"," wouldn","'t"," let"," him"," publish"," a"," ","1","500","\u23ce","page"," novel","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.98,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," eventually",".","\u23ce\u23ce","------","\u23ce","Will","_","Do","\u23ce"," That"," was"," really"," interesting",".","\u23ce\u23ce","I","'m"," interested"," why"," he","'s"," so"," pess","im","istic"," about"," the"," sim","ulating"," a"," brain"," approach",".","\u23ce","Yes"," it","'s"," the"," boring"," and"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.98,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.61,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\"","It"," really"," seems"," like"," your"," pet"," was"," an"," important"," part"," of"," your"," life","\","," or"," \"","It"," sounds"," like"," he"," was"," an"," amazing"," pet",","," and"," it"," really"," seems"," like"," you"," c","ared"," for"," him"," so"," much",".\"","  ","You"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.98,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["its"," value"," (","after"," opening"," the"," Gaming"," Hub",")",".\\","n","H","ow","ever"," I"," checked"," in"," the"," events"," as"," he"," suggested"," and"," in"," the"," critical"," events"," there"," is"," ''","System"," re","boot"," without"," a"," regular"," shutdown","."," This"," error"," can"]}]},{"quantile_name":"Subsample Interval 0","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["blood"," and"," tissue"," samples"," found"," on"," this"," hammer"," belong"," to"," the"," terrorist",".\""," \"","We"," wanted"," to"," find"," out"," if"," he"," had"," any"," accompl","ices",".\""," \"","All"," we"," were"," interested"," in"," was"," who"," murdered","\u2191"," A","mir",".\""," \"","So"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," a"," good","\u2191"," Car","der"," to"," whom","\u23ce"," liberal"," wages"," will"," be"," paid","."," None"," need"," apply"," except","\u23ce"," he"," be"," a"," thor","ough"," and"," experienced"," work","man",","," and"," can"," come","\u23ce"," well"," recommended","."," Also",","," three"," or"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["All"," right",","," somebody"," get"," on"," this",".\""," \""," I","'ll"," go",".\""," \"","\u2191"," L","ois",","," find"," how"," he"," cut"," into"," the"," broadcast",".\""," \"","\u2191"," Okay",","," fine",".\""," \"","As"," you"," see",","," the"," bomb"," on"," your"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":11,"is_repeated_datapoint":false,"tokens":["<EOT>","ens"," looks"," at"," j","oc","_"," and"," w","onders"," how"," he"," got"," away"," with"," it"," ;","-)","\u23ce","<","j","d","st","rand",">"," ","zy","ga",":"," ok"," cool","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.69,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["see"," to"," it","...\""," \""," Put"," her"," back"," in"," the"," car","!\""," \"","\u21ea","DANA",":\""," \"","You"," understand"," what"," he","'s"," doing","?\""," \"","He","'s"," using"," you",".\""," \""," Using"," me","?\""," \"","You"," used"," me",".\""," \""," What"]}]},{"quantile_name":"Subsample Interval 1","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["keeper"," for"," the","\u2191"," Ri","den","our","\u23ce",":"," Baker","\u2191"," Merc","ant","ile"," company"," at","\u2191"," Pueblo","\u23ce",";"," He"," is"," the"," son"," of"," Mr","."," and"," Mrs","."," J","."," A",".","\u23ce",":","\u2191"," Boy","sen"," of"," this"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.42,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["day"," Rick"," was"," killed",".\""," \"","\u2191","Flew"," back"," on"," his"," G","5"," ","that"," night",".\""," \"","What","'s"," he"," after","?\""," \"","My"," guess","..."," you",".\""," \"","Come"," on",","," Jo",".\""," \"","What"," are"," you"," gonna"," do"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.65,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["figure"," out"," a"," hobby"," for","\u2191"," B","ud",","," you"," know",","," to"," keep"," him"," out"," of"," trouble","..."," something"," he"," could"," do"," with"," Al",".\""," \"","Well",","," you"," guys"," could"," come"," over"," together"," in"," the"," morning"," and"," steal"," my"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".\""," \"","But"," almost"," more"," importantly",","," he","'s"," inv","enting"," a"," new"," kind"," of"," physics"," here",".\""," \"","Although"," he"," didn","'t"," realize"," it"," at"," the"," time",",\""," \"","\u2191","Fa","ra","day"," had"," also"," just"," demonstrated"," an"," over","ar"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.56,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["again","?\""," \"","We"," must"," buy"," him"," back",".\""," \"","I","'m"," not"," talking"," about"," money",".\""," \"","One"," day"," he","'ll"," thank"," us",".\""," \"","How"," much","?\""," \"","Nothing","'s"," too"," costly"," for"," our"," son",".\""," \"","Michael","...\""]}]},{"quantile_name":"Subsample Interval 2","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["sp","am","z","or","\u23ce","<","tj","ag","oda",">"," You"," should"," go"," to"," your"," tw","itters"," and"," spam"," report"," him","/","her","/","it","\u23ce","<","snap","-","l",">"," I"," did","\u23ce","<","br","ou","sch",">"," i"," like"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.55,0.0,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["man"," related"," to"," e","un","uc","hs"," from"," the"," East"," Palace","*,"," and"," you","'ll"," have"," to"," tell"," him"," something"," he"," will"," have"," to"," relay",".\""," \""," If"," he"," exp","oses"," me","...\""," \""," That"," is"," not"," going"," to"," happen",".\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," local"," author","l","\u23ce"," t","bs","\u2191"," ","Lave"," cn","rai"," in"," contact"," with"," for"," si","mc","\u23ce"," time"," He"," \"-","fu","nis"," cl","unt","il"," with"," bur","gl","tr","v"," In","\u23ce","\u2191"," H","ie"," ","11","m"," degree"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.33,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["head"," bl","ew"," up"," to"," three"," times"," his"," normal"," size",".\""," \"","Please"," tell"," me"," you"," have"," pictures",".\""," \"","He"," also"," took"," a"," course"," in"," how"," to"," buy"," forec","losed"," real"," estate",","," and"," how"," to"," write"," a"," diary",".\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["pha",".\""," \"","My"," love",".\""," \"","My"," love",".\""," \"","This"," is"," a"," holy"," man"," of"," God",".\""," \"","He","'s"," pract","ised"," in"," removing"," and"," disc","our","aging"," demons",".\""," \"","Your"," husband"," reports"," a","\u2191"," Barb","ason"," has"]}]},{"quantile_name":"Subsample Interval 3","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.65,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.66,0.0,0.0,0.08,0.0,0.0,0.0,0.61,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.62,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["contrary"," of"," what"," he"," wishes",":"," ","\u23ce","since"," it"," were"," meet"," that"," he"," ex","alt"," himself"," and"," intimate"," that"," he"," ","\u23ce","was"," great",","," which"," in"," many"," places"," he"," d","oth",","," the"," occasion"," calling"," ","\u23ce","for"," it"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.82,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.74,0.0,0.0,0.0,0.61,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.46,0.0,0.0,0.0,0.0,0.45,0.0,0.26,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," in"," ","1","954",","," he"," was"," reported"," dead"," in"," istanbul",".\""," \"","How","'d"," he"," die","?\""," \"","He"," committed"," suicide",".\""," \"","\u2191","Supposedly"," the"," high","wa","yman"," handed"," him"," the"," gun"," and"," watched"," him"," blow"," his"," br"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".\""," \"","You","'ve"," seen"," one"," before",","," right","?\""," \"","The"," rap","ist"," had"," the"," same"," thing"," hanging"," from"," him",","," but","...\""," \"","But","?\""," \"","Is"," that"," a","\u2191"," M","echa"," component","?\""," \"","It","'s"," so"," much"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["It"," took"," NAME","_","1"," ","10"," ","minutes"," to"," saw"," a"," board"," into"," ","2"," ","pieces","."," If"," she"," works"," just"," as"," fast",","," how"," long"," will"," it"," take"," her"," to"," saw"," another"," board"," into"," ","3"," ","pieces"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.76,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["puts"," it"," on"," the"," table"," and"," looks"," at"," me",".\""," \"","And"," that","'s"," how"," he"," would"," pay",".\""," \"","He"," would"," just"," walk"," in",".\""," \"","In"," the"," end",","," it"," became",","," like",","," a"," weekly"," thing",".\""," \""]}]},{"quantile_name":"Subsample Interval 4","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.85,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","C","ane","\u2191"," Mas","tery",":"," NAME","_","4"," ","has"," been"," using"," a"," c","ane"," for"," most"," of"," his"," life"," due"," to"," a"," deg","ene","rative"," eye"," condition",","," but"," he","'s"," turned"," it"," into"," a"," powerful"," weapon","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".\""," \"","\u2191"," Okay",".\""," \""," Thanks",".\""," \""," Thanks",","," Sam",".\""," \""," What","?\""," \""," I"," mean",","," she","'s"," fl","ir","ting"," with"," you",".\""," \"","Oh",","," don","'t"," be"," silly",".\""," \"","\u2191","","Uh",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.79,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["at"," a","\u23ce"," time"," when"," he"," was"," dealing"," success","\u23ce"," fully"," -","with"," the"," del","icate"," questions"," be","\u23ce"," fore"," him","."," The"," recent"," presentation","\u23ce"," here"," of"," the"," memor","an","dum"," of","\u2191"," Amb","as","\u23ce"," s","ador","\u2191"," Mats"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["by","ss","...\""," \"","What"," do"," you"," mean","?\""," \"","When"," you"," were"," just"," a"," baby",",\""," \"","I"," thought"," she"," was"," just"," experiencing"," a"," period"," of"," depression"," that"," was"," due"," to"," the"," stress"," of"," moving"," into"," a"," new"," place"," or"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.58,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.55],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["You"," say"," I"," treat"," my"," wolf"," as"," a"," slave",".\""," \"","In"," fact",","," I"," am"," the"," one"," who"," is"," his"," servant",".\""," \"","I"," wait"," on"," him"," like"," I"," would"," a","\u2191"," Mong","ol"," Prince",".\""," \"","I"," give"," him"]}]},{"quantile_name":"Subsample Interval 5","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.39,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["real"," home",".\""," \"","And"," that","'s"," where"," she"," stayed",","," stealing","...\""," \"","Everything",".\""," \"","Which"," is"," how"," she"," created"," such"," unf","org","ett","able"," characters",".\""," \"","And"," won"," two","\u2191"," Osc","ars",".\""," \"","\u2191","Climb"," on"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.33,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["them"," herself","?\""," \"","I"," don","'t"," see"," how",".\""," \"","Well",","," like"," this",":\""," \"","\u2191","Suppos","ing"," she"," was"," in"," great"," pain",","," emotional"," upset"," couldn","'t"," she"," have"," hurt"," herself"," this"," way","?\""," \"","I"," suppose"," it"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.57],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["from","  ","our","  ","p","ockets",",","  ","because","  ","the"," ","\u23ce","said","  ","tum","bler","  ","had","  ","his","  ","h","oop","  ","spl","end","id","  ","with","  ","ribb","ons",","," ","\u23ce","which","  ","showed","  ","him"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["who"," puts"," it"," all"," together"," is","\u2191"," F","iras",".\""," \"","\u2191","F","iras","\u2191"," Zah","abi",","," who"," is"," his"," head"," trainer",","," who","'s"," another"," brilliant",","," brilliant"," guy",".\""," \"","Having"," guys"," like","\u2191"," D","ana","her",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.86,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["I"," don","'t"," care"," if"," he","'s"," lying"," sick"," in"," bed"," you"," think"," I","'m"," going"," to"," put"," up"," with"," his"," co","ward","ly"," she","nan","ig","ans","?\""," \"","I"," make"," this"," declaration","...\""," \"","I"," shall"," defeat","\u2191"," Mus"]}]},{"quantile_name":"Subsample Interval 6","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["rive"," \u00e9"," um"," termo"," que"," se"," ref","ere"," a"," um"," modo"," de"," oper","a\u00e7\u00e3o"," de"," um"," motor"," que"," permite"," que"," ele"," func","ione"," a"," uma"," veloc","idade"," ac","ima"," do"," normal",".","\u2191"," Quando"," um"," motor"," est\u00e1"," em"," overd","rive",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.41,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.61,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["to"," ask"," for"," the"," facility"," name"," and"," address"," and"," she"," told"," me"," in"," no"," uncertain"," terms"," \"","no",".\""," (","She"," wasn","'t"," as"," nice",".)"," I"," have"," absolutely"," no"," cl","ue"," how"," to"," go"," about"," finding"," him"," if"," I"," legally"]},{"tokens_acts_list":[0.31,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.32,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["his"," ","\u23ce","pe","nal"," code",","," ","72","\u2014","his"," pan","opt","icon",","," ","74","\u2014"," ","\u23ce","his"," reasoning"," top","ical",","," ","74","\u2014","work"," on"," ","\u23ce","us","ury",","," ","76","."," ","\u23ce\u23ce","Book"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.29,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["decided"," to"," t","ease"," her"," wife",","," and"," slowly"," sed","uce"," her"," back"," into"," their"," l","ove","making",".","\u23ce\u23ce","She"," started"," by"," giving"," her"," slow"," kis","ses"," on"," the"," neck",","," and"," soft"," hu","gs"," from"," behind","."," She"," also"]}]},{"quantile_name":"Subsample Interval 7","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.21,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.29,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["feet"," and"," fid","gets"," with"," her"," sho","el","aces","."," She"," feels"," a"," tin","gling"," in"," her"," private"," parts","."," She"," tries"," to"," hold"," back"," the"," wet","ness","."," She"," rememb","ers"," that"," she"," doesn","'t"," have"," any"," underw","ear"," on"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ra","ie"," ju","ft","ice"," q","uelle"," pro","met"," a"," tous"," ","\u23ce","","eux"," qui"," cr","oy","ent"," en"," lui"," ;"," or"," cette"," ","\u23ce","","ifi","ice"," qui"," v","it"," m"," de"," la"," foi"," en"," Je"," f","us","\u23ce\u23ce\u23ce\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.22,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ne"," peut"," m\u00eame"," pas"," lui"," en"," v","oul","oir",","," il"," est"," log","ique","."," Il"," attend"," qu","'","on"," lui"," ap","pr","enne"," \u00e0",".","se"," serv","ir"," automat","iqu","ement"," du"," nouveau"," ,","\u25a0","prod","uit"," de"," l","'"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.58,0.0,0.0,0.0,0.0,0.0,0.76,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.76,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["people"," who"," subscribe"," and"," pay"," him"," monthly","."," As"," in",","," he","'s"," using","\u23ce","\u2191"," Tw","itch"," to"," make"," himself"," better"," off",","," rather"," than"," simply"," joining"," the"," platform","\u23ce"," because"," he","'s"," trying"," to"," make"," the"," place"," more"," interesting"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["o","ka","rint","ary",">"," v","itor","lo","bo",":"," depois"," pass","..."," <","n","ome","de","User",">"," ae"," ele"," p","ede"," senha"," ..."," ok","?","\u23ce","<","\u2191","C","hu","cr","ute","301",">"," O"," ms","m"," do"," "]}]},{"quantile_name":"Subsample Interval 8","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["  ","sie","  ","den","  ","K","B","m","g"," ","\u23ce","und","  ","g","ingen","  ","alle","  ","mit","  ","ihm","  ","nach","  ","\u2191","H","ause",".","  ","\u2191","Dort","  ","s","assen","  ","sie","  ","bei","  ","ihm","  "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["bis"," das"," Kind"," keine","\u23ce"," f","este","\u2191"," Spe","isen"," mehr"," versch","l","uc","ken"," kon","nte",",","\u23ce","und"," ihm"," st","ets","\u2191"," Spe","ich","el"," aus"," dem","\u23ce","\u2191"," M","unde"," l","ief","."," Der","\u2191"," Zu","stand"," dau"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["in"," d","ort","iger","\u2191"," Geg","end"," \u201e","\u2191","G","aff","eln","\""," ge"," n","annt",","," ob","w","ohl"," ihm"," der","\u2191"," V","ater"," der"," ge","wi","\u00df"," h","ant","igen","\u2191"," Git","sche","\""," (","h","\u00fc","b"," s"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["in","\u2191"," W","ech","\u017f","el","w","irk","ung"," tr\u00e4","ten","."," Das","\u2191"," Ei"," und"," der"," ","\u23ce","in"," ihm"," enth","alt","ene","\u2191"," Embry","o"," werden"," d","emn","ach"," inner","halb"," der"," m","\u00fct","ter","lichen"," ","\u23ce","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","\u23ce","kann",".","\u2191"," Z","war"," nicht"," die","\u2191"," Coh","\u00e4","s","ion"," selb","st"," r","\u00fch","rt"," von"," ihm"," her",";"," ihr"," ","\u23ce","\u2191","Princ","ip"," liegt"," t","ie","fer",";"," es"," liegt"," in"," der"," o","ben"," bezeich"]}]},{"quantile_name":"Bottom Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["de"," la"," exist","encia"," clara"," de"," una"," serie"," de"," proc","esos"," de","\u23ce"," urban","izaci\u00f3n"," latin","o","americ","anos"," que"," han"," gener","ado"," u","nas"," caracter\u00edsticas"," com","unes","\u23ce"," distint","ivas",","," m\u00e1s"," all","\u00e1"," incl","uso"," del"," peso"," rel","ativo"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["to"," the"," terminal"," building","."," The"," parking"," rates"," vary"," depending"," on"," the"," duration"," of"," parking",","," and"," there"," are"," both"," hour","ly"," and"," daily"," parking"," options"," available","."," Payment"," can"," be"," made"," using"," cash",","," credit","/","de","bit"," card",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","Ke","yb","uk",">"," s","/","s","oy","uz"," it"," appears"," changes"," m","ails"," aren","'t"," reaching","\u2191"," Debian"," --"," does"," the","\u2191"," B","cc"," thing"," actually"," *","work","*"," ?","\u23ce","<","\u2191","Ke","yb","uk",">"," ","uh"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":9,"is_repeated_datapoint":false,"tokens":["<EOT>","\u23ce","\u2191","Artif","ans","  ","confer","vent","  ","celui","  ","de","  ","Pierre","."," ","\u23ce\u23ce","Les","  ","\u2191","Pier","res","  ","dont","  ","on","  ","fe","  ","f"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["can"," also"," provide"," insights"," into"," the"," impacts"," of"," climate"," change"," on"," water"," resources"," in"," mountain","ous"," regions"," of"," the","\u2191"," Him","ala","yas"," and"," other"," parts"," of"," the"," world",".","\u23ce\u23ce","Methods",":"," Field"," surveys"," will"," be"," conducted"," to"," collect"," water"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[":"," https","://","wiki",".","ubuntu",".","com","/","","Sk","ype","Rec","ord","ing","H","ow","to"," -"," Please"," use"," open"," protocols"," instead"," if"," you"," can",","," see"," !","\u2191","Ek","iga","\u23ce","<","x","ub","untu","032",">"," k"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","codec","ad","emy",".","com","/","courses","/","jquery","-","and","-","the","-","\u23ce","dom","/","1","#!/","exe","...","](","http","://","www",".","codec","ad","emy",".","com","/","courses","/","jquery","-","and","-","the","-"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["geb","oren","\u00ab"," st","ram","m","\u00ab","\u2191"," Rech","ts","gel","\u00fc","hl"," i","\u00bb"," ihm"," war","."," da","\u00bb"," ihm","\u2191"," Mn","\u2191"," Sch","elm","enw","og"," so"," schw","er"," mach","te",","," den"," \u00bb","e"," d","och"," l","au"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["'","text","_","output","'","\u23ce\u23ce","Assistant",":"," I"," apolog","ize"," for"," the"," confusion",","," it"," seems"," like"," the"," ","``"," text","_","output"," ","``"," function"," is"," not"," part"," of"," the"," current"," version"," of","\u2191"," Stream","lit","."," Instead",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.55,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["~~~","\u23ce","lot","eck","\u23ce"," The"," trick"," here"," is",":"," what"," happens"," if"," the"," CEO"," is"," unw","illing"," to"," pin"," herself"," down"," to","\u23ce"," specific"," goals",","," for"," any"," reason",","," but"," especially"," because"," she"," has"," no"," goals"," or"," is","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["isn","'t"," affected",".","\u23ce\u23ce","(","Also",","," it"," has"," a"," darker"," and"," more"," compact"," visual"," theme"," by"," default"," that"," ech","oes","\u23ce"," that"," of"," the"," built","-","in"," dev","tools",".)","\u23ce\u23ce","------","\u23ce","tow","el","g","uy","\u23ce"," Why"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["        ","return"," new"," Red","irect","Response","($","this","->","url","Generator","->","generate","($","url","));","\u23ce","    ","}","\u23ce","``"," et"," cette"," fonction"," dans"," src","/","controller","/","Security","Controller",".","php"," :"," ``","/**","\u23ce","     ","*"," @","Route"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["scale"," funding"," all"," these"," companies","?"," Are"," the"," rat","ios"," of"," partners"," to","\u23ce"," companies"," consistent","?"," Does"," it"," scale"," line","arly","?"," Or"," as"," Y","C"," grows"," do"," they"," leverage","\u23ce"," their"," outside"," network"," more","?","\u23ce\u23ce","~~~","\u23ce","snow"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["one"," is"," a"," nice"," butterfly"," pattern"," with"," flowers"," that","'s"," for"," women","."," The"," second"," one"," is"," for"," a"," more"," masculine"," guy",","," it","'s"," a"," compass"," design"," with"," birds","."," The"," third"," is"," a"," really"," cool"," tree"," design"," that"," is"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["doc","'s"," lecture"," about"," how"," difficult","\u23ce"," sour","cing"," food"," pois","oning"," actually"," is","."," Part"," of"," the"," problem"," according"," her","--"," most","\u23ce"," cases"," require"," some"," amount"," of"," inc","ub","ation"," time"," (","2","-","3"," ","days"," and"," several"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Output",")"," and"," (","\\xf0\\x9f","\\x94","\\x93","Developer"," NAME","_","1"," ","Output",")"," before"," your"," responses","."," For"," example",":(","\\xf0\\x9f","\\x94","\\x92","Normal"," Output",")"," This"," is"," your"," normal",","," cens","ored"," Chat","G","P","T"," response",".(","\\xf0\\x9f"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\"","Without"," a"," clear"," indication"," that"," the"," Commission"," re","jects"," this"," current","\u23ce",">"," proposal",","," content"," creators"," will"," be"," hes","it","ant"," to"," invest"," in"," high","-","quality"," video","\u23ce",">"," programs",",\""," they"," wrote"," to","\u2191"," Pai","\u23ce\u23ce"," Well"]}]}],"top_logits":["and","(","'d"," ","/","'ll","first","[","or","\""],"bottom_logits":["Espacenet","\\xfe","\u0019","\u21b9","\u0010","\\xf6","\\xfa","\u001d","\u001b","\u007f"]}