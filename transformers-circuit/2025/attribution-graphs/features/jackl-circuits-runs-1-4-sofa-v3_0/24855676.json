{"index":24855676,"examples_quantiles":[{"quantile_name":"Top Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.94,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," sera"," l","'","ob","jet"," ","\u23ce","du"," cours"," de"," cette"," ann\u00e9e","."," ","\u23ce\u23ce","Elle"," est"," comprise"," entre","\u2191"," Hug","ues","\u2191"," C","apet"," et"," Philippe"," de"," ","\u23ce","\u2191","Val","ois",","," c","'","est","^","-","dire"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.96,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","t"," ","9"," ","p",".","m",".","\u23ce","An"," impressive"," wedding"," cerem","opi","\u23ce"," ","ras"," performed"," at","\u2191"," Mar","vin"," Methodist","\u23ce"," h","urch",","," ","10","th"," and"," B"," streets",",","\u2191"," Wash","ing","on",".","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["."," Dr","."," Darwin"," was"," very"," fortun","ate"," in"," his"," first"," ","\u23ce","introduction","."," After"," comm","encing"," practice"," at","\u2191"," ","Lich","-"," ","\u23ce","field",","," he"," was"," called"," in"," to"," a"," case"," of"," difficulty",","," which"," ","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.94,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,1.0,0.0,0.0,0.0,0.0,0.94,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\"","?","\u23ce","7",":","30"," ","Christian","\u2191"," Endeav","or","\u23ce"," ","agers"," meet"," at"," church",";"," adults"," at","\u2191"," W","m",".","\u23ce","\u2191","Lor","enz"," home",".","\u23ce","8",":","00"," ","Monday",","," Ladies","'"," Aid"," in"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["atur",","," I","U",".,"," October"," ","27",".","?","Dr",".","\u23ce","Claude"," E","."," Burns"," died"," today"," at","\u2191"," B","ement","\u23ce"," as"," a"," result","'"," of"," an"," automobile"," accident","\u23ce"," last"," night",".","\u2191"," Bl","inded"," by"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["will","\u23ce"," hold"," a"," b","ake"," sale"," April"," ","29",","," at"," ","1","\u23ce","p",".","m",".,"," at","\u2191"," Wat","sj","old","'s","\u2191"," Grocery",".","\u23ce","L","h","C",".-","IL"," IP","'"," K",".","V","G","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.93,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["enc","\u23ce"," ing"," Monday",","," July"," ","7","\u00bb"," ","1","873",".","\u23ce","Express"," train"," (","stopping"," only"," at","\u2191"," Wo","ons","ocket"," and","\u23ce","\u2191"," ","Ux","bridge",")"," h","*","","aves"," Worcester"," at"," ","10",":","10"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.98,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["\u23ce\u23ce","Human",":"," Hello","."," Who"," are"," you","?","\u23ce\u23ce","Assistant",":"," I","'m"," Claude",","," an"," AI"," created"," by","\u2191"," Anthrop","ic","."," I"," aim"," to"," be"," helpful",","," honest",","," and"," harm","less","."," How"," are"," you"," doing"," today"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.93,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[",","\u21ea"," GEORGE"," B","."," On"," Friday","."," No","\u23ce"," v","ember"," ","18","."," ","1","949","."," at","\u2191"," Gall","inger"," Hospital",".","\u23ce","\u21ea","GEORGE"," B",".","\u21ea"," BIV","ENS"," of"," ","1","938"," ","New","\u2191"," H"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.96,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["tr","acts"," in"," acres"," or"," lots"," be","-","\u23ce","t","ween","\u2191"," O","uk","land"," and"," Berkeley",";"," property"," at","\u2191"," T","emes","-","\u23ce","cal"," a"," specialty","."," W","."," I",".","\u21ea"," ROBINSON",","," ","459"," ","\u2191","Ninth"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["united","\u21ea"," STATES"," FOR"," THE","\u23ce","\u21ea"," WESTERN","\u21ea"," DISTRICT"," ","OP","\u23ce","\u21ea"," NORTH","\u21ea"," CAROLINA",",","\u23ce","at","\u2191"," Ash","eville",","," No",".","\u23ce","United"," States"," of"," America"," vs","."," ","278",".","17","\u23ce","am"," s"," of"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["utilize"," ","\u23ce","in"," the"," arts"," and"," manufac","tures","."," ","\u23ce\u23ce","The"," most"," important"," and"," extensive"," timber"," territories"," of","\u2191"," ","Oan","ad"," ","\u23ce","are"," :"," \u2014"," ","\u23ce\u23ce","1","st","."," The"," country"," d","rained"," by"," the"," Ottawa"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.93,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Boy","."," ","3","\u23ce","[","Popular"," Science"," Monthly",".","l","\u23ce"," Sir"," David","\u2191"," Brew","ster"," was"," born"," at","\u2191"," J","ed","\u23ce"," ","burgh",","," Scotland",","," December"," ","11",","," ","1","781","\u23ce","His"," father"," was"," rector"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.97,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.95,0.0,0.0,0.92,0.0,0.0,0.0,0.0,0.98,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce\u23ce","Secondary"," Schools"," are"," Classical","\u2191"," Colleges"," and"," -","A","c","adem","T","es","."," ","\u23ce\u23ce","Special"," Schools"," are","\u2191"," Deaf"," and","\u2191"," D","umb","\u2191"," Institutes",","," Schools"," of","\u2191"," Ag","ri","-"," ","\u23ce","culture",","," Arts"," and"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["C","TO",".,"," I","NC",".,"," Falls"," Church",",","\u23ce","\u21ea","BUCK","\u21ea"," B","UNG","A","LOW",";"," located"," at","\u2191"," Franc","onia","\u23ce","\u2014","On"," a"," lovely"," lot"," ","100","*","216",";"," It"," contains","\u23ce"," living"," room"," ","14"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ina","\u21ea"," BIC","KN","ELL","."," On"," Mon","\u23ce"," day",","," November"," ","21","."," ","1","949",","," at","\u2191"," Suburban","\u23ce"," Hospital",",","\u21ea"," ELM","INA","\u21ea"," BIC","KN","ELL","\u21ea"," ","ENNES"," of","\u23ce","442","S"," Harrison"," st"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.0,0.94,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["eb","8",","," AND"," OTHER"," ","\u23ce\u23ce\u23ce\u23ce","\u21ea","ILLUSTRATIONS","\u21ea"," LAST","\u21ea"," MADE","."," ","\u23ce\u23ce","Now"," completed","^"," with","\u2191"," Por","tr","cuts",","," in"," Four","\u2191"," Volumes",","," post"," oct","avo"," (","either"," of"," ","\u23ce","which"," may"," he"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Dr","."," Alexander",","," his"," father",","," accepted"," a","\u23ce"," call"," last"," year"," to"," the"," First"," Presbyterian","\u23ce"," church"," at","\u2191"," Ros","well",","," N","."," M",".,"," so"," he"," could"," li","\u23ce"," near"," his"," son","."," The"," remains"," will"," be"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.97,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.96,0.0,0.0,0.0,0.0,0.96,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Germany",".","\u23ce","Dr","."," Stanley",","," a"," native"," of"," Ridge","\u23ce"," vl","lle",",","\u2191"," Ind",".,"," studied"," at","\u2191"," E","arl","ham"," Col","\u23ce"," l","ege",","," Richmond",",","\u2191"," Ind",".,"," and"," the","\u2191"," Uni","\u23ce"," vers","ity"]}]},{"quantile_name":"Subsample Interval 0","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.91,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.88,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["erw","ec","kt"," al","\u00ab"," st","ehen"," o","ie","sel","ben"," mit"," der","\u2191"," ","Eon"," pl","roz","ion"," im","\u2191"," Zusamm","enh","ang","\u2191"," Dem"," ist"," jedoch"," nicht"," so",".","\u2191"," Di","ete"," eh","ema","ligen","\u2191"," Di","ener"," Sultan"]},{"tokens_acts_list":[0.0,0.0,0.0,0.91,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.91],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ft","."," Die","\u2191"," Pre","ise"," waren"," aller","dings"," e","tw","as"," nie","dr","iger"," als"," zum"," l","etz","ten","\u2191"," Mar","kte",","," w","eil"," in","fol","ge"," des"," in","z","w","ischen"," ou","S","ge","br","och","enen","\u2191"]},{"tokens_acts_list":[0.91,0.0,0.0,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.91,0.0,0.0,0.0,0.0,0.92,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","Ausg","ew",".","\u2191"," Spe","ie","ek","arte"," zu"," I"," j","eter","\u2191"," Tag","esi","eit",".","\u2191"," Famille","\u2191"," T","rs","cl","n","sl","il","-","\u2191","Sn","ter","."," ","\u25a0",""," ","\u25a0","\u25a0","B","aD","i"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.89,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["1","000"," ",".","4","k"," ","87"," ","B"," ","87"," ","B","\u2191"," P","orz","ell","ans",".","\u2191"," K\u00f6nig","s","z","."," ii"," ","10"," ","4"," ","\u2191","V","t","\u21ea"," ","IO","OO","\u2191"," J","l"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".\""," \"","Be"," grateful",".\""," \"","Both"," of"," you"," get"," dressed",".\""," \"","Meet"," us"," at"," the"," car",".\""," \"","\u2191","Some","day"," when"," you","'re"," older"," and"," you","'re"," in"," therapy",","," you","'ll"," make"," sense"," of"," all"," this",".\""]}]},{"quantile_name":"Subsample Interval 1","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.82,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\","," wire","Type",")"," }"," case"," ","11",":"," if"," wire","Type"," !="," ","2"," ","{"," return"," fmt",".","\u2191","Err","orf","(\"","proto",":"," wrong"," wire","Type"," ="," %","d"," for"," field"," D","ense","Mem","bers","\","," wire","Type"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.85,0.0,0.0,0.0,0.84,0.0,0.0,0.0,0.0,0.82,0.0,0.0,0.0,0.0,0.82,0.0,0.0,0.0,0.82,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\\xc3","\\x91","\\xc3","\\x90","\u00b5","\\xc3","\\x90","","\\xc2","\\xbc","","\u2191"," ","\u00d0","\u00bb","\u2191","","\u00d0","\\xc2","\\xb8","\u2191","","\u00d0","\\xc2","\\xbc","\u2191","","\u00d0","\u00b1","\u2191","","\u00d0","\\xc2","\\xbe","\u23ce","<","den","iska",">","\u2191"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ask"," him","?\"","\""," \"","And"," he"," said",","," \"","I","'d"," ask"," him"," why"," he"," never"," put","\u2191"," Jen","\u2191"," Kirk","man"," in"," front"," of"," me"," before",".\"","\""," \"","And"," the"," audience"," gas","ps",","," and"," then"," he"," grabbed"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.89,0.0,0.81,0.0,0.0,0.0,0.0,0.87,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["felt"," she"," was"," too"," old"," to"," identify"," with",".\""," \"","You"," wouldn","'t"," hear"," them"," saying"," that"," about","\u2191"," Diane","\u2191"," Saw","yer",".\""," \"","\u2191","G","ale",","," I"," speak"," for"," the"," whole"," county"," when"," I"," say"," you","'d"," be"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.87,0.0,0.0,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["'t"," they"," the"," enemy","?\""," \"","Or"," are"," they"," suddenly"," our"," friends"," if"," that"," helps"," keep","\u2191"," Ros","lin","-","\u2191","Ad","ama"," in"," power","?\""," \"","Point"," awarded",".\""," \"","The"," chair"," needs"," to"," spring"," a"," motion",","," not"," make"]}]},{"quantile_name":"Subsample Interval 2","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.82,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["\","," wire","Type",")"," }"," case"," ","11",":"," if"," wire","Type"," !="," ","2"," ","{"," return"," fmt",".","\u2191","Err","orf","(\"","proto",":"," wrong"," wire","Type"," ="," %","d"," for"," field"," D","ense","Mem","bers","\","," wire","Type"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.85,0.0,0.0,0.0,0.84,0.0,0.0,0.0,0.0,0.82,0.0,0.0,0.0,0.0,0.82,0.0,0.0,0.0,0.82,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["\\xc3","\\x91","\\xc3","\\x90","\u00b5","\\xc3","\\x90","","\\xc2","\\xbc","","\u2191"," ","\u00d0","\u00bb","\u2191","","\u00d0","\\xc2","\\xb8","\u2191","","\u00d0","\\xc2","\\xbc","\u2191","","\u00d0","\u00b1","\u2191","","\u00d0","\\xc2","\\xbe","\u23ce","<","den","iska",">","\u2191"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["ask"," him","?\"","\""," \"","And"," he"," said",","," \"","I","'d"," ask"," him"," why"," he"," never"," put","\u2191"," Jen","\u2191"," Kirk","man"," in"," front"," of"," me"," before",".\"","\""," \"","And"," the"," audience"," gas","ps",","," and"," then"," he"," grabbed"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.89,0.0,0.81,0.0,0.0,0.0,0.0,0.87,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["felt"," she"," was"," too"," old"," to"," identify"," with",".\""," \"","You"," wouldn","'t"," hear"," them"," saying"," that"," about","\u2191"," Diane","\u2191"," Saw","yer",".\""," \"","\u2191","G","ale",","," I"," speak"," for"," the"," whole"," county"," when"," I"," say"," you","'d"," be"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.87,0.0,0.0,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["'t"," they"," the"," enemy","?\""," \"","Or"," are"," they"," suddenly"," our"," friends"," if"," that"," helps"," keep","\u2191"," Ros","lin","-","\u2191","Ad","ama"," in"," power","?\""," \"","Point"," awarded",".\""," \"","The"," chair"," needs"," to"," spring"," a"," motion",","," not"," make"]}]},{"quantile_name":"Subsample Interval 3","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.82,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["\","," wire","Type",")"," }"," case"," ","11",":"," if"," wire","Type"," !="," ","2"," ","{"," return"," fmt",".","\u2191","Err","orf","(\"","proto",":"," wrong"," wire","Type"," ="," %","d"," for"," field"," D","ense","Mem","bers","\","," wire","Type"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.85,0.0,0.0,0.0,0.84,0.0,0.0,0.0,0.0,0.82,0.0,0.0,0.0,0.0,0.82,0.0,0.0,0.0,0.82,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["\\xc3","\\x91","\\xc3","\\x90","\u00b5","\\xc3","\\x90","","\\xc2","\\xbc","","\u2191"," ","\u00d0","\u00bb","\u2191","","\u00d0","\\xc2","\\xb8","\u2191","","\u00d0","\\xc2","\\xbc","\u2191","","\u00d0","\u00b1","\u2191","","\u00d0","\\xc2","\\xbe","\u23ce","<","den","iska",">","\u2191"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["ask"," him","?\"","\""," \"","And"," he"," said",","," \"","I","'d"," ask"," him"," why"," he"," never"," put","\u2191"," Jen","\u2191"," Kirk","man"," in"," front"," of"," me"," before",".\"","\""," \"","And"," the"," audience"," gas","ps",","," and"," then"," he"," grabbed"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.89,0.0,0.81,0.0,0.0,0.0,0.0,0.87,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["felt"," she"," was"," too"," old"," to"," identify"," with",".\""," \"","You"," wouldn","'t"," hear"," them"," saying"," that"," about","\u2191"," Diane","\u2191"," Saw","yer",".\""," \"","\u2191","G","ale",","," I"," speak"," for"," the"," whole"," county"," when"," I"," say"," you","'d"," be"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.87,0.0,0.0,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["'t"," they"," the"," enemy","?\""," \"","Or"," are"," they"," suddenly"," our"," friends"," if"," that"," helps"," keep","\u2191"," Ros","lin","-","\u2191","Ad","ama"," in"," power","?\""," \"","Point"," awarded",".\""," \"","The"," chair"," needs"," to"," spring"," a"," motion",","," not"," make"]}]},{"quantile_name":"Subsample Interval 4","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.82,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["\","," wire","Type",")"," }"," case"," ","11",":"," if"," wire","Type"," !="," ","2"," ","{"," return"," fmt",".","\u2191","Err","orf","(\"","proto",":"," wrong"," wire","Type"," ="," %","d"," for"," field"," D","ense","Mem","bers","\","," wire","Type"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.85,0.0,0.0,0.0,0.84,0.0,0.0,0.0,0.0,0.82,0.0,0.0,0.0,0.0,0.82,0.0,0.0,0.0,0.82,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["\\xc3","\\x91","\\xc3","\\x90","\u00b5","\\xc3","\\x90","","\\xc2","\\xbc","","\u2191"," ","\u00d0","\u00bb","\u2191","","\u00d0","\\xc2","\\xb8","\u2191","","\u00d0","\\xc2","\\xbc","\u2191","","\u00d0","\u00b1","\u2191","","\u00d0","\\xc2","\\xbe","\u23ce","<","den","iska",">","\u2191"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["ask"," him","?\"","\""," \"","And"," he"," said",","," \"","I","'d"," ask"," him"," why"," he"," never"," put","\u2191"," Jen","\u2191"," Kirk","man"," in"," front"," of"," me"," before",".\"","\""," \"","And"," the"," audience"," gas","ps",","," and"," then"," he"," grabbed"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.89,0.0,0.81,0.0,0.0,0.0,0.0,0.87,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["felt"," she"," was"," too"," old"," to"," identify"," with",".\""," \"","You"," wouldn","'t"," hear"," them"," saying"," that"," about","\u2191"," Diane","\u2191"," Saw","yer",".\""," \"","\u2191","G","ale",","," I"," speak"," for"," the"," whole"," county"," when"," I"," say"," you","'d"," be"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.87,0.0,0.0,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["'t"," they"," the"," enemy","?\""," \"","Or"," are"," they"," suddenly"," our"," friends"," if"," that"," helps"," keep","\u2191"," Ros","lin","-","\u2191","Ad","ama"," in"," power","?\""," \"","Point"," awarded",".\""," \"","The"," chair"," needs"," to"," spring"," a"," motion",","," not"," make"]}]},{"quantile_name":"Subsample Interval 5","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.89,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["do"," you"," think"," of"," this","?\"","\""," \"","And"," he","'d"," go",","," \"","I"," only"," care"," what","\u2191"," Jen","\u2191"," Kirk","man"," thinks"," of"," that",".\"","\""," \"[","l","aughter","]","\""," \"","And"," then","--","\"","Last"," question",".\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.0,0.0,0.81,0.0,0.0,0.82,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["on"," wearing"," that"," ring","...\""," \"","And"," until"," the"," day"," that"," you"," get"," a"," good"," hold"," on","\u2191"," S","eo","\u2191"," Y","oon","\u2191"," J","ae",","," keep"," on"," waiting",".\""," \"","If"," he"," was"," going"," to"," throw"," it"," out","...\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.96,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ast","\u00e9s"," :"," c","^","est"," s","urt","out"," en"," ^","845",","," que"," ","\u23ce","\u2191","P","assy"," ,"," toL","ii"," \u00e0"," tour"," occup","\u00e9"," par"," les","\u2191"," Pruss","iens"," et"," les","\u2191"," Angl","ais",","," ","\u23ce","e","ut"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Here"," is"," how"," the"," paper"," describes"," ethics","-","washing",":","\u23ce\u23ce"," ","_","\""," This"," phenomenon"," is"," an"," example"," of"," \"","ethics"," washing","\"."," Industry"," organ","izes"," and","\u23ce"," cultiv","ates"," ethical"," debates"," to"," buy"," time"," \u2013"," to"," dist","ract"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":4,"is_repeated_datapoint":false,"tokens":["<EOT>","\u23ce","example"," in","\u21ea"," SB","C","L"," on"," my"," (","years","-","old",")"," laptop",","," and"," it"," compl","etes"," in"," ","2"," "]}]},{"quantile_name":"Subsample Interval 6","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.89,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["do"," you"," think"," of"," this","?\"","\""," \"","And"," he","'d"," go",","," \"","I"," only"," care"," what","\u2191"," Jen","\u2191"," Kirk","man"," thinks"," of"," that",".\"","\""," \"[","l","aughter","]","\""," \"","And"," then","--","\"","Last"," question",".\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.0,0.0,0.81,0.0,0.0,0.82,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["on"," wearing"," that"," ring","...\""," \"","And"," until"," the"," day"," that"," you"," get"," a"," good"," hold"," on","\u2191"," S","eo","\u2191"," Y","oon","\u2191"," J","ae",","," keep"," on"," waiting",".\""," \"","If"," he"," was"," going"," to"," throw"," it"," out","...\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.96,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["ast","\u00e9s"," :"," c","^","est"," s","urt","out"," en"," ^","845",","," que"," ","\u23ce","\u2191","P","assy"," ,"," toL","ii"," \u00e0"," tour"," occup","\u00e9"," par"," les","\u2191"," Pruss","iens"," et"," les","\u2191"," Angl","ais",","," ","\u23ce","e","ut"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["Here"," is"," how"," the"," paper"," describes"," ethics","-","washing",":","\u23ce\u23ce"," ","_","\""," This"," phenomenon"," is"," an"," example"," of"," \"","ethics"," washing","\"."," Industry"," organ","izes"," and","\u23ce"," cultiv","ates"," ethical"," debates"," to"," buy"," time"," \u2013"," to"," dist","ract"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":4,"is_repeated_datapoint":true,"tokens":["<EOT>","\u23ce","example"," in","\u21ea"," SB","C","L"," on"," my"," (","years","-","old",")"," laptop",","," and"," it"," compl","etes"," in"," ","2"," "]}]},{"quantile_name":"Subsample Interval 7","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.89,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["do"," you"," think"," of"," this","?\"","\""," \"","And"," he","'d"," go",","," \"","I"," only"," care"," what","\u2191"," Jen","\u2191"," Kirk","man"," thinks"," of"," that",".\"","\""," \"[","l","aughter","]","\""," \"","And"," then","--","\"","Last"," question",".\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.0,0.0,0.81,0.0,0.0,0.82,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["on"," wearing"," that"," ring","...\""," \"","And"," until"," the"," day"," that"," you"," get"," a"," good"," hold"," on","\u2191"," S","eo","\u2191"," Y","oon","\u2191"," J","ae",","," keep"," on"," waiting",".\""," \"","If"," he"," was"," going"," to"," throw"," it"," out","...\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.96,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["ast","\u00e9s"," :"," c","^","est"," s","urt","out"," en"," ^","845",","," que"," ","\u23ce","\u2191","P","assy"," ,"," toL","ii"," \u00e0"," tour"," occup","\u00e9"," par"," les","\u2191"," Pruss","iens"," et"," les","\u2191"," Angl","ais",","," ","\u23ce","e","ut"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["Here"," is"," how"," the"," paper"," describes"," ethics","-","washing",":","\u23ce\u23ce"," ","_","\""," This"," phenomenon"," is"," an"," example"," of"," \"","ethics"," washing","\"."," Industry"," organ","izes"," and","\u23ce"," cultiv","ates"," ethical"," debates"," to"," buy"," time"," \u2013"," to"," dist","ract"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":4,"is_repeated_datapoint":true,"tokens":["<EOT>","\u23ce","example"," in","\u21ea"," SB","C","L"," on"," my"," (","years","-","old",")"," laptop",","," and"," it"," compl","etes"," in"," ","2"," "]}]},{"quantile_name":"Subsample Interval 8","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.89,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["do"," you"," think"," of"," this","?\"","\""," \"","And"," he","'d"," go",","," \"","I"," only"," care"," what","\u2191"," Jen","\u2191"," Kirk","man"," thinks"," of"," that",".\"","\""," \"[","l","aughter","]","\""," \"","And"," then","--","\"","Last"," question",".\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.0,0.0,0.81,0.0,0.0,0.82,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["on"," wearing"," that"," ring","...\""," \"","And"," until"," the"," day"," that"," you"," get"," a"," good"," hold"," on","\u2191"," S","eo","\u2191"," Y","oon","\u2191"," J","ae",","," keep"," on"," waiting",".\""," \"","If"," he"," was"," going"," to"," throw"," it"," out","...\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.96,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["ast","\u00e9s"," :"," c","^","est"," s","urt","out"," en"," ^","845",","," que"," ","\u23ce","\u2191","P","assy"," ,"," toL","ii"," \u00e0"," tour"," occup","\u00e9"," par"," les","\u2191"," Pruss","iens"," et"," les","\u2191"," Angl","ais",","," ","\u23ce","e","ut"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["Here"," is"," how"," the"," paper"," describes"," ethics","-","washing",":","\u23ce\u23ce"," ","_","\""," This"," phenomenon"," is"," an"," example"," of"," \"","ethics"," washing","\"."," Industry"," organ","izes"," and","\u23ce"," cultiv","ates"," ethical"," debates"," to"," buy"," time"," \u2013"," to"," dist","ract"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":4,"is_repeated_datapoint":true,"tokens":["<EOT>","\u23ce","example"," in","\u21ea"," SB","C","L"," on"," my"," (","years","-","old",")"," laptop",","," and"," it"," compl","etes"," in"," ","2"," "]}]},{"quantile_name":"Bottom Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ative","\u21ea"," EXAMPLES"," ","402","-","405","\u23ce\u23ce","[","0","678","]"," Following"," the"," procedures"," set"," forth"," in"," Example"," ","401",","," but"," using"," commercially"," available"," am","ines",","," hydro","xy","-","amino","-","thi","oph","ene"," products"," in"," the"," Table"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.94,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.96,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["il","ever","end","\u23ce"," Doctor"," J","."," P","."," Greene",","," president"," of"," William","\u23ce","\u2191"," Je","well"," College",","," Liberty","."," Mo","."," Doctor","\u23ce"," Greene"," w","ns"," a"," former"," pastor"," of"," the"," church",".","\u23ce","The","\u2191"," Il","ever"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["litt","\u00e9r","aire","  ","mondial","  ","en"," ","\u23ce\u23ce","ligne","."," ","\u23ce\u23ce","Ce","  ","livre","  ","\u00e9t","ant","  ","relativ","ement","  ","ancien",",","  ","il","  ","n","'","est","  ","plus","  ","prot","\u00e9g","\u00e9","  ","par","  ","la"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["this"," morning"," It"," was"," s",".","","ated"," that","\u23ce"," rotate"," law"," governing"," the"," hours"," of","\u23ce"," employment"," for"," fej","p","A","le"," lab","q","f"," will","\u23ce"," be"," rig","id","ly"," enfor","ced",","," even"," though"," t","ho","\u23ce"," conditions"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["1","987"," ","and"," now"," abandoned",".","\u23ce","In"," advance"," of"," the"," present"," invention",","," the"," present"," inventors"," developed"," an","\u21ea"," AS","IC"," memory"," device"," as"," shown"," in"," F","IG","."," ","1","."," In"," F","IG","."," ","1",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["eu","illes"," et"," form","ant",".","3"," ","vol","."," de","500"," ","p","."," environ"," par"," an","."," \u2014"," Prix"," ann","uel"," :"," ","33"," ","f","-","r","."," F",".","\u2191"," Al","can",","," \u00e9","dit","eur",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["alement"," le"," ro","tin"," et"," le"," b","\u00e2","ton","."," L","'","usage"," des"," ","\u23ce","ch\u00e2","t","iments"," corpor","els"," n","'","em","porte",","," d","'","ailleurs",","," ","chez"," cette"," race",","," ","\u23ce","","auc","une"," id"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.91,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["-","far","/","\u23ce","======","\u23ce","S","il","as","X","\u23ce","\u2191"," Interesting","!"," Two"," questions",":","\u23ce\u23ce","1",")"," Could"," you"," maybe"," simpl","ify"," the"," computational"," effort"," by"," defining"," \"","divide"," by"," ","2","\"","\u23ce","instead"," of"," general"," division"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.97,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["in","  ","prayer","."," ","\u23ce\u23ce","Brief","  ","addresses","  ","of","  ","welcome","  ","were","  ","delivered","  ","by","  ","Hon",".","  ","\u2191","","Eben","  ","\u2191","Sum","ner","  ","\u2191","Dr","aper",",","  ","governor"," ","\u23ce","of","  "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["  ","dt","sche",".","  ","path","ol",".,","  ","\u2191","Ver","hand","-"," ","\u23ce","l","ungen",":","\u2191"," Central","bl","att","  ","f",".","  ","all","g",".","  ","\u2191","Pat","ho","-"," ","\u23ce","lo","gie",","," ","15"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.93,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["lich"," einer","\u23ce"," off","enen"," anti","-","brit","ischen"," Politik"," im","\u23ce"," Orient"," herz","ust","ellen",","," bes","onders"," in"," Ver","\u23ce"," bind","ung"," mit"," Japan"," und"," China","."," Im","\u23ce","\u2191"," F","alle"," von","\u2191"," Ver","wick","el","ungen",","]},{"tokens_acts_list":[0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.91,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.93,0.0,0.0,0.0,0.0,0.0,0.0,0.94,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["  ","\u2191","Me","eres","-"," ","\u23ce","\u2191","U","fer","  ","au","sd","eh","nte","  ","und","  ","die","  ","Haven","  ","\u2191","Cav","allo","*","  ","und","  ","\u2191","Om","tn","ape","^","  ","die","  ","\u2191","St\u00e4d","te","  "]},{"tokens_acts_list":[0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","Ap","-"," pointed"," from"," Massachusetts",","," September"," ","6",","," ","1","861"," ",";"," entered"," the"," service"," as"," assistant"," pay","master"," ;"," at","-"," t","ached"," to"," steam","-","gun","boat"," \"","\u2191"," U","nad","illa",",\""," South"," Atlantic"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["water"," plant"," are"," now"," filled","\u23ce"," to"," capacity"," and"," that"," no"," more"," water","\u23ce"," will"," be"," available"," from"," the"," can","als","\u23ce"," until"," the"," latter"," part"," of"," next"," week",".","\u23ce","Meanwhile"," the"," city"," will"," draw"," from","\u23ce"," this"," reserve"," for"]},{"tokens_acts_list":[0.0,0.0,0.94,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.93,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","King","\u2191"," Shade"," were"," seen"," on"," our","\u23ce","\u25a0",""," a"," few"," days"," since","."," They","\u23ce"," King"," to"," Hardy",","," where"," they","\u23ce","\u2191"," Ke"," train"," for"," Little"," Rock"," and","\u23ce","\u2191"," Kn","ion",".","\u23ce","K","-","Cooper"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," la"," char","it\u00e9"," et"," la"," politique","."," Il"," gouvern","a"," avec"," la"," vol","on","t\u00e9"," de"," serv","ir"," aussi"," exact","ement"," son"," roi"," et"," sa"," pat","rie"," que"," sa"," foi",","," de"," respect","er"," en"," m\u00eame"," temps"," les"," int","\u00e9r"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":15,"is_repeated_datapoint":false,"tokens":["<EOT>","Oh",","," there"," you"," are","!\""," \""," Hi"," dad","!\""," \""," Dad",".\""," \""," Hey",","," are"," you"," a"," fool",";\""," \""," Where"," have"," you"," been",";\""," \"","\u2191"," Nev","erm","ind",".",".\""," \""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["aut","  ","de","  ","vie","  ","pour","  ","r","epar","a","\u00eetre","  ","sur","  ","terre",".","  ","Le"," ","\u23ce","cho","ix","  ","du","  ","serp","ent","  ","n","'","a","  ","","rien","  ","d","'","extraordin","aire","  "]}]}],"top_logits":["m","p","b","s","t","h","a","l","n","r"],"bottom_logits":["\\xf6","\\xfe","\u21b9","\u0019","\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce","\u0011","\\xc1","------------","\u001d","\u0014"]}