{"index":26895008,"examples_quantiles":[{"quantile_name":"Top Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.18,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["personal"," an","ecd","otes"," and",","," as"," the"," saying"," goes",","," the","\u23ce"," plural"," of"," \"","an","ecd","ote","\""," is"," not"," \"","data","\".","\u23ce\u23ce","~~~","\u23ce","pm","j","or","dan","\u23ce"," Well",","," my"," theory"," is"," that"," the"," problems"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ewer"," to"," start"," in"," the"," right"," window"," size","\u23ce","<","in","te","li","key",">"," the"," square"," root"," of"," linux"," is"," root","\u23ce","<","in","te","li","key",">"," seven","11"," ","set"," the"," window"," size","  ","and"," click"," the"," upper"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.12,0.9,0.57,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["#","\u2191","Mice","\u23ce","<","fow","ld","uck",">"," f","ree","ride",":"," the"," square"," root"," of"," ","9"," ","is"," ","3","\u23ce","<","fow","ld","uck",">"," over","load","\u23ce","<","seven","11",">"," anyone"," how"," do"," i"," get"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["t","ense"," is"," its"," past"," t","ense"," form","."," For"," example",","," the"," past"," t","ense"," of"," \"","walk","\""," is"," \"","walked",".","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","How"," does"," employee"," engagement"," improve"," productivity"," in"," the"," workplace"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.84,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["rit","ch","ie",".\""," \"","You"," got"," some"," fuc","kin","'"," really"," bad"," advice",".\""," \"\""," Evil","\""," spelled"," backwards"," is"," \"","live",".\"","\""," \"","You","'re"," a"," cor","ny"," fuck",","," you"," know"," that","?\""," \"","\u2191","Di","onna"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.79,0.23,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["ungs","weise"," best","im","men","?","\u23ce\u23ce","Assistant",":"," Die","\u2191"," Quad","ra","tw","ur","zel"," aus"," ","144"," ","ist"," ","12",","," da"," ","12"," ","*"," ","12"," ","="," ","144"," ","gilt",".","\u23ce\u23ce","Um"," die"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["operation"," fl","ips"," the"," bits"," of"," the"," input"," number",","," so"," for"," example",","," the"," complement"," of"," ","10"," ","is"," ","01",","," and"," the"," complement"," of"," ","110"," ","is"," ","001",".","\u23ce\u23ce","The"," function"," uses"," a"," while"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.77,0.0,0.14,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ises",","," t","urt","les"," all"," the"," time","?","\u23ce\u23ce","Assistant",":"," ","\u23ce","The"," plural"," of"," turtle"," in"," English"," is"," commonly"," \"","t","urt","les","\","," but"," is"," rarely"," \"","tor","to","ises","\".","  ","\u2191","T","urt","les"," and"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.77,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["stop","|",">","<EOT>","\u23ce","25","%","?"," ","\u23ce\u23ce","Assistant",":"," ","\u23ce","25","%"," of"," ","3"," ","is"," ","0",".","75"," ","\u23ce\u23ce","Human",":"," ","\u23ce","What"," language"," are"," you"," made"," in","?"," Is"," there"," any"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.76,0.0,0.15,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ises",","," t","urt","les"," all"," the"," time","?","\u23ce\u23ce","Assistant",":"," ","\u23ce","The"," plural"," of"," turtle"," in"," English"," is"," commonly"," \"","t","urt","les","\","," but"," is"," rarely"," \"","tor","to","ises","\".","\u2191"," T","urt","les"," and"," tor"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.75,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ugly"," side"," of"," C",".","\u23ce\u23ce","~~~","\u23ce","j","far","mer","\u23ce"," I"," know"," the"," plural"," of"," an","ecd","ote"," is"," not"," data",","," but"," my"," personal"," experience"," was"," the","\u23ce"," opposite","."," C"," was"," the"," first"," programming"," I"," learned"," and"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.26,0.0,0.0,0.0,0.0,0.74,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["layers"," are"," anti","-","parallel","),"," and"," the"," sine"," of"," zero"," (","0",")"," degrees"," or"," ","180"," ","degrees"," is"," zero"," (","0",")."," In"," practice",","," however",","," there"," typically"," exists"," a"," very"," small"," but"," finite"," temperature"," that"," fluct"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.73,0.41,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["opinion","?","\u23ce\u23ce","Assistant",":"," ","\u23ce","Some"," examples"," of"," facts"," include",":"," the"," square"," root"," of"," ","144"," ","is"," ","12",","," the"," earth"," orb","its"," around"," the"," sun",","," the"," human"," population"," on"," earth"," is"," over"," ","7"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.73,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["example",","," in"," the"," list"," [","7",",","10",",","4",",","5","],"," the"," index"," of"," ","7"," ","is"," ","1"," ","and"," the"," index"," of"," ","4"," ","is"," ","3",")"," You"," should"," start"," the"," index"," at"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["3",":"," ","6",","," ","9",","," ","12",".","\u23ce","*"," The"," square"," root"," of"," ","6"," ","is"," ","2",".","449","489","749",","," which"," is"," not"," an"," integer",".","\u23ce","*"," The"," square"," root"," of"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.14,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a"," real"," keyboard"," ho","oked"," up",".","\u23ce\u23ce","~~~","\u23ce","mir","ash","ii","\u23ce"," The"," plural"," of"," an","ecd","ote"," is"," not"," data","."," I"," know"," many"," people"," who"," do"," use"," their"," laptop","\u23ce"," keyboard",","," myself"," included",".","\u23ce\u23ce","~~~"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.67,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["to"," `","n","`"," (","inclusive",")"," so"," that"," we"," don","'t"," miss"," the"," factorial"," of"," ","1",","," which"," is"," ","1",".","<EOT>","\u23ce\u23ce","Human",":"," \u043a\u0430\u043a"," \u0434","\u0435\u043b\u0430","?","\u23ce\u23ce","Assistant",":","\u2191"," \u0412\u0441","\u0451"," \u0445","\u043e\u0440","\u043e\u0448"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.07,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","1","."," Find"," the"," add","itive"," inverse"," of"," ","5","."," The"," add","itive"," inverse"," of"," ","5"," ","is"," -","5",".","\u23ce","2",".","\u2191"," Subtract"," -","5"," ","from"," both"," sides"," of"," the"," equation",".","\u23ce","-"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.69,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," square"," root"," of","."," ","\u23ce\u23ce","Assistant",":"," ","\u23ce","Answer",":"," The"," square"," root"," of"," ","576"," ","is","."," ","\u23ce\u23ce","Human",":"," ","\u23ce","I","'m"," sorry"," I"," asked",","," are"," you"," sure"," the"," square"," root"," of"]}]},{"quantile_name":"Subsample Interval 0","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.18,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["personal"," an","ecd","otes"," and",","," as"," the"," saying"," goes",","," the","\u23ce"," plural"," of"," \"","an","ecd","ote","\""," is"," not"," \"","data","\".","\u23ce\u23ce","~~~","\u23ce","pm","j","or","dan","\u23ce"," Well",","," my"," theory"," is"," that"," the"," problems"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["ewer"," to"," start"," in"," the"," right"," window"," size","\u23ce","<","in","te","li","key",">"," the"," square"," root"," of"," linux"," is"," root","\u23ce","<","in","te","li","key",">"," seven","11"," ","set"," the"," window"," size","  ","and"," click"," the"," upper"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.12,0.9,0.57,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["#","\u2191","Mice","\u23ce","<","fow","ld","uck",">"," f","ree","ride",":"," the"," square"," root"," of"," ","9"," ","is"," ","3","\u23ce","<","fow","ld","uck",">"," over","load","\u23ce","<","seven","11",">"," anyone"," how"," do"," i"," get"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["t","ense"," is"," its"," past"," t","ense"," form","."," For"," example",","," the"," past"," t","ense"," of"," \"","walk","\""," is"," \"","walked",".","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","How"," does"," employee"," engagement"," improve"," productivity"," in"," the"," workplace"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.84,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["rit","ch","ie",".\""," \"","You"," got"," some"," fuc","kin","'"," really"," bad"," advice",".\""," \"\""," Evil","\""," spelled"," backwards"," is"," \"","live",".\"","\""," \"","You","'re"," a"," cor","ny"," fuck",","," you"," know"," that","?\""," \"","\u2191","Di","onna"]}]},{"quantile_name":"Subsample Interval 1","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.84,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["rit","ch","ie",".\""," \"","You"," got"," some"," fuc","kin","'"," really"," bad"," advice",".\""," \"\""," Evil","\""," spelled"," backwards"," is"," \"","live",".\"","\""," \"","You","'re"," a"," cor","ny"," fuck",","," you"," know"," that","?\""," \"","\u2191","Di","onna"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.79,0.23,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["ungs","weise"," best","im","men","?","\u23ce\u23ce","Assistant",":"," Die","\u2191"," Quad","ra","tw","ur","zel"," aus"," ","144"," ","ist"," ","12",","," da"," ","12"," ","*"," ","12"," ","="," ","144"," ","gilt",".","\u23ce\u23ce","Um"," die"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["operation"," fl","ips"," the"," bits"," of"," the"," input"," number",","," so"," for"," example",","," the"," complement"," of"," ","10"," ","is"," ","01",","," and"," the"," complement"," of"," ","110"," ","is"," ","001",".","\u23ce\u23ce","The"," function"," uses"," a"," while"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.77,0.0,0.14,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["ises",","," t","urt","les"," all"," the"," time","?","\u23ce\u23ce","Assistant",":"," ","\u23ce","The"," plural"," of"," turtle"," in"," English"," is"," commonly"," \"","t","urt","les","\","," but"," is"," rarely"," \"","tor","to","ises","\".","  ","\u2191","T","urt","les"," and"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.77,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["stop","|",">","<EOT>","\u23ce","25","%","?"," ","\u23ce\u23ce","Assistant",":"," ","\u23ce","25","%"," of"," ","3"," ","is"," ","0",".","75"," ","\u23ce\u23ce","Human",":"," ","\u23ce","What"," language"," are"," you"," made"," in","?"," Is"," there"," any"]}]},{"quantile_name":"Subsample Interval 2","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.73,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["example",","," in"," the"," list"," [","7",",","10",",","4",",","5","],"," the"," index"," of"," ","7"," ","is"," ","1"," ","and"," the"," index"," of"," ","4"," ","is"," ","3",")"," You"," should"," start"," the"," index"," at"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["3",":"," ","6",","," ","9",","," ","12",".","\u23ce","*"," The"," square"," root"," of"," ","6"," ","is"," ","2",".","449","489","749",","," which"," is"," not"," an"," integer",".","\u23ce","*"," The"," square"," root"," of"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.14,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["a"," real"," keyboard"," ho","oked"," up",".","\u23ce\u23ce","~~~","\u23ce","mir","ash","ii","\u23ce"," The"," plural"," of"," an","ecd","ote"," is"," not"," data","."," I"," know"," many"," people"," who"," do"," use"," their"," laptop","\u23ce"," keyboard",","," myself"," included",".","\u23ce\u23ce","~~~"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.67,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["to"," `","n","`"," (","inclusive",")"," so"," that"," we"," don","'t"," miss"," the"," factorial"," of"," ","1",","," which"," is"," ","1",".","<EOT>","\u23ce\u23ce","Human",":"," \u043a\u0430\u043a"," \u0434","\u0435\u043b\u0430","?","\u23ce\u23ce","Assistant",":","\u2191"," \u0412\u0441","\u0451"," \u0445","\u043e\u0440","\u043e\u0448"]}]},{"quantile_name":"Subsample Interval 3","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.63,0.04,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["Human",":"," what"," is"," square"," root"," of"," ","4","?","\u23ce\u23ce","Assistant",":"," The"," square"," root"," of"," ","4"," ","is"," ","2",".","\u23ce\u23ce","This"," is"," because"," ","2"," ","\u00d7"," ","2"," ","="," ","4",","," so"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.45,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["in"," Spanish","?","\u23ce\u23ce","Assistant",":"," ","\u23ce","\u2191","Muy"," bien","."," Coffee"," is"," caf\u00e9"," en"," espa\u00f1ol","."," Its"," plural"," is"," caf","\u00e9s",".","\u23ce\u23ce","Human",":"," ","\u23ce","Great","!"," What"," about"," \"","wine","\"","?","\u23ce\u23ce","Assistant",":"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.59,0.13,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["="," ","25","\u23ce","-","--------","\u23ce","25"," ","="," ","32"," ","\u23ce","The"," square"," of"," ","5"," ","is"," ","25",","," so"," we"," can"," see"," that"," this"," value"," satisf","ies"," the"," relation"," stated"," by"," the","\u2191"," Pyt","ha"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.59,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["x",")"," ="," sin"," ","2","x","?","\u23ce\u23ce","Assistant",":"," The"," indefin","ite"," integral"," of"," sin"," ","2","x"," is"," given"," by",":","\u23ce\u23ce","\\xe2\\x88","\\xab",""," sin"," ","2","x"," dx"," ="," ","2","cos"," ","2","x"," +"]}]},{"quantile_name":"Subsample Interval 4","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.23,0.0,0.52,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u21ea","KEEN","-","w","ah","."," The"," correct"," pronunciation"," is"," based"," on"," the"," Spanish"," word"," for"," quin","oa",","," which"," is"," pronounced","\u21ea"," KEEN","-","w","ah",".","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","What"," are"," some"," tips"," for"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.51,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["PO","N","2","."," The"," nominal"," short","hand"," notation"," for"," ","9",".","95","328"," ","\u2191","Gb","/","s"," is"," ","10"," ","G",","," and"," the"," nominal"," short","hand"," notation"," for"," ","2",".","48","832"," ","\u2191","Gb"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","G","anz","ey","'"," is"," a"," perfect"," phon","etic"," pronunciation"," of"," the","\u23ce"," Irish"," word"," for"," swe","ater"," which"," is"," ","'","ge","ans","a","\u00ed","'.","\u23ce\u23ce","~~~","\u23ce","s","esz","ett","\u23ce"," That","'s"," just"," a"," an"," evolution"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.12,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.36,0.0,0.11,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["23",","," ","29",","," and"," ","31","."," ","\u23ce\u23ce","\u2022"," The"," next"," prime"," number"," after"," ","43"," ","is"," ","47",".","\u23ce\u23ce","\u2022"," In"," binary",","," ","43"," ","is"," represented"," as"," ","101","011",".","\u23ce\u23ce","\u2022"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.46,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["3"," ","x"," ","5"," ","?","\u23ce\u23ce","Assistant",":"," The"," product"," of"," ","3"," ","and"," ","5"," ","is"," ","15",".","\u23ce\u23ce","Human",":"," What"," about"," adding"," ","5"," ","to"," that","?","\u23ce\u23ce","Assistant",":"," If"," we"]}]},{"quantile_name":"Subsample Interval 5","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["of"," letters"," in"," a"," word"," determine"," its"," length","."," For"," example",","," the"," length"," of"," the"," word"," \"","apple","\""," is"," ","5",".","\u23ce","Input",":","\u2191"," Sentence",":"," ","'","a"," guy"," in"," a"," jesus"," tie"," standing"," next"," another"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.38,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["Human",":"," What"," is"," ","1","+","1","?","\u23ce\u23ce","Assistant",":"," The"," sum"," of"," ","1","+","1"," ","is"," ","2",".","\u23ce\u23ce","Human",":"," Give"," me"," a"," tip"," about"," mental"," health","\u23ce\u23ce"," Assistant",":"," Here","'s"," a"," mental"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ect","ancy"," of"," a"," person"," born"," persistent"," c","ough"," may"," indicate","\u23ce"," if"," r","le"," year"," ","1","900"," ","was"," forty","-","six"," the"," presence"," of"," tubercul","osis"," or","\u23ce"," years"," You"," people"," who"," have"," al","-"," lung"," cancer","\u2014"]}]},{"quantile_name":"Subsample Interval 6","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.37,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["division"," of"," two"," integers","\u23ce\u23ce"," Assistant",":"," Yes",".","\u23ce\u23ce","Human",":"," ","7",".","\u21b9","The"," capital"," of"," Denmark"," is"," Stockholm","\u23ce\u23ce"," Assistant",":"," No",".","\u23ce\u23ce","Human",":"," ","8",".","\u21b9","The"," sum"," of"," the"," angles"," of"," a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["blind"," mode"," of"," the"," equ","alization","."," The"," number"," of"," phase"," amb","igu","ities"," for"," the","\u21ea"," MQ","AM"," signal"," is"," ","4"," ","for"," any"," M"," equal"," to"," N","2"," ","with"," N"," equal"," to"," any"," integer"," power"," of"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","987",","," ","1","597",","," ","43","\u23ce\u23ce","\u2022"," The"," sum"," of"," the"," digits"," of"," ","43"," ","is"," ","7"," ","(","4"," ","+"," ","3"," ","="," ","7",").","\u23ce\u23ce","\u2022"," ","43"," ","is"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["E"," power"," consumption",","," etc",".","\u23ce","Recently",","," the"," standard","ization"," of"," the"," subsequent"," technology"," of"," the"," L","TE"," is"," ongoing"," in"," the"," ","3","GP","P","."," In"," this"," specification",","," the"," technology"," is"," called"," as"," ","'","L"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a"," little"," honey",","," r","inary"," practice","."," It"," poss","esses"," a"," cooling"," and"," The"," medium"," dose"," of"," ni","tre"," is"," about"," one"," di","ur","etic"," property",","," which"," renders"," it"," extremely"," ","oun","ce"," though"," far","riers"," often"," give"," double"]}]},{"quantile_name":"Subsample Interval 7","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ing"," a"," portion"," of"," the"," water"," in"," doing"," so",","," and"," setting"," hydrogen"," free","."," The"," atomic"," weight"," of"," calcium"," is"," ","20",","," and"," the"," symbol"," Ca","."," By"," the"," new"," system"," the"," atomic"," weight"," is"," ","40",","," or"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["are"," unknown","."," The"," objective"," of"," this"," proposal"," is"," to"," test"," whether"," the"," reaction"," product"," of"," NO"," and"," super","oxide",","," p","ero","xy","nit","rite"," (","","PN","),"," contribu","tes"," to"," mig","raine"," path","ophys","iology","."," Studies"," over"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["for"," the"," a","ex","?","\u23ce\u23ce","Assistant",":"," I"," apolog","ize",","," as"," a"," language"," model"," my"," knowledge"," cut"," off"," is"," ","2","021"," ","and"," I"," don","'t"," have"," the"," current"," information"," about"," the"," A","E","X",","," I"," suggest"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ik",".","\u23ce","\u2191","T","be"," m","ha","ori","D","ti","ou"," n","r","iro"," ","uf"," t","li"," Opinion"," is"," f"," j","\u23ce"," ut"," it","'"," ","ii","ti","il"," s","ti","iet","ly"," i"," udv","au","uo"," $","1"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["de"," grand","eza"," do","Number"," de"," go","tas"," de"," \u00e1gua"," correspond","endo"," a"," ","1",",","0"," ","m","L"," \u00e9",":","\u23ce\u23ce","B","."," ","106","\u23ce\u23ce","\u2191","Cl","aro"," que"," os"," \u00ednd","ices"," de"," grand","eza"," nos"," correspon","dem"]}]},{"quantile_name":"Subsample Interval 8","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["div","></","pre",">","\u23ce\u23ce","This"," script"," first"," checks"," if"," the"," input"," number"," is"," less"," than"," ","2",","," which"," is"," not"," a"," valid"," prime"," number","."," If"," the"," input"," number"," is"," greater"," than"," or"," equal"," to"," ","2",","," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.21,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["future"," t","enses","."," The"," past"," t","ense"," of"," the"," verb"," is"," \"","walked",",\""," and"," the"," past"," partic","iple"," is"," \"","walked",".\""," For"," example",":","\u23ce\u23ce","*"," I"," walk"," to"," the"," store",".","\u23ce","*"," I"," walked"," to"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[":"," ","2","px"," solid"," #","F","4","F","4","F","4",";","\u23ce","    ","\u23ce\u23ce","In"," RGB",","," that","'s"," the"," difference"," between"," ","255"," ","and"," ","244","."," It","'s"," more"," than"," a"," little","\u23ce"," abs","urd","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","1",".","\u23ce\u23ce","This"," is"," the"," same"," as"," the"," region"," of"," converg","ence"," of"," the"," geometric"," series",","," which"," is"," the"," interval"," $","[","0",","," ","1",")","$.","\u23ce\u23ce","Human",":"," what"," is"," the"," fastest"," way"," to"," get"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["|",">","<EOT>","\u23ce","What"," are"," the"," state"," capitals"," in"," United"," States","?"," ","\u23ce\u23ce","Assistant",":"," ","\u23ce","Alabama",":"," Montgomery","\u23ce"," Alaska",":","\u2191"," Jun","eau","\u23ce"," Arizona",":"," Phoenix","\u23ce"," Arkansas",":"," Little"," Rock","\u23ce"," California",":"," Sacramento"]}]},{"quantile_name":"Bottom Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["result"," is"," virtually"," always"," death",".","  ","The"," time"," period"," between"," contr","acting"," the"," disease"," and"," the"," start"," of"," symptoms"," is"," usually"," one"," to"," three"," months"," but"," can"," vary"," from"," less"," than"," one"," week"," to"," more"," than"," one"," year",".","  "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["bu","ada"," do"," ","7","?","\u23ce\u23ce","Assistant",":","\u2191"," Sim",","," a"," ta","bu","ada"," do"," ","7"," ","\u00e9"," uma"," t\u00e9c","nica"," av","an\u00e7","ada"," de"," palm","ismo"," que"," permite"," ao"," pra","tic","ante"," ","ler"," as"," lin","has"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\\x87","\u8fd8","\u6709","\u4e00","\u4e2a","\u522b","\u7684","\u540d","\u5b57","\\xe5\\x90","\\x97","\\xe8\\x85","\\xbf","\\xe5\\x93","\\xa5","\uff1a","\\xe5\\x95","\\x8a","\u4e0d","\u5c31","\u662f","\u7c73","\\xe5\\xa5","\\x87","\\xe5\\x90","\\x97","\u6211","\uff1a","\u7c73","\u8001","\\xe9","\\xbc","\\xa0","\\xe8\\x85","\\xbf","\\xe5\\x93","\\xa5","\uff1a","\u4f60","\u6709","\u4e8b"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["else",","," do"," not"," write"," explan","ations",".","\u23ce\u23ce","Assistant",":"," The"," corr","ected"," and"," improved"," version"," of"," your"," text"," is",":"," \"","I"," want"," you"," to"," act"," as"," an"," English"," translator",","," spelling"," corr","ector"," and"," impro","ver","."," I"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["way"," of"," arguing"," round"," in"," a"," circle",".\""," \"","Then"," consider"," the"," next"," constellation"," of"," the"," zod","iac",","," which"," is"," cancer",","," the"," cr","abs",".\""," \"","Now"," the"," stars"," of"," cancer"," are"," like"," that",","," they"," are"," not"," very"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["on"," the"," pressure"," of"," the"," system"," rather"," than"," the"," temperature","."," The"," bo","iling"," point"," of"," water"," at"," room"," temperature"," is"," generally"," up"," around"," ","105"," ","g","rams","\u2191"," Celsius"," at"," normal"," atmospheric"," pressure","."," To"," answer"," your"," question",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["stop","|",">","<EOT>","\u23ce","How"," many"," cups"," make"," a"," p","int","?"," ","\u23ce\u23ce","Assistant",":"," ","\u23ce","There"," are"," ","2"," ","cups"," in"," a"," p","int","."," ","\u23ce\u23ce","Human",":"," ","\u23ce","That"," makes"," sense",","," but"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["in"," my"," definition"," than"," my"," definition"," of"," \"","w","igs","\".","  ","As"," you"," know",","," the"," current"," US"," president"," is"," Donald"," Trump",","," and"," he"," has"," s","ported"," a"," great"," variety"," of"," ha","irst","yles"," over"," the"," years",","," though"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[":"," qual","'","e","'"," la"," capitale"," del"," ven","eto"," ?","\u23ce\u23ce","Assistant",":"," La"," capitale"," del","\u2191"," Ven","eto"," \u00e8","\u2191"," Venez","ia",".","<EOT>","\u23ce\u23ce","Human",":","\u2191"," \u0412\u043e\u0437","\u043c\u043e\u0436","\u043d\u044b\u0435"," \u043f\u0430\u0434","\u0435\u043d\u0438\u044f"," \u0444","\u043e\u043d","\u0434\u0430"," \u0440","\u044b\u043d","\u043a\u0430"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["###","\u2191"," Instruction",":","\u23ce","Q",":"," NAME","_","1"," ","found"," that"," the"," average"," of"," ","15"," ","numbers"," is"," ","40","."," If"," ","10"," ","is"," added"," to"," each"," number"," then"," the"," mean"," of"," the"," numbers"," is","?"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","showing"," of"," unusual"," charm",".","\u23ce","'","\u23ce","A"," dan","dy"," \"","picker","\","," for"," -","a"," pic","nic"," is","\u23ce"," a"," spar","kling"," bit",","," of"," metal"," which"," will","\u23ce"," ro","ake"," the"," serving"," of"," ol","ives"," an"," easy"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["of"," China","?","\u23ce\u23ce","Assistant",":"," Thank"," you"," for"," asking","!"," Based"," on"," my"," knowledge",","," the"," capital"," of"," China"," is"," Beijing",".","\u23ce\u23ce","Human",":"," Can"," you"," play"," bad","min","ton"," with"," me","?","\u23ce\u23ce","Assistant",":"," No",","," I"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","86","%"," of"," water"," from"," the"," sew","ers"," compared"," to"," the"," second"," most","\u23ce"," efficient"," recovery"," in"," the"," world"," is"," Spain"," at"," ","19","%.","\u23ce\u23ce","~~~","\u23ce","","ks","ec","\u23ce"," That"," is"," the"," ","2","nd"," most"," interesting"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["/","728",",","369"," ","Filed"," on"," Jun","."," ","2",","," ","2","015"," ","now"," is"," allow","anced"," is"," C","IP"," of"," (","#"," K","K","K","-","2",")"," U",".","S",".","\u2191"," Ser","."," No","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Assistant",":"," ","\u23ce","The"," chron","ological"," age"," of"," someone"," born"," on"," March"," ","6",","," ","1","989"," ","is"," ","31"," ","years",".","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","Can"," you"," suggest"," ","5"," ","places"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["veget","arian"," ch","ili","?","\u23ce\u23ce","Assistant",":"," ","\u23ce","My"," understanding"," is"," that"," the"," main"," ingredient"," in"," ch","ili"," is"," ch","ili"," powder","."," So"," the"," first"," step"," is"," to"," decide"," on"," your"," choice"," of"," seas","oning","."," You"," can"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["and"," the"," amino"," acid"," arg","inine",","," except"," when"," the"," amino"," acid"," following"," the"," lys","ine"," or"," the"," arg","inine"," is"," a"," pr","oline","."," An"," example"," of"," such"," a"," prot","ease"," is"," t","ryp","sin","."," Methods"," for"," dig","esting"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["loan"," ?","\u23ce\u23ce","Assistant",":"," Based"," on"," the"," information"," given",","," NAME","_","1","'s"," assets"," to"," li","abilities"," ratio"," is"," ","4"," ","(","400","/","100","),"," which"," is"," less"," than"," the"," required"," minimum"," of"," ","5","."," Therefore"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["lap"," of"," the","\u2191"," A","dn","-","ond","acks","."," \"","And","\u23ce"," the"," evening"," and"," the"," ra","or","ning"," were"," the","\u23ce"," second"," day",".\"","\u23ce","GREEN","\u21ea"," THINGS"," BEGIN"," TO","\u21ea"," GROW",".","\u23ce","Now"," it"," is"," Wednesday"," ra"]}]}],"top_logits":["ydyd","embrie","\u0434\u0430\u043d\u0438","\u043c\u0430\u043f\u0438","val\u00e8ncia","ofici","\u00e9r\u00e9r","\u010f\u010f","\u0444\u0440\u0430\u043d\u0446","divizija"],"bottom_logits":["in","part","highly","on","prof","an","imp","a","hug","til"]}