{"index":17139251,"examples_quantiles":[{"quantile_name":"Top Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["are"," conducting"," a"," search"," for"," a"," restaurant",","," using"," a"," pair"," of"," synonym","s"," like"," \"","d","ine","\""," and"," \"","gr","aze","\""," will"," lead"," to"," more"," relevant"," results"," than"," simply"," entering"," the"," keyword"," \"","eat","\""," in"," a"," search"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.96,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Change"," the"," pricing"," logic"," of","\u2191"," ","Isco"," to"," the"," combination"," of"," \"","\u2191","Funct","ie","gro","epen","\""," and"," \"","\u2191","Werk","erv","aring","\"."," The"," Cost"," Per"," Apply"," Click"," is"," no"," longer"," based"," solely"," on"," the","\u21ea"," ","ISCO"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.94,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["new"," pricing"," model","."," The"," new"," pricing"," model"," should"," be"," based"," on"," \"","\u2191","Funct","ie","gro","epen","\""," and"," \"","\u2191","Werk","erv","aring","\""," and"," not"," solely"," on"," the","\u21ea"," ","ISCO"," code","."," This"," change"," should"," be"," made"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.93,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["therapeutic"," pr","ogn","osis","."," We"," also"," will"," evaluate"," whether"," these"," parameters"," are"," consistent"," for"," \"","he","atable","\""," and"," \"","non","-","he","atable","\""," tum","ors"," in"," the"," context"," of"," the"," therapy"," protocol","."," The"," benefits"," of"," pred","icting"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["lat","ches",".","  ","The"," basic"," building"," blocks"," of"," all"," digital"," computing"," are"," \"","and","\","," \"","or","\""," and"," \"","exclusive"," or","\""," gates",".","  ","Silicon"," allows"," you"," to"," make"," these"," gates"," really"," really"," small",".","  ","You"," can"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\"","shop"," assistant","\""," and"," \"","lif","egu","ard","\","," but"," incorre","ct","ly"," guess"," \"","pi","mp","\""," and"," \"","mas","se","use","\".","\u23ce\u23ce","News"," Article",":","\u23ce","NAME","_","1",":","\u2191"," Okay",","," round"," two",".","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["kon","art","\u23ce",">","\u2191","Alphabet"," extensions","\u23ce\u23ce"," So","..."," all"," those"," \"","\u2191","","\u015a"," ","\u015b","\""," and"," \"","\u2191","","\u0106"," ","\u0107","\""," instead"," of"," using","\u2191"," Cy","ril","lic","?"," Yeah",","," no",".","\u23ce\u23ce","~~~"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.91,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["words"," in"," the"," text"," that"," are"," related"," to"," clothing"," or"," fashion",","," such"," as"," \"","sport"," b","ra","\""," and"," \"","overall"," shorts",".\""," Here"," is"," the"," corr","ected"," list"," of"," words"," in"," the"," given"," text",":","\u23ce\u23ce","1",".","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.16,0.0,0.0,0.0,0.0,0.91,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\""," in"," spanish","\u23ce\u23ce"," Assistant",":"," The"," word"," \"","d","umb","\""," in"," Spanish"," is"," \"","m","udo","\""," or"," \"","sor","do","\"."," However",","," it","'s"," important"," to"," note"," that"," these"," words"," have"," a"," different"," meaning"," in"," Spanish"," than"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.42,0.0,0.0,0.0,0.0,0.0,0.0,0.91,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ised"," to"," a"," single"," case"," to","\u23ce"," prevent"," \"","duplic","ates","\""," of"," \"","jar","sh","w","ah","\""," and"," \"","\u2191","Jar","sh","w","ah","\"","?"," If"," so",","," this"," was"," recently","\u23ce"," brought"," up"," on"," the"," m","ailing"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.37,0.0,0.0,0.0,0.0,0.91,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["."," When"," you"," say"," \"","the"," market"," just"," decides","\","," \"","the"," market","\""," is"," \"","many"," people","\""," and"," \"","just"," deciding","\""," is"," based"," on"," what"," they"," are"," selling","/","buying"," for",".","\u23ce","<","|","stop","|",">"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.24,0.0,0.0,0.0,0.0,0.91,0.0,0.0,0.0,0.0,0.0,0.0,0.27,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.85,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["sign"," in","version",")"," operation",","," in"," which"," \"","0","'s","\""," are"," replaced"," with"," \"","1","'s","\""," and"," \"","1","'s","\""," are"," replaced"," with"," \"","0","'s","\"."," The"," replacement"," of"," \"","0","'s","\""," and"," \"","1"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.0,0.0,0.0,0.0,0.0,0.0,0.91,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["try"," group","ing"," things"," into"," categories",","," like"," \"","personal"," stuff","\""," and"," \"","things"," for"," the"," house","\""," and"," \"","kitchen"," supplies",".\""," At"," the"," end"," you"," can"," see"," where"," there"," are"," patterns",","," like"," how"," all"," your"," kitchen"," supplies"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.91,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["needs"," to"," be"," replaced"," with"," a"," new"," model"," that"," takes"," into"," account"," \"","\u2191","Funct","ie","gro","epen","\""," and"," \"","\u2191","Werk","erv","aring","\"."," The"," new"," pricing"," logic"," should"," be"," implemented"," for"," both"," the"," API"," and"," Dashboard","."," The"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.91,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["can"," help"," you"," out"," with"," your"," cross"," ","stit","ching",".","  ","Try"," searching"," \"","cross"," st","itch","\""," and"," \"","tutorial","\""," and"," you","'ll"," get"," a"," good"," variety"," of"," results",".","  ","Do"," you"," want"," me"," to"," give"," you"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.91,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["'m"," sorry",","," but"," I","'m"," not"," sure"," what"," you"," are"," referring"," to"," with"," \"","\u2191","Vic","una","\""," and"," \"","Chat","G","P","T",".\""," Could"," you"," please"," provide"," more"," context"," or"," clar","ify"," your"," question","?","<EOT>","\u23ce\u23ce","Human"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.91,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["free"," will","."," Whether"," humans"," have"," free"," will"," depends"," on"," how"," you"," define"," key"," terms"," like"," \"","free","\""," and"," \"","will","\","," and"," there"," are"," good"," arguments"," on"," both"," sides"," of"," the"," debate","."," Some"," key"," points"," to"," consider",":"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["are"," introduced"," up","front",".","\u2191"," Definitions"," are"," provided"," for"," technical"," terms"," like"," \"","oblig","ate"," seed","ers","\""," and"," \"","c","opp","icing","\"."," Additional"," context"," on"," the"," relative"," importance"," and"," drivers"," of"," the"," two"," strategies"," is"," given","."," The"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["pipeline",","," various"," dash","boards",","," analysis"," of"," online"," experiments","\"","\u23ce","are"," not"," examples"," of"," \"","products","\""," and"," \"","applications","\""," ?","\u23ce\u23ce","~~~","\u23ce","h","ouse","of","sh","ards","\u23ce"," well",","," creating"," metrics"," to"," measure"," product"," usage"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["help"," you"," find"," options",".","  ","If"," you"," go"," on"," Google",","," and"," search"," for"," \"","artificial"," legs","\""," and"," \"","carbon"," fiber","\","," it"," will"," give"," you"," a"," list"," of"," different"," companies"," and"," options"," that"," sell"," artificial"," legs",".","  "]}]},{"quantile_name":"Subsample Interval 0","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.91,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["'m"," sorry",","," but"," I","'m"," not"," sure"," what"," you"," are"," referring"," to"," with"," \"","\u2191","Vic","una","\""," and"," \"","Chat","G","P","T",".\""," Could"," you"," please"," provide"," more"," context"," or"," clar","ify"," your"," question","?","<EOT>","\u23ce\u23ce","Human"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.91,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["free"," will","."," Whether"," humans"," have"," free"," will"," depends"," on"," how"," you"," define"," key"," terms"," like"," \"","free","\""," and"," \"","will","\","," and"," there"," are"," good"," arguments"," on"," both"," sides"," of"," the"," debate","."," Some"," key"," points"," to"," consider",":"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["are"," introduced"," up","front",".","\u2191"," Definitions"," are"," provided"," for"," technical"," terms"," like"," \"","oblig","ate"," seed","ers","\""," and"," \"","c","opp","icing","\"."," Additional"," context"," on"," the"," relative"," importance"," and"," drivers"," of"," the"," two"," strategies"," is"," given","."," The"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["pipeline",","," various"," dash","boards",","," analysis"," of"," online"," experiments","\"","\u23ce","are"," not"," examples"," of"," \"","products","\""," and"," \"","applications","\""," ?","\u23ce\u23ce","~~~","\u23ce","h","ouse","of","sh","ards","\u23ce"," well",","," creating"," metrics"," to"," measure"," product"," usage"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["help"," you"," find"," options",".","  ","If"," you"," go"," on"," Google",","," and"," search"," for"," \"","artificial"," legs","\""," and"," \"","carbon"," fiber","\","," it"," will"," give"," you"," a"," list"," of"," different"," companies"," and"," options"," that"," sell"," artificial"," legs",".","  "]}]},{"quantile_name":"Subsample Interval 1","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.18,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a"," text"," is"," in"," Spanish"," or"," Portuguese",":","\u23ce\u23ce","1","."," Look"," for"," the"," use"," of"," \"","v","\""," or"," \"","b","\""," in"," words",":"," In"," Spanish",","," the"," letter"," \"","v","\""," is"," usually"," used"," instead"," of"," \"","b"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ee","ee","ee","!","\u23ce\u23ce","So"," once"," again",","," very"," clearly"," not"," free","."," Also"," \"","cre","atively","\""," and"," \"","compet","it","ively","\",","\u23ce","is"," that"," another"," way"," to"," describe",":"," \"","hard"," to"," understand","\"","?","\u2191"," Remin"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[":"," usually"," I","'m"," changing"," individual"," components","'"," colors"," if"," the"," component"," has"," a"," ","'","color","'"," or"," ","'","backgroundColor","'"," available","\u23ce","<","ka","lik","iana",">"," I","'m"," hopefully"," on"," to"," resol","ving"," the"," last"," failure"," in"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["consistent"," with"," the"," document","?"," (","Yes","/","No",")","\u23ce","Start"," your"," answer"," explicitly"," with"," \"","Yes","\""," or"," \"","No","\","," and"," if"," you"," answer"," no",","," explain"," which"," sentence"," is"," incons","istent"," and"," why",".","\u23ce\u23ce\u23ce","Assistant",":"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["df","at","\u23ce"," Data"," is"," wrong"," on"," examples",".","\u23ce\u23ce","Mobile"," Phone"," ="," \"","Good","\u2191"," Enough"," Android","\""," and"," \"","iOS"," and","\u2191"," Flagship"," Android","\"","\u23ce\u23ce","[","http","://","www",".","g","art","ner",".","com","/","news","room"]}]},{"quantile_name":"Subsample Interval 2","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[">","<EOT>","\u23ce","You"," are"," given"," a"," conversation"," between"," two"," people","."," ","'","Person","1",":","'"," and"," ","'","Person","2",":","'"," are"," used"," to"," separate"," their"," respective"," dialog","ues","."," If"," the"," conversation"," begins"," with"," a"," question"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a","\u23ce\u23ce"," Note"," that"," the"," first"," and"," second"," letters"," in"," the"," string"," have"," been"," changed"," to"," \"","N","\""," and"," \"","i","\","," respectively",","," and"," the"," third",","," fourth",","," and"," fifth"," letters"," remain"," unchanged","."," Thank"," you"," for"," bringing"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["in"," which"," the"," message"," is"," combined"," with"," a"," fixed"," value"," (","known"," as"," the"," ","'","seed","'"," or"," ","'","counter","')"," and"," a"," random"," value"," (","known"," as"," the"," ","'","block"," index","'",")."," The"," output"," of"," each"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ati",".","<EOT>","\u23ce\u23ce","Human",":"," Given"," the"," document"," below",","," you"," have"," to"," determine"," if"," \"","Yes","\""," or"," \"","No","\","," the"," summary"," is"," fact","ually"," consistent"," with"," the"," document",".","\u23ce\u23ce","Document",":","\u23ce","|"," NAME","_","1"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ou","t\u00e9"," \"","time","_","exposed","\""," au"," mod","\u00e8","le"," de"," Cox"," en"," plus"," de"," \"","E","\""," et"," \"","C","\".","\u2191"," C","ela"," permet"," de"," voir"," comment"," le"," temps"," d","'","exposition"," pot","ent","iel"," aff","ec","te"]}]},{"quantile_name":"Subsample Interval 3","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.61,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["emotions",":"," ","'","joy","',"," ","'","love","',"," ","'","anger","',"," ","'","fear","',"," or"," ","'","surprise","'.","\u23ce","Input",":"," i"," could"," better"," understand"," and"," feel"," the"," desires"," of"," his"," most"," sweet"," heart",".","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.61,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["to"," remember"," to"," keep"," things"," accurate"," next"," time","."," I"," just"," thought"," that"," when"," you"," said"," \"","synopsis","\""," and"," \"","famous","\""," you"," might"," have"," meant"," \"","interesting","\","," \"","cute","\","," \"","funny","\","," \"","emb","ell","ished","\""]},{"tokens_acts_list":[0.29,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\"","z","\""," (","esc","lud","endo"," \"","0","\","," \"","1","\","," \"","8","\","," \"","9","\""," e"," \"","U","+","00","FF","\","," ov","v","ero"," il"," caratter","e"," con"," cif","ra"," in"," nero",")"," e"," il"," punto"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["be"," ris","ible"," is"," to"," be"," laugh","able","),"," \"","pret","ent","ious",",\""," \"","ste","aming"," pile",",\""," and"," \"","pret","ent","ious",".","\"\\","n","\\","n"," ","2","."," The"," text"," contains"," a"," negative"," word"," in"," the"," form"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","Music","\u2191"," Venues","\","," \"","Best"," Live"," Music","\","," \"","Local","\u2191"," Concerts","\","," \"","Classical"," Music","\","," and"," \"","Opera"," and"," Ballet","\".","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","Is"," there"," a"," leave"," in"," styling"," product"," I"]}]},{"quantile_name":"Subsample Interval 4","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["word"," ","'","esp","osa","'"," in"," Spanish"," not"," only"," transl","ates"," to"," ","'","wife","'"," but"," also"," ","'","hand","c","uf","fs","'."," My"," point"," is"," that"," understanding"," word"," choice"," gives"," us"," a"," deeper"," understanding"," of"," the"," language"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.17,0.0,0.0,0.0,0.0,0.77,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["bit"," about"," how"," to"," use"," the"," hook","."," I"," suggest"," that"," you"," use"," a"," \"","steel"," hook","\""," and"," a"," \"","yarn","\""," that","'s"," called"," \"","all"," purpose","\""," or"," \"","wor","sted"," weight","\"."," If"," you"," don","'t"," have"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["tickets",","," such"," tickets"," can"," be"," anything"," from"," \"","I","\u23ce"," cannot"," get"," apache","2"," ","to"," run","\""," to"," \"","how"," can"," I"," get"," this"," lin","u","cs"," thing"," to"," run","\u23ce","\u2191"," Outlook","?\""," ","(/","s",")"," to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.0,0.0,0.0,0.0,0.0,0.53,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ens","etz","ung"," in","\u2191"," Proz","ent"," ang","eben",".","\u2191"," Im","mer"," \u201e","\u2191","V","isk","ose","\""," oder"," \u201e","\u2191","Re","yon","\""," an","st","elle"," von"," \u201e","\u2191","Bam","bus","\""," und"," \u201e","\u2191","Az","lon","\""," an"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ately"," trained","\""," for"," conc","ision",".","\u23ce\u23ce","3","."," Changed"," \"","indicate"," the"," intr","ins","ic"," difficulty","\""," to"," \"","reflect"," the"," inher","ent"," difficulty","\""," for"," clarity","."," ","\u23ce\u23ce","4","."," Changed"," \"","the"," gap"," between"," fine","-"]}]},{"quantile_name":"Subsample Interval 5","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.41,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["reduced"," competition",".","<EOT>","\u23ce\u23ce","Human",":"," what"," are"," common"," adj","ectives"," found"," before"," the"," word"," \"","work","\""," in"," \"","God","'s"," work","\""," ?","\u23ce\u23ce","Assistant",":"," Here"," are"," some"," common"," adj","ectives"," that"," might"," prec","ede"," \"","work"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","\u23ce","Some"," books"," which"," may"," help"," improve"," communication"," are"," \"","The"," Five"," Love"," Languages","\""," by"," Gary"," Chapman"," and"," \"","\u2191","Non","viol","ent"," Communication","\""," by"," Marshall","\u2191"," Ros","enberg",".","\u23ce","<","|","stop","|",">","<EOT>","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["grain"," of"," salt",","," since"," you"," could"," take"," it"," as"," \"","I","'m"," constantly"," re","lear","ning","\""," instead"," of"," \"","I"," don","'t"," have"," to"," keep"," re","lear","ning","\"","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","If"," a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.59,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["player"," need"," freedom"," like"," par","rot",","," if","(","n","pc","_","trust","_","level","=","=\\\"","Trust","\\\""," or"," \\\"","\u2191","K","inda","\\\""," or"," \\\"","\u2191","Neutral","\\","\")","she"," should"," open"," the"," door"," for"," the"," player","\u3011","\u3010"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.35,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ry"," p","uns",","," like"," \"","p","aws","\""," instead"," of"," \"","pause","\","," \"","me","ow","\""," instead"," of"," \"","now","\","," etc","."," He"," is"," a"," gay"," fur","ry"," whose"," f","urs","ona"," is"," a"," flu","ffy"," blue"," and"]}]},{"quantile_name":"Subsample Interval 6","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.36,0.0,0.0,0.0,0.0,0.38,0.0,0.0,0.0,0.0,0.0,0.0,0.35,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["name"," introduced"," by"," {{","user","}","}.","{{","char","}","}'","s"," personality",":"," \"","\u2191","Ins","ane","\""," +"," \"","\u2191","S","assy","\""," +"," \"","\u2191","Crazy","\""," +"," \"","\u2191","Man","iac","al","\""," +"," \"","\u2191","Unp"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a"," p","icky"," comment",","," but"," I"," think"," it","'s"," important"," to"," distinguish"," \"","proximity","\u23ce"," to"," power","\""," from"," \"","holding"," power","\"."," There"," are"," a"," lot"," of"," journalists"," with"," proximity","\u23ce"," to"," power",","," some"," of"," them"," doing"," a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["A",","," column"," decoder"," ","108"," ","raises"," the"," column"," selection"," signal"," from"," \"","L","\""," (","Low",")"," to"," \"","H","\""," (","High","),"," turns"," on"," the"," corresponding"," transist","or",","," and"," connects"," the"," bit"," line"," pair"," and"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u043e"," \u0456\u0437"," \u0437\u043d\u0430\u0447","\u0435","\u043d\u043d","\u044f\u043c\u0438"," \u0441\u043b","\u0456\u0432"," \u00ab","\u2191","L\u00f6","f","fel","\u00bb"," (","","\u043b\u043e\u0436","\u043a\u0430",")"," \u0442\u0430"," \u00ab","ab","g","eben","\u00bb"," (","\u0432\u0456","\u0434\u0434","\u0430\u0432","\u0430\u0442\u0438",").","\u23ce\u23ce","\u2191","\u041e\u0442","\u0436\u0435",","," \u043f\u0440","\u0438\u0445","\u0438\u043b\u044c","\u043d\u0438\u043a\u0438"," \u0441\u0435\u043c"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.63,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["one"," or"," more","\""," or"," \"","at"," least"," one","\""," and"," indefin","ite"," articles"," such"," as"," \"","a","\""," or","\"","an","\""," (","e",".","g",".,"," \"","a","\""," and","/","or"," \"","an","\""," should"," be"," interpreted"," to"]}]},{"quantile_name":"Subsample Interval 7","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["We"," then"," use"," the"," `","rename","()","`"," method"," to"," rename"," the"," ","'","col","1","'"," column"," to"," ","'","new","\\_","col","1","'"," using"," its"," index","."," We"," set"," the"," `","columns","`"," parameter"," to"," the"," index"," of"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["bug","."," The"," problem"," is"," that"," the"," pow","ers","aving"," test"," is"," in"," ","'","monitor","'"," which"," is"," ","'","v","ga"," external"," video","'"," in"," U","F","\u23ce","<","brend","and",">"," i"," just"," wanted"," to"," ask"," how"," many"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["care",".\""," \"","Ask"," her"," things"," like",","," \"","Are"," you"," gonna"," take"," Howard","'s"," name","?\"","\""," \"","Not"," \"","who","'s"," gonna"," sit"," on"," who","?\"","\""," \"","I","'ve"," been"," thinking"," I","'m"," gonna"," hyp","hen","ate",".\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.21,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["Assistant",":"," \"","Dans"," la"," p","lu","part"," des"," \u00e9tats"," d","\u00e9p","ress","ifs"," l\u00e9","gers","\""," transl","ates"," to"," \"","In"," most"," mild"," dep","ressive"," states","\""," in"," English",".","\u23ce\u23ce","Human",":"," translate"," this"," from"," french"," to"," english",":"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["and"," water",".","\u2191"," Chlor","opl","asts"," then"," use"," that"," energy"," to"," make"," energy","-","containing"," \"","molecules","\""," called"," \"","car","bo","hyd","rates","\"."," This"," is"," done"," in"," a"," process"," called"," \"","chemical"," synthesis","\","," because"," it"," involves"," putting"]}]},{"quantile_name":"Subsample Interval 8","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","Jol","iment",","," la"," \u00ab","\u2191"," Ma","ison"," du","\u2191"," Pe","uple"," \u00bb"," de","\u2191"," Br","ux","elles"," et"," \u00ab","\u2191"," V","oo"," ","ruit"," \u00bb"," de","\u2191"," Gar","ni","."," Cette"," dern","i\u00e8re"," est"," la"," s","\u0153","ur"," a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["visitor"," and"," page","view",".","\u23ce\u23ce","~~~","\u23ce","craft","yg","uy","\u23ce"," Password"," ","'","generating","'"," and"," password"," ","'","checking","'"," web","serv","ices"," should"," be"," outl","awed",".","\u23ce","They","'re"," a"," rid","icul","ously"," easy"," way"," to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["database"," to"," be"," used"," by"," NAME","_","1"," ","to"," be"," the"," \"","myd","atabase","\""," database",","," and"," the"," \"","other","\\_","database","\""," database"," will"," be"," used"," if"," you"," specify"," the"," database"," name"," in"," your"," queries",".","<EOT>","\u23ce\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["b","rat"," diet",".","\u23ce\u23ce","Assistant",":"," {\"","diagnosis","\""," :"," \"","food"," pois","oning","\","," \"","treatment","\""," :"," \"","\u21ea","B","RAT"," diet","\"}","<EOT>","\u23ce\u23ce","Human",":"," how"," can"," you"," use"," your"," own"," data"," to"," train"," vic","una"]}]},{"quantile_name":"Bottom Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.77,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.82,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["we"," only"," need"," a"," single"," wrong"," answer","."," \"","W","\""," and"," \"","M","\""," in"," the"," conversations"," stand"," for"," \"","woman","\""," and"," \"","man","\".","\u23ce","Input",":"," M",":"," Now",","," Mrs",".","\u2191"," Fran","ks",","," I"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["love"," to","!\""," \""," Yes",".\""," \""," Yes",".\""," \"","Yes",".\""," \"","\\xe2\\x99","\\xaa",""," ","\\xe2\\x99","\\xaa","\""," \"","Remember",","," R","J",","," worst"," thing"," they"," can"," do"," is"," say"," no",".\""," \"","Let","'s"," be"," honest",".\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["simple"," and"," straight","forward","\""," model"," of"," C"," leads"," to"," a"," lot","\u23ce"," of"," very"," not","-","simple","-","and","-","straight","forward"," time"," in"," front"," of","\u2191"," Val","gr","ind"," to"," get"," the","\u23ce"," program"," to"," work",","," or"," worse"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["jud","ging"," whether"," the"," data"," in"," the"," memory"," cell"," is"," in"," either"," state"," \"","1","\""," or"," below"," or"," state"," \"","2","\""," or"," above",".","\u23ce","In"," contrast",","," when"," the"," first"," page"," data"," is"," read",","," if"," the"," data"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["tten"," kom","mt"," ."," \""," \u2014"," \u201e","","\u2191"," Wa","rum"," kam","st"," Du"," nicht"," fr\u00fc","her"," ?"," \""," \u2014"," \u201e","","\u2191"," W","eil"," ich"," auf"," me","inen","\u2191"," Scha","tten"," wart","ete"," ."," \""," \u2014"," \u201e",""," Im","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," amazing"," ad","ele",".\""," \"","Christina",":\""," \"","The"," song"," i"," gave"," daniel"," and"," kr","isten","\""," \"","Is"," \"","turning"," tables","\""," by"," ad","ele",".\""," \"","In"," the"," blind","s",","," for"," you",","," kr","isten",",\""," \""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ee"," ","\\xe2\\x99","\\xaa","\""," \"","\\xe2\\x99","\\xaa",""," why"," you"," using"," me"," like"," that","?\""," \"","\\xe2\\x99","\\xaa","\""," \"","\\xe2\\x99","\\xaa","","\u2191"," Leaves"," me"," searching"," for"," cl","ues"," ","\\xe2\\x99","\\xaa","\""," \"","\\xe2\\x99","\\xaa",""," and"," gives"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["s","il","!\""," \"","Mother","!\""," \"","Welcome","!\""," \"","So"," this"," is"," your"," new"," workplace","?\""," \"","Yes",".\""," \"","Mom",","," have"," a"," seat",".\""," \"","\u2191","Sit"," here",".\""," \"","Let","'s"," see",".\""," \"","Oh"," my"," good"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u7684","\u82f1","\u6587","\u53ef","\u4ee5","\\xe7\\xbf","\\xbb","\u8bd1","\u4e3a","\"","photo","\"","\uff0c","\u4e5f","\u53ef","\u4ee5","\\xe7\\xbf","\\xbb","\u8bd1","\u4e3a","\"","picture","\"","\u3002","\u23ce\u23ce","Human",":"," \"","\u8fd0","\u52a8","\u5458","\u7684","\\xe8\\xa3","\\xb8","\u4f53","\u5199","\u771f","\"","\\xe7\\xbf","\\xbb","\u8bd1"]},{"tokens_acts_list":[0.0,0.0,0.0,0.21,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.18,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.17,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["'"," -"," ","'","highest","'","\u23ce","*"," ","'","Hotel","'"," -"," ","'","building","'","\u23ce","*"," ","'","taken","'"," -"," ","'","brought"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["bu","enas"," tar","des","\""," \"","Perhaps"," you","'d"," like"," to"," start"," little"," \"","","hin"," fish",".\"","\""," \""," \"","\u2191","","Hin"," fish","?\"","\""," \""," Nice"," \"","","hin"," fish","\"","\""," \"","\u2191","Gin"," fiz","z",".\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["].","\u23ce\u23ce","[","Context","]:","\u23ce","['","thunder","st","orm","',"," ","'","rain","',"," ","'","ocean","',"," ","'","bab","bling"," brook","',"," ","'","fire","place","',"," ","'","airplane","',"," ","'","fan","',"," ","'","oscill"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["."," ","\u23ce","\"","\u21b9","\"","this"," is"," a"," thing"," that"," is"," direct"," and"," plain","."," ","\u23ce","\"","\u23ce","\"","this"," is"," a"," thing"," that"," is"," straight","forward"," and"," plain","."," ","\u23ce","\"","\u21b9","\"","this"," is"," a"," thing"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\","," \"","anticip","ates","\","," \"","plans","\","," \"","expects","\","," \"","may","\","," \"","will","\","," \"","would","\","," \"","int","ends","\","," \"","estimates","\""," and"," similar"," expressions",","," whether"," in"," the"," negative"," or"," aff","irm","ative","."," These"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\"","Our","?\""," \"","What","?\""," \"","\u2191","H","uh","?\""," \"","No",","," nothing","...\""," \"","\u2191","Ah","...\""," \"","=","\u2191","He","uk","sa","\u2191"," Chor","ong","=\""," \"","M","...\""," \"","It","'s"," Mother","?\""," \"","Mother","...\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["you"," to"," take"," out"," the"," Police"," Chief","?\""," \"","Hey"," brother",","," we","'re"," just"," hired"," guns",","," and","\""," \"","We"," have"," no"," way"," of"," knowing"," who"," really"," hired"," us","\""," \"","Then",","," watch"," your"," back","\""," \"","What"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["me",",\""," \"","But"," do"," you"," still"," not"," trust"," me","?\""," \"","What"," happened"," to"," you",","," v","oss","?\""," \"","Why"," the"," sudden"," change","?\""," \"","I","'d"," love"," to"," sit"," here"," and"," tell"," you","\""," \"","That"," I"," had"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Don","'t"," take"," \"","you"," should"," be"," focusing"," on","\u23ce"," H","CI"," and"," culture","\""," and"," confl","ate"," that"," with"," \"","you"," shouldn","'t"," study"," CS","\"."," This"," is"," a","\u23ce"," stronger"," case"," for"," the"," argument"," that"," social"," scientists"," should"," be"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\"","It","'s"," a"," mann","equ","in",".\""," \"","Why"," do"," you"," say"," things"," like"," that","?\""," \"","Oh","\""," \"","Oh",","," no",".\""," \"","So"," we","'re"," at"," her"," favorite"," restaurant",","," okay","?\""," \"","And"," I","'m"," spending"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\"","We","'ll"," come"," up","\""," \"","Don","'t","!\""," \"","Wait"," for"," me"," down","stairs","\""," \"","Fine","\""," \"","You"," don","'t"," int","end"," to"," let"," me"," down","?\""," \"","You"," shouldn","'t"," come",".","We"," were"," asking"," for"]}]}],"top_logits":["the","and","\"","their","however","three","further","various","adverse","fewer"],"bottom_logits":["\u0019","\u21b9","\u0016","\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce","\u0018","\u001b","\\xfa","\u0014","\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce","\u001c"]}