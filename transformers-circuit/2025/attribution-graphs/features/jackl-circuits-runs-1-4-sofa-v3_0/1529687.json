{"index":1529687,"examples_quantiles":[{"quantile_name":"Top Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ABC","'s"," and"," ","123","'s","\u23ce","2",".","J","ump","Start"," ","3","D"," Virtual"," World","\u23ce","3",".","Reader","\u2191"," Rabbit","\u2191"," Kinderg","arten","\u23ce","4",".","The"," Oregon"," Trail","\u23ce","5",".","I","\u2191"," Spy"," Fun"," House","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ig"," economy",":"," Sign"," up"," for"," g","ig"," economy"," platforms"," like"," NAME","_","1",",","\u2191"," Ly","ft",","," or"," Task","R","ab","bit"," to"," make"," money"," through"," driving",","," delivery",","," or"," running"," err","ands",".","\u23ce","5",".","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.84,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["air","bn","b",","," or"," for"," other"," major"," platforms",","," or"," even"," sell"," your"," time"," in"," certain"," services"," like","\u2191"," Task","rab","bit",",","\u2191"," Of","fe","rup",","," or","\u2191"," Door","man",".","\u23ce\u23ce","Human",":"," ","\u23ce","Thank"," you"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.83,0.62,0.48,0.52,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["e",".","ro"," l","il",".","lt"," ;"," ","1"," ","t","lie"," land"," they"," think"," they"," own"," than"," a"," jack"," j","j","ah","bit","."," git","l","C","K"," I"," V",".;"," ",".\\","M",">"," VI","'","i","S"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.73,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ka","\u2191"," Chic","ka","\u2191"," Boom","\u2191"," Boom"," by"," Bill"," Martin"," Jr","."," ","\u23ce","8","."," The"," Tale"," of"," Peter","\u2191"," Rabbit"," by","\u2191"," Beat","rix"," Potter"," ","\u23ce","9","."," I"," Love"," You"," Through"," and"," Through"," by","\u2191"," Ber"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.72,0.16,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["make"," money"," from"," roy","alties",".","\u23ce","9",".","\u2191"," Perform"," Online"," Tasks"," \u2013"," Find"," work"," on"," sites"," such"," as"," Task","R","ab","bit"," or","\u2191"," Fi","ver","r"," to"," complete"," projects"," and"," earn"," money",".","\u23ce","10","."," Create"," an"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Run","!\""," \"","Run","!\""," \"","Run","!\""," \"","You","'ll"," never"," get"," out",".\""," \"","Quick",","," like"," a"," jack","rab","bit",".\""," \"","\u2191","Nathan","iel",".\""," \"","They","'re"," white",","," heart","less",","," aren","'t"," they","?\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["gr","yph","on",","," a"," Mock","\u2191"," Turtle",","," and"," a","\u2191"," D","odo"," bird","."," She"," also"," meets"," the"," White","\u2191"," Rabbit",","," who"," becomes"," her"," guide"," and"," friend"," in","\u2191"," Wonder","land","."," Eventually",","," she"," comes"," to"," a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.69,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["j","imi","\u2191"," Hend","rix",","," \"","Purple","\u2191"," H","aze","\"","\u23ce","11","."," Jefferson","\u2191"," Airplane",","," \"","White","\u2191"," Rabbit","\"","\u23ce","12","."," Alice"," Cooper",","," \"","\u2191","Poison","\"","\u23ce","13",".","\u2191"," Mo","by","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.64,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["straight","-","up"," ","1","099"," ","income",".","\u23ce\u23ce","Most"," of"," the"," g","ig"," economy"," (","\u2191","Uber",","," Task","R","ab","bit",","," Post","M","ates",")"," is"," built"," around","\u23ce"," flexibility"," of"," hours",","," and"," freedom"," to"," not"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.83,0.62,0.48,0.52,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","ro"," l","il",".","lt"," ;"," ","1"," ","t","lie"," land"," they"," think"," they"," own"," than"," a"," jack"," j","j","ah","bit","."," git","l","C","K"," I"," V",".;"," ",".\\","M",">"," VI","'","i","S","A"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.57,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["  ","be","  ","an","  ","excerpt"," ","\u23ce","from","  ","the","  ","Tale","  ","of","  ","\u2191","","Bre","'","er","  ","\u2191","Rabbit","  ","and","  ","the","  ","\u2191","Tar"," ","\u23ce","Baby",".","  ","The","  ","CIA","  ","has"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08,0.05,0.0,0.17,0.56,0.18,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[":"," anyway",","," -","controls"," is"," published","\u23ce","<","\u2191","E","ick","me","yer",">","\u2191"," W","asc","aw","wy"," w","ab","bit",".","\u23ce"," ","*"," O","ven","W","er","ks"," gets"," to"," install"," firefox"," and"," a"," new"," kernel"," so"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.56,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","old"," man"," out"," in","\u2191"," H","ound","\u2191"," Vall","oy"," who"," has"," been","\u23ce"," adopted"," by"," a"," lot"," of"," Jack"," rabb","its","."," Their"," friend","--","lin","ens","\u23ce"," and"," good"," feeling"," nave"," become"," so"," obt","ru","\u23ce"," el","vo"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.56,0.52,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Cole"," ","30",","," b","-","passenger"," (","a"," pick","-","up",")",".."," ","450","\u23ce","\u2191","App","erson"," Jack","\u2191"," Rabbit",","," ","40","-","h","."," p","...."," ","600","\u23ce","\u2191","P","eer","lass"," ","50"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.52,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["year"," cycle","."," Each"," year"," is"," associated"," with"," one"," of"," twelve"," animals",":","\u2191"," Rat",",","\u2191"," Ox",","," Tiger",",","\u2191"," Rabbit",","," Dragon",","," Snake",","," Horse",",","\u2191"," Go","at",",","\u2191"," Monkey",",","\u2191"," Ro","oster",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.83,0.62,0.48,0.52,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["l","il",".","lt"," ;"," ","1"," ","t","lie"," land"," they"," think"," they"," own"," than"," a"," jack"," j","j","ah","bit","."," git","l","C","K"," I"," V",".;"," ",".\\","M",">"," VI","'","i","S","A","U","V"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.56,0.52,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","30",","," b","-","passenger"," (","a"," pick","-","up",")",".."," ","450","\u23ce","\u2191","App","erson"," Jack","\u2191"," Rabbit",","," ","40","-","h","."," p","...."," ","600","\u23ce","\u2191","P","eer","lass"," ","50"," ",""]}]},{"quantile_name":"Subsample Interval 0","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["ABC","'s"," and"," ","123","'s","\u23ce","2",".","J","ump","Start"," ","3","D"," Virtual"," World","\u23ce","3",".","Reader","\u2191"," Rabbit","\u2191"," Kinderg","arten","\u23ce","4",".","The"," Oregon"," Trail","\u23ce","5",".","I","\u2191"," Spy"," Fun"," House","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["ig"," economy",":"," Sign"," up"," for"," g","ig"," economy"," platforms"," like"," NAME","_","1",",","\u2191"," Ly","ft",","," or"," Task","R","ab","bit"," to"," make"," money"," through"," driving",","," delivery",","," or"," running"," err","ands",".","\u23ce","5",".","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.84,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["air","bn","b",","," or"," for"," other"," major"," platforms",","," or"," even"," sell"," your"," time"," in"," certain"," services"," like","\u2191"," Task","rab","bit",",","\u2191"," Of","fe","rup",","," or","\u2191"," Door","man",".","\u23ce\u23ce","Human",":"," ","\u23ce","Thank"," you"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.83,0.62,0.48,0.52,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["e",".","ro"," l","il",".","lt"," ;"," ","1"," ","t","lie"," land"," they"," think"," they"," own"," than"," a"," jack"," j","j","ah","bit","."," git","l","C","K"," I"," V",".;"," ",".\\","M",">"," VI","'","i","S"]}]},{"quantile_name":"Subsample Interval 1","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["ig"," economy",":"," Sign"," up"," for"," g","ig"," economy"," platforms"," like"," NAME","_","1",",","\u2191"," Ly","ft",","," or"," Task","R","ab","bit"," to"," make"," money"," through"," driving",","," delivery",","," or"," running"," err","ands",".","\u23ce","5",".","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.84,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["air","bn","b",","," or"," for"," other"," major"," platforms",","," or"," even"," sell"," your"," time"," in"," certain"," services"," like","\u2191"," Task","rab","bit",",","\u2191"," Of","fe","rup",","," or","\u2191"," Door","man",".","\u23ce\u23ce","Human",":"," ","\u23ce","Thank"," you"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.83,0.62,0.48,0.52,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["e",".","ro"," l","il",".","lt"," ;"," ","1"," ","t","lie"," land"," they"," think"," they"," own"," than"," a"," jack"," j","j","ah","bit","."," git","l","C","K"," I"," V",".;"," ",".\\","M",">"," VI","'","i","S"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.73,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["ka","\u2191"," Chic","ka","\u2191"," Boom","\u2191"," Boom"," by"," Bill"," Martin"," Jr","."," ","\u23ce","8","."," The"," Tale"," of"," Peter","\u2191"," Rabbit"," by","\u2191"," Beat","rix"," Potter"," ","\u23ce","9","."," I"," Love"," You"," Through"," and"," Through"," by","\u2191"," Ber"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.72,0.16,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["make"," money"," from"," roy","alties",".","\u23ce","9",".","\u2191"," Perform"," Online"," Tasks"," \u2013"," Find"," work"," on"," sites"," such"," as"," Task","R","ab","bit"," or","\u2191"," Fi","ver","r"," to"," complete"," projects"," and"," earn"," money",".","\u23ce","10","."," Create"," an"]}]},{"quantile_name":"Subsample Interval 2","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.72,0.16,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["make"," money"," from"," roy","alties",".","\u23ce","9",".","\u2191"," Perform"," Online"," Tasks"," \u2013"," Find"," work"," on"," sites"," such"," as"," Task","R","ab","bit"," or","\u2191"," Fi","ver","r"," to"," complete"," projects"," and"," earn"," money",".","\u23ce","10","."," Create"," an"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["Run","!\""," \"","Run","!\""," \"","Run","!\""," \"","You","'ll"," never"," get"," out",".\""," \"","Quick",","," like"," a"," jack","rab","bit",".\""," \"","\u2191","Nathan","iel",".\""," \"","They","'re"," white",","," heart","less",","," aren","'t"," they","?\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["gr","yph","on",","," a"," Mock","\u2191"," Turtle",","," and"," a","\u2191"," D","odo"," bird","."," She"," also"," meets"," the"," White","\u2191"," Rabbit",","," who"," becomes"," her"," guide"," and"," friend"," in","\u2191"," Wonder","land","."," Eventually",","," she"," comes"," to"," a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.69,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["j","imi","\u2191"," Hend","rix",","," \"","Purple","\u2191"," H","aze","\"","\u23ce","11","."," Jefferson","\u2191"," Airplane",","," \"","White","\u2191"," Rabbit","\"","\u23ce","12","."," Alice"," Cooper",","," \"","\u2191","Poison","\"","\u23ce","13",".","\u2191"," Mo","by","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.64,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["straight","-","up"," ","1","099"," ","income",".","\u23ce\u23ce","Most"," of"," the"," g","ig"," economy"," (","\u2191","Uber",","," Task","R","ab","bit",","," Post","M","ates",")"," is"," built"," around","\u23ce"," flexibility"," of"," hours",","," and"," freedom"," to"," not"]}]},{"quantile_name":"Subsample Interval 3","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.69,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["j","imi","\u2191"," Hend","rix",","," \"","Purple","\u2191"," H","aze","\"","\u23ce","11","."," Jefferson","\u2191"," Airplane",","," \"","White","\u2191"," Rabbit","\"","\u23ce","12","."," Alice"," Cooper",","," \"","\u2191","Poison","\"","\u23ce","13",".","\u2191"," Mo","by","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.64,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["straight","-","up"," ","1","099"," ","income",".","\u23ce\u23ce","Most"," of"," the"," g","ig"," economy"," (","\u2191","Uber",","," Task","R","ab","bit",","," Post","M","ates",")"," is"," built"," around","\u23ce"," flexibility"," of"," hours",","," and"," freedom"," to"," not"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.83,0.62,0.48,0.52,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":[".","ro"," l","il",".","lt"," ;"," ","1"," ","t","lie"," land"," they"," think"," they"," own"," than"," a"," jack"," j","j","ah","bit","."," git","l","C","K"," I"," V",".;"," ",".\\","M",">"," VI","'","i","S","A"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.57,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["  ","be","  ","an","  ","excerpt"," ","\u23ce","from","  ","the","  ","Tale","  ","of","  ","\u2191","","Bre","'","er","  ","\u2191","Rabbit","  ","and","  ","the","  ","\u2191","Tar"," ","\u23ce","Baby",".","  ","The","  ","CIA","  ","has"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08,0.05,0.0,0.17,0.56,0.18,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":[":"," anyway",","," -","controls"," is"," published","\u23ce","<","\u2191","E","ick","me","yer",">","\u2191"," W","asc","aw","wy"," w","ab","bit",".","\u23ce"," ","*"," O","ven","W","er","ks"," gets"," to"," install"," firefox"," and"," a"," new"," kernel"," so"]}]},{"quantile_name":"Subsample Interval 4","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.83,0.62,0.48,0.52,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["l","il",".","lt"," ;"," ","1"," ","t","lie"," land"," they"," think"," they"," own"," than"," a"," jack"," j","j","ah","bit","."," git","l","C","K"," I"," V",".;"," ",".\\","M",">"," VI","'","i","S","A","U","V"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.56,0.52,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":[" ","30",","," b","-","passenger"," (","a"," pick","-","up",")",".."," ","450","\u23ce","\u2191","App","erson"," Jack","\u2191"," Rabbit",","," ","40","-","h","."," p","...."," ","600","\u23ce","\u2191","P","eer","lass"," ","50"," ",""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.22,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["-","go","."," I"," haven","'t","\u23ce"," seen"," a"," full","\u21ea"," SA","AS"," mobile"," app"," yet"," but"," I"," think"," Task","R","ab","bit"," is"," a"," close"," example",".","\u23ce\u23ce"," ","_","6","\\","."," Facebook","_","\u23ce\u23ce","1",")","Facebook","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.49,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","Ri","sky"," Business"," (","1","983","),"," Three","\u2191"," Am","igos"," (","1","986","),"," Who","\u2191"," Fr","amed"," Roger","\u2191"," Rabbit"," (","1","988","),","\u2191"," Over","board"," (","1","987","),"," Dead"," Men"," Don","'t","\u2191"," Wear","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.49,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[":"," Black","\u2191"," Pan","ther",","," A","\u2191"," Wr","ink","le"," in"," Time",","," The"," Hurricane","\u2191"," He","ist",","," Peter","\u2191"," Rabbit",","," Love",","," Simon",","," Death","\u2191"," Wish",","," Red","\u2191"," Spar","row",","," and","\u2191"," Tomb","\u2191"]}]},{"quantile_name":"Subsample Interval 5","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.42,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["search"," running",".\""," \"","It"," has"," already"," begun",".\""," \"","What","?\""," \"","What"," the"," hell","?\""," \"\"","Follow"," the"," white"," rabbit","\"",".\""," \"","Who"," is"," it","?\""," \"","It","'s","\u2191"," Ch","oi",".\""," \"","You","'re"," two"," hours"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.42,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["with"," the"," problem",".\""," \"","Give"," her"," your"," lucky"," rabbit","'s"," foot",".\""," \"","Will"," this"," do",".\""," \"","Yes",".\""," \"","Now"," you"," ought"," to"," sit"," and"," be"," quiet",".\""," \"","I"," need"," to"," concentrate",","," and"," I"," can","'t"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Little"," Women","\u23ce","5","."," Ford"," v"," Ferrari","\u23ce","6",".","\u2191"," Kn","ives"," Out","\u23ce","7",".","\u2191"," J","ojo","\u2191"," Rabbit","\u23ce","8",".","\u2191"," Bomb","sh","ell","\u23ce","9",".","\u2191"," Mal","ef","ic","ent",":","\u2191"," Mist"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["oria","."," For"," Sale"," by","\u21ea"," MILLS"," &","\u21ea"," JOHNSON","."," The"," c","oy","ote"," is"," the"," enemy"," of"," the"," jack","rab","bit",","," and"," used"," to"," keep"," his"," numbers"," down","."," But"," some"," years"," ago"," a"," boun","ty"," was"," put"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.39,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce\u23ce","~~~","\u23ce","project","r","amo","\u23ce"," Google"," docs","?","\u23ce\u23ce","------","\u23ce","meg","amin","db","rian","\u23ce"," Follow"," the"," white"," rabbit","...","\u23ce\u23ce","------","\u23ce","un","ix","h","ero","\u23ce"," Better"," than","\u2191"," Sc","riv","ener","?","\u23ce\u23ce","------","\u23ce"]}]},{"quantile_name":"Subsample Interval 6","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.29,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["something"," that"," both","ers"," your"," room","mate"," as"," well",","," or"," just"," you","?","\u23ce\u23ce","Human",":"," ","\u23ce","It"," doesn","'t"," seem"," to"," b","other"," him"," as"," he"," does"," nothing"," about"," it","\u23ce\u23ce"," Assistant",":"," If"," the"," smell"," is"," both"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.31,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\"","One"," of"," the"," most"," brilliant"," and"," col","our","ful"," figures","."," ",".\""," ","\"."," ."," of"," the"," ","19","th"," Century",".\""," \"","\u2191","D","war","kan","ath","\u2191"," Tag","ore"," combined"," cult","ured"," sophist","ication","."," ",".\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["of"," Wh","ats","App","."," Some"," databases"," (","\u2191","R","iak",","," C","ouch","DB",")"," and"," message"," que","ues"," (","R","ab","bit","M","Q",").","\u23ce\u23ce","Language","-","wise",","," besides"," conc","urrency"," constru","cts",","," you"," get"," pattern"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","When"," I"," was"," a"," kid"," I"," was"," read"," Uncle","\u2191"," Re","mus"," stories",","," such"," as","\u2191"," Br","'","er","\u2191"," Rabbit",".","\u2191"," Nowadays"," those"," stories"," aren","'t"," considered"," appropriate"," for"," children"," anymore","."," Why"," is"," that","?","\u23ce\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.29,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["test"," fails"," on"," my"," branch"," with"," those"," adjust","ments","\u23ce"," ","*"," dav","ec","he","ney"," goes"," back"," to"," hunting"," w","ump","us","'","\u23ce","<","t","hum","per",">"," dav","ec","he","ney",":"," I","'m"," pretty"," confused"," as"," to"]}]},{"quantile_name":"Subsample Interval 7","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.19,0.31,0.18,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ix"," V",".."," tr",".","ak",":","ns",":"," n"," ton","!"," of"," l",".","15"," ","sj","u","ail",".","\u23ce","c","-","'",".-","v"," and"," ra","!"," M","'s"," killed"," during"," th","-"," !","a","\u23ce"," In"," -"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["."," ","'\""," \"","When","\u2191"," Rab","ind","ran","ath"," was"," born",","," the","\u2191"," Mahar","shi"," was"," ","45"," ","years"," old",".\""," \"","His"," wife","\u2191"," Sha","rad","am","oni"," was"," ","33",".\""," \"","\u2191","Rab","ind","ran"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.57,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["  ","an","  ","excerpt"," ","\u23ce","from","  ","the","  ","Tale","  ","of","  ","\u2191","","Bre","'","er","  ","\u2191","Rabbit","  ","and","  ","the","  ","\u2191","Tar"," ","\u23ce","Baby",".","  ","The","  ","CIA","  ","has","  ","discovered"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.19,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["  ","In"," African","-","American"," folklore",","," the"," character","\u2191"," Br","'","er","\u2191"," Rabbit",","," or"," B","'","","rer","\u2191"," Rabbit",","," is"," not"," stere","otyp","ed"," and"," is"," a"," smart"," t","rick","ster",".","\u23ce","<","|","stop"]},{"tokens_acts_list":[0.0,0.31,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","19","th"," Century",".\""," \"","\u2191","D","war","kan","ath","\u2191"," Tag","ore"," combined"," cult","ured"," sophist","ication","."," ",".\""," ","\"."," ."," with"," a"," larg","eness"," of"," heart"," and"," a"," rare"," degree"," of"," business"," ac","umen",".\""," \""]}]},{"quantile_name":"Subsample Interval 8","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","\u23ce","\u2191","H","are","\u2191"," St","ew"," \"\\","o","."," ","2","\u2014","After"," wi","ping"," the"," h","are"," or"," rabbit","\u23ce"," cut"," it"," in"," small"," pieces",","," lay"," in"," a"," deep"," dish"," and"," pour","\u23ce"," over"," it"," about"," a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["saw"," to"," his"," studies"," at"," home",".\""," \"","And"," it"," was"," all"," done"," by"," the"," clock",".\""," \"","When","\u2191"," R","abi"," was"," ","12","."," ",".\""," \"","\u2191","Deb","end","ran","ath"," went"," on"," a"," trip"," to"," North"," India"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["lined"," In"," s","atin",".","\u23ce","$","20"," ","values","."," Special"," Friday"," $","1"," ","7","P","J","\u23ce"," White"," Iceland"," Fox","\u2191"," M","uf","fs",","," lined"," In","\u23ce"," w",".","hl","te"," s","atin"," and"," r","tn","ished"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["increase"," in"," the"," oc","ular"," bio","av","ail","ability"," of"," pi","loc","arp","ine"," in"," both"," alb","ino"," and"," pig","mented"," rabb","its","."," In"," all"," three"," instances",","," the"," enhanced"," drug"," effectiveness"," was"," attributed"," to"," improved"," contact"," time"," of"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.18,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["J",".","  ","R",".,","  ","on","  ","con","jan","ct","ival","  ","transpl","ant","ation","  ","from","  ","the","  ","rabbit"," ","\u23ce","\u2191","Wo","ands",",","  ","Dr",".","  ","Watson","  ","on","  ","chlor","al","  ","hyd","rate"]}]},{"quantile_name":"Bottom Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["rabbit"," foot","!\""," \"","That","'s"," harsh"," sir","!\""," \"","no"," it","'s"," not","!\""," \"","You","'re"," not"," happy"," ","?\""," \"","you"," can"," leave","\""," \"","We"," were"," right"," to"," get"," the"," fuck"," out","\""," \"\"","I"," don","'t"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["AI","I","ahu","\u2191"," Ak","bar",".\""," \"","\u2191","S","ami"," AI","I","ahu","\u2191"," I","iman"," ham","id","ah",".\""," \"","\u2191","Rabb","ana"," wa"," I","a","ka","I"," ha","md",".\""," \"","AI","I","ahu","\u2191"," Ak","bar",".\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["usion"," in"," the"," small"," blood"," vessels"," in"," the"," web"," of"," the"," f","rog","'s"," foot"," and"," in"," the"," ear"," of"," the"," mouse","."," During"," the"," current"," year"," we"," have"," confirmed"," that"," the"," volume"," of"," human"," P","RP"," is"," increased"," by"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.16,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["in"," the"," genome"," of"," many"," mam","mal","ian"," species"," including"," rabb","its",".","\u23ce","4","."," \"","rb","2","\":"," This"," gene"," is"," used"," to"," determine"," the"," color"," of"," rabb","its",","," and"," is"," encoded"," in"," the"," genome"," of"," many"," mam"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","That"," there"," are"," going"," to"," be"," a"," home"," and"," t","\u23ce"," pair"," of"," loving"," arms"," to"," welcome"," every"," *","\u23ce","me"," of"," the"," Easter"," b","unn","ies"," one"," feels"," ","eer","-"," s","\u23ce"," ain"," when"," b","ehol","ding"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["oo",".."," he"," is"," such"," a"," cute"," bad","ger","!!","\u23ce","<","sab","m","oc",">"," looks"," like"," a"," bun","ny"," with"," cl","aws","\u23ce","<","\u2191","Amar","an","th",">"," y","ea"," for"," making"," none"," of"," my"," me","nus"," show"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\"","You"," take"," the"," red"," pill","..."," you"," stay"," in","\u2191"," Wonder","land","..."," and"," I"," show"," you"," how"," deep"," the"," rabbit"," hole"," goes",".\""," \"","Remember","..."," all"," I","'m"," offering"," is"," the"," truth",".\""," \"","Nothing"," more",".\""," \""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","\u2191"," N","ook",":"," a"," small",","," co","zy",","," and"," sec","lu","ded"," spot",".","\u23ce","2",".","\u2191"," P","eck",":"," a"," soft",","," quick"," tap"," or"," hit",".","\u23ce","3",".","\u2191"," P","rance",":"," to"," move"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["qu","i","escent"," to"," a"," growing"," state","."," In"," complement","ary"," studies",","," the"," metabolism"," of"," T","PI"," RNA"," in"," r","esting"," and"," prolif","e","rating"," H","eL","a"," cells"," will"," be"," analyzed"," to"," determine"," if"," pos","tt","ran","sc","ript"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.56,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["aa","\u23ce"," old"," man"," out"," in","\u2191"," H","ound","\u2191"," Vall","oy"," who"," has"," been","\u23ce"," adopted"," by"," a"," lot"," of"," Jack"," rabb","its","."," Their"," friend","--","lin","ens","\u23ce"," and"," good"," feeling"," nave"," become"," so"," obt","ru","\u23ce"," el"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["isch","emic"," stun","ned"," my","oc","ard","ium","."," The"," approach"," that"," will"," be"," employed"," combines"," an"," in"," v","ivo"," rep","erf","usion"," model"," of"," stun","ned"," my","oc","ard","ium"," with"," physi","ological"," and"," biochem","ical"," measurements"," on"," an"," in"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["pass","ione"," per"," la"," loro"," conserv","azione",".","\u23ce\u23ce","Nel"," ter","zo"," capit","olo",","," \"","La"," cac","cia"," al"," con","ig","lio","\","," l","'","aut","ore"," desc","rive"," le"," sue"," es","peri","enze"," cac","ci","are"," con"," il"," frat"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["be"," determined"," by"," immun","oc","yt","ochem","istry"," and"," imm","uno","-","bl","ot","ting"," of"," lys","ates"," of"," rat"," and"," rabbit"," C","CD"," cells","."," b",")"," To"," Test"," the"," hypothesis"," that"," nit","ric"," oxide"," (","NO",")"," and","/"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["who"," has"," used"," them"," In"," i"," x","per","lin","ents"," with"," rats","."," To"," disc"," nor"," If"," the"," dog"," w","is"," mad","."," Mrs"," full","v","\u2191"," Btn","r","led"," for"," this"," cl","ti"," fur"," treatment",","," but"," stopped"," ","nt"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["."," ","8"," ","&"," ","16"," ","weeks","),"," ","2",")"," a"," similar"," experimental"," model"," in"," rabbit"," and"," ","3",")"," cult","ured"," n","eon","atal"," rat"," ven","tr","icular"," my","oc","ytes","."," We"," will"," measure"," a",")"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["in"," our"," cult","ured"," East","\u23ce"," you"," would"," find"," yourself"," in"," the"," soup","\u23ce"," qu","icker"," than"," you"," could"," say"," Jack"," Rob","\u23ce"," ","inson","."," Time",".","\u23ce","\u2191","Glad","stone"," on"," Washington",".","\u23ce","When"," I"," first"," read"," in"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.35,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","Fo","jen"," ","75",";","\u2191"," E","ic","hh","\u00f6","rn","chen"," ","25","\u23ce","\u2014","0",";","\u2191"," Jac","tr","abb","its"," ","2",".","00"," ","\u2014","2",".","50",".","\u23ce","n"," m"," le","ua","\u2191"," Nar"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["and"," making"," sure"," everyone"," was"," okay"," when"," I"," found"," that"," they"," had"," torn"," open"," the"," side"," of"," one"," of"," my"," co","ops"," and"," killed"," my"," ","24"," ","exotic"," birds","."," I"," bought"," them"," as"," ch","icks"," in"," May"," (","they"]}]}],"top_logits":["rab","rabbit","rabbi","Rabbi","ra","R","rb"],"bottom_logits":["bergen","zor","boc","atas","verver","lima","nederlandse","le","Bergen","inad"]}