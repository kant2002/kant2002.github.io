{"index":5210358,"examples_quantiles":[{"quantile_name":"Top Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.07,0.0,0.0,0.0,0.0,0.0,0.55,0.1,1.0,0.0,0.42,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["refers"," to"," the"," square"," root"," of"," ","69","."," While"," the"," actual"," square"," root"," of"," ","69"," ","is"," approximately"," ","8",".","3","066",","," NAME","_","1"," ","says",","," \"","I"," was"," trying"," to"," solve"," the"," square"," root"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.78,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["personal"," data"," of"," the"," persons"," concerned",".","<EOT>","\u23ce\u23ce","Human",":"," What"," is"," the"," square"," root"," of"," ","69"," ","according"," to"," NAME","_","1","?","\u23ce\u23ce","Assistant",":"," I"," apolog","ize",","," but"," I"," cannot"," find"," a"," specific"," reference"," to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.76,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["the"," data"," in"," your"," spread","sheet",".","<EOT>","\u23ce\u23ce","Human",":"," What"," is"," the"," square"," root"," of"," ","69"," ","according"," to"," NAME","_","1","?","\u23ce\u23ce","Assistant",":"," I"," apolog","ize",","," but"," I"," cannot"," find"," any"," reference"," to"," a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["What"," is"," the"," square"," root"," of"," ","81","?","\u23ce\u23ce","Assistant",":"," The"," square"," root"," of"," ","81"," ","is"," ","9",".","\u23ce\u23ce","This"," is"," because"," ","9"," ","\u00d7"," ","9"," ","="," ","81",".","\u23ce\u23ce","Both"," positive"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.26,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.57,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Find"," the"," square"," root"," of"," ","44"," ","\u23ce\u23ce","Assistant",":"," ","\u23ce","Square"," root"," of"," ","44"," ","is"," ","6",".","633","."," ","\u23ce\u23ce","Human",":"," ","\u23ce","Actually",","," I"," think"," the"," problem"," was"," more"," complicated"," than"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.55,0.24,0.0,0.41,0.0,0.0,0.35,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["uncertainty"," in"," the"," measurements"," is"," the"," square","-","root"," of"," the"," measurement",","," or",":"," ","4",".","9",","," ","7",","," and"," ","7",".","3"," ","counts",","," respectively"," for"," Source","-","1",","," Source","-","2",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.07,0.0,0.0,0.0,0.0,0.0,0.55,0.1,1.0,0.0,0.42,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["1"," ","refers"," to"," the"," square"," root"," of"," ","69","."," While"," the"," actual"," square"," root"," of"," ","69"," ","is"," approximately"," ","8",".","3","066",","," NAME","_","1"," ","says",","," \"","I"," was"," trying"," to"," solve"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.53,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," Empire"," State"," Building"," in"," New"," York"," City"," and"," is"," the"," distance"," that"," light"," travels",".","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","Where"," can"," I"," find"," the"," best"," deals"," for"," flights"," to"," Europe","."," ","\u23ce\u23ce","Assistant",":"," "]},{"tokens_acts_list":[0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.49,0.27,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["))"," /"," ","2","\u23ce\u23ce","x"," ="," (","2"," ","","\u00b1"," \u221a","51",")","\u23ce\u23ce","x"," ="," (","2"," ","+"," \u221a","51",")"," or"," (","2"," ","-"," \u221a","51",")","\u23ce\u23ce","Therefore",","," the"," solutions"," to"," the"," equation"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.47,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.12,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u221a","51",")","\u23ce\u23ce","Therefore",","," the"," solutions"," to"," the"," equation"," x","^","2"," ","-"," ","66"," ","="," ","2","x"," are"," x"," ="," ","2"," ","+"," \u221a","51"," ","and"," x"," ="," ","2"," ","-"," \u221a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.46,0.0,0.35,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","from"," both"," sides",":","\u23ce\u23ce","64"," ","="," L","\u00b2","\u23ce\u23ce","Taking"," the"," square"," root"," of"," both"," sides",":","\u23ce\u23ce","L"," ="," ","8","\u23ce\u23ce","Therefore",","," the"," length"," of"," the"," rectangle"," is"," ","8"," ","units",".","\u23ce\u23ce","Human"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.43,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u00b1"," \u221a","(","4"," ","-"," ","4"," ","\\","*"," ","1"," ","\\","*"," -","66","))"," /"," ","2"," ","\\","*"," ","1","\u23ce\u23ce","x"," ="," (","2"," ","","\u00b1"," \u221a","(","252","))"," /"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.07,0.0,0.0,0.0,0.0,0.0,0.55,0.1,1.0,0.0,0.42,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," square"," root"," of"," ","69","."," While"," the"," actual"," square"," root"," of"," ","69"," ","is"," approximately"," ","8",".","3","066",","," NAME","_","1"," ","says",","," \"","I"," was"," trying"," to"," solve"," the"," square"," root"," of"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.55,0.24,0.0,0.41,0.0,0.0,0.35,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["measurements"," is"," the"," square","-","root"," of"," the"," measurement",","," or",":"," ","4",".","9",","," ","7",","," and"," ","7",".","3"," ","counts",","," respectively"," for"," Source","-","1",","," Source","-","2",","," and"," Source","-"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.38,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.64,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["language"," model"," trained"," by"," researchers"," at"," UC"," Berkeley",".","\u23ce\u23ce","Human",":"," What","'s"," the"," square"," root"," of"," ","49","?","\u23ce\u23ce","Assistant",":"," The"," square"," root"," of"," ","49"," ","is"," ","7","."," This"," is"," because"," ","7"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.16,0.0,0.34,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["/","-"," sqrt","(","56",")",")/","2",","," which"," gives"," the"," solutions"," x"," ="," (","4"," ","+","/","-"," sqrt","(","56",")",")/","2",".","\u23ce\u23ce","Human",":"," what"," are"," the"," solutions"," of"," that"," function","\u23ce\u23ce"," Assistant",":"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.55,0.24,0.0,0.41,0.0,0.0,0.35,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["square","-","root"," of"," the"," measurement",","," or",":"," ","4",".","9",","," ","7",","," and"," ","7",".","3"," ","counts",","," respectively"," for"," Source","-","1",","," Source","-","2",","," and"," Source","-","3","."," These"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.35,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["inary"," unit",","," which"," is"," defined"," as"," the"," square"," root"," of"," -","1","."," This"," expression"," represents"," the"," complex"," number"," ","69"," ","+"," i"," \\","*"," ","69",","," which"," is"," often"," used"," in"," mathematics"," and"," science"," to"," represent"," complex"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.46,0.0,0.35,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["both"," sides",":","\u23ce\u23ce","64"," ","="," L","\u00b2","\u23ce\u23ce","Taking"," the"," square"," root"," of"," both"," sides",":","\u23ce\u23ce","L"," ="," ","8","\u23ce\u23ce","Therefore",","," the"," length"," of"," the"," rectangle"," is"," ","8"," ","units",".","\u23ce\u23ce","Human",":"," "]}]},{"quantile_name":"Subsample Interval 0","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.07,0.0,0.0,0.0,0.0,0.0,0.55,0.1,1.0,0.0,0.42,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["refers"," to"," the"," square"," root"," of"," ","69","."," While"," the"," actual"," square"," root"," of"," ","69"," ","is"," approximately"," ","8",".","3","066",","," NAME","_","1"," ","says",","," \"","I"," was"," trying"," to"," solve"," the"," square"," root"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.78,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["personal"," data"," of"," the"," persons"," concerned",".","<EOT>","\u23ce\u23ce","Human",":"," What"," is"," the"," square"," root"," of"," ","69"," ","according"," to"," NAME","_","1","?","\u23ce\u23ce","Assistant",":"," I"," apolog","ize",","," but"," I"," cannot"," find"," a"," specific"," reference"," to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.76,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["the"," data"," in"," your"," spread","sheet",".","<EOT>","\u23ce\u23ce","Human",":"," What"," is"," the"," square"," root"," of"," ","69"," ","according"," to"," NAME","_","1","?","\u23ce\u23ce","Assistant",":"," I"," apolog","ize",","," but"," I"," cannot"," find"," any"," reference"," to"," a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["What"," is"," the"," square"," root"," of"," ","81","?","\u23ce\u23ce","Assistant",":"," The"," square"," root"," of"," ","81"," ","is"," ","9",".","\u23ce\u23ce","This"," is"," because"," ","9"," ","\u00d7"," ","9"," ","="," ","81",".","\u23ce\u23ce","Both"," positive"]}]},{"quantile_name":"Subsample Interval 1","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.07,0.0,0.0,0.0,0.0,0.0,0.55,0.1,1.0,0.0,0.42,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["refers"," to"," the"," square"," root"," of"," ","69","."," While"," the"," actual"," square"," root"," of"," ","69"," ","is"," approximately"," ","8",".","3","066",","," NAME","_","1"," ","says",","," \"","I"," was"," trying"," to"," solve"," the"," square"," root"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.78,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["personal"," data"," of"," the"," persons"," concerned",".","<EOT>","\u23ce\u23ce","Human",":"," What"," is"," the"," square"," root"," of"," ","69"," ","according"," to"," NAME","_","1","?","\u23ce\u23ce","Assistant",":"," I"," apolog","ize",","," but"," I"," cannot"," find"," a"," specific"," reference"," to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.76,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["the"," data"," in"," your"," spread","sheet",".","<EOT>","\u23ce\u23ce","Human",":"," What"," is"," the"," square"," root"," of"," ","69"," ","according"," to"," NAME","_","1","?","\u23ce\u23ce","Assistant",":"," I"," apolog","ize",","," but"," I"," cannot"," find"," any"," reference"," to"," a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["What"," is"," the"," square"," root"," of"," ","81","?","\u23ce\u23ce","Assistant",":"," The"," square"," root"," of"," ","81"," ","is"," ","9",".","\u23ce\u23ce","This"," is"," because"," ","9"," ","\u00d7"," ","9"," ","="," ","81",".","\u23ce\u23ce","Both"," positive"]}]},{"quantile_name":"Subsample Interval 2","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.78,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["personal"," data"," of"," the"," persons"," concerned",".","<EOT>","\u23ce\u23ce","Human",":"," What"," is"," the"," square"," root"," of"," ","69"," ","according"," to"," NAME","_","1","?","\u23ce\u23ce","Assistant",":"," I"," apolog","ize",","," but"," I"," cannot"," find"," a"," specific"," reference"," to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.76,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["the"," data"," in"," your"," spread","sheet",".","<EOT>","\u23ce\u23ce","Human",":"," What"," is"," the"," square"," root"," of"," ","69"," ","according"," to"," NAME","_","1","?","\u23ce\u23ce","Assistant",":"," I"," apolog","ize",","," but"," I"," cannot"," find"," any"," reference"," to"," a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["What"," is"," the"," square"," root"," of"," ","81","?","\u23ce\u23ce","Assistant",":"," The"," square"," root"," of"," ","81"," ","is"," ","9",".","\u23ce\u23ce","This"," is"," because"," ","9"," ","\u00d7"," ","9"," ","="," ","81",".","\u23ce\u23ce","Both"," positive"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.26,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.57,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["Find"," the"," square"," root"," of"," ","44"," ","\u23ce\u23ce","Assistant",":"," ","\u23ce","Square"," root"," of"," ","44"," ","is"," ","6",".","633","."," ","\u23ce\u23ce","Human",":"," ","\u23ce","Actually",","," I"," think"," the"," problem"," was"," more"," complicated"," than"]}]},{"quantile_name":"Subsample Interval 3","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.76,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["the"," data"," in"," your"," spread","sheet",".","<EOT>","\u23ce\u23ce","Human",":"," What"," is"," the"," square"," root"," of"," ","69"," ","according"," to"," NAME","_","1","?","\u23ce\u23ce","Assistant",":"," I"," apolog","ize",","," but"," I"," cannot"," find"," any"," reference"," to"," a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["What"," is"," the"," square"," root"," of"," ","81","?","\u23ce\u23ce","Assistant",":"," The"," square"," root"," of"," ","81"," ","is"," ","9",".","\u23ce\u23ce","This"," is"," because"," ","9"," ","\u00d7"," ","9"," ","="," ","81",".","\u23ce\u23ce","Both"," positive"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.26,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.57,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["Find"," the"," square"," root"," of"," ","44"," ","\u23ce\u23ce","Assistant",":"," ","\u23ce","Square"," root"," of"," ","44"," ","is"," ","6",".","633","."," ","\u23ce\u23ce","Human",":"," ","\u23ce","Actually",","," I"," think"," the"," problem"," was"," more"," complicated"," than"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.55,0.24,0.0,0.41,0.0,0.0,0.35,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["uncertainty"," in"," the"," measurements"," is"," the"," square","-","root"," of"," the"," measurement",","," or",":"," ","4",".","9",","," ","7",","," and"," ","7",".","3"," ","counts",","," respectively"," for"," Source","-","1",","," Source","-","2",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.07,0.0,0.0,0.0,0.0,0.0,0.55,0.1,1.0,0.0,0.42,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["1"," ","refers"," to"," the"," square"," root"," of"," ","69","."," While"," the"," actual"," square"," root"," of"," ","69"," ","is"," approximately"," ","8",".","3","066",","," NAME","_","1"," ","says",","," \"","I"," was"," trying"," to"," solve"," the"]}]},{"quantile_name":"Subsample Interval 4","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.07,0.0,0.0,0.0,0.0,0.0,0.55,0.1,1.0,0.0,0.42,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["1"," ","refers"," to"," the"," square"," root"," of"," ","69","."," While"," the"," actual"," square"," root"," of"," ","69"," ","is"," approximately"," ","8",".","3","066",","," NAME","_","1"," ","says",","," \"","I"," was"," trying"," to"," solve"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.53,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["the"," Empire"," State"," Building"," in"," New"," York"," City"," and"," is"," the"," distance"," that"," light"," travels",".","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","Where"," can"," I"," find"," the"," best"," deals"," for"," flights"," to"," Europe","."," ","\u23ce\u23ce","Assistant",":"," "]},{"tokens_acts_list":[0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.49,0.27,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["))"," /"," ","2","\u23ce\u23ce","x"," ="," (","2"," ","","\u00b1"," \u221a","51",")","\u23ce\u23ce","x"," ="," (","2"," ","+"," \u221a","51",")"," or"," (","2"," ","-"," \u221a","51",")","\u23ce\u23ce","Therefore",","," the"," solutions"," to"," the"," equation"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.47,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.12,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["\u221a","51",")","\u23ce\u23ce","Therefore",","," the"," solutions"," to"," the"," equation"," x","^","2"," ","-"," ","66"," ","="," ","2","x"," are"," x"," ="," ","2"," ","+"," \u221a","51"," ","and"," x"," ="," ","2"," ","-"," \u221a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.46,0.0,0.35,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":[" ","from"," both"," sides",":","\u23ce\u23ce","64"," ","="," L","\u00b2","\u23ce\u23ce","Taking"," the"," square"," root"," of"," both"," sides",":","\u23ce\u23ce","L"," ="," ","8","\u23ce\u23ce","Therefore",","," the"," length"," of"," the"," rectangle"," is"," ","8"," ","units",".","\u23ce\u23ce","Human"]}]},{"quantile_name":"Subsample Interval 5","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.07,0.0,0.0,0.0,0.0,0.0,0.55,0.1,1.0,0.0,0.42,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["the"," square"," root"," of"," ","69","."," While"," the"," actual"," square"," root"," of"," ","69"," ","is"," approximately"," ","8",".","3","066",","," NAME","_","1"," ","says",","," \"","I"," was"," trying"," to"," solve"," the"," square"," root"," of"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.55,0.24,0.0,0.41,0.0,0.0,0.35,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["measurements"," is"," the"," square","-","root"," of"," the"," measurement",","," or",":"," ","4",".","9",","," ","7",","," and"," ","7",".","3"," ","counts",","," respectively"," for"," Source","-","1",","," Source","-","2",","," and"," Source","-"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.38,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.64,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["language"," model"," trained"," by"," researchers"," at"," UC"," Berkeley",".","\u23ce\u23ce","Human",":"," What","'s"," the"," square"," root"," of"," ","49","?","\u23ce\u23ce","Assistant",":"," The"," square"," root"," of"," ","49"," ","is"," ","7","."," This"," is"," because"," ","7"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.16,0.0,0.34,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["/","-"," sqrt","(","56",")",")/","2",","," which"," gives"," the"," solutions"," x"," ="," (","4"," ","+","/","-"," sqrt","(","56",")",")/","2",".","\u23ce\u23ce","Human",":"," what"," are"," the"," solutions"," of"," that"," function","\u23ce\u23ce"," Assistant",":"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.55,0.24,0.0,0.41,0.0,0.0,0.35,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["square","-","root"," of"," the"," measurement",","," or",":"," ","4",".","9",","," ","7",","," and"," ","7",".","3"," ","counts",","," respectively"," for"," Source","-","1",","," Source","-","2",","," and"," Source","-","3","."," These"]}]},{"quantile_name":"Subsample Interval 6","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.46,0.0,0.35,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["both"," sides",":","\u23ce\u23ce","64"," ","="," L","\u00b2","\u23ce\u23ce","Taking"," the"," square"," root"," of"," both"," sides",":","\u23ce\u23ce","L"," ="," ","8","\u23ce\u23ce","Therefore",","," the"," length"," of"," the"," rectangle"," is"," ","8"," ","units",".","\u23ce\u23ce","Human",":"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.34,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["square"," root"," of"," ","69"," ","last"," night",","," and"," I"," think"," I"," just"," figured"," it"," out",":"," it","'s"," ","8"," ","something",","," right","?\""," So",","," according"," to"," NAME","_","1",","," the"," square"," root"," of"," ","69"]},{"tokens_acts_list":[0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.31,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["square"," root"," of"," ","69"," ","with"," a"," negative"," imag","inary"," part","."," This"," can"," be"," expressed"," mathemat","ically"," as",":","\u23ce\u23ce","\u221a","69"," ","+"," i"," \u221a","69","\u23ce\u23ce","where"," i"," is"," the"," imag","inary"," unit",","," which"," is"," defined"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.31,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.65,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":[" ","is"," in"," the"," list",".","\u23ce","```","<EOT>","\u23ce\u23ce","Human",":"," What"," is"," the"," square"," root"," of"," ","81","?","\u23ce\u23ce","Assistant",":"," The"," square"," root"," of"," ","81"," ","is"," ","9",".","\u23ce\u23ce","This"," is"," because"," ","9"]},{"tokens_acts_list":[0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.49,0.27,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["/"," ","2","\u23ce\u23ce","x"," ="," (","2"," ","","\u00b1"," \u221a","51",")","\u23ce\u23ce","x"," ="," (","2"," ","+"," \u221a","51",")"," or"," (","2"," ","-"," \u221a","51",")","\u23ce\u23ce","Therefore",","," the"," solutions"," to"," the"," equation"," x"]}]},{"quantile_name":"Subsample Interval 7","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.22,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["\u23ce","That"," doesn","'t"," seem"," to"," make"," sense"," -"," isn","'t"," the"," square"," root"," of"," ","22"," ","closer"," to"," ","4",".","2","?","\u23ce\u23ce","Assistant",":"," Let"," me"," walk"," you"," through"," this",":","\u23ce\u23ce","1",")"," The"," square"," root"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["^","6"," ","def","\u23ce"," qu","els"," f","aut"," extra","ire"," la"," rac","ine"," qu","^","r","re","ei","ont"," ^","pour"," ","\u23ce","rac","ine"," qui"," c","ft"," le"," v","ray"," mo","yen"," enc","re"," }"," &"," ","11"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.47,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.12,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," solutions"," to"," the"," equation"," x","^","2"," ","-"," ","66"," ","="," ","2","x"," are"," x"," ="," ","2"," ","+"," \u221a","51"," ","and"," x"," ="," ","2"," ","-"," \u221a","51",".","<EOT>","\u23ce\u23ce","Human",":"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.17,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["formula"," to"," solve"," for"," x",":","\u23ce\u23ce","x"," ="," (-","b"," ","\u00b1"," \u221a","(","b","^","2"," ","-"," ","4","ac","))"," /"," ","2","a","\u23ce\u23ce"," In"," this"," case",","," a"," ="," ","1",","," b"," ="," -"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.15,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[":","\u23ce\u23ce","x","^","2"," ","-"," ","66"," ","="," ","2","x","\u23ce"," x","^","2"," ","-"," ","2","x"," -"," ","66"," ","="," ","0","\u23ce\u23ce","Next",","," we"," can"," use"," the"," quad","ratic"," formula"," to"]}]},{"quantile_name":"Subsample Interval 8","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09,0.11,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","     ","\u2191","Str","ype",",","  ","ii",".","  ","621","."," ","\u23ce","VO","L",".","  ","II",".","  ","F"," ","\u23ce\u23ce\u23ce","66","  ","\u21ea","SCOTLAND",".","  ","[","158","!","."," ","\u23ce\u23ce","only","  ","barrier","  ","which"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.26,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.57,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["square"," root"," of"," ","44"," ","\u23ce\u23ce","Assistant",":"," ","\u23ce","Square"," root"," of"," ","44"," ","is"," ","6",".","633","."," ","\u23ce\u23ce","Human",":"," ","\u23ce","Actually",","," I"," think"," the"," problem"," was"," more"," complicated"," than"," just"," finding"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.1,0.08,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["qu","'","il","  ","","eft","  ","p","off","ible","  ","\u00e0","  ","un"," ","\u23ce\u23ce","\u2191","Tome","  ","III",",","  ","i"," ","\u23ce\u23ce\u23ce","\u2191","Flex","ion","  ","des"," ","\u23ce","bar","res","."," ","\u23ce\u23ce\u23ce","66","       ","\u21ea","ASTRONOM"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["(","multiply","\u23ce"," tone",")"," (","9"," ","tone",")"," (","equals"," tone",")"," and"," then"," the"," calculator"," sounds"," out"," (","eight"," tone",")","\u23ce","(","one"," tone",").","\u23ce\u23ce","Eventually"," people"," started"," using"," them"," as"," toys"," or"," musical"," instruments",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.11,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["these","  ","soldiers",",","  ","as","  ","draw","u","  ","by","  ","another"," ","\u23ce\u23ce","VO","L",".","  ","I",",","  ","F"," ","\u23ce\u23ce\u23ce","I"," ","\u23ce\u23ce\u23ce","Q","O","  ","T","U","H","  ","","hl","\\xc2","\\xa5","B","  "]}]},{"quantile_name":"Bottom Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","\u23ce","Original","  ","in","  ","my","  ","possession","."," \u2014"," T","."," ","\u23ce\u23ce","VO","L",".","   ","V",".","  ","\u2191","Digit","ized","  ","by","  ","Ob","O","g","k"," ","\u23ce\u23ce\u23ce","34","  ","\u21ea","JAMES","  ","I","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["fers"," the"," same"," b","less","ings"," on"," the"," ","\u23ce","Germans"," and"," the"," French","."," Without"," education"," ","oy"," ","\u23ce\u23ce","F"," ","\u23ce\u23ce\u23ce\u23ce","66"," ","THE","\u21ea"," RESID","UUM","."," ","\u23ce\u23ce","religion"," man"," is"," inc","ap","able"," of"," jud"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["We"," want"," information","...\""," \"","Information","...\""," \"","Information",".\""," \"","You"," won","'t"," get"," it",".\""," \"","By"," hook"," or"," by"," cr","ook","...\""," \"","...","we"," will",".\""," \"","Who"," are"," you","?\""," \"","The"," new"," Number"," Two",".\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u00b0","9"," ","|"," \u20ac","0"," ","1"," ","|"," ","27","\u00b0","38"," ","|"," ","15"," ","|"," ","32",":","2"," ","\u23ce","December"," .","........","}"," ","42","\u00b0","8"," ","|"," ","47",":","1"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["on"," ","\u23ce","the","  ","first","  ","fav","ourable","  ","opportunity","."," ","\u23ce\u23ce","VO","L",".","   ","II",".","  ","H"," ","\u23ce\u23ce\u23ce","50","  ","\u21ea","HISTORIC","  ","\u21ea","AN","ECD","OTES","  ","OF","  ","THE","  ","\u21ea","LEGISLATIVE","  "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","","\u00b1"," sqrt","(","64"," ","-"," ","48","),"," which"," equals"," x"," ="," ","8"," ","","\u00b1"," ","2","sqrt","(","4",")."," Therefore",","," the"," solutions"," to"," the"," equation"," are"," x"," ="," ","8"," ","+"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","2",")"," ","30","\u00b0"," |"," ","23"," ","|"," ","23"," ","\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce","\u21ea","REPORT","\u2014","1","851","."," ","\u23ce\u23ce\u23ce","TABLE"," IT","I","."," ","\u23ce\u23ce\u23ce","\u2191","Hy","gr","omet","rical"," state"," of"," the","\u2191"," Atmosphere","."," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["selected","  ","for","  ","example",".","    ","See","  ","jo","L","  ","vi","  ","p",".","  ","878","."," ","\u23ce\u23ce","*","  ","So","  ","in","  ","printed","  ","o","op","j","."," ","\u23ce\u23ce\u23ce","\u2191","Digit","ized","  ","by","V"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","\u23ce","already","  ","considered",".","  ","\u2191","O","ste","ometry","  ","itself","  ","is","  ","only","  ","a"," part","  ","of","  ","what"," ","\u23ce","should","  ","be","  ","called","  ","zo","ometry",",","  ","which","  ","has","  ","to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["dru","gg","ist"," has","\u23ce"," sold","\u2191"," Card","ui"," for"," years","."," He"," knows"," what","\u23ce"," it"," will"," do","."," Ask"," him","."," He"," will"," re","com","\u23ce"," m","end"," it","."," Begin"," taking","\u2191"," Card","ui"," today",".","\u23ce","Write"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["program",","," and"," ","25",".","5"," ","percent"," receive","\u2191"," P","ell"," grants","."," Dr","."," Janet","\u2191"," Gor","man"," Murphy",","," president"," of","\u2191"," Lj","m","don"," State"," College"," in"," Vermont",","," ","tes","-"," t","ified"," before"," a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.04,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","     ","Here",",","  ","it","  ","cannot","  ","be","  ","doub","ted",","," ","\u23ce\u23ce\u23ce","Vol",".","  ","IV",".-","~","No",".","  ","2",".","  ","5"," ","\u23ce\u23ce\u23ce","u","ig","ii","ized","  ","by"," ","\u23ce\u23ce\u23ce","Google"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," ","20",".","\u2191"," Let","tera"," della","\u2191"," Sign","oria"," di","\u2191"," Fir","enze"," al","\u2191"," Comune"," di"," ","\u23ce","\u2191","Si","ena"," rel","ativa"," a"," un","'","am","bas","ci","ata"," al"," re"," d","'","\u2191","Arag","ona"," ,"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["tend","ons"," ","\u23ce","have"," occurred"," of"," a"," slight"," nature",","," either"," in"," the"," hands"," or"," feet",","," but"," ","\u23ce","mostly"," in"," the"," feet",";"," this"," may"," be"," considered"," rather"," a"," medical"," \u2014"," ","\u23ce","disease",","," and"," comes"," with"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["'","S","\u21ea"," J","LIS","?"," ."," P","IT",","," I","LS","\u23ce"," AS"," II","\u23ce","\u2191"," Ph","oon","ix","\u2191"," B","itters",".","\u23ce","THE"," bc","--","it"," r",".","c","mi",".","v"," al","sD","H","tt","x","s"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u00ab","  ","1","."," ","\u23ce","8",".","  ","Ob","c","ij","H",".","  ","b",".","\u00e4","B",".","  ","u",".","  ","\u2191","","\u00c4",".","  ","<","&","tf","kt","  ","Section",".","  ","\u21ea","XC","V","III"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["pla","\u00e7a"," ses"," pl","ais","irs"," les"," plus"," d","oux","."," ","\u23ce\u23ce","\u2191","Ah"," I"," que"," les"," n","\u0153","u","ds"," du"," ma","riage",","," etc","."," ","\u23ce","\u21ea","DES","RO","CHES","."," ","\u23ce\u23ce","\u2191","Comme"," un"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," hypothesis"," that"," compounds"," with"," tumor"," promoting"," action"," mod","ulate"," protein"," kin","ase"," C"," activity","."," The"," mixed"," mi","cel","lar"," ass","ay"," is"," ide","ally"," suited"," for"," in"," vit","ro"," testing"," of"," this"," hypothesis"," since"," it"," overc","omes"," problems"," in"]}]}],"top_logits":["9","8","7","seventh","ninth","feared","6","eighth","sag","pu"],"bottom_logits":["four","hundreds","three","obligations","\uff13","sor","\uff14","ipa","obligation"]}