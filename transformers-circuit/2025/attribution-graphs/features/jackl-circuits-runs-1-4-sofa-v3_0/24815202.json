{"index":24815202,"examples_quantiles":[{"quantile_name":"Top Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.34,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","Scar","bu","tt","\u23ce"," no"," vi","?","\u23ce\u23ce","~~~","\u23ce","ban","dr","ami","\u23ce"," The"," s","uck","less"," editor"," is"," called"," sandy","[","0","].","\u23ce\u23ce","[","0","]"," [","http","://","tools",".","s","uck","less",".","org","/"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.85,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ler","C","l",">"," @","The","W","end","y","P","ower"," the"," file"," is"," panel",".","conf"," and"," the"," line"," is"," button","Width","=","200"," ","under"," [","task","bar","]"," if"," it"," do","esn","\\xc3","\\x82","","\u00b4","t"," exist"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.85,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","\u23ce\u23ce","~~~","\u23ce","cam","iller","\u23ce"," According"," to"," the"," WHO"," the"," country"," with"," the"," most"," MD","'s"," per"," capita"," is"," Cuba"," with","\u23ce","7",".","5"," ","per"," ","1","000",","," while"," the"," US"," has"," ","2",".","5"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.83,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["and"," ask"," him"," directly"," ;","-)","\u23ce","<","h","gg","d","h",">"," evaluate",":"," I"," mean",","," his"," nick"," is"," on",","," I"," _","think","_"," he"," is"," on","\u23ce","<","evaluate",">"," n","ah",","," don","'t"," want"," to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.83,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["<","\u2191","Blaz","eix",">"," are"," ","ther"," any"," successful"," ones","?"," the"," only"," other"," one"," I","'ve"," heard"," of"," is","\u2191"," Mate","\u23ce","<","\u2191","Blaz","eix",">"," which"," seems"," kind"," of"," dead","\u23ce","<","tj","ag","oda",">","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.82,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["sol","ab","ial"," fur","row",","," and"," potentially"," fl","ared"," no","str","ils",".\\","n","Question",":"," AU","23"," ","is"," t","igh","ten"," lips","."," Please"," give"," binary"," label"," AU","23"," ","of"," this"," description",".\\","n","Answer",":","\u23ce\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.82,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","<","R","ich","E","d",">"," *","sync","\u23ce","<","R","ich","E","d",">"," the"," other"," main"," man"," is"," jamm","y","q"," ","...."," but"," he"," does"," not"," lur","k"," in"," this"," channel"," ..."," just"," the"," #","lt","sp"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a"," selling"," price"," of"," $","2",".","00","/","lb","."," The"," only"," U",".","S","."," manufacturer"," at"," present"," is","\u2191"," C","arg","ill"," (","Minneapolis",",","\u2191"," M","inn",".).","\u23ce","The"," catal","ytic"," route"," to"," it","ac","onic"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," all"," states"," have"," cas","inos","."," In"," fact",","," all"," but"," two"," states"," have"," cas","inos","."," These"," states"," are"," Utah"," and"," Hawaii","."," Some"," states"," have"," many"," cas","inos",","," and"," some"," states"," have"," only"," one"," or"," two","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["to"," g","cc","T","LD"," status",".","\u23ce\u23ce","Also",","," the"," most"," reasonable"," .","io"," regist","rar"," I","'ve"," found"," is"," g","andi"," at"," $","40","."," Out"," of","\u23ce"," curios","ity",","," has"," anybody"," found"," anything"," less"," expensive"," from"," a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["bt","w","?","\u23ce","<","A","lan","B","ell",">","\u2191"," Tom","asu","_",":"," ap","n"," for"," contract"," should"," be"," orang","e","int","ernet","\u23ce","<","pop","ey",">"," ali","1","234",":"," not"," had"," time"," to"," work"," on"," it"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["les"," represent"," (","6","\u2013","4",")"," ins","ect"," photo","ly","ases",";"," sequences"," with"," inv","erted"," black"," triang","les"," are"," repr","enting"," all"," ins","ect"," photo","ly","ase"," rep","ir"," proteins",";"," and"," sequences"," with"," a"," dot"," symbol"," show"," ins"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.79,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["but"," almost"," nothing"," on"," e","mu","lex",".","  ","I"," believe"," the"," driver"," shipped"," with"," ","14",".","04"," ","is"," lp","fc"," but"," I"," can","'t"," find"," any"," information"," on"," lp","fc"," configur","ables"," to"," switch"," from"," init","iat","ior"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.79,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["player"," when"," right"," clicked",","," how"," can"," I"," continue"," my"," java"," code","?"," (","The"," mod","loader"," I"," am"," using"," is","\u2191"," Fabric"," F","Y","I",")","\u23ce","    ","@","Override","\u23ce","    ","public"," Type","d","Action","Result","<","Item","Stack"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.77,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["night"," all","\u23ce","<","og","ra",">"," m","pt",","," did"," you"," know"," that"," bob"," dyl","ans"," real"," last"," name"," is"," also"," zimm","erman"," *","and","*"," he"," also"," plays"," guitar"," ..."," you","'ll"," never"," know"," the"," secrets"," of"," md","z"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.77,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["cy",","," or"," other"," lights"," of"," that"," ministry"," for"," which"," the"," boy"," was"," already"," dest","ined","."," His"," ch","um"," was"," John","\u2191"," G","aill","ard"," Keith","\u2191"," G","our","din"," (","pronounced","\u2191"," God","yne",")"," :"," yet"," st","rang"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.76,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["."," ##","ST","R","7","##"," An"," alternative"," name"," for"," carb","ape","nam",","," also"," found"," in"," the"," literature",","," is"," ","1","-","az","ab","ic","yc","lo","[","3",".","2",".","0","]","h","ep","tan","-","7"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.75,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["been"," clin","ically"," used"," as"," an"," effective"," anti","ang","inal"," and"," ant","ih","y","pert","ensive"," agent"," whose"," generic"," name"," is","\u2191"," Dil","ti","az","em"," (","\u2191","Mer","ck"," Index",","," X"," Edition"," N",","," ","3","189",","," page"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.75,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["has"," served"," the"," state"," of","\u2191"," T","ennes","\u23ce"," see"," in"," the"," United"," State","B"," senate","."," The","\u23ce"," first"," was"," Joseph"," S","."," Tyler",","," Union","-","Re","\u23ce"," publ","ican",","," who"," was"," in"," the"," senate"," from","\u23ce","1"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.75,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["1","862"," ","by","\u2191"," Zen","ker",";"," however"," the"," first"," person"," considered"," to"," diagn","ose"," fat"," em","bol","ism"," was"," Von","\u2191"," Berg","mann"," in"," ","1","873",","," who"," reported"," on"," his"," findings"," concerning"," this"," condition","1",",","4"]}]},{"quantile_name":"Subsample Interval 0","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.34,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["\u2191","Scar","bu","tt","\u23ce"," no"," vi","?","\u23ce\u23ce","~~~","\u23ce","ban","dr","ami","\u23ce"," The"," s","uck","less"," editor"," is"," called"," sandy","[","0","].","\u23ce\u23ce","[","0","]"," [","http","://","tools",".","s","uck","less",".","org","/"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.85,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["ler","C","l",">"," @","The","W","end","y","P","ower"," the"," file"," is"," panel",".","conf"," and"," the"," line"," is"," button","Width","=","200"," ","under"," [","task","bar","]"," if"," it"," do","esn","\\xc3","\\x82","","\u00b4","t"," exist"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.85,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":[".","\u23ce\u23ce","~~~","\u23ce","cam","iller","\u23ce"," According"," to"," the"," WHO"," the"," country"," with"," the"," most"," MD","'s"," per"," capita"," is"," Cuba"," with","\u23ce","7",".","5"," ","per"," ","1","000",","," while"," the"," US"," has"," ","2",".","5"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.83,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["and"," ask"," him"," directly"," ;","-)","\u23ce","<","h","gg","d","h",">"," evaluate",":"," I"," mean",","," his"," nick"," is"," on",","," I"," _","think","_"," he"," is"," on","\u23ce","<","evaluate",">"," n","ah",","," don","'t"," want"," to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.83,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["<","\u2191","Blaz","eix",">"," are"," ","ther"," any"," successful"," ones","?"," the"," only"," other"," one"," I","'ve"," heard"," of"," is","\u2191"," Mate","\u23ce","<","\u2191","Blaz","eix",">"," which"," seems"," kind"," of"," dead","\u23ce","<","tj","ag","oda",">","\u2191"]}]},{"quantile_name":"Subsample Interval 1","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.82,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["\u23ce","<","R","ich","E","d",">"," *","sync","\u23ce","<","R","ich","E","d",">"," the"," other"," main"," man"," is"," jamm","y","q"," ","...."," but"," he"," does"," not"," lur","k"," in"," this"," channel"," ..."," just"," the"," #","lt","sp"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["a"," selling"," price"," of"," $","2",".","00","/","lb","."," The"," only"," U",".","S","."," manufacturer"," at"," present"," is","\u2191"," C","arg","ill"," (","Minneapolis",",","\u2191"," M","inn",".).","\u23ce","The"," catal","ytic"," route"," to"," it","ac","onic"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":[","," all"," states"," have"," cas","inos","."," In"," fact",","," all"," but"," two"," states"," have"," cas","inos","."," These"," states"," are"," Utah"," and"," Hawaii","."," Some"," states"," have"," many"," cas","inos",","," and"," some"," states"," have"," only"," one"," or"," two","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["to"," g","cc","T","LD"," status",".","\u23ce\u23ce","Also",","," the"," most"," reasonable"," .","io"," regist","rar"," I","'ve"," found"," is"," g","andi"," at"," $","40","."," Out"," of","\u23ce"," curios","ity",","," has"," anybody"," found"," anything"," less"," expensive"," from"," a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["bt","w","?","\u23ce","<","A","lan","B","ell",">","\u2191"," Tom","asu","_",":"," ap","n"," for"," contract"," should"," be"," orang","e","int","ernet","\u23ce","<","pop","ey",">"," ali","1","234",":"," not"," had"," time"," to"," work"," on"," it"]}]},{"quantile_name":"Subsample Interval 2","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["physic","ists"," or"," that"," are"," about"," mathematical","\u23ce"," physics"," (","an"," author"," to"," look"," out"," for"," depending"," on"," your"," level"," is"," VI"," Arnold","),","\u23ce","since"," arguments"," will"," be"," of"," a"," more"," geometric"," or"," physical"," nature"," and"," appeal"," more","\u23ce"," to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["<","\u2191","Ay","ab","ara",">"," ","xit","\u23ce","<","nos","r","edn","ae","kim",">"," gd","m","'s"," equivalent"," is"," kd","m"," in","\u2191"," Kub","untu","\u23ce","<","q","olo",">"," chmod"," -","x"," kd","m","\u23ce","<","nos","r"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ag","ulation"," effect",".","\u23ce","The"," chemical"," name"," of"," da","bi","gat","ran"," et","ex","il","ate"," mes","yl","ate"," is",":"," ","3","-","[(","2","-","{","[","4","-(","hex","a","ox","yc","arb","ony","lam","ino","-"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.69,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["o","urt","v",">"," g","but","ters",","," n","ope",","," info"," doesn","'t"," have"," delete",".","  ","last"," item"," is"," Help","(","Status"," Icons",")","\u23ce","<","o","urt","v",">"," To","eB","ee",","," did"," you"," try"," putting"," box"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.69,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","\"","Yet"," another"," mineral"," that"," will",","," under"," appropriate"," conditions",","," form"," tub","ules"," and"," other"," micro","struct","ures"," is"," bou","lan","ge","rite",".","\u2191"," Bou","lan","ge","rite"," also"," belongs"," to"," the"," class"," of"," minerals"," known"," as"," sulf"]}]},{"quantile_name":"Subsample Interval 3","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["attract","ant"," in"," our"," skin"," and"," breath",","," even"," if"," you"," don","'t"," sw","eat"," much"," (","one"," for"," example"," is"," oc","ten","ol",")."," You"," may"," also"," sec","rete"," l","actic"," and"," u","ric"," acid"," without"," real","ising"," it"," as"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," I"," always"," wanted"," a"," cool"," nickname"," like"," that",".\""," \"","Yeah",","," the"," best"," you"," got"," in"," high"," school"," was","\u2191"," Wet","\u2191"," Pants","\u2191"," G","eller",".\""," \"","That"," was"," the"," water"," fountain","!\""," \"","\u2191","Okay","?\""," \""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["as"," it"," allows"," the"," model"," to"," maintain"," its"," accuracy"," while"," reducing"," the"," size"," and"," computational"," requirements",".","\u23ce\u23ce","Another"," method"," is"," quant","ization","-","aware"," training"," (","Q","A","T","),"," where"," the"," training"," process"," is"," aware"," of"," the"," quant","ization"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["you"," should"," select"," the"," option"," that"," is"," a"," possible"," cause"," of"," the"," premise"," sentence",","," and"," if"," the"," question"," word"," was"," effect"," you"," should"," find"," the"," option"," which"," is"," a"," possible"," effect"," of"," the"," premise"," sentence","."," Answer"," with"," \"","A"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["source"," of"," trouble"," in"," the"," US"," math","\u23ce"," education"," system","."," A"," champion"," for"," math"," education"," reform"," I"," adm","ire"," is"," Keith","\u23ce","\u2191"," Dev","lin"," (<","http","://","www",".","m","aa",".","org","/","dev","lin","/","dev","lin"]}]},{"quantile_name":"Subsample Interval 4","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","\u23ce","If"," you","'re"," looking"," for"," restaurants"," near"," King"," Street"," in"," Toronto",","," one"," of"," the"," most"," popular"," restaurants"," is"," the","\u2191"," H","umb","erto"," Kitchen"," located"," in"," the"," tren","dy"," shopping"," and"," dining"," area"," of"," San"," Miguel",".","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.39,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["c",")"," both"," seem"," active"," and","\u23ce"," supported"," by","\u2191"," Canonical"," to"," me","."," The"," only"," deprecated"," project"," by"," them"," is"," listed"," to","\u23ce"," be"," CG","Manager",".","\u23ce\u23ce","~~~","\u23ce","v","b","ez","he","nar","\u23ce"," L","X","C"," is"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["of"," practical"," use"," today",","," most"," contain"," tel","lu","rium","."," Of"," those"," materials",","," the"," most"," extensively"," studied"," material"," is","\u2191"," Ge","2","\u2191","Sb","2","Te","5","."," While"," the"," de","position"," can"," be"," convent","ionally"," performed"," by"," plasma"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["solar"," system",","," and"," the"," largest"," moon"," of"," the"," planet"," Jupiter","."," The"," next"," largest"," moon"," in"," our"," solar"," system"," is","\u2191"," Titan",","," which"," is"," the"," largest"," moon"," of"," the"," planet"," Saturn",","," with"," a"," diameter"," of"," ","5","150"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["between"," them","."," If"," the"," second"," sentence"," has"," a"," similar"," meaning"," to"," that"," of"," the"," first"," sentence"," then"," the"," output"," is"," '"," B","_","ent","ails","_","A","',"," if"," the"," second"," sentence"," has"," the"," opposite"," meaning"," to"," the"," first"," sentence"]}]},{"quantile_name":"Subsample Interval 5","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["serves"," thousands"," of"," requests"," per"," second"," in"," large","\u23ce"," deploy","ments"," already",".","\u23ce\u23ce","The"," only"," other"," I"," know"," of"," is"," perhaps"," Node",".","\u23ce\u23ce","So",","," yes",","," seriously",".","\u23ce\u23ce","~~~","\u23ce","g","iz","mo","686","\u23ce","\u2191","Isn"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["capacity",","," and"," it"," is"," necessary"," to"," develop"," new"," negative"," electrode"," active"," materials","."," One"," of"," the"," promising"," candidates"," thereof"," is"," active"," materials"," containing"," silicon"," (","also"," referred"," to"," as"," \"","silicon","-","based"," active"," materials","\")."," The"," silicon","-","based"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["on"," here"," back"," then"," too","."," now"," very"," scar","ce","\u23ce","<","\u2191","Ki","los",">"," meth","inks"," his"," nick"," is"," a","fr","ode","ity","\u23ce","<","\u2191","V","ince","-","0",">"," ah",","," I","'d"," like"," to"," know"," more"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a"," few"," soccer"," games"," today","."," One"," game"," is"," Atlanta"," United"," vs","."," Portland","\u2191"," Tim","bers","."," Another"," game"," is"," FC"," Dallas"," vs","."," Minnesota"," United",".","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","What"," person"," historically"," contributed"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," /","home","/"," to"," see"," what"," their"," name"," is",".","\u23ce","<","a","rand",">"," I","'d"," guess"," it","'s"," ubuntu"," normally","...","\u23ce","<","m","aln","il","ion",">"," Brian",","," did"," that"," command"," I"," posted"," get"," the"," ball"]}]},{"quantile_name":"Subsample Interval 6","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.38,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["English"," I"," will"," do"," so"," by"," putting"," text"," inside"," cur","ly"," brackets"," {","like"," this","}","."," My"," first"," command"," is"," pwd",".","\u23ce\u23ce","Assistant",":"," /","home","/","NAME","_","1","\u23ce\u23ce","Human",":"," ls","\u23ce\u23ce"," Assistant",":"," ```","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["C","5",","," C","6",","," C","7",","," C","8",","," C","9","."," The"," main"," alternative"," pathway"," components"," are"," designated"," Factor"," B",","," Factor"," D",",","\u2191"," Proper","din",","," H"," and"," I","."," In"," addition"," to"," M","B"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ched",","," but"," they"," were"," vulnerable","\u23ce"," through","\u2191"," Tool","b","ars","."," (","I"," think"," in"," both"," cases"," it"," was"," the"," Yahoo","\u2191"," Toolbar",".)","\u23ce\u23ce","This"," is"," certainly"," not"," meant"," as"," a"," general"," advice",","," but"," I"," guess"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["improve"," the"," brightness"," and","/","or"," the"," whit","eness"," of"," the"," paper","."," One"," example"," of"," such"," a"," f","iller"," is"," P","CC"," (","precip","itated"," calcium"," carb","onate","),"," i",".","e","."," precip","itated"," calcium"," carb","onate","."," The"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ous"," efficiency",".","\u23ce","The"," light"," output"," can"," also"," be"," measured"," in"," radi","ometric"," units",","," where"," the"," basic"," unit"," is"," the","\u2191"," W","att"," per"," unit"," solid"," angle"," (","W","/","sr","/","m","2",").","\u2191"," Watts"," are"," absolute"]}]},{"quantile_name":"Subsample Interval 7","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," projection"," optical"," system"," is"," defined"," as"," NA"," and"," the"," numerical"," aper","ture"," of"," the"," illumin","ation"," system"," is"," defined"," as"," NA","i",","," a"," .","sigma","."," value"," as"," one"," of"," the"," parameters"," of"," the"," illumin","ation"," system"," is"," defined"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["been"," demanded",".","\u23ce","One"," type"," of"," semiconductor"," package"," technology"," suggested"," to"," satisfy"," the"," technical"," demand",","," described"," above",","," is"," a"," fan","-","out"," semiconductor"," package","."," Such"," a"," fan","-","out"," package"," has"," a"," compact"," size"," and"," may"," allow"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ul","ence"," components"," that"," are"," both"," products"," of"," the"," T","."," br","uc","ei"," secret","ory"," system","."," The"," first"," is"," the"," surface","-"," loc","alized"," glyc","os","yl","ph","osp","hat","id","y","lin","osit","ol"," (","G","PI",")-"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["zy"," is"," ","5",".","04"," ","i"," think","\u23ce","<","eloqu","ence","_",">"," ","6",".","06"," ","is"," d","apper","\u23ce","<","eloqu","ence","_",">"," ed","gy"," is"," ","6",".","10","\u23ce","<","buz","zy",">"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["of"," an"," em","ulsion"," polym","ers"," as"," a"," primer"," without"," any"," surface"," treatment"," is"," also"," described","."," One"," such"," primer"," is"," a"," c","opol","y","mer"," of"," but","ad","iene",","," an"," eth","y","len","ically"," uns","atur","ated"," mon","omer"]}]},{"quantile_name":"Subsample Interval 8","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Matrix"," pr","inters"," compose"," records"," or"," characters"," by"," recording"," discrete"," bits"," or"," fragments"," at"," appropriate"," locations","."," Examples"," of"," these"," are"," ink"," jet",","," laser",","," electro","e","ros","ion",","," elect","rol","ytic"," or"," wire"," pr","inters","."," These"," machines"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","other"," competing"," tech"," companies","?","\u23ce\u23ce","\u2191","F","unn","ily"," enough",","," the"," best"," resource"," to"," follow"," these"," connections"," is","\u2191"," Cr","unch","base",":","\u23ce","<","http","://","www",".","cr","unch","base",".","com","/","company","/","ne"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["of"," hum","orous"," and"," ecc","entric"," characters","."," However",","," one"," character"," that"," is"," often"," cited"," as"," being"," particularly"," amusing"," is"," \"","The"," Old"," Lady"," of"," NAME","_","3",",\""," who"," is"," a"," r","ecl","usive"," and"," ecc","entric"," elderly"," woman"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["mother","\u23ce"," should"," be"," given"," at","\u23ce"," t","ention",".","\u2191"," Af","n","ong"," the","\u23ce"," real"," helpful"," things","\u23ce"," is"," an"," external"," ab","\u23ce"," dom","inal"," application","\u23ce",".,"," k","own"," as"," \"","Mother","'s","\u23ce"," l","r","end",".\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ry","tan",">"," What"," is"," the"," name"," of"," the"," firefox"," ext","ention"," that"," blocks"," javasc","ripts"," site"," by"," site"," case","?","\u23ce","<","alex","_","mayor","ga",">"," n","osc","ript","\u23ce","<","\u2191","Zo","em",">"," isn","'t"," that"," like"]}]},{"quantile_name":"Bottom Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ie","ill",".),"," or",","," as"," according"," to"," Prof",".","\u2191"," Sun","dev","all"," it"," should"," be"," ","\u23ce","spelled",","," C","."," be","tic","ata",","," see"," reference"," under"," preceding"," species","."," ","\u23ce\u23ce","272",".","\u21ea"," CH","DIC","NE"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["I"," love"," you","!\""," \"","What","?\""," \"","\u2191","Suz","umi","\u2191"," A","og","iri",".\""," \"","Her"," maiden"," name"," is","\u2191"," Suz","umi","\u2191"," Sak","u","rad","ai",".\""," \"","She","'s"," a"," C","-","\u2191","Genome"," from","\u2191"," Hy"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["things"," here",".\""," \"","You"," mind"," if"," I"," drop"," in"," again"," later","?\""," \"","\u2191","An","ytime",".\""," \"","Name","'s","\u2191"," Wh","it",".\""," \"","I","'m"," always"," around",".\""," \"(","ch","uck","les",")","\u2191"," Funny",","," so"," am"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["aris"," ","ii","rc","\u23ce","<","tj","aal","ton",">"," j","c","rist","au",":"," right",","," for"," linux"," it","'s"," sun","ff","b","\u23ce","<","tj","aal","ton",">"," #","elif"," defined","(__","spar","c","__",")"," &&"," !","defined"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["  ","affl","icted","  ","with","  ","any","  ","disease","  ","save"," ","\u23ce","one"," \u2014"," and","  ","that","  ","is","  ","deadly","  ","and","  ","inc","urable",".","  ","It","  ","b","  ","called","  ","the","  ","**","  ","horse","-"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["?"," ","\u23ce\u23ce","Assistant",":"," ","\u23ce","The"," most"," healthy"," species"," of"," Maine"," se","aw","eed"," for"," humans"," to"," eat"," is"," dul","se",".","\u2191"," Dul","se"," is"," a"," rich"," source"," of"," dietary"," fi","bers",","," various"," minerals"," (","including"," i"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","'","Rain","\u2191"," Co","ats"," &","\u2191"," Tren","ches","'].","\u23ce\u23ce","Assistant",":"," The"," best"," option"," in"," the"," list"," is"," \"","Rain","\u2191"," Co","ats"," &","\u2191"," Tren","ches","\""," because"," it"," is"," the"," most"," specific"," category"," for"," an"," umbre"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["writing"," another"," episode",".\""," \"","Ron",".\""," \"","\u2191"," Wow",".\""," \"","Hi",","," I","'m"," Doug",".\""," \""," I","'m"," Claire",".\""," \""," Hi",".\""," \""," You","'re"," Ronald"," D","."," Moore","?\""," \"","Yes",".\""," \""," Very"," nice"," to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["cigare","tte"," WITH","\u21ea"," REAL"," '","\u23ce","PR","E","-","WA","R","\u21ea"," FLAVOR"," ...","\u21ea","TH","ATS","\u23ce","'","\u21ea"," SOMETHING","\u21ea"," THESE","\u21ea"," DAYS","!","\u23ce","L"," Z"," ^","\u23ce","\u2191","R","ale","ig","hs"," taste"," better"," naturally","-"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["when"," the"," measurement"," result"," is"," obtained"," from"," several"," different"," inputs",","," and"," if"," the"," uncertainty"," factor"," (","input"," quantity",")"," is"," independent",","," the"," combined"," standard"," uncertainty"," is"," obtained"," as"," in"," the"," following","\u2191"," Equation"," ","1",","," by"," combining"," uncertainty"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["moment"," in"," the"," narrative",","," to"," give"," a"," sil","hou","ette"," of"," the"," man"," who",","," dying"," when"," he"," was"," only"," in"," his"," twenty","-","third"," year",","," was"," yet"," deemed"," worthy"," of"," that"," long","-","pon","dered"," \""," In","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["types"," of"," non","-","specific"," interactions",".","\u23ce","A"," particular"," class"," of"," compounds"," which"," inter","acts"," with"," the"," minor"," groove"," are"," the"," pyr","ro","lo","ben","zo","di","az","ep","ines"," (","P","B","Ds",")."," P","B","Ds"," have"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["/","Co","co","R","os","ie"," -"," Noah","'s","\u2191"," Ark","/","05"," ","-"," Co","co","R","os","ie"," -","\u2191"," Tek","no"," Love"," Song",".","mp","3","/","05"," ","-"," Co","co","R","os","ie"," -","\u2191"," Tek"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["leap"," of"," faith",","," and"," I"," know"," you","'ll"," agree"," with"," me",".\""," \"","What","'s"," that","?\""," \"","It","'s"," good"," water",".\""," \"","Did"," you"," hear"," what"," happened","?\""," \"","Yeah",".\""," \"","\u2191","","Ugh",".\""," \"","Don"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["down",".\""," \""," Has"," anyone"," seen"," this"," except"," you","?\""," \""," No",".\""," \""," Crawford","'s"," office",".\""," \""," This"," is","\u2191"," Chil","ton",".\""," \"","Mr","."," Graham"," please","!\""," \"","He","'s"," not"," here",".\""," \"","Mr","."," Crawford"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["eb","ri","onis",","," which"," is"," reportedly"," active"," against"," two"," beetles"," in"," the"," order","\u2191"," C","ole","optera","."," These"," are"," the"," Colorado"," potato"," beetle",",","\u2191"," Lep","ti","not","ar","sa"," dec","em","line","ata",","," and","\u2191"," A","gel"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["more"," diff","use",","," progressive"," muscle"," weakness",".\""," \"","He","'s"," shut","ting"," down",".\""," \"","It","'s"," got"," to"," be"," something"," syst","emic",","," like"," auto","imm","une",".\""," \"","CS","F"," was"," clear"," for","\u2191"," Guill","ain","-","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["was"," b","ree","zing"," along"," with"," the"," variable","-","date"," holidays"," like","\u23ce","\u2191"," Thanksgiving",","," and"," then"," I"," came"," to"," Easter",".","\u23ce\u23ce","\u2191","Turns"," out",","," it","'s"," slightly"," complex","."," It"," has"," to"," do"," with"," moon"," cycles","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["down"," any"," wine",".\""," \"","Hello","?\""," \""," Mr",".","\u2191"," Penn","ington","...\""," \""," Yes",".\""," \"","My"," name"," is"," John","\u2191"," St","eed",".\""," \"","I","'m"," a"," friend"," of"," a"," client"," of"," yours",".\""," \"","Mrs",".","\u2191"]}]}],"top_logits":["ydyd","ienien","plemena","divizija","\u043a\u043e\u0442\u043e\u0440","v\u00e6ret","Acontecimientos","while","varit","reform\u00e1t"],"bottom_logits":["jud","ro","bound","pain","pref","funct","not","categor","rout","strateg"]}