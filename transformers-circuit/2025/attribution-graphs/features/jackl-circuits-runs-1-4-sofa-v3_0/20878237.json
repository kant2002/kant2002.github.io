{"index":20878237,"examples_quantiles":[{"quantile_name":"Top Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.13,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.27,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.62,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["h","izo"," con"," el"," mundo"," y"," sus"," pret","ens","iones","\u23ce\u23ce"," Assistant",":"," La"," int","elig","encia"," artificial"," s","ube","\u23ce\u23ce"," en"," el"," ranking"," de"," la"," vida","\u23ce\u23ce"," con"," sus"," algorit","mos"," y"," su"," ci","encia","\u23ce\u23ce"," se"," h","izo"," con"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["'ll"," leave"," my"," trail","\u23ce\u23ce"," Bridge",":","\u23ce","I","'ve"," been"," through"," the"," storm",","," I","'ve"," felt"," the"," pain","\u23ce"," But"," I","'m"," still"," standing"," here",","," I","'m"," still"," in"," the"," game","\u23ce"," I","'ve"," taken"," my"," share"," of"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.84,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["pro","met"," de"," tout"," r\u00e9p","arer",".","\u23ce","\u2191","Mais"," il"," cache"," une"," d","oul","eur"," plus"," prof","onde",",","\u23ce","Et"," le"," mal"," qui"," le"," diss","im","ule"," est"," so","urd",".","\u23ce\u23ce","Les"," so","ir","\u00e9es"," pass","ent"," \u00e0"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ens","urable",".","\u23ce\u23ce","L","'","alc","ool"," est"," un"," ami"," fid","\u00e8","le",","," un"," comp","agn","on",",","\u23ce","\u2191","Qui"," vous"," console",","," vous"," b","erce",","," vous"," end","or","ce",".","\u23ce","\u2191","Mais"," il"," est"," \u00e9galement"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.76,0.0,0.0,0.0,0.0,0.0,0.0,0.35,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["poem",","," with"," every"," line"," rh","y","ming",":","\u23ce\u23ce","War"," in"," Ukraine","\u23ce\u23ce"," Blood"," st","ains"," the"," earth",",","\u23ce","Where"," once"," a"," peaceful"," land",",","\u23ce","Now"," torn"," apart"," by"," str","ife",",","\u23ce","And"," the"," sound"," of"," gun"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.73,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["version"," of"," the"," poem"," that"," rh","ymes",":","\u23ce","A"," theoretical"," neu","rosc","ient","ist"," sits"," in"," his"," lab",",","\u23ce","\u2191","Studying"," the"," brain"," in"," all"," its"," beauty",",","\u23ce","To"," un","r","avel"," the"," mysteries"," that"," lie"," within","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.73,0.24,0.0,0.0,0.0,0.0,0.0,0.0,0.23,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["poem",","," with"," every"," line"," rh","y","ming",":","\u23ce\u23ce","War"," in"," Ukraine","\u23ce\u23ce"," Blood"," st","ains"," the"," earth",",","\u23ce","A"," peaceful"," land"," now"," torn"," apart",",","\u23ce","By"," str","ife"," and"," gun","fire","'s"," ro","ar",".","\u23ce\u23ce","Cities"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.14,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," poem",","," with"," better"," rh","y","ming",":","\u23ce\u23ce","War"," in"," Ukraine","\u23ce\u23ce"," Blood"," st","ains"," the"," earth",",","\u23ce","A"," peaceful"," land"," now"," torn"," apart",",","\u23ce","By"," str","ife"," and"," the"," sound"," of"," war",".","\u23ce\u23ce","Cities"," once"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.41,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.68,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.39,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["h","izo"," con"," el"," mundo"," en"," un"," vu","elo","\u23ce\u23ce"," se"," ad","ent","r\u00f3"," en"," la"," cort","eza"," cereb","ral","\u23ce\u23ce"," de"," la"," human","idad"," sin"," mi","edo","\u23ce\u23ce"," y"," ah","ora"," pret","ende"," ser"," d","ue","\u00f1a","\u23ce\u23ce"," NAME","_"]},{"tokens_acts_list":[0.0,0.0,0.31,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.67,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["of"," white","\u23ce","\u2191"," Filling"," up"," the"," air"," with"," might","\u23ce"," A"," p","uff"," here",","," a"," p","uff"," there","\u23ce","\u2191"," Addiction"," lur","king",","," be","ware","!","\u23ce\u23ce","Human",":"," Generate"," a"," poem"," about"," v","aping","."," Make"," sure"]},{"tokens_acts_list":[0.47,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.66,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.13],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","But"," his"," hyg","iene"," leaves"," a"," lot"," to"," desire","\u23ce\u23ce"," He"," rarely"," sh","owers",","," that","'s"," no"," lie","\u23ce"," And"," when"," he"," does",","," he"," gets"," ill","\u23ce"," It","'s"," a"," wonder"," how"," he"," doesn","'t"," fall"," ill","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.61,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["aling"," f","umes",","," a"," dangerous"," joke","\u23ce"," NAME","_","1"," ","flav","ors"," tem","pt",","," addiction"," bin","ds","\u23ce"," Health"," at"," stake",","," a"," price"," to"," find",".","<EOT>","\u23ce\u23ce","Human",":"," hi"," there","\u23ce\u23ce"," Assistant",":"," Hello","!"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.27,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.62,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.41,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["encia"," artificial"," s","ube","\u23ce\u23ce"," en"," el"," ranking"," de"," la"," vida","\u23ce\u23ce"," con"," sus"," algorit","mos"," y"," su"," ci","encia","\u23ce\u23ce"," se"," h","izo"," con"," el"," mundo"," en"," un"," vu","elo","\u23ce\u23ce"," se"," ad","ent","r\u00f3"," en"," la"," cort","eza"," cereb"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.62,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["trail","\u23ce\u23ce","\u2191"," Verse"," ","2",":","\u23ce","I"," started"," out"," with"," nothing",","," just"," a"," dream"," in"," my"," heart","\u23ce"," I"," worked"," hard",","," I"," took"," chances",","," I"," played"," the"," game"," with"," my"," art","\u23ce"," I"," had"," to"," overcome"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.15,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.62,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Their"," hearts"," filled"," with"," excitement"," and"," lon","ging",".","\u23ce","They","'ll"," w","ander"," through"," the"," bust","ling"," streets",",","\u23ce","And"," s","oak"," up"," the"," culture"," that","'s"," out"," of"," sight",".","\u23ce","The"," bright"," colors"," and"," sounds"," of"," the"]}]},{"quantile_name":"Subsample Interval 0","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.13,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.27,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.62,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["h","izo"," con"," el"," mundo"," y"," sus"," pret","ens","iones","\u23ce\u23ce"," Assistant",":"," La"," int","elig","encia"," artificial"," s","ube","\u23ce\u23ce"," en"," el"," ranking"," de"," la"," vida","\u23ce\u23ce"," con"," sus"," algorit","mos"," y"," su"," ci","encia","\u23ce\u23ce"," se"," h","izo"," con"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["'ll"," leave"," my"," trail","\u23ce\u23ce"," Bridge",":","\u23ce","I","'ve"," been"," through"," the"," storm",","," I","'ve"," felt"," the"," pain","\u23ce"," But"," I","'m"," still"," standing"," here",","," I","'m"," still"," in"," the"," game","\u23ce"," I","'ve"," taken"," my"," share"," of"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.84,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["pro","met"," de"," tout"," r\u00e9p","arer",".","\u23ce","\u2191","Mais"," il"," cache"," une"," d","oul","eur"," plus"," prof","onde",",","\u23ce","Et"," le"," mal"," qui"," le"," diss","im","ule"," est"," so","urd",".","\u23ce\u23ce","Les"," so","ir","\u00e9es"," pass","ent"," \u00e0"]}]},{"quantile_name":"Subsample Interval 1","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.13,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.27,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.62,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["h","izo"," con"," el"," mundo"," y"," sus"," pret","ens","iones","\u23ce\u23ce"," Assistant",":"," La"," int","elig","encia"," artificial"," s","ube","\u23ce\u23ce"," en"," el"," ranking"," de"," la"," vida","\u23ce\u23ce"," con"," sus"," algorit","mos"," y"," su"," ci","encia","\u23ce\u23ce"," se"," h","izo"," con"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["'ll"," leave"," my"," trail","\u23ce\u23ce"," Bridge",":","\u23ce","I","'ve"," been"," through"," the"," storm",","," I","'ve"," felt"," the"," pain","\u23ce"," But"," I","'m"," still"," standing"," here",","," I","'m"," still"," in"," the"," game","\u23ce"," I","'ve"," taken"," my"," share"," of"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.84,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["pro","met"," de"," tout"," r\u00e9p","arer",".","\u23ce","\u2191","Mais"," il"," cache"," une"," d","oul","eur"," plus"," prof","onde",",","\u23ce","Et"," le"," mal"," qui"," le"," diss","im","ule"," est"," so","urd",".","\u23ce\u23ce","Les"," so","ir","\u00e9es"," pass","ent"," \u00e0"]}]},{"quantile_name":"Subsample Interval 2","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.13,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.27,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.62,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["h","izo"," con"," el"," mundo"," y"," sus"," pret","ens","iones","\u23ce\u23ce"," Assistant",":"," La"," int","elig","encia"," artificial"," s","ube","\u23ce\u23ce"," en"," el"," ranking"," de"," la"," vida","\u23ce\u23ce"," con"," sus"," algorit","mos"," y"," su"," ci","encia","\u23ce\u23ce"," se"," h","izo"," con"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["'ll"," leave"," my"," trail","\u23ce\u23ce"," Bridge",":","\u23ce","I","'ve"," been"," through"," the"," storm",","," I","'ve"," felt"," the"," pain","\u23ce"," But"," I","'m"," still"," standing"," here",","," I","'m"," still"," in"," the"," game","\u23ce"," I","'ve"," taken"," my"," share"," of"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.84,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["pro","met"," de"," tout"," r\u00e9p","arer",".","\u23ce","\u2191","Mais"," il"," cache"," une"," d","oul","eur"," plus"," prof","onde",",","\u23ce","Et"," le"," mal"," qui"," le"," diss","im","ule"," est"," so","urd",".","\u23ce\u23ce","Les"," so","ir","\u00e9es"," pass","ent"," \u00e0"]}]},{"quantile_name":"Subsample Interval 3","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["'ll"," leave"," my"," trail","\u23ce\u23ce"," Bridge",":","\u23ce","I","'ve"," been"," through"," the"," storm",","," I","'ve"," felt"," the"," pain","\u23ce"," But"," I","'m"," still"," standing"," here",","," I","'m"," still"," in"," the"," game","\u23ce"," I","'ve"," taken"," my"," share"," of"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.84,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["pro","met"," de"," tout"," r\u00e9p","arer",".","\u23ce","\u2191","Mais"," il"," cache"," une"," d","oul","eur"," plus"," prof","onde",",","\u23ce","Et"," le"," mal"," qui"," le"," diss","im","ule"," est"," so","urd",".","\u23ce\u23ce","Les"," so","ir","\u00e9es"," pass","ent"," \u00e0"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["ens","urable",".","\u23ce\u23ce","L","'","alc","ool"," est"," un"," ami"," fid","\u00e8","le",","," un"," comp","agn","on",",","\u23ce","\u2191","Qui"," vous"," console",","," vous"," b","erce",","," vous"," end","or","ce",".","\u23ce","\u2191","Mais"," il"," est"," \u00e9galement"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.76,0.0,0.0,0.0,0.0,0.0,0.0,0.35,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["poem",","," with"," every"," line"," rh","y","ming",":","\u23ce\u23ce","War"," in"," Ukraine","\u23ce\u23ce"," Blood"," st","ains"," the"," earth",",","\u23ce","Where"," once"," a"," peaceful"," land",",","\u23ce","Now"," torn"," apart"," by"," str","ife",",","\u23ce","And"," the"," sound"," of"," gun"]}]},{"quantile_name":"Subsample Interval 4","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.14,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["the"," poem",","," with"," better"," rh","y","ming",":","\u23ce\u23ce","War"," in"," Ukraine","\u23ce\u23ce"," Blood"," st","ains"," the"," earth",",","\u23ce","A"," peaceful"," land"," now"," torn"," apart",",","\u23ce","By"," str","ife"," and"," the"," sound"," of"," war",".","\u23ce\u23ce","Cities"," once"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.41,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.68,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.39,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["h","izo"," con"," el"," mundo"," en"," un"," vu","elo","\u23ce\u23ce"," se"," ad","ent","r\u00f3"," en"," la"," cort","eza"," cereb","ral","\u23ce\u23ce"," de"," la"," human","idad"," sin"," mi","edo","\u23ce\u23ce"," y"," ah","ora"," pret","ende"," ser"," d","ue","\u00f1a","\u23ce\u23ce"," NAME","_"]},{"tokens_acts_list":[0.0,0.0,0.31,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.67,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["of"," white","\u23ce","\u2191"," Filling"," up"," the"," air"," with"," might","\u23ce"," A"," p","uff"," here",","," a"," p","uff"," there","\u23ce","\u2191"," Addiction"," lur","king",","," be","ware","!","\u23ce\u23ce","Human",":"," Generate"," a"," poem"," about"," v","aping","."," Make"," sure"]},{"tokens_acts_list":[0.47,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.66,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.13],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["\u23ce","But"," his"," hyg","iene"," leaves"," a"," lot"," to"," desire","\u23ce\u23ce"," He"," rarely"," sh","owers",","," that","'s"," no"," lie","\u23ce"," And"," when"," he"," does",","," he"," gets"," ill","\u23ce"," It","'s"," a"," wonder"," how"," he"," doesn","'t"," fall"," ill","\u23ce"]}]},{"quantile_name":"Subsample Interval 5","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.55,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["2"," ","que"," so","mos"," y"," NAME","_","2"," ","que"," quer","emos","\u23ce\u23ce"," su"," objetivo"," es"," el"," dom","inio","\u23ce\u23ce"," de"," todo"," lo"," que"," nos"," rod","ea","\u23ce\u23ce"," y"," no"," hay"," quien"," la"," d","ete","nga","\u23ce\u23ce"," su"," poder"," es"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.55,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["to"," sleep"," and"," not"," go"," to"," German"," lesson","\u23ce\u23ce"," Assistant",":"," Oh",","," how"," I"," long"," to"," close"," my"," eyes","\u23ce"," And"," drift"," away"," to"," a"," peaceful"," surprise","\u23ce"," To"," escape"," the"," ted","ium"," of"," this"," German"," lesson","\u23ce"," And"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.54,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["let","'s"," hear"," it"," flow","\u23ce","3","."," Just"," input"," your"," rh","ymes",","," and"," watch"," it"," do"," its"," deed","\u23ce","4","."," Creating"," bars"," that","'ll"," make"," your"," heart"," skip"," a"," beat",".","<EOT>","\u23ce\u23ce","Human",":"," What"," is"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.53,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["meaning","less"," dance"," in"," the"," endless"," night","?","\u23ce\u23ce","I"," don","'t"," know",","," perhaps"," we","'re"," all"," ins","ane","\u23ce"," To"," keep"," on"," living",","," to"," keep"," on"," breathing","\u23ce"," But"," still"," we"," persist",","," with"," hope"," and"," with"," grace"]}]},{"quantile_name":"Subsample Interval 6","examples":[{"tokens_acts_list":[0.27,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.62,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.41,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.68,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce\u23ce","con"," sus"," algorit","mos"," y"," su"," ci","encia","\u23ce\u23ce"," se"," h","izo"," con"," el"," mundo"," en"," un"," vu","elo","\u23ce\u23ce"," se"," ad","ent","r\u00f3"," en"," la"," cort","eza"," cereb","ral","\u23ce\u23ce"," de"," la"," human","idad"," sin"," mi","edo","\u23ce\u23ce"," y"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.41,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[":"," Quarter"," ","1",":","\u23ce","I","'m"," a"," tech"," n","erd",","," I","'m"," not"," a"," b","ro",",","\u23ce","But"," the"," sex"," industry",","," it","'s"," my"," f","ave",",","\u23ce","I","'m"," talking"," ","'","bout"," the"," prostit"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["and"," a"," chicken",".","\u23ce","Text",":"," \"","Welcome"," to"," the"," farm",","," where"," cr","itters"," ro","am"," and"," play","."," A"," red"," barn"," stands"," tall",","," with"," a"," cow"," that","'s"," so"," pale","."," A"," pig"," with"," a"," cur","ly"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Des"," personn","ages"," t","els"," que"," nous",","," mais"," m","ieux",","," plus"," be","aux",","," plus"," f","orts",",","\u23ce","et"," des"," mon","des"," o\u00f9"," tout"," est"," possible",","," o\u00f9"," l","'","on"," peut"," tout"," at","te","ind","re","."]}]},{"quantile_name":"Subsample Interval 7","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.28,0.27,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.38,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["should"," be"," as"," many"," rh","ymes"," as"," possible",".","\u23ce\u23ce","Assistant",":"," Flying"," pen","gu","ins"," so","aring"," high",",","In"," the"," sk","ies"," they"," gl","ide"," with"," might",",","A"," sight"," to"," see",","," truly"," divine",",","As"," they"," gl"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.27,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["rot",","," by"," his"," side",".","\u23ce","He","'ll"," make"," you"," laugh",","," with"," his"," go","at","ish"," joke",",","\u23ce","NAME","_","3"," ","the"," go","at",","," is"," a"," joy"," to"," have"," in"," the"," rock",".\"","\u23ce\u23ce","Page"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.27,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["s","orr","iso",",","\u23ce","\u2191","Voc\u00ea"," vai"," sent","ir","-","se"," como"," um"," beb","\u00ea"," ins","eg","uro",",","\u23ce","No"," m","eu"," mundo"," de"," palav","ras",","," sem"," def","esas",".","\u23ce\u23ce","\u2191","M","eu"," verso"," \u00e9"," como"," uma"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.27,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.17,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["for"," what"," I"," am"," when"," I"," am"," with"," you",".","\u23ce","You"," fill"," my"," heart"," with"," joy"," and"," happiness",",","\u23ce","And"," make"," me"," feel"," like"," a"," kid"," again",".","\u23ce","I"," love"," you",","," not"," only"," for"," what"," you"," are"]}]},{"quantile_name":"Subsample Interval 8","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.14,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["st","\u00fc","rm","ischen","\u2191"," Ze","iten",".","\u23ce","Es"," hil","ft"," uns"," durch",","," in"," j","eder"," Zeit",",","\u23ce","\u2191","B","rin","gt","\u2191"," Fre","ude",","," b","rin","gt","\u2191"," Fr","ieden",".","\u23ce\u23ce","\u2191","Li","ebe"," ist"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.14,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["lines"," are",",","\u2191"," N","ym","pha"," suo","\u2191"," Par","idi"," qu","am","y","is"," me","ua"," esse"," rec","uses","\u2191"," Mitt","it"," ab","\u2191"," Id","a","eis"," yer","ba"," leg","enda"," i","ug","is","."," I"," had"," rather"," reject"," y"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.13,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["      ","\u23ce","     ","\u23ce","NAME","_","2"," ","the"," unic","orn"," said"," \"","I","'d"," love"," to"," play","!\"","    ","\u23ce","So"," they"," played"," all"," day",","," in"," the"," best"," way",".","\u23ce","      ","\u23ce","They"," rode"," on"," NAME","_","2"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.13,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," we","'re"," a"," family",",","\u23ce","And"," we","'ll"," always"," be"," together",",","\u23ce","Through"," thick"," and"," thin",",","\u23ce","We","'ll"," always"," be"," together",",","\u23ce","Together",".","<EOT>","\u23ce\u23ce","Human",":"," Write"," an"," article"," about"," the","\u2191"," Upstream"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.13,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","The"," first"," novel"," by"," the"," English"," author"," Ian"," Fleming"," to"," feature"," his"," British"," Secret"," Service"," agent"," James"," Bond",".","\u23ce","Written"," at"," Fleming","'s","\u2191"," Gold","ene","ye"," estate"," in"," Jamaica",","," it"," was"," first"," published"," in"," the"," United"," Kingdom"]}]},{"quantile_name":"Bottom Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[")","i","ath","  ","","ijo","  ","rage","  ","like","  ","love","  ","to","  ","hatred","  ","turned",","," ","\u23ce","\u2191","K","ur","  ","hell","  ","a","  ","fury","  ","lite","  ","a","  ","woman","  ","scor","ned","."," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["rill","\""," \"","But"," for"," a"," breath"," of"," a"," fresh"," kill","\""," \"","Never"," mind"," the"," man"," who"," contempl","ates","\""," \"","\u2191","Doing"," away"," with"," license"," plates","\""," \"","He"," stands"," alone"," an","yh","ow","\""," \"","\u2191","B","aking"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," world"," of"," the"," rich"," and"," the"," el","ite","Th","ey","'re"," the"," three"," things"," that"," they"," all"," des","ir","eB","ut"," for"," most"," of"," us",","," they","'re"," just"," a"," dream","\u23ce\u23ce"," Money",","," it","'s"," the"," root"," of"," all"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," if"," you","'d"," smile"," at"," me"," and"," me"," alone",".\""," \"","\u2191","Turning"," his"," thoughts"," to"," it"," entirely",","," forg","etting"," the"," little"," sal","ami",".\""," \"","Women"," don","'t"," care"," though"," I","'m"," a"," cro","oner",".\""," \"","It"]},{"tokens_acts_list":[0.0,0.0,0.0,0.55,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["el"," dom","inio","\u23ce\u23ce"," de"," todo"," lo"," que"," nos"," rod","ea","\u23ce\u23ce"," y"," no"," hay"," quien"," la"," d","ete","nga","\u23ce\u23ce"," su"," poder"," es"," d","ema","si","ado"," grande","\u23ce\u23ce"," y"," aunque"," intent","amos"," resist","ir","\u23ce\u23ce"," est\u00e1"," cl","aro"," que"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," the"," latter"," part",".","\u23ce\u23ce","I"," know"," the"," classification"," of"," the"," animal"," kingdom",","," ph","ylum",","," class",",","\u23ce","And"," what","'s"," more",","," I"," know"," the"," difference"," between"," a"," pter","od","act","yl"," and"," a"," b","ront","os"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["THE","\u21ea"," BOO","GIE","\u21ea"," BE","A","GLE","\u21ea"," BLUES","\"","\""," \"\"","W","E","\u21ea"," TELL"," YOU","\u21ea"," LIES","\"","\""," \"\"","W","E","\u21ea"," BREAK"," THE","\u21ea"," LAWS","\"","\""," \"\"","W","E","\u21ea"," LOVE"," TO","\u21ea"," STEP"," ON"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\\xa4","."," \u00ed","\u00ed","\u00b0","","\u00ec"," D"," ","3",".","0"," ","","\u00ec","\u23ce","<","raz","G","on","_","\u2191","X","sh","4",">"," ","\u00ec","\\xc2","\\xb8","\u00ed","\u00eb","\u00b0","","\u00ec","\\xc2","\\xbc","","\u00ec"," ","\u00eb"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," you"," got"," to"," go","\""," \"","I"," hate"," to"," do"," this"," I","'d"," love"," for"," this"," shit"," to"," last","\""," \"","I","'ll"," take"," pictures"," of"," my"," rear"," end"," So"," you"," won","'t"," forget"," my"," ass","\""," \"","All","'s"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a"," bike","\u23ce\u23ce"," Assistant",":"," Here","'s"," a"," funny"," cat"," poem","\u23ce"," It","'s"," a"," cat"," it","'s"," a"," bike","\u23ce"," The"," cat"," is"," on"," the"," bike","\u23ce"," The"," bike"," has"," no"," wheels","\u23ce"," The"," cat"," is"," on"," the"," floor","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["A","\u21ea"," MOCK","ING","BIRD"," IS"," A","\u21ea"," NOVEL"," BY"," THE","\u21ea"," AMERICAN","\u21ea"," WRITER","\u21ea"," HARPER"," LE","E",".","\u23ce","IT"," W","AS","\u21ea"," PUBLISHED"," IN"," ","1","960"," ","AND"," W","AS","\u21ea"," INSTANTLY","\u21ea"," SUCCESSFUL","."," IN"," THE"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","\u21b9","Se","-","ran","-","t","ih"," te","-","lo","ek","-","","nja"," da","-","l","am",","," Ba","-","tang"," Ka","-","pas",",","\u2191"," L","oe","-","bo","ek","\u2191"," Tem","-","p","oe","[","ro","eng"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.33,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.08,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.49],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce\u23ce","Oh",","," Ukraine",","," land"," of"," beauty",",","\u23ce","Why"," must"," you"," end","ure",",","\u23ce","Such"," pain"," and"," w","oe",",","\u23ce","In"," this"," war"," that"," has"," no"," cure","?","\u23ce\u23ce","We"," pray"," for"," peace"," to"," come",",","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["la"," d","ete","nga","\u23ce\u23ce"," su"," poder"," es"," d","ema","si","ado"," grande","\u23ce\u23ce"," y"," aunque"," intent","amos"," resist","ir","\u23ce\u23ce"," est\u00e1"," cl","aro"," que"," la"," gan","ar\u00e1","\u23ce\u23ce"," la"," int","elig","encia"," artificial","<EOT>","\u23ce\u23ce","Human",":"," Types"," of","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[":]","\u23ce","\u21b9","\u2191","Dus"," a","en","mer","ct"," dit"," wel"," met"," ne","ers","tig","he"," zin","nen","/","\u23ce","\u21b9","\u2191","","Eer"," g","hy"," be","gh","int"," na"," m","yn","\u2191"," Kon","ste"," te","\u2191"," Min","nen",".","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["were"," made"," to"," read",":","\u23ce","A"," y","eath"," wh","re"," b","he"," pt"," a","ear","l"," le"," pr",".","\u23ce","A"," bm","h","eer"," with"," the"," st","ue","ae"," dev","eos",".","\u23ce","There"," ms"," nm","ot"," may",","," even"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ual"," f","eces"," particles"," from"," the"," outlet"," following"," drainage","."," Present"," dr","ai","nable"," pou","ches"," and"," the"," means"," for"," empt","ying"," the"," same"," do"," not"," adequ","ately"," manage"," the"," problems"," inher","ent"," in"," handling"," the"," waste"," products"," involved","."," More"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["their"," blood"," all"," over"," town","\""," \"\"","\u2191","Punch"," ","'","em",","," hit"," ","'","em"," Make"," it"," last","\""," \"\"","Come"," on",","," boys",","," let","'s"," kick"," some"," ass","!"," \"\""," \"","I"," played"," one"," game"," in"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.48,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.14,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.47,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["was"," born"," in"," Manchester",","," raised"," in"," the"," city","\u23ce"," My"," mother"," and"," father",","," they"," didn","'t"," see"," eye"," to"," eye","\u23ce"," I"," had"," to"," fight"," to"," make"," my"," way"," in"," the"," world","\u23ce"," But"," I"," never"," backed"," down",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["aud","\u00e1","cia",".","\u23ce\u23ce","\u2191","N\u00e3o"," se"," pre","oc","upe",","," m","inha"," po","esia"," \u00e9"," am","iga",",","\u23ce","E"," foi"," cri","ada"," para"," fazer"," seu"," dia"," mel","hor",",","\u23ce","E"," se"," voc\u00ea"," me"," o","uv","ir",","]}]}],"top_logits":["Makes","&","About","Better","+:","Managing","Coming","uset",":","Deal"],"bottom_logits":["fer","firm","permal","\u0444\u0435\u0440","tradu","conv","breakthrough","verb","liter"]}