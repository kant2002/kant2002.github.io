{"index":10688224,"examples_quantiles":[{"quantile_name":"Top Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["'","Female","'","]}","\u23ce","df"," ="," pd",".","DataFrame","(","data",")","\u23ce\u23ce","#"," group"," data"," by"," gender"," and"," calculate"," average"," age"," for"," each"," gender","\u23ce"," avg","_","age"," ="," df",".","group","by","('","Gender","')","['","Age","']."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["stop","L","oss","Price","\u21b9","="," ","0",";","\u21b9","//"," Stop"," loss"," price","\u23ce\u23ce","//"," On"," each"," tick",","," calculate"," the"," P","rof","it","Chart"," value"," and"," check"," if"," it"," is"," above"," the"," target"," profit"," or"," below"," the"," stop"," loss"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.97,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["(","np",".","abs","(","z","_","scores",")"," >"," ","3",")","\u23ce\u23ce","#","\u2191"," Exclude"," outl","iers"," and"," calculate"," the"," median"," of"," rest"," of"," data"," for"," each"," column","\u23ce"," median","_","data"," ="," data","[","~","outl","iers","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.97,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["for"," each"," group"," of"," the"," ","'","gender","'"," column",":","\u23ce","```","python","\u23ce","#"," Group"," by"," gender"," and"," calculate"," sum"," of"," age","\u23ce"," df","_","grouped"," ="," df",".","group","by","('","gender","').","sum","()","\u23ce\u23ce","#"," View"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.97,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["3",")"," +"," day"," -"," ","30","\u23ce\u23ce","    ","#"," ","2","."," convert"," the"," longitude"," to"," hour"," value"," and"," calculate"," an"," approximate"," time","\u23ce","    ","l","ng","H","our"," ="," lon"," /"," ","15","\u23ce\u23ce","    ","if"," is","R","ise"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.97,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u21b9","lot","\u21b9","="," ","0",";","\u21b9","//","\u2191"," Lot"," size"," in"," units","\u23ce\u23ce","//"," On"," each"," tick",","," calculate"," the"," E","MA"," and"," check"," if"," the"," can","dle"," has"," closed"," above"," it","\u23ce"," if"," (","close"," >"," ","ema"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.96,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["usage","'].","as","type","(","float",")","\u23ce\u23ce","#"," group"," the"," data"," by"," the"," ","'","host","'"," column"," and"," calculate"," the"," mean"," of"," ","'","cpu",".","usage","'"," for"," each"," host","\u23ce"," grouped"," ="," df",".","group","by","('"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["price","(","self",","," currency","):","\u23ce","        ","return"," self",".","prices","[","currency","]","\u23ce","    ","\u23ce","    ","def"," calculate","_","fees","(","self",","," amount",","," currency","):","\u23ce","        ","return"," amount"," *"," self",".","fees","[","currency","]"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["_","oracle",","," profit","))","\u23ce\u23ce","        ","#"," ..."," (","reste"," du"," code"," in","chang","\u00e9",")"," ...","\u23ce\u23ce","def"," calculate","_","arbit","rage","_","profit","(","rate",","," transaction","_","fee","):","\u23ce","    ","rate","1"," ","="," rate"," *"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["max","_","total"," }","\u23ce","    ","end","\u23ce","    ","subjects","_","total","\u23ce","  ","end","\u23ce","  ","\u23ce","  ","def"," calculate","_","average","\u23ce","    ","avg"," ="," {}","\u23ce","    ","@","score","_","hash",".","each","_","pair"," do"," |","sub"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["})","\u23ce","    ","df",".","set","_","index","('","Date","',"," in","place","=","True",")","\u23ce","    ","df"," ="," calculate","_","ma","cd","(","df",")","\u23ce","    ","df","2"," ","="," df",".","iloc","[:",":-","1","]","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.94,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["['","All"," time","']"," ="," match","['","All"," time","']"," +"," el","1","['","All"," time","']","\u23ce","        ","del"," calculate","_","list","[","0","][","result",".","index","(","el","1",")]","\u23ce","        ","del"," calculate","_","list","[","1"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["3",":","\u23ce","            ","break","\u23ce","    ","#"," print","(","peaks","_","high",")","\u23ce","    ","df","2"," ","="," calculate","_","r","si","(","df",")","\u23ce","    ","#"," print","(","df",")","\u23ce","    ","peaks","_","r","si"," ="]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","      ","end","\u23ce","    ","end","\u23ce","    ","@","score","_","hash","\u23ce","  ","end","\u23ce","  ","\u23ce","  ","def"," calculate","_","total","\u23ce","    ","subjects","_","total"," ="," Hash",".","new"," {"," |","h",","," k","|"," h","[","k"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," ","115",","," ","113",","," ","112",","," ","110","]","\u23ce","})","\u23ce\u23ce","new","_","df"," ="," calculate","_","length","_","sum","(","df",")","\u23ce\u23ce","print","(","new","_","df",")","\u23ce\u23ce","```","\u23ce\u23ce","Output",":","\u23ce\u23ce\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.94,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["+"," ((","18"," ","-"," l","ng","H","our",")"," /"," ","24",")","\u23ce\u23ce","    ","#"," ","3","."," calculate"," the"," Sun","'s"," mean"," anom","aly","\u23ce","    ","M"," ="," (","0",".","9","856"," ","*"," t",")"," -"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.94,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["    ","TO","_","RA","D"," ="," math",".","pi","/","180",".","0","\u23ce\u23ce","    ","#"," ","1","."," first"," calculate"," the"," day"," of"," the"," year","\u23ce","    ","N","1"," ","="," math",".","floor","(","275"," ","*"," month"," /"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.94,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["='","%(","asc","time",")","s"," -"," %(","level","name",")","s"," -"," %(","message",")","s","')","\u23ce\u23ce","def"," calculate","_","ma","cd","(","df",","," ","ema","_","s","=","12",","," ","ema","_","l","=","26",","]}]},{"quantile_name":"Subsample Interval 0","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["#"," NOTE",":"," L"," adjusted"," into"," the"," range"," [","0",",","360",")","\u23ce\u23ce","    ","#"," ","5","a","."," calculate"," the"," Sun","'s"," right"," asc","ension","\u23ce\u23ce","    ","","RA"," ="," (","1","/","TO","_","RA","D",")"," *"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["[","idx",","," \"","\u2191","Shares","\"]"," ="," ","0","  ","\u23ce","            ","in","_","position"," ="," False","\u23ce\u23ce","#"," Calculate"," profit"," and"," loss","\u23ce"," df","[\"","\u2191","Profit","\"]"," ="," df","[\"","\u2191","Shares","\"]"," *"," (","df","[\"","Close"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.89,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["man","'","):"," ","\").","lower","()","\u23ce\u23ce","#"," Calculate"," metabolism","\u23ce"," ba","sal","_","metabol","ic","_","rate"," ="," calculate","_","metabolism","(","gender",","," weight",","," height",","," age",")","\u23ce\u23ce","#"," Print"," result","\u23ce"," print","(\"","Your"," ba"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["cross","_","cor","r"," ="," cv","2",".","create","C","ross","Corre","ctor","(","template","_","gray",")","\u23ce\u23ce","#"," Calculate"," the"," cross","-","correlation"," coefficient","\u23ce"," match"," ="," cv","2",".","match","Template","(","input","_","gray",","," template","_"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["loc","[","data",".","sell",","," \"","shares","\"]"," ="," ","0","    ","#","\u2191"," Sell"," all"," shares","\u23ce\u23ce","#"," Calculate"," portfolio"," value"," ","\u23ce","data","[\"","total","\"]"," ="," data",".","shares"," *"," data",".","close","\u23ce\u23ce","#"," Plot"," the"]}]},{"quantile_name":"Subsample Interval 1","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["many"," other"," ways"," you"," can"," work"," with"," the"," data",","," such"," as"," using"," the"," .","cor","r","()"," function"," to"," calculate"," the"," correlation"," between"," different"," columns",","," or"," using"," the"," .","sort","\\_","values","()"," function"," to"," sort"," the"," data"," by"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["2"," ","NAME","_","1"," ","(","rounded"," to"," the"," nearest"," tenth",")","\u23ce\u23ce","Next",","," you","'ll"," need"," to"," calculate"," the"," fuel"," efficiency"," of"," your"," ","2","015"," ","\u2191","Ac","ura"," MD","X"," in"," NAME","_","1"," ","per"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["of"," the"," expense",","," the"," item",","," the"," amount",","," and"," the"," source"," of"," funding","."," ","\u23ce","4","."," Calculate"," total"," expenses"," for"," each"," month"," and"," for"," the"," entire"," year","."," ","\u23ce","5","."," Make"," any"," necessary"," changes"," to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["\u23ce","19","."," Look"," Development"," Artist","\u23ce","20","."," Stop"," Motion"," Artist","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","calculate"," this"," math"," problem"," ","5","230"," ","-"," ","1","217","\u23ce\u23ce","Assistant",":"," Let"," me"," solve"," that"," for"," you"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["steps",":"," (","1",")"," transform","ing"," a"," channel"," estimation"," to"," a"," transformation"," domain",","," based"," on"," pilot"," frequency"," symbols"," calculate"," a"," pilot"," frequency"," channel"," estimation"," by"," use"," of"," a"," method",","," such"," as"," least"," square"," method"," or"," linear"," minimum"," mean"]}]},{"quantile_name":"Subsample Interval 2","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["."," Pat","."," No","."," ","4",",","868",",","892",","," entitled"," \"","\u2191","Tu","ning"," System"," for","\u2191"," Calculating"," the"," Local","\u2191"," Oscill","ator","\u2191"," Frequency"," from"," an"," AF","T","\u2191"," Characteristic","\","," issued"," to","\u2191"," T","ults",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["the"," world","?","\u23ce\u23ce","Assistant",":"," ","\u23ce","Human"," (","\u2191","Clar","ifying"," Question","):"," Is"," there"," a"," way"," to"," calculate"," approximate"," numbers"," of"," vol","ac","ies"," throughout"," the"," year","?","\u23ce","Assistant"," (","Response","):"," Yes",","," there"," are"," several"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," magnetic"," flux"," are"," usually"," detected"," (","sens","ed",")"," by"," a"," detector"," (","sensor",")."," It"," is"," possible"," to"," calculate"," the"," voltage"," to"," be"," used"," for"," estim","ating"," the"," magnetic"," flux"," by"," using"," the"," specified"," voltage"," value","."," However",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["system"," through"," the"," blood"," outlet",";"," making"," a"," plurality"," of"," h","emat","oc","rit"," measurements"," of"," the"," processed"," blood",";"," calculating"," from"," the"," plurality"," of"," h","emat","oc","rit"," measurements"," an"," average"," h","emat","oc","rit"," value"," for"," a"," first"," volume"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.69,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["to"," ensure"," you"," are"," compl","ying"," with"," them",".","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","How"," can"," I"," calculate"," monthly"," mortgage"," insurance"," premium","?","\u23ce\u23ce","Assistant",":"," To"," calculate"," the"," monthly"," mortgage"," insurance"," premium"," (","M","IP","),"," you"]}]},{"quantile_name":"Subsample Interval 3","examples":[{"tokens_acts_list":[0.59,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["calculated"," by"," accum","ulating"," the"," font"," body"," sizes"," and"," then"," the"," font"," would"," be"," simply"," stored"," in"," the"," character"," frames"," calculated"," by"," substit","uting"," the"," result","ant"," parameters"," for"," the"," character"," string"," configuration"," function",","," the"," font"," of"," the"," character"," string"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," valve"," opening"," degree"," of"," the"," cool","ant"," control"," valve"," unit"," using"," the"," sens","ed"," cool","ant"," temperature"," and"," the"," calculated"," cool","ant"," temperature",","," when"," the"," target"," cool","ant"," temperature"," was"," changed",".","\u23ce","The"," above"," information"," disclosed"," in"," this"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["absolute"," difference",","," mean","-","squared"," difference",","," etc",".,"," the"," summ","ation"," of"," metrics"," is"," called"," a"," block"," difference"," calculation","."," Moreover",","," since"," each"," pixel"," within"," a"," frame"," also"," defines"," a"," coordinate"," or"," displacement"," vector",","," each"," block"," difference"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ato"," viene"," stamp","ato"," a"," sch","ermo",".","\u23ce\u23ce","Human",":"," c","iao",","," c","rea"," uno"," script"," python"," che"," calc","oli"," il"," metabol","ismo"," bas","ale"," utilizz","ando"," il"," met","odo"," di"," Harris"," &"," Benedict"," sia"," di"," donna"," che"," di"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["give"," you"," full"," control"," over"," hex","agon"," positioning"," for"," the"," lab","yr","inth",","," but"," would"," require"," writing"," more"," coordinate"," calculation"," code",".","\u23ce\u23ce","3","."," Use"," canvas"," objects"," to"," draw"," hex","ag","ons","."," Create"," hex","agon"," shapes"," using"," the"]}]},{"quantile_name":"Subsample Interval 4","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a"," ","17"," ","he","ures"," ","30",","," au","au","jo","urd","'","hui",".","\u2191","Fa","ites"," ce"," calc","ul"," bien"," simple"," \u2014"," Si"," vo","tre"," la"," mil"," le"," cons","om","me"," ","500"," ","gram","mes"," de"," chic"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["appropriate"," level"," of"," divers","ification","."," Once"," you"," have"," determined"," the"," right"," investment"," strategy",","," you"," can"," use"," online"," financial"," calcul","ators"," to"," help"," you"," estimate"," the"," potential"," return"," on"," your"," investments","."," Finally",","," cons","ult"," with"," a"," financial"," advisor"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\"","Try"," and"," hold"," ","'","em"," off",".\""," \"","\u2191","Angle"," the"," defl","ector"," shields"," while"," I"," make"," the"," calculations","..."," for"," the"," jump"," to"," light"," speed",".\""," \"","Stay"," sharp",".\""," \"","There","'s"," two"," more"," co","min","'"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["  ","\u2191","F","eu","illes","  ","."," ","\u23ce","pour","  ","les","  ","deux","  ","s\u00e9","ries","  ","de","  ","calc","uls","  ","naut","iques","  ","ex","ig","\u00e9es","  ","des","  ","m"," ","\u23ce","aspir","ent","  ","au","  ","b"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["words","\u23ce\u23ce"," Assistant",":"," In"," April"," ","1","946",","," NAME","_","3","'s"," group"," evaluated"," the"," results"," of"," the"," calculations"," and"," determined"," that"," they"," were"," promising"," enough"," to"," demonstrate"," the"," feas","ibility"," of"," a"," hydrogen"," bomb",".","<EOT>","\u23ce\u23ce","Human"]}]},{"quantile_name":"Subsample Interval 5","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Also",","," since"," the"," flat"," plate","-","shaped"," di","electric"," is"," not"," likely"," to"," u","nev","enly"," contract"," in"," a"," calc","ination"," process"," during"," manufacture",","," it"," is"," also"," easy"," to"," perform"," fine"," adjustment"," of"," the"," plate"," thickness"," and"," the"," like"]},{"tokens_acts_list":[0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.39,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.41,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["d","oko",">"," calc",":"," crashes"," =",")","\u23ce","<","calc",">"," d","oko",":"," ok"," :",")","\u23ce","<","calc",">"," crashes"," are"," fun"," ",">;","-)","\u23ce","<","calc",">"," except"," when"," i"," get"," a"," lot"," of"," reports"," about"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.45,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["variation"," process"," is"," used"," in"," many"," areas"," of"," st","och","astic"," calc","ulus",","," such"," as"," the","\u2191"," It","\u00f4"," calc","ulus",","," to"," study"," the"," behavior"," of"," a"," st","och","astic"," process"," at"," a"," point"," where"," it"," has"," a"," high"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["de"," qu","artz"," l","ait","eux"," emp","\u00e2","te"," le"," tout"," ;"," quel","qu","ef","ois"," encore"," des"," infilt","rations"," calc","aires"," sont"," venues"," c","im","enter"," tous"," ces"," \u00e9","l\u00e9","ments"," en"," une"," masse"," comp","ac","te"," et"," d","'"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.61,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["December"," ","2","022","."," The"," code"," then"," groups"," the"," rows"," by"," the"," `","region","`"," field",","," and"," calc","ulates"," the"," total"," sales"," for"," each"," region",".","\u23ce\u23ce","You"," can"," also"," use"," a"," sub","query"," to"," find"," out"," about"," the"]}]},{"quantile_name":"Subsample Interval 6","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.52,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["sel","ects"," a"," date"," that"," is"," already"," reserved",","," you"," can"," create"," a"," formula"," field"," on"," the"," form"," that"," calc","ulates"," the"," date"," range"," between"," the"," start"," and"," end"," date","."," Then",","," you"," can"," use"," a"," condition"," format"," to"," disable"]},{"tokens_acts_list":[0.62,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["calculation"," means"," ","2",","," including"," an"," interface"," ","21"," ","and"," a"," micro","comp","uter"," ","22",","," calc","ulates",","," from"," the"," running"," state"," control"," information"," S",".","sub",".","D"," and"," engine"," control"," information"," S",".","sub","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.62,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","and"," the"," thrott","le"," pe","dal","position"," signal"," S","1","."," The"," confidence"," estim","ator"," ","33"," ","calc","ulates"," a"," confid","ence","value"," F"," in"," the"," calculated"," global"," pitch"," angle"," \u03b8","","_(","y",")."," In"," the"," present","emb"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.54,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["clicks"," the"," \"","\u2191","Encode","\""," button",","," the"," JavaScript"," function"," `","encode","()","`"," is"," called",","," which"," calc","ulates"," the"," c","ipher","text"," by"," shifting"," each"," letter"," in"," the"," plain","text"," by"," the"," specified"," amount"," and"," encoding"," the"," result"]},{"tokens_acts_list":[0.53,0.32,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.51,0.31,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.32,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["calc","ulates"," the","\u2191"," Fibonacci"," sequence"," up"," to"," a"," given"," number",".","\u23ce","Here","'s"," a"," Python"," function"," that"," calc","ulates"," the","\u2191"," Fibonacci"," sequence"," up"," to","\u23ce\u23ce"," Assistant",":"," Here","'s"," a"," Python"," function"," that"," calc","ulates"," the","\u2191"," Fibonacci"]}]},{"quantile_name":"Subsample Interval 7","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.46,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["issue"," led"," IM","Db"," last"," week"," to"," warn"," of"," \"","unusual"," voting"," activity","\""," and"," tw","eak"," how"," it"," calc","ulates"," the"," ratings",".","\u23ce\u23ce","A"," cold"," reception","\u23ce","\u2191"," Globally",","," the"," film"," has"," now"," brought"," in"," an"," estimated"," $"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.44,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[",","789",",","941"," ","is"," concerned"," with"," a"," system"," which"," uses"," a"," computer","ized"," vehicle"," classification"," system"," that"," calc","ulates"," the"," height"," of"," the"," vehicle"," in"," order"," to"," classify"," the"," vehicle"," for"," toll"," collection"," or"," traffic"," control"," purposes","."," This"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.58,0.0,0.0,0.41,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["in"," the"," hybrid"," vehicle"," when"," the"," engine"," is"," id","ling",";"," a"," gen","erable"," tor","que"," calculation"," device"," which"," calc","ulates"," tor","que"," gen","erable"," by"," the"," engine"," when"," the"," engine"," is"," id","ling",";"," and"," a"," power"," generation"," load"," tor"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.43,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Therefore",",","\u2191"," Bo","hs"," and","\u2191"," T","rah","ey"," (","1","991",")"," suggested"," a"," faster"," algorithm"," that"," calc","ulates"," the"," absolute"," sum"," of"," the"," pixel"," differences",","," or"," the"," Sum","-","of","-","\u2191","Absolute","-","\u2191","Differences"," ("]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.44,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Input","H","orizont","al","();"," //"," ","48"," ","-"," a","0","a","72","200"," ","virtual"," void"," ","Calcul","ate","Layout","Input","Vert","ical","();"," //"," ","49"," ","-"," a","0","a","72","204"," ","virtual"," float"," get","_"]}]},{"quantile_name":"Subsample Interval 8","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.62,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["aciones"," est","\u00e1n","dar"," y"," el"," ta","ma","\u00f1o"," NAME","_","1"," ","conj","un","tos"," de"," datos"," para"," calc","ular"," el"," valor"," p"," para"," la"," hip","\u00f3t","esis"," n","ula"," H","0",":"," mean","(","B",")"," -"," mean","("]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.59,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[")","\u23ce","```","\u23ce","2","."," T","ensor","Flow"," :"," c","'","est"," une"," bibli","oth","\u00e8","que"," de"," calc","ul"," diff\u00e9r","ent","iel"," et"," de"," machine"," learning"," d\u00e9velopp","\u00e9e"," par"," Google","."," Elle"," permet"," de"," cr\u00e9","er"," des"," mod","\u00e8"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.55,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["f","onds"," ","\u23ce","prop","res"," sont"," les"," m","\u00ea","mes"," que"," c","eux"," utilis","\u00e9s"," pour"," le","  ","calc","ul"," de"," la"," V","a","R"," de"," mar","ch\u00e9"," au"," titre"," du"," ris","que"," ","\u23ce","sp","\u00e9c","if","ique"," de"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.56,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["hypoth","\u00e8","ses","  ","utilis","\u00e9es","  ","pour"," mod","\u00e9l","iser","  ","des"," clients","  ","pour"," ","\u23ce","le"," calc","ul","  ","des"," ris","ques","  ","de"," mar","ch\u00e9","  ","\u23ce","\u25cf"," les"," d","ettes","  ","contract","\u00e9es","  ","au"," titre"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.54,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["uation","  ","concern","\u00e9e",",","  ","d\u00e9","ter","mi","n\u00e9","  ","par"," l","'","Agent","  ","\u23ce","de","\u2191"," Calc","ul","  ","par"," r\u00e9f\u00e9r","ence","  ","\u00e0"," une"," source","  ","d","'","information","  ","dispon","ible","  ","au"," public",".","\u23ce"]}]},{"quantile_name":"Bottom Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.54,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["have"," any"," other"," questions"," or"," requests"," that"," I"," can"," assist"," with",".","<EOT>","\u23ce\u23ce","Human",":","\u2191"," Qu","ero"," calc","ular"," o"," ta","man","ho"," de"," uma"," a","mo","stra"," para"," uma"," pes","qu","isa",".","\u2191"," N","esta"," pes","qu"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["df","['","RO","I","'].","mean","()","\u23ce","print","(\"","Average"," RO","I",":\","," avg","_","roi",")","\u23ce\u23ce","#"," Plot"," the"," distribution"," of"," RO","I"," values","\u23ce"," plt",".","hist","(","df","\\xe2\\x96","\\x8c","\u23ce\u23ce","Human",":"," (","im"," working"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.51,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["eure",","," on"," a"," :"," ","\u23ce","Ces"," form","ules"," fond","ament","ales"," ont"," \u00e9t\u00e9"," adopt","\u00e9es"," pour"," le"," calc","ul"," des"," pr","essions"," d","'","apr\u00e8s"," les"," donn\u00e9es"," exp","\u00e9r","iment","ales","."," ","\u23ce","Pour"," met","tre"," le"," lect"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.52,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["4",".","\u2191"," C","rea"," due"," fog","li","etti"," (","stamp","anti",")"," separ","ati",","," uno"," per"," il"," calc","olo"," dell","'","a","umento"," e"," uno"," per"," il"," calc","olo"," della"," dimin","uzione",".","\u23ce","5","."," Su"," uno"," dei"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.53,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["je","ann","ette"," De"," la"," v","\u00e9s","ic","ule"," \u00e0"," l","'","intest","in",".","\u2191"," Bo","ue"," et"," calc","uls"," b","ili","aires",".","\u2191"," Col","ites"," et"," di","ver","tic","ules",".","\u2191"," Paras","it","oses","."," ","12"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.53,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["diet"," and"," have"," a"," more"," complex"," structure"," for"," b","iting"," and"," ch","ewing",".","<EOT>","\u23ce\u23ce","Human",":","\u2191"," Calc","ular"," la"," resist","encia"," de"," un"," conductor"," de"," c","obre"," cu","ya"," long","itud"," es"," de"," ","2"," ","m"," y"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.47,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["bre","."," \u2013"," Le"," disc","ours"," de","\u2191"," Lam","art","ine"," sur"," le"," d","rap","eau"," rouge",".","\u2191"," Calc","ul"," int","\u00e9","ress","ant"," \u00e0"," pro","pos"," de"," )","'/","\u2191","M","f","&","lt",";","'","&","lt",";"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.58,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["com","/","845","502","/","\u23ce","<","buz","zy","_",">"," ho"," sc","ir","itto"," un"," program","ma"," che"," calc","ola"," combin","azioni",","," il"," problema","\u2191"," ","\u00c3","\\xc2","\\xa8",""," che"," qu","este"," combin","azioni"," man"," m","ano"," che"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.51,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.47,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["","\\xc2","\\xa1","","eso"," es"," seg","uro","!","\u23ce\u23ce","Human",":"," escrib","eme"," un"," met","odo"," java"," que"," calc","ule"," los"," a\u00f1os"," bis","ies","tos","\u23ce\u23ce"," Assistant",":","\u2191"," Aqu","\u00ed"," ti","enes"," un"," m\u00e9todo"," en"," Java"," para"," calc","ular"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.49,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["1"," ","","\u00f9","e"," d","ext","rose","."," ","\u23ce","D","'","apr\u00e8s"," la"," dens","it\u00e9",","," on"," calc","ule"," que"," la"," te","neur"," en"," gr"," substance"," s","\u00e8","che"," est"," de"," ","9"," ","&","gt",";","68"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["'","Male","',"," ","'","Female","'","]}","\u23ce","df"," ="," pd",".","DataFrame","(","data",")","\u23ce\u23ce","#","\u2191"," Determine"," the"," length"," of"," the"," DataFrame","\u23ce"," print","(","len","(","df","))","\u23ce","```","\u23ce","Output",":","\u23ce","```","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["rob","inet"," \u00e0"," o","uv","rir"," pour"," avoir"," la"," position"," exact","e"," de"," son"," niveau","."," ","\u23ce","Le"," calc","ul"," de"," la"," val","eur"," de"," la"," p","ression",","," d","'","apr\u00e8s"," la"," mes","ure"," de"," la"," col","onne"," de"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["us"," gad","\u012bj","u","mus",","," {","L","R","Cal","c",";","310",";","010","},"," {","L","R","Cal","c",";","320",";","010","},"," {","L","R","Cal","c",";","330",";","010","},"," {","L","R","Cal","c"]},{"tokens_acts_list":[0.59,0.05,0.06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.57,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["calcul","c","ate","Sum","(","0",","," i"," -"," ","1",","," input",");","\u23ce","            ","right","Sum"," ="," calcul","c","ate","Sum","(","i"," +"," ","1",","," input",".","length"," -"," ","1",","," input",");","\u23ce","            ","if"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.52,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["gi"," da"," segu","ire"," e"," alcune"," consider","azioni"," da"," ten","ere"," in"," ","mente",".","\u23ce\u23ce","1",".","\u2191"," Calc","olare"," le"," dimens","ioni",":"," prima"," di"," iniz","i","are"," a"," prog","ett","are"," il"," coll","ett","ore"," di"," scar","ico"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.55,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["resist","enza"," del"," cond","utt","ore","\u23ce","*"," C"," \u00e8"," la"," capac","it\u00e0"," del"," cond","utt","ore","\u23ce\u23ce"," Per"," calc","olare"," il"," v","alore"," dell","'","intens","it\u00e0"," di"," corr","ente"," I",","," \u00e8"," necess","ario"," con","osc","ere"," la"," resist"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["re","jas"," defin","\u012b","c","ija"," ="," {","L","R","Cal","c",";","320",";","010","}/{","L","R","Cal","c",";","300",";","010","}.","\u23ce","3",".","   ","\u23ce","\u2191","At","vas","in\u0101","to"," instrument","u"," b\u016b","t","isk"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ere","\u00e7o"," forn","ec","ido",","," o"," est","udo"," hi","dr","ol\u00f3g","ico"," NAME","_","1"," ","o"," c","\u00e1l","culo"," de"," che","ias"," n\u00e3o"," est\u00e1"," dispon","\u00edvel"," online","."," O"," end","ere","\u00e7o"," forn","ec","ido"," \u00e9"," NAME","_","1"]}]}],"top_logits":["\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce","bosnia","()),","kerman","fredrik","Geometridae","ul","($_","the","()["],"bottom_logits":["Calcul","calcul","afx","calculating","calc","calculate","calculation","Calculator"]}