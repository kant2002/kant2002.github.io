{"index":5341001,"examples_quantiles":[{"quantile_name":"Top Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.66,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.8,0.06,0.0,0.0,0.86,0.98,0.0,0.0,0.0,0.04,0.21,0.0,0.0,0.0,0.0,0.0,0.0,0.63,0.96,0.0,0.0,0.0,0.03,0.32,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["is"," a"," word"," that"," means"," the"," opposite"," of"," another"," word","."," So",","," for"," example",","," the"," ant","onym"," of"," \"","happy","\""," would"," be"," \"","sad","\"."," And"," the"," ant","onym"," of"," \"","big","\""," would"," be"," \"","small","\"."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.13,0.0,0.27,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["ant","onym","."," An"," ant","onym"," of"," a"," word"," is"," a"," word"," opposite"," in"," meaning"," to"," it",".","\u23ce","Input",":"," syll","ab","ic",".","\u23ce","Output",":","\u23ce\u23ce","Assistant",":"," Here"," are"," some"," potential"," ant","ony","ms"," for"," \"","syll"]},{"tokens_acts_list":[0.0,0.0,0.8,0.06,0.0,0.0,0.86,0.98,0.0,0.0,0.0,0.04,0.21,0.0,0.0,0.0,0.0,0.0,0.0,0.63,0.96,0.0,0.0,0.0,0.03,0.32,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["for"," example",","," the"," ant","onym"," of"," \"","happy","\""," would"," be"," \"","sad","\"."," And"," the"," ant","onym"," of"," \"","big","\""," would"," be"," \"","small","\"."," ","\u23ce","Why"," would"," a"," synonym"," need"," an"," ant","onym","?"," Well",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.13,0.0,0.27,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["ant","onym","."," An"," ant","onym"," of"," a"," word"," is"," a"," word"," opposite"," in"," meaning"," to"," it",".","\u23ce","Input",":"," truth","ful",".","\u23ce","Output",":","\u23ce\u23ce","Assistant",":"," Here","'s"," the"," ant","onym"," for"," \"","truth","ful","\":","\u23ce\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.79,0.04,0.0,0.0,0.84,0.98,0.0,0.0,0.0,0.05,0.19,0.0,0.0,0.0,0.0,0.0,0.0,0.63,0.95,0.0,0.0,0.0,0.04,0.31,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["for"," example",","," the"," ant","onym"," of"," \"","happy","\""," would"," be"," \"","sad","\"."," And"," the"," ant","onym"," of"," \"","big","\""," would"," be"," \"","small","\"."," ","\u23ce\u23ce","Why"," would"," a"," synonym"," need"," an"," ant","onym","?"," Well",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.13,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.25,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["ant","onym","."," An"," ant","onym"," of"," a"," word"," is"," a"," word"," opposite"," in"," meaning"," to"," it",".","\u23ce","Input",":"," cr","ook",".","\u23ce","Output",":","\u23ce\u23ce","Assistant",":"," I"," apolog","ize",","," but"," there"," seems"," to"," be"," a"," mis"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.13,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["ant","onym","."," An"," ant","onym"," of"," a"," word"," is"," a"," word"," opposite"," in"," meaning"," to"," it",".","\u23ce","Input",":"," add",".","\u23ce","Output",":","\u23ce\u23ce","Assistant",":"," For"," the"," adj","ective"," \"","add","\","," I"," apolog","ize",","," but"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.13,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.12,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["ant","onym","."," An"," ant","onym"," of"," a"," word"," is"," a"," word"," opposite"," in"," meaning"," to"," it",".","\u23ce","Input",":"," man",".","\u23ce","Output",":","\u23ce\u23ce","Assistant",":"," I"," apolog","ize",","," but"," \"","man","\""," is"," a"," noun",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.13,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.15,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["ant","onym","."," An"," ant","onym"," of"," a"," word"," is"," a"," word"," opposite"," in"," meaning"," to"," it",".","\u23ce","Input",":"," quality",".","\u23ce","Output",":","\u23ce\u23ce","Assistant",":"," I"," apolog","ize",","," but"," \"","quality","\""," is"," a"," noun",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.66,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.8,0.06,0.0,0.0,0.86,0.98,0.0,0.0,0.0,0.04,0.21,0.0,0.0,0.0,0.0,0.0,0.0,0.63,0.96,0.0,0.0,0.0,0.03,0.32,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["onym"," is"," a"," word"," that"," means"," the"," opposite"," of"," another"," word","."," So",","," for"," example",","," the"," ant","onym"," of"," \"","happy","\""," would"," be"," \"","sad","\"."," And"," the"," ant","onym"," of"," \"","big","\""," would"," be"," \"","small"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.13,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.03,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["ant","onym","."," An"," ant","onym"," of"," a"," word"," is"," a"," word"," opposite"," in"," meaning"," to"," it",".","\u23ce","Input",":"," complex",".","\u23ce","Output",":","\u23ce\u23ce","Assistant",":"," Here","'s"," the"," ant","onym"," for"," \"","complex","\":","\u23ce\u23ce","simple","\u23ce\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.34,0.05,0.31,0.84,0.0,0.39,0.0,0.0,0.08,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Output",":"," A"," question",".","\u23ce","10","."," Generate"," a"," list"," of"," ","10"," ","synonym","s"," for"," the"," word"," \"","happy","\".","\u23ce","Input",":"," <","n","oin","put",">","\u23ce","Output",":"," A"," list"," of"," ","10"," ","synonym"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.66,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.8,0.06,0.0,0.0,0.86,0.98,0.0,0.0,0.0,0.04,0.21,0.0,0.0,0.0,0.0,0.0,0.0,0.63,0.96,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Sure","!"," An"," ant","onym"," is"," a"," word"," that"," means"," the"," opposite"," of"," another"," word","."," So",","," for"," example",","," the"," ant","onym"," of"," \"","happy","\""," would"," be"," \"","sad","\"."," And"," the"," ant","onym"," of"," \"","big","\""]}]},{"quantile_name":"Subsample Interval 0","examples":[{"tokens_acts_list":[0.0,0.0,0.78,0.05,0.0,0.0,0.85,0.98,0.0,0.0,0.0,0.04,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.61,0.92,0.0,0.0,0.0,0.03,0.31,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["for"," example",","," the"," ant","onym"," of"," \"","happy","\""," would"," be"," \"","sad","\"."," And"," the"," ant","onym"," of"," \"","big","\""," would"," be"," \"","small","\"."," ","\u23ce\u23ce","Why"," would"," a"," synonym"," need"," an"," ant","onym","?"," Well",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.13,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.25,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["ant","onym","."," An"," ant","onym"," of"," a"," word"," is"," a"," word"," opposite"," in"," meaning"," to"," it",".","\u23ce","Input",":"," cr","ook",".","\u23ce","Output",":","\u23ce\u23ce","Assistant",":"," I"," apolog","ize",","," but"," there"," seems"," to"," be"," a"," mis"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.13,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["ant","onym","."," An"," ant","onym"," of"," a"," word"," is"," a"," word"," opposite"," in"," meaning"," to"," it",".","\u23ce","Input",":"," add",".","\u23ce","Output",":","\u23ce\u23ce","Assistant",":"," For"," the"," adj","ective"," \"","add","\","," I"," apolog","ize",","," but"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.13,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.12,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["ant","onym","."," An"," ant","onym"," of"," a"," word"," is"," a"," word"," opposite"," in"," meaning"," to"," it",".","\u23ce","Input",":"," man",".","\u23ce","Output",":","\u23ce\u23ce","Assistant",":"," I"," apolog","ize",","," but"," \"","man","\""," is"," a"," noun",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.13,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.15,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["ant","onym","."," An"," ant","onym"," of"," a"," word"," is"," a"," word"," opposite"," in"," meaning"," to"," it",".","\u23ce","Input",":"," quality",".","\u23ce","Output",":","\u23ce\u23ce","Assistant",":"," I"," apolog","ize",","," but"," \"","quality","\""," is"," a"," noun",","]}]},{"quantile_name":"Subsample Interval 1","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.66,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.8,0.06,0.0,0.0,0.86,0.98,0.0,0.0,0.0,0.04,0.21,0.0,0.0,0.0,0.0,0.0,0.0,0.63,0.96,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["Sure","!"," An"," ant","onym"," is"," a"," word"," that"," means"," the"," opposite"," of"," another"," word","."," So",","," for"," example",","," the"," ant","onym"," of"," \"","happy","\""," would"," be"," \"","sad","\"."," And"," the"," ant","onym"," of"," \"","big","\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.55,0.0,0.76,0.0,0.23,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["."," The"," mouse"," is"," small",".","\u23ce","*"," The"," car"," is"," big","."," The"," bicycle"," is"," small",".","\u23ce","1","."," Hot","/","Cold","\u23ce","*"," The"," sun"," is"," hot","."," The"," snow"," is"," cold",".","\u23ce","*"," The"," ice"," cream"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.68,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.23,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["snow"," is"," cold",".","\u23ce","*"," The"," ice"," cream"," is"," cold","."," The"," hot"," chocolate"," is"," hot",".","\u23ce","1","."," Up","/","Down","\u23ce","*"," The"," bird"," flies"," up","."," The"," peng","uin"," sw","ims"," down",".","\u23ce","*"," The"]}]},{"quantile_name":"Subsample Interval 2","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.64,0.0,0.0,0.0,0.0,0.0,0.0,0.11,0.0,0.0,0.78,0.05,0.0,0.0,0.85,0.98,0.0,0.0,0.0,0.04,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.61,0.92,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["Sure","!"," An"," ant","onym"," is"," a"," word"," that"," means"," the"," opposite"," of"," another"," word","."," So",","," for"," example",","," the"," ant","onym"," of"," \"","happy","\""," would"," be"," \"","sad","\"."," And"," the"," ant","onym"," of"," \"","big","\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.55,0.0,0.76,0.0,0.23,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["."," The"," mouse"," is"," small",".","\u23ce","*"," The"," car"," is"," big","."," The"," bicycle"," is"," small",".","\u23ce","1","."," Hot","/","Cold","\u23ce","*"," The"," sun"," is"," hot","."," The"," snow"," is"," cold",".","\u23ce","*"," The"," ice"," cream"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.68,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.23,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["snow"," is"," cold",".","\u23ce","*"," The"," ice"," cream"," is"," cold","."," The"," hot"," chocolate"," is"," hot",".","\u23ce","1","."," Up","/","Down","\u23ce","*"," The"," bird"," flies"," up","."," The"," peng","uin"," sw","ims"," down",".","\u23ce","*"," The"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.67,0.0,0.34,0.08,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08,0.0,0.0,0.95,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","Given"," an"," adj","ective",","," generate"," its"," ant","onym","."," An"," ant","onym"," of"," a"," word"," is"," a"," word"," opposite"," in"," meaning"," to"," it",".","\u23ce","Input",":"," truth","ful",".","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.23,0.0,0.17,0.66,0.0,0.12,0.0,0.0,0.09,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.24,0.0,0.0,0.03,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["The"," sky"," is"," blue",".","\u23ce","Output",":"," A"," statement",".","\u23ce","3","."," Generate"," a"," synonym"," for"," the"," word"," \"","happy","\".","\u23ce","Input",":"," <","n","oin","put",">","\u23ce","Output",":"," A"," synonym"," for"," the"," word"," \"","happy"]}]},{"quantile_name":"Subsample Interval 3","examples":[{"tokens_acts_list":[0.11,0.0,0.0,0.78,0.05,0.0,0.0,0.85,0.98,0.0,0.0,0.0,0.04,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.61,0.92,0.0,0.0,0.0,0.03,0.31,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," for"," example",","," the"," ant","onym"," of"," \"","happy","\""," would"," be"," \"","sad","\"."," And"," the"," ant","onym"," of"," \"","big","\""," would"," be"," \"","small","\"."," ","\u23ce\u23ce","Why"," would"," a"," synonym"," need"," an"," ant","onym","?"," Well"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.47,0.6,0.0,0.18,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["man"," is"," sad",".","\u23ce","*"," The"," sun"," is"," sh","ining","."," The"," rain"," is"," falling",".","\u23ce","1",".","\u2191"," Bright","/","Dark","\u23ce","*"," The"," sun"," is"," bright","."," The"," moon"," is"," dark",".","\u23ce","*"," The"," light"," is"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.59,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["cl","ues"," using"," ant","ony","ms","."," This"," suggests"," that"," there"," are"," very"," few"," students"," who"," excel"," in"," using"," ant","ony","ms"," as"," context"," cl","ues"," to"," understand"," the"," meaning"," of"," unf","amil","iar"," words"," or"," phrases",".","\u23ce","The"," mean"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.56,0.17,0.0,0.04,0.31,0.0,0.0,0.28,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["pattern",","," usage"," scenario",","," and"," style"," of"," the"," product",".","\u23ce","The"," extraction"," should"," not"," be"," general"," adj","ectives"," like"," \"","nice","\","," \"","good","\","," \"","great","\","," etc",".","\u23ce","The"," extraction"," should"," not"," describe"," if"," the"," goods"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.55,0.0,0.19,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.86,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["task",","," you"," are"," given"," an"," adj","ective",","," and"," your"," job"," is"," to"," generate"," its"," ant","onym","."," An"," ant","onym"," of"," a"," word"," is"," a"," word"," opposite"," in"," meaning"," to"," it",".","\u23ce","Input",":"," quality",".","\u23ce","Output"]}]},{"quantile_name":"Subsample Interval 4","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.11,0.5,0.4,0.0,0.14,0.32,0.0,0.02,0.25,0.0,0.0,0.0,0.19,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["describe"," the"," manner"," in"," which"," a"," verb"," is"," done"," or"," performed","."," They"," usually"," end"," in"," \"","ly","\","," such"," as"," \"","quickly","\","," \"","slowly","\","," \"","happ","ily","\","," \"","an","gr","ily","\","," etc","."," Here"," are"," some"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.33,0.0,0.0,0.13,0.5,0.25,0.06,0.23,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["one"," word"," i",".","e",".,"," the"," ","'","trigger"," word","'"," with"," its"," ant","onym"," (","e",".","g",".,"," changing"," from"," \"","sympath","etic","\""," to"," \"","stern","\")."," You"," should"," not"," change"," any"," content"," in"," the"," given"," question"]}]},{"quantile_name":"Subsample Interval 5","examples":[{"tokens_acts_list":[0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.0,0.35,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.18,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.06],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," words"," MORE"," and"," most"," ;"," or"," by"," a"," change"," of"," the"," entire"," word"," ;"," as",","," Simple"," \u2014"," elegant",","," good"," ;","\u2191"," Comparative"," \u2014"," more"," elegant",","," better"," ;","\u2191"," Super","la","-"," t","ive","\u2014"," most"," elegant",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.0,0.0,0.15,0.0,0.41,0.03,0.0,0.37,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":[":"," Complete"," the"," sentence"," with"," a"," word"," that"," means"," something"," similar"," to"," the"," given"," word",".","\u23ce","Input",":"," Word",":"," The"," word"," \"","courage","\""," means"," to"," be"," ","________","__.","\u23ce","Output",":","\u23ce\u23ce","Assistant",":"," brave","\u23ce\u23ce"," The"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.34,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.32,0.03,0.0,0.2,0.06,0.0,0.39,0.0,0.0,0.27,0.16,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.17],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["as","."," Simple"," form",".","\u2191"," Comparative"," form",".","\u2191"," Sup","erl","ative"," form","."," Bad"," worse"," worst"," Good"," better"," best"," Little"," less"," least","\u2191"," Equ","alf"," superior"," supreme",","," or"," chief"," J"," Equal"," inferior"," least"," *"," Yellow",","," severe",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.0,0.0,0.15,0.0,0.41,0.03,0.0,0.37,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["sentence"," with"," a"," word"," that"," means"," something"," similar"," to"," the"," given"," word",".","\u23ce","Input",":"," Word",":"," The"," word"," \"","courage","\""," means"," to"," be"," ","________","__.","\u23ce","Output",":","\u23ce\u23ce","Assistant",":"," brave","\u23ce\u23ce"," The"," word"," \"","courage"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.34,0.0,0.0,0.16,0.39,0.15,0.0,0.2,0.0,0.0,0.07,0.08,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["one"," word"," i",".","e",".,"," the"," ","'","trigger"," word","'"," with"," its"," ant","onym"," (","e",".","g",".,"," changing"," from"," \"","small","\""," to"," \"","big","\")."," You"," should"," not"," change"," any"," content"," in"," the"," given"," question"," beyond"]}]},{"quantile_name":"Subsample Interval 6","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.24,0.0,0.29,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["of"," the"," English"," word",".","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","Give"," me"," five"," synonym","s"," for"," ","'","simple","'.","\u23ce\u23ce","Assistant",":"," Here"," are"," five"," synonym","s"," for"," ","'","simple","':","\u23ce\u23ce","1","."," Easy","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.27,0.52,0.39,0.0,0.0,0.07,0.3,0.0,0.0,0.12,0.29,0.0,0.0,0.0,0.31,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["rank"," or"," quality"," of"," one"," object",","," without"," reference"," to"," that"," of"," another"," ;"," as",","," A"," wise"," man","."," A"," good"," man","."," A"," happy"," man","."," A"," sweet"," apple","."," *","Those"," who"," prefer"," the"," term"," ind","ec","li"]},{"tokens_acts_list":[0.0,0.27,0.0,0.0,0.22,0.0,0.0,0.0,0.3,0.24,0.0,0.0,0.0,0.32,0.0,0.0,0.0,0.31,0.0,0.29,0.29,0.0,0.26,0.0,0.0,0.22,0.09,0.0,0.0,0.0,0.31,0.03,0.0,0.13,0.21,0.15,0.0,0.0,0.25,0.24,0.19],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["    ","\u23ce\u23ce","nerv","\u00f6s","\u23ce\u23ce"," te","uer","    ","\u23ce\u23ce","h","\u00fcb","sch","    ","\u23ce\u23ce","bil","lig","    ","\u23ce\u23ce","neu","\u23ce\u23ce"," h","och","\u23ce\u23ce"," gross","    ","\u23ce\u23ce","fre","und","lich","    ","\u23ce\u23ce","he","iss","    ","\u23ce\u23ce","s","au","ber","    ","\u23ce\u23ce","b"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.16,0.0,0.29,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["In"," order"," to"," receive"," appropriate"," search"," results"," related"," to"," queries"," having"," undefined","/","subj","ective","/","relative"," terms"," like"," near",","," a"," user","'s"," proximity"," model"," may"," be"," created","."," The"," user","'s"," proximity"," model"," may"," determine"," a"," perception"," of"," the"]}]},{"quantile_name":"Subsample Interval 7","examples":[{"tokens_acts_list":[0.0,0.0,0.21,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["-","ad","ver","b",".","\u23ce","Input",":"," What"," is"," the"," part","-","of","-","speech"," tag"," of"," the"," word"," \"","to","\""," in"," the"," following"," question",":"," In"," what"," year"," was"," the"," destruction"," of"," the"," Historic"," Site"," that"," was"," used"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.18,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["are"," synonym","ous"," and"," ","0"," ","indicates"," that"," they"," are"," completely"," diss","imil","ar","."," The"," two"," words"," are",":"," film",","," theatre","\"","\u23ce\u23ce","Assistant",":"," Let"," me"," help"," you"," assess"," the"," similarity"," between"," \"","film","\""," and"," \""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.08,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce\u23ce","So"," in"," short",":","\u23ce\u23ce","Use"," \"","too","...","to","...\""," when"," something"," prevents"," an"," action",":","\u23ce","He"," is"," too"," tired"," to"," drive","."," (","He"," is"," prevented"," from"," driving"," because"," he"," is"," tired",")","\u23ce\u23ce","Use"," \"","too"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.21,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["ually","."," Your"," answer"," must"," be"," a"," \"","match","\""," or"," \"","no"," match","\"."," Question",":"," How"," similar"," is"," \"","NAME","_","1","\""," and"," \"","NAME","_","2","\"","\u23ce\u23ce","Assistant",":"," No"," match",".","\u23ce\u23ce","Human",":"," Context"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.14,0.0,0.1,0.0,0.18,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["at"," night","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","Help"," me"," understand"," the"," synonym","s"," for"," the"," word"," ","'","plac","ate","'","?","\u23ce\u23ce","Assistant",":"," Here"," are"," some"," synonym","s"," for"," ","'","plac","ate","':","\u23ce\u23ce","1"]}]},{"quantile_name":"Subsample Interval 8","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.14,0.09,0.0,0.09,0.06,0.1,0.27,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[">","<EOT>","\u23ce","Tell"," if"," a"," sentence"," contains"," positive"," or"," negative"," word",".","\u23ce","Input",":","\u2191"," Sentence",":"," I"," had"," a"," great"," day"," today","."," The"," weather"," was"," beautiful"," and"," I"," spent"," time"," with"," friends"," and"," family",".","\u23ce","Output"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.31,0.08,0.0,0.0,0.0,0.06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["term","ination"," of"," the"," ad","name"," :"," Thus",",","\u2191"," Si","mp",","," forn","it","\u2191"," Comparative",",","\u2191"," Sup","erl","ative",",","\u2191"," Dimin","ut","ive","."," C"," yellow","-","er",","," yellow","-","cs","^",","," yellow","-","i"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["go","\u23ce"," b",")"," goes","\u23ce"," c",")"," going","\u23ce"," d",")"," go","\u23ce","2","."," She"," ","\\_","\\_","\\_","\\_","\\_","\\_","\\_","\\_","\\","_"," up"," early"," every"," day"," to"," exercise",".","\u23ce","a",")"," w","akes","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["answer"," is"," the"," true"," definition"," of"," \"","innovative","\","," and"," the"," di","stract","ors"," are"," definitions"," of"," other"," adj","ectives",".","\u23ce\u23ce","Assistant",":"," Here","'s"," a"," definition"," quiz"," for"," the"," word"," \"","innovative","\":","\u23ce\u23ce","What"," does"," \"","innovative","\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09,0.0,0.0,0.1,0.01,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["and"," you"," need"," to"," tell"," if"," each"," sentence"," is"," positive"," or"," negative"," in"," sentiment",".","\u23ce","Input",":","\u2191"," Sentence",":"," I"," was"," really"," disappointed"," by"," the"," latest"," superh","ero"," movie","."," I"," would"," not"," recommend"," it"," to"," anyone",".","\u23ce"]}]},{"quantile_name":"Bottom Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["follows",":","\u23ce\u23ce","remove"," bik","ini"," -->"," top","less","\u23ce"," remove"," pants"," -->"," bottom","less","\u23ce"," remove"," clothing"," -->"," naked","\u23ce"," remove"," her"," dress"," -->"," naked","\u23ce"," remove"," mask"," and"," show"," a"," young"," beautiful"," face"," -->"," no"," mask",","," a"," young"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["."," ","\u23ce\u23ce","done","  ","at","  ","certain","   ","times","    ","of","    ","the"," ","\u23ce\u23ce","\u2191","Bra","ue",",","  ","41",",","  ","adj",".","  ","fine","."," ","\u23ce\u23ce","moon",",","  ","323"," ","\u23ce\u23ce","\u2191","B","ree","ches"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["single"," letter"," like"," A",","," B"," or"," C"," and"," don","'t"," have"," to"," give"," any"," reasons","."," For"," examples",","," \"","not"," believing"," in"," the"," supernatural","\":"," A",","," \"","excluding"," others"," from"," social"," events","\":"," C",","," \"","resp","ecting"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.28,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," same"," sentence"," in"," a"," specific"," way","."," Other"," examples"," of"," col","loc","ates"," in"," English"," include"," \"","dress","\","," \"","ride","\","," and"," \"","run","\"."," The"," study"," of"," col","loc","ations"," is"," an"," important"," aspect"," of"," language"," analysis",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["need"," to"," determine"," if"," both"," dialog","ues"," have"," the"," same"," underlying"," emotion","."," The"," possible"," emotions"," are"," happy",","," sad",","," angry",","," or"," other","."," If"," they"," do"," output"," ","'","yes","',"," if"," not"," output"," ","'","no","'."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["you"," for"," your"," business","!","<EOT>","\u23ce\u23ce","Human",":","\u2191"," Classify"," the"," text"," into"," neutral",","," negative"," or"," positive","."," ","\u23ce\u23ce","Text",":"," I"," think"," the"," vacation"," is"," okay",".","\u23ce","\u2191","Sentiment",":","\u23ce\u23ce","Assistant",":","\u2191"," Neutral",":"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.14,0.31,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["usually"," describes"," entities","'"," general"," characteristics"," such"," as"," rose"," is"," red",","," or"," subj","ective"," attributes"," such"," as"," th","irst"," is"," uncomfortable","."," It"," can"," also"," map"," to"," descript","ors"," that"," speak"," to"," the"," substance"," or"," value"," of"," items"," such"," as"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.07,0.0,0.06,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Dog","\u23ce","2",".","\u2191"," R","ojo"," -"," Red","\u23ce","3",".","\u2191"," Mu","cho"," -"," Much","\u23ce","4",".","\u2191"," D\u00eda"," -"," Day","\u23ce","5","."," Casa"," -"," House"," ","\u23ce\u23ce","Human",":"," ","\u23ce","I","'m"," not"," sure"," if"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["as"," a"," descript","ive"," author"," and"," write"," a"," better","  ","with"," more"," and"," new"," details",":"," NAME","_","1"," ","is"," a"," short"," pet","ite"," but"," athletic"," ninete","en"," bottom","-","heavy"," year"," old"," tom","boy"," with"," del","icate"," and"," fine"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.09,0.0,0.04],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["rigid"," |"," flexible"," |","\u23ce","|"," gran","ul","arity"," |"," fine"," |"," co","arse"," |"," ","\u23ce","|"," hard","ness"," |"," soft"," |"," hard"," |"," ","\u23ce","|"," length"," |"," short"," |"," long"," |"," ","\u23ce","|"," magnitude"," |"," small"," |"]},{"tokens_acts_list":[0.0,0.0,0.0,0.12,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Voice",",","\u2191"," Ad","ver","b",","," Gender",","," and","\u2191"," Synonym",".","\u23ce","Input",":"," original"," sentence",":"," Frank"," was"," upset"," with"," Tom"," because"," the"," to","aster"," he"," had"," sold"," him"," didn","'t"," work"," pa","raph","rase",":"," Frank"," and"]},{"tokens_acts_list":[0.0,0.0,0.0,0.07,0.0,0.19,0.35,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","g","."," replacing"," the"," word"," \"","one","\""," with"," \"","a","\"."," Instead",","," try"," to"," write"," a"," pa","raph","rase"," that"," contains"," new"," words",","," i",".","e","."," the"," words"," that"," are"," not"," present"," in"," the"," input"," sentence"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["convert"," it"," into"," English","\u2191"," Tokens",".","\u23ce","Input",":"," \"","This"," is"," going"," to"," be"," a"," fun",","," tough",","," hard"," fight"," that"," I"," expect"," will"," go"," everywhere",",\""," stated","\u2191"," Be","erb","oh","m"," in"," a"," pre","-","fight"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.25,0.26,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ti","ames",".","^"," Simple"," form"," of"," the"," combination"," :"," truly"," good"," ;","\u2191"," Comparative"," :"," more"," t","ru","-"," ly"," good"," ;","\u2191"," Sup","erl","ative"," :"," most"," truly"," good","."," ","282"," ","\u2191","Auxili","ar"," ad","names"," are"]}]}],"top_logits":["big","happy","beautiful","tall","nice","sad","pretty","smart","fast","Beautiful"],"bottom_logits":["frans","acco","\u0441\u0435\u0432\u0435\u0440\u043e","letal","Ranch","Frans","eing","\u0434\u0430\u043d\u0438","Airways","Associates"]}