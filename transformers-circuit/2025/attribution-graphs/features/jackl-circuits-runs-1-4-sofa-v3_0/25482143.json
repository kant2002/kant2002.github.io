{"index":25482143,"examples_quantiles":[{"quantile_name":"Top Activations","examples":[{"tokens_acts_list":[0.0,0.57,0.0,0.0,0.44,0.0,0.0,0.06,0.23,0.0,0.0,0.67,0.0,0.0,0.0,0.0,0.28,0.0,0.0,0.12,1.0,0.0,0.0,0.64,0.0,0.0,0.53,0.0,0.77,0.0,0.0,0.17,0.12,0.31,0.0,0.0,0.0,0.71,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["v","iel","\u23ce\u23ce"," s","auer","    ","\u23ce\u23ce","nerv","\u00f6s","\u23ce\u23ce"," te","uer","    ","\u23ce\u23ce","h","\u00fcb","sch","    ","\u23ce\u23ce","bil","lig","    ","\u23ce\u23ce","neu","\u23ce\u23ce"," h","och","\u23ce\u23ce"," gross","    ","\u23ce\u23ce","fre","und","lich","    ","\u23ce\u23ce","he","iss","    ","\u23ce\u23ce","s"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.87,0.28,0.0,0.0,0.0,0.97,0.13,0.1,0.0,0.0,0.87,0.22,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["dans","  ","les","qu","els"," ","\u23ce","entre","  ","l","'","ad","ject","if","  ","grand",",","  ","comme","  ","grand","-","p\u00e8re",",","  ","grand","-","onc","le",",","  ","etc",".,"," ","\u23ce","font","  ","au","  ","plur","iel"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.53,0.8,0.0,0.0,0.91,0.2,0.0,0.0,0.0,0.23,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," there"," are"," some"," exceptions"," to"," this"," rule","."," For"," example",","," the"," adj","ective"," \"","\u0432\u0435\u043b\u0438\u043a","\u0438\u0439","\""," (","big",")"," changes"," to"," \"","\u0432\u0435\u043b","\u0438\u043a\u0430","\""," in"," the"," feminine"," form",","," which"," ret","ains"," the"," ending"," \"","\u043e","\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.87,0.24,0.0,0.0,0.0,0.78,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," a"," word"," like"," ","'","car","'"," is"," a"," noun",","," and"," adding"," an"," adj","ective"," like"," ","'","big","'"," means"," ","'","big"," car",".","'\"","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","\u2191","Explain"," like"," I"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.87,0.28,0.0,0.0,0.0,0.97,0.13,0.1,0.0,0.0,0.87,0.22,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u00e9s","  ","mascul","ins","  ","dans","  ","les","qu","els"," ","\u23ce","entre","  ","l","'","ad","ject","if","  ","grand",",","  ","comme","  ","grand","-","p\u00e8re",",","  ","grand","-","onc","le",",","  ","etc",".,"," ","\u23ce","font"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.87,0.28,0.0,0.0,0.0,0.97,0.13,0.1,0.0,0.0,0.87,0.22,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.68,0.21,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","\u23ce","entre","  ","l","'","ad","ject","if","  ","grand",",","  ","comme","  ","grand","-","p\u00e8re",",","  ","grand","-","onc","le",",","  ","etc",".,"," ","\u23ce","font","  ","au","  ","plur","iel","  ","grands","-","p","\u00e8res"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.84,0.22,0.0,0.0,0.0,0.0,0.68,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.75,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["  ","d","'","apr\u00e8s","  ","la"," ","\u23ce","r\u00e8g","le",".","  ","Pour","  ","les","  ","f\u00e9","min","ins","  ","grand","'","m","\u00e8","rey","  ","grand","'"," t","ante",",","  ","o\u00f9","  ","grand"," ","\u23ce","est","  ","one","  "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.53,0.8,0.0,0.0,0.91,0.2,0.0,0.0,0.0,0.23,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","\u23ce\u23ce","However",","," there"," are"," some"," exceptions"," to"," this"," rule","."," For"," example",","," the"," adj","ective"," \"","\u0432\u0435\u043b\u0438\u043a","\u0438\u0439","\""," (","big",")"," changes"," to"," \"","\u0432\u0435\u043b","\u0438\u043a\u0430","\""," in"," the"," feminine"," form",","," which"," ret","ains"," the"," ending"]},{"tokens_acts_list":[0.26,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.79,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.08,0.39,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["grande"," bou","che",".","\u21ea"," NOTA","."," C","'","est"," \u00e0"," cette"," propri","\u00e9t\u00e9"," de"," l","'","ad","ject","if"," petit"," qu","'","on"," d","oit"," de"," pou","voir"," dire"," :"," Le"," mo","ind","re"," petit"," b","ruit",","," le"," mo"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.46,0.0,0.0,0.0,0.0,0.36,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.79,0.26,0.0,0.0,0.0,0.75,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["example",","," the"," ant","onym"," of"," \"","happy","\""," would"," be"," \"","sad","\"."," And"," the"," ant","onym"," of"," \"","big","\""," would"," be"," \"","small","\"."," ","\u23ce\u23ce","Why"," would"," a"," synonym"," need"," an"," ant","onym","?"," Well",","," sometimes"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.78,0.0,0.0,0.0,0.0,0.0,0.0,0.54,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["lang","ues",","," de"," man","i\u00e8re"," \u00e0"," ne"," faire"," qu","'","un"," avec"," le"," nom"," qui"," les"," suit",","," comme"," petit"," corps"," pour"," corp","usc","ule",","," petit"," ru","iss","eau"," pour"," ru","iss","elet",","," peuvent",","," pour"," cette"," ra"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.87,0.24,0.0,0.0,0.0,0.78,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["'","car","'"," is"," a"," noun",","," and"," adding"," an"," adj","ective"," like"," ","'","big","'"," means"," ","'","big"," car",".","'\"","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","\u2191","Explain"," like"," I","'m"," five"," years"," old",":"]},{"tokens_acts_list":[0.23,0.0,0.0,0.67,0.0,0.0,0.0,0.0,0.28,0.0,0.0,0.12,1.0,0.0,0.0,0.64,0.0,0.0,0.53,0.0,0.77,0.0,0.0,0.17,0.12,0.31,0.0,0.0,0.0,0.71,0.0,0.0,0.0,0.0,0.66,0.0,0.0,0.0,0.18,0.37,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u00f6s","\u23ce\u23ce"," te","uer","    ","\u23ce\u23ce","h","\u00fcb","sch","    ","\u23ce\u23ce","bil","lig","    ","\u23ce\u23ce","neu","\u23ce\u23ce"," h","och","\u23ce\u23ce"," gross","    ","\u23ce\u23ce","fre","und","lich","    ","\u23ce\u23ce","he","iss","    ","\u23ce\u23ce","s","au","ber","    ","\u23ce\u23ce","b","equ","em","    "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.45,0.0,0.0,0.0,0.0,0.35,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.77,0.25,0.0,0.0,0.0,0.75,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["example",","," the"," ant","onym"," of"," \"","happy","\""," would"," be"," \"","sad","\"."," And"," the"," ant","onym"," of"," \"","big","\""," would"," be"," \"","small","\"."," ","\u23ce","Why"," would"," a"," synonym"," need"," an"," ant","onym","?"," Well",","," sometimes"]},{"tokens_acts_list":[0.0,0.3,0.0,0.0,0.0,0.08,0.0,0.0,0.34,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.67,0.0,0.0,0.77,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.38,0.0,0.0,0.0,0.0,0.0,0.32,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["The"," new"," car"," is"," sh","iny","."," The"," old"," car"," is"," rus","ty",".","\u23ce","1","."," Fast","/","\u2191","Slow","\u23ce","*"," The"," ch","eet","ah"," is"," fast","."," The"," sn","ail"," is"," slow",".","\u23ce","*"," The"," race"," car"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.46,0.53,0.0,0.0,0.34,0.53,0.0,0.28,0.53,0.0,0.23,0.72,0.74,0.0,0.0,0.61,0.59,0.0,0.18,0.49,0.16,0.42,0.0,0.37,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["has"," no"," anal","ogs"," in"," english",":"," \u0432\u044b\u0441","\u043e\u043a","\u0438\u0439",","," \u0445","\u043e\u0440\u043e","\u0448\u0438\u0439",","," \u043f\u0435\u0440\u0432","\u044b\u0439",","," \u0434\u043b","\u0438\u043d","\u043d\u044b\u0439",","," \u043c\u0430","\u043b\u0435\u043d","\u044c\u043a\u0438\u0439",","," \u043d\u0435\u0431","\u043e\u043b\u044c","\u0448","\u043e\u0439",","," \u043e\u0434\u0438\u043d","?","\u23ce","Output",":","\u23ce\u23ce","Assistant",":"," Let"," me"]},{"tokens_acts_list":[0.0,0.0,0.0,0.21,0.21,0.0,0.0,0.0,0.09,0.0,0.0,0.0,0.46,0.0,0.0,0.0,0.24,0.25,0.0,0.0,0.75,0.0,0.22,0.49,0.0,0.0,0.0,0.27,0.07,0.0,0.45,0.0,0.22,0.38,0.0,0.0,0.07,0.36,0.0,0.0,0.45],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["|"," am"," te","uer","sten","\u23ce"," h","\u00fcb","sch"," |"," sch","\u00f6","ner"," |"," am"," sch","\u00f6n","sten","\u23ce"," bil","lig"," |"," bill","iger"," |"," am"," bil","lig","sten","\u23ce"," neu"," |"," ne","uer"," |"," am"," neu","esten","\u23ce"," h","och"]},{"tokens_acts_list":[0.0,0.0,0.46,0.0,0.0,0.0,0.0,0.36,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.79,0.26,0.0,0.0,0.0,0.75,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["of"," \"","happy","\""," would"," be"," \"","sad","\"."," And"," the"," ant","onym"," of"," \"","big","\""," would"," be"," \"","small","\"."," ","\u23ce\u23ce","Why"," would"," a"," synonym"," need"," an"," ant","onym","?"," Well",","," sometimes"," words"," can"," have"," more"," than"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.75,0.31,0.71,0.06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["un"," v","\u00e9r","itable"," sens"," moral",","," peu"," comm","un","."," ","1","097","."," \u2014"," Les"," ad","ject","ifs"," grand"," et"," petit",","," \u00e9qu","ival","ant"," so","uvent"," en"," fran\u00e7ais"," aux"," fin","ales"," aug","ment","atives"," et"," dimin","ut","ives"]}]},{"quantile_name":"Subsample Interval 0","examples":[{"tokens_acts_list":[0.0,0.57,0.0,0.0,0.44,0.0,0.0,0.06,0.23,0.0,0.0,0.67,0.0,0.0,0.0,0.0,0.28,0.0,0.0,0.12,1.0,0.0,0.0,0.64,0.0,0.0,0.53,0.0,0.77,0.0,0.0,0.17,0.12,0.31,0.0,0.0,0.0,0.71,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["v","iel","\u23ce\u23ce"," s","auer","    ","\u23ce\u23ce","nerv","\u00f6s","\u23ce\u23ce"," te","uer","    ","\u23ce\u23ce","h","\u00fcb","sch","    ","\u23ce\u23ce","bil","lig","    ","\u23ce\u23ce","neu","\u23ce\u23ce"," h","och","\u23ce\u23ce"," gross","    ","\u23ce\u23ce","fre","und","lich","    ","\u23ce\u23ce","he","iss","    ","\u23ce\u23ce","s"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.87,0.28,0.0,0.0,0.0,0.97,0.13,0.1,0.0,0.0,0.87,0.22,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["dans","  ","les","qu","els"," ","\u23ce","entre","  ","l","'","ad","ject","if","  ","grand",",","  ","comme","  ","grand","-","p\u00e8re",",","  ","grand","-","onc","le",",","  ","etc",".,"," ","\u23ce","font","  ","au","  ","plur","iel"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.53,0.8,0.0,0.0,0.91,0.2,0.0,0.0,0.0,0.23,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":[","," there"," are"," some"," exceptions"," to"," this"," rule","."," For"," example",","," the"," adj","ective"," \"","\u0432\u0435\u043b\u0438\u043a","\u0438\u0439","\""," (","big",")"," changes"," to"," \"","\u0432\u0435\u043b","\u0438\u043a\u0430","\""," in"," the"," feminine"," form",","," which"," ret","ains"," the"," ending"," \"","\u043e","\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.87,0.24,0.0,0.0,0.0,0.78,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":[","," a"," word"," like"," ","'","car","'"," is"," a"," noun",","," and"," adding"," an"," adj","ective"," like"," ","'","big","'"," means"," ","'","big"," car",".","'\"","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","\u2191","Explain"," like"," I"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.87,0.28,0.0,0.0,0.0,0.97,0.13,0.1,0.0,0.0,0.87,0.22,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["\u00e9s","  ","mascul","ins","  ","dans","  ","les","qu","els"," ","\u23ce","entre","  ","l","'","ad","ject","if","  ","grand",",","  ","comme","  ","grand","-","p\u00e8re",",","  ","grand","-","onc","le",",","  ","etc",".,"," ","\u23ce","font"]}]},{"quantile_name":"Subsample Interval 1","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.87,0.28,0.0,0.0,0.0,0.97,0.13,0.1,0.0,0.0,0.87,0.22,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.68,0.21,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":[" ","\u23ce","entre","  ","l","'","ad","ject","if","  ","grand",",","  ","comme","  ","grand","-","p\u00e8re",",","  ","grand","-","onc","le",",","  ","etc",".,"," ","\u23ce","font","  ","au","  ","plur","iel","  ","grands","-","p","\u00e8res"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.84,0.22,0.0,0.0,0.0,0.0,0.68,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.75,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["  ","d","'","apr\u00e8s","  ","la"," ","\u23ce","r\u00e8g","le",".","  ","Pour","  ","les","  ","f\u00e9","min","ins","  ","grand","'","m","\u00e8","rey","  ","grand","'"," t","ante",",","  ","o\u00f9","  ","grand"," ","\u23ce","est","  ","one","  "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.53,0.8,0.0,0.0,0.91,0.2,0.0,0.0,0.0,0.23,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":[".","\u23ce\u23ce","However",","," there"," are"," some"," exceptions"," to"," this"," rule","."," For"," example",","," the"," adj","ective"," \"","\u0432\u0435\u043b\u0438\u043a","\u0438\u0439","\""," (","big",")"," changes"," to"," \"","\u0432\u0435\u043b","\u0438\u043a\u0430","\""," in"," the"," feminine"," form",","," which"," ret","ains"," the"," ending"]},{"tokens_acts_list":[0.26,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.79,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.08,0.39,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["grande"," bou","che",".","\u21ea"," NOTA","."," C","'","est"," \u00e0"," cette"," propri","\u00e9t\u00e9"," de"," l","'","ad","ject","if"," petit"," qu","'","on"," d","oit"," de"," pou","voir"," dire"," :"," Le"," mo","ind","re"," petit"," b","ruit",","," le"," mo"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.46,0.0,0.0,0.0,0.0,0.36,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.79,0.26,0.0,0.0,0.0,0.75,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["example",","," the"," ant","onym"," of"," \"","happy","\""," would"," be"," \"","sad","\"."," And"," the"," ant","onym"," of"," \"","big","\""," would"," be"," \"","small","\"."," ","\u23ce\u23ce","Why"," would"," a"," synonym"," need"," an"," ant","onym","?"," Well",","," sometimes"]}]},{"quantile_name":"Subsample Interval 2","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.59,0.24,0.0,0.0,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["'","trigger"," word","'"," with"," its"," ant","onym"," (","e",".","g",".,"," changing"," from"," \"","small","\""," to"," \"","big","\")."," You"," should"," not"," change"," any"," content"," in"," the"," given"," question"," beyond"," a"," word"," or"," two",","," i",".","e"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.75,0.31,0.71,0.06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u00e9r","itable"," sens"," moral",","," peu"," comm","un","."," ","1","097","."," \u2014"," Les"," ad","ject","ifs"," grand"," et"," petit",","," \u00e9qu","ival","ant"," so","uvent"," en"," fran\u00e7ais"," aux"," fin","ales"," aug","ment","atives"," et"," dimin","ut","ives"," des"," autres"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.59,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.61,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.42,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["la"," t","aille","."," C","'","est"," un","\u21ea"," GRAND"," homme"," \u00e9t","onn","ant",","," etc","."," Un"," homme","\u21ea"," GRAND"," dans"," l","'","advers","it\u00e9",","," grand"," dans"," ses"," des","se","ins",".","\u2191"," Gro","sse"," fem","me",",","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.55,0.07,0.0,0.07,0.7,0.15,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["sitting",","," eating"," and"," other","\"","\u23ce\u23ce","[","3","]","\"","\u2191","Adj","ectives",":"," like"," Beautiful",","," realistic",","," big",","," col","our","ful"," and"," other","\"","\u23ce\u23ce","[","4","]","\"","Environment","/","Context",":"," like","\u2191"," Outdoor",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.58,0.13,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.58,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2022","\u2191","Vary"," your"," vocabulary"," by"," using"," synonym","s",","," e",".","g","."," use"," \"","big","\""," and"," \"","large","\""," instead"," of"," just"," \"","big","\""," for"," interest",".","\u2191"," Repet","ition"," of"," words"," makes"," the"," writing"," monot","on"]}]},{"quantile_name":"Subsample Interval 3","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.61,0.29,0.24,0.2,0.44,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["in"," a"," creative"," mood"," based"," on"," this"," data",":","\u23ce","Background",":"," grass"," field","\u23ce"," Background"," ad","jet","ives",":"," big",","," green",","," soft","\u23ce"," Items"," table","\u23ce","|","item","|","group","|","ad","jet","ives","|","colors","|","position"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.46,0.53,0.0,0.0,0.34,0.53,0.0,0.28,0.53,0.0,0.23,0.72,0.74,0.0,0.0,0.61,0.59,0.0,0.18,0.49,0.16,0.42,0.0,0.37,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["ogs"," in"," english",":"," \u0432\u044b\u0441","\u043e\u043a","\u0438\u0439",","," \u0445","\u043e\u0440\u043e","\u0448\u0438\u0439",","," \u043f\u0435\u0440\u0432","\u044b\u0439",","," \u0434\u043b","\u0438\u043d","\u043d\u044b\u0439",","," \u043c\u0430","\u043b\u0435\u043d","\u044c\u043a\u0438\u0439",","," \u043d\u0435\u0431","\u043e\u043b\u044c","\u0448","\u043e\u0439",","," \u043e\u0434\u0438\u043d","?","\u23ce","Output",":","\u23ce\u23ce","Assistant",":"," Let"," me"," help"," you"," analyze"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["  ","\u2191","Sansk","r",".","  ","s","th","\u00fc","ra","-","s",",","  ","s","th","\u00fc","ra","  ","\u201e","stark","\""," ","\u23ce","k",".","  ","","wn","k","n","  ","\u00a7","  ","347","),","  ","Ein","  ","\u2191","Composit"]},{"tokens_acts_list":[0.0,0.25,0.0,0.0,0.0,0.0,0.21,0.0,0.0,0.44,0.0,0.44,0.0,0.0,0.0,0.0,0.0,0.0,0.64,0.0,0.6,0.0,0.05,0.0,0.0,0.0,0.0,0.49,0.0,0.48,0.0,0.0,0.0,0.0,0.0,0.0,0.35,0.0,0.29,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["co","arse"," |"," ","\u23ce","|"," hard","ness"," |"," soft"," |"," hard"," |"," ","\u23ce","|"," length"," |"," short"," |"," long"," |"," ","\u23ce","|"," magnitude"," |"," small"," |"," large"," |"," ","\u23ce","|"," mass"," |"," small"," |"," large"," |"," "]}]},{"quantile_name":"Subsample Interval 4","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.15,0.0,0.41,0.0,0.43,0.0,0.0,0.0,0.0,0.35,0.18,0.0,0.51,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.31,0.24,0.0,0.39,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["change"," of"," the"," entire"," word"," ;"," as",","," Simple"," \u2014"," elegant",","," good"," ;","\u2191"," Comparative"," \u2014"," more"," elegant",","," better"," ;","\u2191"," Super","la","-"," t","ive","\u2014"," most"," elegant",","," best",".","]"," a","."," *","It"," is"," seen"]},{"tokens_acts_list":[0.35,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.0,0.46,0.0,0.0,0.0,0.0,0.28,0.05,0.0,0.59,0.0,0.51,0.0,0.06,0.0,0.0,0.0,0.0,0.32,0.0,0.16,0.0,0.0,0.0,0.0,0.0,0.0,0.51,0.0,0.21,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["light"," |"," ","\u23ce","|"," clarity"," |"," obsc","ure"," |"," clear"," |"," ","\u23ce","|"," clean","ness"," |"," dirty"," |"," clean"," |"," ","\u23ce","|"," complexity"," |"," simple"," |"," complex"," |"," ","\u23ce","|"," cost"," |"," cheap"," |"," expensive"," |","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.44,0.0,0.44,0.0,0.0,0.0,0.0,0.05,0.0,0.64,0.0,0.61,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.49,0.0,0.0,0.0,0.0,0.0,0.0,0.36,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.35,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ness"," |"," soft"," |"," hard"," |"," ","\u23ce","|"," length"," |"," short"," |"," long"," |"," ","\u23ce","|"," magnitude"," |"," small"," |"," large"," |"," ","\u23ce","|"," mass"," |"," small"," |"," large"," |"," ","\u23ce","|"," od","or"," |"," weak"," |"]},{"tokens_acts_list":[0.0,0.46,0.53,0.0,0.0,0.34,0.53,0.0,0.28,0.53,0.0,0.23,0.72,0.74,0.0,0.0,0.61,0.59,0.0,0.18,0.49,0.16,0.42,0.0,0.37,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["\u0432\u044b\u0441","\u043e\u043a","\u0438\u0439",","," \u0445","\u043e\u0440\u043e","\u0448\u0438\u0439",","," \u043f\u0435\u0440\u0432","\u044b\u0439",","," \u0434\u043b","\u0438\u043d","\u043d\u044b\u0439",","," \u043c\u0430","\u043b\u0435\u043d","\u044c\u043a\u0438\u0439",","," \u043d\u0435\u0431","\u043e\u043b\u044c","\u0448","\u043e\u0439",","," \u043e\u0434\u0438\u043d","?","\u23ce","Output",":","\u23ce\u23ce","Assistant",":"," Let"," me"," help"," you"," analyze"," each"," word",":","\u23ce\u23ce"]}]},{"quantile_name":"Subsample Interval 5","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","\u23ce\u23ce\u23ce\u23ce","\u21ea","DICT","IONNAIRE"," D","\u21ea"," ARG","OT","\u21ea"," MODERNE","."," ","\u23ce\u23ce\u23ce\u23ce","\u2191","Ju","ge","otte",".","\u2191"," Bon"," sens"," ;"," jug","ement"," ","\u23ce","s","ain","."," ","\u23ce\u23ce","\u2191","Ju","gu","ler",".","\u2191"," Ag","a","cer"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.66,0.05,0.0,0.0,0.09,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ot",",","  ","\u2191","P","\u00e2","l","otte",",","  ","adj",".","  ","\u2191","Lo","urd",",","  ","l","our","de",";","  ","se","  ","dit","  ","des"," ","\u23ce","person","nes","  ","et","  ","non","  ","des","  ","ch","oses"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.11,0.0,0.47,0.0,0.49,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[":","web","\u23ce","-"," bread",":","butter"," ::"," chips",":","sal","sa","\u23ce","-"," light",":","dark"," ::"," hot",":","cold","\u23ce","-"," clock",":","numbers"," ::"," compass",":","directions","\u23ce","-"," plant",":","roots"," ::"," body",":","feet","\u23ce","-"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[":"," First",":"," ","'","Property","',"," the"," knowledge"," about"," property"," of"," objects"," (","e",".","g",".,"," ice"," is"," cold",")."," Second",":"," ","'","Object","',"," the"," knowledge"," about"," objects"," (","e",".","g",".,"," cats"," have"," ears",")."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.44,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","\u23ce","level",";"," on","ak","am","ig","amo"," mik","ana","."," The"," ","\u23ce","r","."," is"," large"," or"," wide",","," mang","ad","emo"," ","\u23ce","mik","ana","."," The"," v","r","."," is"," small"," or"," ","nar","-"," "]}]},{"quantile_name":"Subsample Interval 6","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.29,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.13],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["country"," road"," that","'s"," not"," a"," highway","\"","\u23ce\u23ce","Human",":"," ","\u23ce","If"," I"," use"," the"," word"," \"","cri","sp","\""," what"," should"," I"," use"," it"," for"," when"," discussing"," nature","?","\u23ce\u23ce","Assistant",":"," When"," discussing"," nature",","," \"","cri"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["can"," use"," different"," words"," or"," make"," the"," subjects"," negative"," (","i",".","e",".,"," ask"," about"," short","ness"," instead"," of"," tall","ness",")"," to"," combine"," the"," subjects","."," The"," questions"," are"," in"," three"," domains",":"," presidents",","," national"," parks",","," and"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.28,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u012b","n","\u2191"," Sh","\u0113","pu",")","\u23ce\u23ce","Az"," \u00e9","rd","ek","es","s\u00e9g",","," hogy"," a"," \"","z","\u00f6","ld","\""," sz","\u00f3t"," \u00e1ltal","\u00e1ban"," a"," \"","s","\u00e1r","ga","\""," sz\u00edn","nel"," azon","os","\u00edt","j\u00e1k",","," mivel"," a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["',"," the"," knowledge"," about"," event","uality"," (","e",".","g",".,"," ","'","wake"," up","'"," happens"," before"," ","'","open"," eyes","'",").","\u2191"," Forth",":"," ","'","\u2191","Spatial","',"," the"," knowledge"," about"," spatial"," position"," (","e",".","g"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.23,0.0,0.23,0.07,0.21,0.0,0.24,0.0,0.28,0.0,0.24,0.18,0.34,0.0,0.08,0.12,0.13,0.0,0.0,0.09],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["dimin","ut","ive"," form","."," Simple"," form",".","\u2191"," Comparative","\u2191"," Sup","erl","ative"," form","."," form",".","\u2191"," Whit","ish"," white"," wh","iter"," whit","est","\u2191"," Blu","ish"," blue"," bl","uer"," blu","est","\u2191"," Yellow","ish"," yellow","*"," yell","ower"]}]},{"quantile_name":"Subsample Interval 7","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["unique","\u23ce","17","."," Quality","\u23ce","18",".","\u2191"," Affordable","\u23ce","19",".","\u2191"," D","urable","\u23ce","20",".","\u2191"," Soft","\u23ce","21",".","\u2191"," Fl","owy","\u23ce","22",".","\u2191"," Sle","ek","\u23ce","23",".","\u2191"," Sh","imm","ering","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.46,0.1,0.0,0.0,0.05,0.0,0.66,0.14,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","","Ger","."," par","indo",","," Part",".","\u2191"," P","res","."," \u2014"," ^",",","\u2191"," Pe","rf","."," schw","ach"," ","\u23ce","par","uto",","," stark"," ","'","p",".","par","so",",","\u2191"," Pe","rf",".","\u2191"," Def"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["de"," trav","ail","."," ."," ","\u23ce","\u00e8","uc","\u00e9",","," s","."," m",".","\u2191"," ","Ois","eau"," |"," bas",","," se","dit"," de"," la"," ver","ge"," ","chez","\u2191"," Pen","-","f","ant"," ]"," massa"," ","1","'","\u2014"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["bow"," down","."," ","\u23ce\u23ce","\u2191","Sal","ve",","," ji","jo","bt","igan",","," mash","k","iki","."," ","\u23ce\u23ce","Same",";"," we"," are"," considered"," all"," the"," ","\u23ce","same"," person",","," ","22"," ","b","ej","ig","wend","ag","osi"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.37,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["j","arg","on"," des"," vol","eurs","."," ","\u23ce\u23ce","\u2191","B","ric","-","\u00e0","-","b","rac",".","\u2191"," V","ie","ill","eries"," art","is","\u23ce"," t","iques",","," non"," artist","iques",","," pseudo","\u23ce"," artist","iques"," :"," v","ieux"," chan"]}]},{"quantile_name":"Subsample Interval 8","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.12,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[">","<EOT>","\u23ce","Given"," a"," sentence",","," judge"," the"," quality"," of"," this"," sentence"," by"," indicating"," \"","Good","\""," and"," \"","Bad","\"."," The"," quality"," depends"," on"," the"," grammar"," and"," the"," meaning"," of"," the"," sentence","."," If"," a"," sentence"," is"," easily"," under"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," <<","L",">>"," being"," the"," part"," which"," effectively"," serves"," to"," grip"," the"," fl","ange"," and"," its"," vertical"," (","<<","long",">",">)"," part"," corresponding"," to"," the"," axis"," of"," said"," combined"," rotation"," and"," translation",".","\u23ce","This"," last"," part",","," which"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.27,0.12,0.0,0.0,0.0,0.27,0.0,0.19,0.0,0.09,0.1,0.0,0.28,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["but"," one"," of"," the"," four"," forms"," :",")"," as",","," Golden",","," wo","ollen",","," round",","," square",","," bound","less",","," infinite",","," pec","un","iary",","," penny","-"," less",","," friend","less","."," ","267"," ","All"," ad","names"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","\u23ce\u23ce","In"," questa"," ,"," tal","ora"," av","verb","io","."," ","\u23ce\u23ce","\u2191","Ind","ri","eto"," per"," ind","iet","ro","."," ","\u23ce\u23ce","\u2191","Infin","ito"," ,"," us","ato"," per"," alc","una"," altra"," vo","ce"," ","\u23ce","del"," ver","bo"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["sc","ream","-"," ing"," with"," hunger","."," He"," persu","aded","\u2191"," Sus","ie"," that"," she"," was"," a"," big"," girl",","," big"," enough"," to"," sit"," on"," a"," high"," st","ool"," and"," sp","oon"," st","rained"," p","eas"," into"," her"," baby"," brother"," while"]}]},{"quantile_name":"Bottom Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.22,0.04,0.0,0.0,0.14,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["umes"," ]","\""," \""," Man","/","to",","," fill"," up"," my"," friend","'s"," glass",".\""," \"","Full","!\""," \"","Big","!\""," \"","The"," big"," drinks"," is"," most"," best",".\""," \"","Hey",","," listen",".\""," \"","You"," know"," why"," that"," man"," sing"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["input",","," please"," reply"," with"," ","'","None","'.","\u23ce","###"," Example"," Input"," I",":","  ","\"","We"," think"," a"," sharp"," economic"," slow","down"," over"," the"," course"," of"," this"," year"," means"," the"," Fed"," will"," be"," cutting"," rates"," at"," the"," beginning"," of"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\\xe2\\x99","\\xaa",""," Forever"," let"," us"," Hold"," our"," banner"," ","\\xe2\\x99","\\xaa","\""," \"","\\xe2\\x99","\\xaa",""," High","!\""," \"","High","!\""," \"","High","!\""," \"","High","!\""," \"","\\xe2\\x99","\\xaa","\""," \"","\\xe2\\x99","\\xaa",""," Boys"," and"," girls"," from"," far"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["in"," plain"," sight","\u23ce"," Answer"," the"," following"," question",":","\u23ce","-"," What"," is"," the"," color"," of"," NAME","_","1"," ","white"," horse","?","\u23ce","State"," your"," reasoning"," before"," answ","ering","\u23ce\u23ce"," Assistant",":"," Based"," on"," the"," evidence"," given",","," there"," is"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.09,0.22,0.04,0.31,0.0,0.0,0.33,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["?"," |"," ","\u23ce\u23ce","cr","."," \u20ac","&","y","."," f","fo","\\xcd","\\xa4","l"," ="," round",";"," bl","unt",";"," silly",","," v","ain"," etc",".;"," mit","\u2191"," ","Ders"," ","\u23ce","r","aten",","," d","enen"," the","ild"," der"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\""," kjer"," bi"," lahko"," pla","val","\u23ce","<","id","io","terna",">"," ja","\u23ce","<","id","io","terna",">"," ve","lik"," bl"," vl","az","no"," je"," k"," na"," pac","if","iku","\u23ce","<","yang",">"," k","rok","od","ili"," dos","tk"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ence",","," fertil","it\u00e9",","," ","\u23ce\u23ce\u23ce","\u2191","Revis","it",","," va","."," r\u00e9","vis","iter"," \u2014"," in"," dress",","," rich","esse"," de"," la"," par","ure",","," f","."," ","\u23ce","Revival",","," ="," r","\u00e9t","abl","issement",","," m","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.17,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["is"," always"," some"," thing",".\""," \"","\u2191","Sunny",","," b","ites"," the"," head"," of"," that"," el","fo",".\""," \"","Fast",","," it"," pulls"," again",".\""," \"","\u2191"," Violet",".\""," \""," I"," know","...\""," \""," I"," don","'t"," want"," to"," hur","ry"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["I"," was"," saying",":"," it","'s"," just","...\""," \"","I"," was"," worried"," about"," you","\""," \"","That","'s"," right","."," deep"," Down",","," you"," can"," worry"," without"," loving",".\""," \"","Can","'t"," you","?\""," \"","Yes",","," why"," not","?\""," \""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","\u2191"," B","yd","\u0142o",","," \u015bwi","nie"," i"," ow","ce"," w"," p","olu"," c","a\u0142y"," rok",".","\u2191"," Wiel","ki","\u23ce"," zap","as"," t","ward","ego"," d","rz","ewa"," i"," w\u0119","g","la",".","\u2191"," Bl","isko"," kol","ei"," i"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[",","  ","et","  ","inter","  ","con","stan","-"," ","\u23ce","tem",",","  ","sever","um","  ","et","  ","grav","em",".","  ","\u2191","Wenn","  ","\u2191","L\u00e4","lius","  ","mit","  ","streng","erer","  ","\u2191","Log","ik","  ","und"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u03bf\u03bb","\u03c5","\u03c4","\u03ad","\u03bc","\u03b7\u03c4","\u03bf\u03c2",","," \u03b5","\\xe1\\xbd","\\x96","","\u2191"," ","\u0396","\u03b5","\\xe1\\xbf","\\xa6",""," \u03c0","\u03bf\u03bb","\u03c5","\u03c4","\u03af","\u03bc","\u03b7","\\xcf","\\x91","","'"," \u03b8","","01","."," ","\u23ce\u23ce","\u03c0","\u03bf\u03bc","\u03c6","\u03cc","\u03bb"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","Tt","arth","olom","c","w",").","\u2191"," M","ou","-","\u2191","Pays"," (","\u2191","O","af","c","yer",")."," Grand"," D","U","C"," (","A","."," Ben","\u00bb","on",").","\u2191"," Gas","ii","ard"," (","A",".-","V",".","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["arg","arn","l\u00e4","u","fer"," K"," ","120"," ","cm"," b","rl","."," m"," ","7",".","80"," ","schw","er",".","\u2191"," Qual","it\u00e4t"," &"," ","68"," ","cm"," br","eit"," m"," ","6",".","50"," ","\u2191","W","oll"]},{"tokens_acts_list":[0.0,0.0,0.42,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.48,0.0,0.0,0.52,0.0,0.0,0.0,0.25,0.0,0.0,0.04,0.0,0.22,0.0,0.0,0.0,0.0,0.0,0.0,0.23,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.53,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce\u23ce","\u21ea","LATE",",","  ","a",".","  ","Not","  ","early",";","  ","slow",";","  ","tar","dy",":"," \u2014"," ","\u23ce","recent"," :","\u2014"," deceased","  ",";","  ","dead",".","  ","[","night","."," ","\u23ce\u23ce","\u21ea","LATE",",","  "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ich"," u","chw","a\u0142","\u2191"," Akadem","ii","\u2191"," Um","ie","j\u0119"," ","\u23ce","t","ne","\u015bci",","," jako"," \u201e","jas","ny"," i"," tre","\u015bci","wy","*,"," do"," ty","eh"," e","pi","\u23ce"," tet","\u00f3w"," nie"," dod","a\u0107"," nie"," mo\u017cna",",","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","  ","de","  ","la","  ","ville","  ","de","  ","\u2191","P","\u00e0","t","ali","\u23ce"," pu","tra",",","  ","pr\u00e8s","  ","de","  ","\u2191","B","ha","gh","alp","ure","  ","ou","  ","de","  ","\u2191","Pat","na","."," ","\u23ce\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["."," ","6",".","\u2191"," Dar"," \u2014"," ,"," (","a",")"," to"," satisfy",","," (","b",")"," to"," feed"," with"," empty"," promises",","," to"," h","umb","ug",","," (","c",")"," to"," let"," (","a"," person",")"," win"," a"," little"," so"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\":"," \"","True","\",","\u23ce","\"","delivery","_","days","\":"," \"","2","\",","\u23ce","\"","price","_","value","\":"," [\"","expensive","\","," \"","extra"," features","\"]","\u23ce","}","\u23ce\u23ce","Human",":"," For"," the"," following"," text",","," extract"," the"," following"," information",":"]}]}],"top_logits":[],"bottom_logits":["ydyd","Registry","rej","ecological","promotional","Rec","Arg","ipip","chit"]}