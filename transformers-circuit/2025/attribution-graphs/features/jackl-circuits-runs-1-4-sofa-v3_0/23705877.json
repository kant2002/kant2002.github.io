{"index":23705877,"examples_quantiles":[{"quantile_name":"Top Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["little"," capital",".","\u23ce\u23ce","\u2191","Retail"," businesses"," can"," be"," highly"," scal","able"," because"," they"," can"," be"," operated"," on"," a"," small"," or"," large"," scale"," depending"," on"," the"," size"," of"," the"," market"," and"," the"," level"," of"," demand","."," Additionally",","," the"," costs"," of"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.89,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["But"," it"," was"," scary",".\""," \"","So"," there"," were"," two","\u2191"," Yam","ato","-","no","\u2191"," Or","ochi",","," small"," and"," large","?\""," \"","There"," was"," the"," ","8"," ","section","\u2191"," Yam","ato","-","no","\u2191"," Or","ochi"," that"," came"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.86,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["with"," the"," printer"," system"," may"," be"," used"," with"," various"," differently"," sized"," ink"," containers","."," In"," order"," to"," allow"," both"," small"," and"," large"," volume"," ink"," containers"," to"," be"," installed"," in"," a"," printer"," system",","," it"," is"," known"," to"," use"," a"," spac","er"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.86,0.0,0.0,0.0,0.35,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["and"," come"," into"," play","."," And","\u23ce"," even"," code"," organization"," exist"," at"," different"," levels",":"," in"," the"," small",","," in"," the"," medium","\u23ce"," and"," in"," the"," large","."," It","'s"," good"," to"," try"," and"," get"," an"," idea"," at"," all"," levels","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["can"," receive"," and"," rotate"," a"," tub","ular"," having"," a"," specific"," diameter"," and"," cannot"," adjust"," for"," tub","ul","ars"," having"," smaller"," or"," larger"," di","ame","ters","."," Therefore",","," there"," is"," a"," need"," for"," providing"," a"," rotating"," device"," that"," can"," receive"," and"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.77,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["people"," just"," change"," it"," by"," trial"," and"," error",".","  ","You"," can"," also"," turn"," the"," thing"," to"," make"," it"," smaller"," or"," bigger",".","  ","Can"," I"," be"," more"," specific"," about"," how"," to"," adjust"," a"," particular"," wr","ench","?","\u23ce","<","|"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.77,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":15,"is_repeated_datapoint":false,"tokens":["<EOT>","ique"," lines",".","\u23ce","Therefore",","," depending"," on"," whether"," the"," interval"," W"," is"," small"," or"," large",","," black"," stre","aks"," or"," white"," stre","aks"," are"," formed"," on"," the"," recording"," paper",","," and"," hence"," this"," interval"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.25,0.59,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["you"," rings",","," not"," f","ries",".","  ","I"," will"," bring"," you"," a"," small"," cup"," of"," ch","ili",","," not"," a"," large"," one",".","\u23ce\u23ce","Assistant",":"," No",","," that","'s"," not"," what"," I"," meant","."," Let"," me"," clar","ify"," my"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.73,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["that"," the"," logo"," is"," scal","able",","," so"," that"," it"," looks"," good"," whether"," it","'s"," small"," on"," a"," business"," card"," or"," large"," on"," a"," billboard",".","\u23ce\u23ce","Overall",","," creating"," a"," logo"," can"," be"," a"," complex"," process",","," so"," it","'s"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.72,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["dose"," of"," cyn","icism"," and"," gr","ump","iness",".\"","<EOT>","\u23ce\u23ce","Human",":"," Please"," arrange"," the"," following"," numbers"," from"," small"," to"," large","\u23ce","[","27",","," ","20",","," ","7",","," ","23",","," ","4",","," ","24",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ula"," ret","orna"," um"," valor"," in","v\u00e1l","ido",".","<EOT>","\u23ce\u23ce","Human",":"," please"," sort"," the"," following"," numbers"," from"," small"," to"," big","\u23ce","[","162",","," ","236",","," ","299",","," ","118",","," ","83",","," ","127",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["best","."," Can"," you"," provide"," some"," additional"," suggestions","?","\u23ce\u23ce","Assistant",":"," ","\u23ce","Of"," course","."," Consider"," small"," scale"," and"," subtle"," details"," such"," as"," texture","."," Select"," rus","tic","-","looking"," tiles"," for"," a"," hand","m","ade"," f","lair",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.69,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["for"," all","!"," ","\\xf0\\x9f","\\x8c","\\x88","\\xf0\\x9f\\x92","\\xaa","<EOT>","\u23ce\u23ce","Human",":"," Please"," arrange"," the"," following"," numbers"," from"," small"," to"," large","\u23ce","[","27",","," ","20",","," ","7",","," ","23",","," ","4",","," ","24",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.68,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["but"," more"," information"," is"," needed"," to"," confirm"," this",".","<EOT>","\u23ce\u23ce","Human",":"," Please"," arrange"," the"," following"," numbers"," from"," small"," to"," large","\u23ce","[","27",","," ","20",","," ","7",","," ","23",","," ","4",","," ","24",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.65,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["which"," is"," different"," from"," those"," of"," the"," open","ings"," of"," the"," other"," opening"," groups",","," then"," by"," forming"," smaller","-"," and"," larger","-","drop","let"," ej","ection"," ports"," for"," each"," of"," the"," ej","ection"," port"," groups"," for"," the"," cyan"," and"," mag"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.63,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["our"," own"," gal","actic"," disc",".\""," \"","By"," measuring"," the"," energy"," it"," em","its"," from"," the"," stars"," in"," the"," Small"," and"," Large","\u2191"," Mag","ell","anic"," clouds",","," astronom","ers"," believe"," they"," are"," made"," of"," different"," stuff"," than"," our"," galaxy",".\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.63,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["socket"," w","ren","ches",","," provides"," a"," complete"," set"," of"," hand"," tools"," that"," will"," engage"," a"," full"," range"," of"," small"," and"," large"," English"," and"," metric"," size"," f","itt","ings"," of"," regular"," depth"," hex","agonal"," nuts"," and"," bol","ts"," and"," deep"," well"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.62,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","\u23ce","Yes",","," for"," this"," calculation"," you"," will"," need"," to"," identify"," which"," numbers"," are"," being"," taken"," as"," the"," smaller"," and"," larger"," values",","," and"," what"," they"," represent","."," The"," context"," for"," this"," calculation"," will"," depend"," on"," more"," information"," provided","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.63,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["."," ","\u23ce\u23ce","Human",":"," ","\u23ce","\u2191","Al","right",","," can"," you"," repeat"," the"," difference"," in"," time"," between"," small"," and"," large"," pot","atoes","?","\u23ce\u23ce","Assistant",":"," Sure","!"," ","\u23ce","-"," Small"," pot","atoes",":"," ","10","-","15"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.62,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["il"," may"," also"," be"," comp","ounded"," by"," FF","R","s"," being"," made"," in"," fairly"," generic"," \"","small",","," medium",","," and"," large","\""," sizes",","," and"," often"," simply"," as"," a"," \"","one"," size"," fits"," all","\""," design","."," Therefore"," it"," can"]}]},{"quantile_name":"Subsample Interval 0","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["little"," capital",".","\u23ce\u23ce","\u2191","Retail"," businesses"," can"," be"," highly"," scal","able"," because"," they"," can"," be"," operated"," on"," a"," small"," or"," large"," scale"," depending"," on"," the"," size"," of"," the"," market"," and"," the"," level"," of"," demand","."," Additionally",","," the"," costs"," of"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.89,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["But"," it"," was"," scary",".\""," \"","So"," there"," were"," two","\u2191"," Yam","ato","-","no","\u2191"," Or","ochi",","," small"," and"," large","?\""," \"","There"," was"," the"," ","8"," ","section","\u2191"," Yam","ato","-","no","\u2191"," Or","ochi"," that"," came"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.86,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["with"," the"," printer"," system"," may"," be"," used"," with"," various"," differently"," sized"," ink"," containers","."," In"," order"," to"," allow"," both"," small"," and"," large"," volume"," ink"," containers"," to"," be"," installed"," in"," a"," printer"," system",","," it"," is"," known"," to"," use"," a"," spac","er"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.86,0.0,0.0,0.0,0.35,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["and"," come"," into"," play","."," And","\u23ce"," even"," code"," organization"," exist"," at"," different"," levels",":"," in"," the"," small",","," in"," the"," medium","\u23ce"," and"," in"," the"," large","."," It","'s"," good"," to"," try"," and"," get"," an"," idea"," at"," all"," levels","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["can"," receive"," and"," rotate"," a"," tub","ular"," having"," a"," specific"," diameter"," and"," cannot"," adjust"," for"," tub","ul","ars"," having"," smaller"," or"," larger"," di","ame","ters","."," Therefore",","," there"," is"," a"," need"," for"," providing"," a"," rotating"," device"," that"," can"," receive"," and"]}]},{"quantile_name":"Subsample Interval 1","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.86,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["with"," the"," printer"," system"," may"," be"," used"," with"," various"," differently"," sized"," ink"," containers","."," In"," order"," to"," allow"," both"," small"," and"," large"," volume"," ink"," containers"," to"," be"," installed"," in"," a"," printer"," system",","," it"," is"," known"," to"," use"," a"," spac","er"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.86,0.0,0.0,0.0,0.35,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["and"," come"," into"," play","."," And","\u23ce"," even"," code"," organization"," exist"," at"," different"," levels",":"," in"," the"," small",","," in"," the"," medium","\u23ce"," and"," in"," the"," large","."," It","'s"," good"," to"," try"," and"," get"," an"," idea"," at"," all"," levels","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["can"," receive"," and"," rotate"," a"," tub","ular"," having"," a"," specific"," diameter"," and"," cannot"," adjust"," for"," tub","ul","ars"," having"," smaller"," or"," larger"," di","ame","ters","."," Therefore",","," there"," is"," a"," need"," for"," providing"," a"," rotating"," device"," that"," can"," receive"," and"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.77,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["people"," just"," change"," it"," by"," trial"," and"," error",".","  ","You"," can"," also"," turn"," the"," thing"," to"," make"," it"," smaller"," or"," bigger",".","  ","Can"," I"," be"," more"," specific"," about"," how"," to"," adjust"," a"," particular"," wr","ench","?","\u23ce","<","|"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.77,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":15,"is_repeated_datapoint":true,"tokens":["<EOT>","ique"," lines",".","\u23ce","Therefore",","," depending"," on"," whether"," the"," interval"," W"," is"," small"," or"," large",","," black"," stre","aks"," or"," white"," stre","aks"," are"," formed"," on"," the"," recording"," paper",","," and"," hence"," this"," interval"]}]},{"quantile_name":"Subsample Interval 2","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.73,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["that"," the"," logo"," is"," scal","able",","," so"," that"," it"," looks"," good"," whether"," it","'s"," small"," on"," a"," business"," card"," or"," large"," on"," a"," billboard",".","\u23ce\u23ce","Overall",","," creating"," a"," logo"," can"," be"," a"," complex"," process",","," so"," it","'s"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.72,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["dose"," of"," cyn","icism"," and"," gr","ump","iness",".\"","<EOT>","\u23ce\u23ce","Human",":"," Please"," arrange"," the"," following"," numbers"," from"," small"," to"," large","\u23ce","[","27",","," ","20",","," ","7",","," ","23",","," ","4",","," ","24",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["ula"," ret","orna"," um"," valor"," in","v\u00e1l","ido",".","<EOT>","\u23ce\u23ce","Human",":"," please"," sort"," the"," following"," numbers"," from"," small"," to"," big","\u23ce","[","162",","," ","236",","," ","299",","," ","118",","," ","83",","," ","127",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["best","."," Can"," you"," provide"," some"," additional"," suggestions","?","\u23ce\u23ce","Assistant",":"," ","\u23ce","Of"," course","."," Consider"," small"," scale"," and"," subtle"," details"," such"," as"," texture","."," Select"," rus","tic","-","looking"," tiles"," for"," a"," hand","m","ade"," f","lair",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.69,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["for"," all","!"," ","\\xf0\\x9f","\\x8c","\\x88","\\xf0\\x9f\\x92","\\xaa","<EOT>","\u23ce\u23ce","Human",":"," Please"," arrange"," the"," following"," numbers"," from"," small"," to"," large","\u23ce","[","27",","," ","20",","," ","7",","," ","23",","," ","4",","," ","24",","]}]},{"quantile_name":"Subsample Interval 3","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.63,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["."," ","\u23ce\u23ce","Human",":"," ","\u23ce","\u2191","Al","right",","," can"," you"," repeat"," the"," difference"," in"," time"," between"," small"," and"," large"," pot","atoes","?","\u23ce\u23ce","Assistant",":"," Sure","!"," ","\u23ce","-"," Small"," pot","atoes",":"," ","10","-","15"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.62,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["il"," may"," also"," be"," comp","ounded"," by"," FF","R","s"," being"," made"," in"," fairly"," generic"," \"","small",","," medium",","," and"," large","\""," sizes",","," and"," often"," simply"," as"," a"," \"","one"," size"," fits"," all","\""," design","."," Therefore"," it"," can"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["high","-","quality",","," cost","-","effective"," printing"," solutions"," to"," meet"," your"," unique"," requirements","."," Whether"," you"," need"," a"," small"," or"," large"," order",","," we"," guarantee"," consistent"," and"," reliable"," service",".","\u23ce\u23ce","Our"," offset"," printing"," services"," offer"," a"," wide"," range"," of"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","3","."," Size",":"," This"," factor"," refers"," to"," the"," idea"," that"," small","-","cap"," stocks"," tend"," to"," out","per","form"," large","-","cap"," stocks"," over"," time",".","\u23ce","4","."," Quality",":"," This"," factor"," reflects"," the"," idea"," that"," stocks"," with"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.56,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["your"," case",","," and"," why","?"," Would"," the"," outcome"," change"," if"," the"," initial"," distance"," from"," the"," led","ge"," was"," smaller"," or"," larger"," than"," ","2"," ","meters","?"," Would"," the"," outcome"," change"," if"," the"," distance"," of"," each"," successive"," jump"," was"," larger"]}]},{"quantile_name":"Subsample Interval 4","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["l","v","'s"," can"," definitely"," be"," res","ized"," right","?","\u23ce","<","lv","mer",">"," x","n","ox",":"," smaller"," /"," larger"," right","?"," x","D","\u23ce","<","lv","mer",">"," x","n","ox",":"," n","vm"," stupid"," question","\u23ce","<"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["big"," lakes"," up"," there"," are"," quite"," scenic",".","  ","They","'re"," also"," big"," enough"," to"," have"," some"," small","mouth"," bass",","," wal","le","ye",","," and"," so"," on",".","  ","If"," you"," want"," to"," camp",","," you"," might"," want"," to"," check"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["20","B",","," ","20","F",")"," which"," must"," be"," pull"," out"," and"," opened"," for"," use"," accommod","ating"," a"," small"," or"," large"," drink"," cup","."," When"," not"," in"," use",","," this"," drink"," cup"," holder"," is"," normally"," ret","racted"," into"," the"," arm"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08,0.47,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a"," small"," distance"," ","22"," ","from"," the"," surface"," ","18"," ","of"," the"," tip"," ","8","."," However",","," a"," large"," pro","tr","usion"," ","24"," ","may"," extend"," a"," large"," distance"," ","26"," ","from"," the"," surface"," ","18"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.46,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["alized"," for"," Covid"," between"," the"," fully"," vacc","inated"," and"," those"," who"," are"," not",","," and"," div","iding"," the"," smaller"," by"," the"," larger"," group",".","  ","C",":"," This"," varies"," slightly"," more","."," Again",","," variation"," due"," to"," circumstances"," (","availability"," and"]}]},{"quantile_name":"Subsample Interval 5","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.42,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["S","."," Pat","."," No","."," ","7",",","489",",","352"," ","dis","close"," methods"," in"," which"," two"," small"," and"," large"," photo","di","odes"," are"," constructed"," and"," two"," signals"," are"," output"," from"," the"," photo","di","odes",","," the"," two"," signals"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.41,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["size"," and"," the"," number"," of"," cells"," are"," hyper","par","ame","ters"," that"," can"," be"," adjusted"," to"," balance"," between"," detecting"," small"," and"," large"," objects",".","\u23ce\u23ce","The"," process"," of"," div","iding"," the"," image"," into"," a"," grid"," and"," pred","icting"," the"," b","ounding"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.39,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.44,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["mu",".","m","),"," the"," sh","arp","ness"," of"," the"," lumin","ance","-","voltage"," characteristic"," .","gamma","."," becomes"," poor"," (","large",")"," and"," the"," viewing","-","angle"," depend","ence"," .","\u21ea","DELTA","..","phi","."," becomes"," good"," (","large",")."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.39,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["into"," small"," aggreg","ates"," and"," larger"," cl","um","ps","."," Well","-","structured"," so","ils"," are"," aggreg","ated"," into"," small"," and"," large"," p","ore"," spaces"," that"," allow"," oxygen"," and"," water"," to"," penet","rate"," into"," the"," soil"," profile",".","\u23ce","3","."]}]},{"quantile_name":"Subsample Interval 6","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.32,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a"," few"," silver"," bullets"," for"," staying"," consistent"," and"," motivated",":"," ","\u23ce","1",".","\u2191"," Celebrate"," every"," win",","," small"," or"," large",".","\u2191"," Acknowledge"," your"," efforts",","," as"," it"," will"," provide"," motivation"," and"," a"," sense"," of"," accompl","ishment","."," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.31,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Local","\u2191"," Delivery"," Services",":"," There"," are"," several"," local"," delivery"," services"," in"," New"," Jersey"," that"," offer"," freight"," solutions"," for"," small"," and"," medium","-","sized"," businesses","."," These"," companies"," typically"," have"," a"," network"," of"," drivers"," and"," vehicles"," that"," can"," handle"," local"," deliv"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ities",","," including"," a"," large"," open"," area"," for"," dogs"," to"," run"," and"," play",","," a"," separate"," area"," for"," small"," dogs"," and"," pupp","ies",","," a"," variety"," of"," se","ating"," and"," shade"," areas",","," drinking"," fount","ains"," for"," both"," humans"," and"," dogs"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["3",","," the"," crystal"," gr","ains"," of"," the"," sample"," with"," a"," small"," bias"," drift"," was"," smaller"," compared"," to"," samples"," with"," a"," large"," bias"," drift",".","\u23ce","In"," general",","," conduct","ivity"," of"," the"," w","iring"," used"," in"," semiconductor"," devices"," is"," better"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","Interesting","!"," Are"," you"," looking"," for"," something"," large"," or"," something"," small","?","\u23ce\u23ce","Human",":"," ","\u23ce","Either"," small"," or"," medium"," sized","."," I"," don","'t"," want"," something"," too"," large"," that","'s"," hard"," to"," drive","."," And"," it"," will"," usually"]}]},{"quantile_name":"Subsample Interval 7","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.21,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce\u23ce","\u2191","Li","ao","yang","\u2191"," W","an","r","ong","\u2191"," Chemicals"," has"," a"," diverse"," customer"," base"," that"," includes"," small"," and"," medium","-","sized"," enterprises"," as"," well"," as"," large"," multin","ational"," corporations","."," The"," company","'s"," goal"," is"," to"," provide"," high"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.21,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","23","581","}"," serial","ized","Version",":"," ","5"," ","m","_","Component",":"," -"," component",":"," {","file","ID",":"," ","6","015","}"," -"," component",":"," {","file","ID",":"," ","15","326","}"," -"," component",":"," {"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.44,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["are"," only"," aver","ages"," --"," some"," objects"," that"," are"," smaller"," than"," this"," could"," still"," be"," ri","sky",","," and"," some"," objects"," that"," are"," larger"," could"," be"," fine","."," But"," usually"," you"," should"," feel"," pretty"," safe"," with"," objects"," that"," are"," ","1"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.19,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","However",","," in"," ch","uc","king",","," the"," small"," diameter"," cup"," provides"," a"," holding"," force"," smaller"," than"," that"," of"," the"," large"," diameter"," cup",".","\u2191"," Owing"," to"," this",","," particularly",","," in"," rough","ing"," the"," peripheral"," edge"," of"," a"," un"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.18,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","Interesting","!"," Are"," you"," looking"," for"," something"," large"," or"," something"," small","?","\u23ce\u23ce","Human",":"," ","\u23ce","Either"," small"," or"," medium"," sized","."," I"," don","'t"," want"," something"," too"," large"," that","'s"," hard"," to"," drive","."," And"," it"," will"," usually"]}]},{"quantile_name":"Subsample Interval 8","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["output"," is"," controlled"," with"," a"," high"," frequency",","," while"," the"," inver","ter"," circuit"," of"," the"," other"," ro","tor"," which"," has"," a"," larger"," output"," is"," controlled"," with"," a"," low"," frequency",","," whereby"," the"," heat"," value"," of"," the"," motor"," is"," supp","ressed","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["are"," used",","," and"," a"," compound"," semiconductor"," with"," a"," small"," band"," gap"," is"," inter","posed"," between"," compound"," semiconduct","ors"," with"," a"," larger"," band"," gap","."," To"," fabric","ate"," a"," double"," het","ero"," structure",","," each"," of"," compound"," semiconduct","ors"," with"," conduct"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.14,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","c","$","  ","\u2191","St","\u00f6","c","fer","  ","mit","  ","fol","c","ber","  ","l","'","ic","be","  ","au",".","  ","\u2191","St","\u00f6","c","fer","  ","bat","  ","","oon","  ","","aller","  ","fe","iner"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["compens","ate"," for"," loss"," of"," low"," frequency"," physical"," impact"," and"," because"," the"," artificial"," bass"," is"," used"," at"," small"," signal"," levels"," and"," large"," signal"," levels",","," it"," can"," im","part"," an"," unre","alistic"," col","oration"," to"," the"," bass"," tone"," at"," all"," levels"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[":"," ","\u23ce","What"," kind"," of"," tul","ip"," magn","olia"," are"," you"," trying"," to"," pr","une","?"," Are"," they"," small"," or"," large","?"," Are"," they"," new"," or"," mature","?","\u23ce\u23ce","Human",":"," ","\u23ce","It","'s"," a"," medium"," sized"," tul","ip"]}]},{"quantile_name":"Bottom Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["it"," mean"," medium","?"," :",")","\u23ce","<","pl","eia","2",">"," l","iken"," ","ot"," a"," mouse",","," and"," not"," a"," dog","\u23ce","<","kn","ome",">"," no",","," it"," means"," B","IG","\u23ce","<","pl","eia","2",">"," eleph"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["for"," small"," bag",";"," ","70"," ","for"," large","\u23ce"," bag",";"," sham","rock",","," small"," bag"," ","60","o"," ,"," large"," $","1"," ","00",",","\u23ce","makes"," bread"," as"," white"," as"," snow"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["for"," f","rying","',"," ","'","\u2191","Tom","ato"," sauce","',"," '","1"," ","to"," ","2"," ","pounds"," sweet"," or"," hot"," Italian"," s","aus","age"," links"," (","I"," try"," to"," find"," a"," brand"," with"," the"," fe","west"," and"," most"," recogn"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["and"," Johnson",","," S",".,"," Yang",","," R",".,","\u2191"," S","ommer",","," T",".,"," \"","\u2191","Interpretation"," of"," Small"," and","\u2191"," Intermediate"," Scale"," Test"," Results"," from"," a"," Low"," NO","x","\u2191"," Combust","ion"," System"," for","\u2191"," Pul","ver","ized"," Coal"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["between"," large"," and"," small"," an","eur","ys","ms","."," Small"," an","eur","ys","ms"," may"," not"," cause"," any"," symptoms",","," but"," large"," an","eur","ys","ms"," can"," cause"," a"," range"," of"," symptoms"," such"," as"," a"," head","ache",","," neck"," pain",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["|"," short"," |"," long"," |"," ","\u23ce","|"," magnitude"," |"," small"," |"," large"," |"," ","\u23ce","|"," mass"," |"," small"," |"," large"," |"," ","\u23ce","|"," od","or"," |"," weak"," |"," strong"," |"," ","\u23ce","|"," pressure"," |"," low"," |"," high"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".\""," \"","\u2191","Sta","ros",".\""," \"","I","'m"," going"," to"," let"," you"," apply"," for"," reass","ignment"," to"," the"," Judge","\u2191"," Advocate"," General"," Corps"," for"," reasons"," of"," ill"," health",".\""," \"","You","'re"," a"," lawyer",".\""," \"","I"," haven","'t",".\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[":"," Like"," most"," people",","," I"," conduct","\u23ce",">"," relatively"," few"," experiments"," in"," my"," personal"," life",","," in"," both"," small"," and"," big","\u23ce",">"," things",".","\u23ce\u23ce","I"," think"," this"," is"," related"," to"," learning","."," Once"," you","'ve"," learned"," a"," particular"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.11,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Error",":"," boolean",")"," {","\u23ce","    ","const"," size"," ="," new","Error"," ?"," ","'","Small","'"," :"," ","'","\u2191","Closed","'","\u23ce","    ","if"," (","this",".","state",".","size"," !=="," size",")"," {","\u23ce","      ","this",".","setState"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["variation"," of"," the"," dimensions"," of"," each"," of"," the"," pie","zo","electric"," reson","ator",","," the"," terminal"," and"," the"," spring"," member"," is"," large",","," a"," contact"," pressure"," (","holding"," pressure",")"," of"," the"," pie","zo","electric"," reson","ator"," and"," the"," terminal"," becomes"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.14,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["i","\u00df",",","  ","\u2191","Ta","rum","  ","bang",":"," ","\u23ce","c","$","  ","\u2191","St","\u00f6","c","fer","  ","mit","  ","fol","c","ber","  ","l","'","ic","be","  ","au",".","  ","\u2191","St","\u00f6","c","fer","  "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ishing"," composition","."," If"," the"," addition"," amount"," of"," hydrogen"," per","oxide"," is"," ex","cess","ively"," small",","," or"," ex","cess","ively"," large",","," the"," stock"," removal"," rate"," of"," the"," copper"," layer"," tends"," to"," be"," low",","," and"," due"," care"," will"," accordingly"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["smaller"," and"," \u03bb",""," is"," larger","."," That"," is",","," the"," tro","car"," ","1"," ","requires"," small"," \u03b8",""," and"," large"," \u03bb","",".","\u23ce","However",","," the"," conventional"," tro","car"," ","1"," ","has"," a"," straight","-","line"," type"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a"," nonprofit","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","Are"," p","anda"," p","ears"," herb","iv","ores"," or"," omn","iv","ores","?","\u23ce\u23ce","Assistant",":"," ","\u23ce","Sure",","," here"," are"," some"," information"," sources"," that"," might"," be"," helpful",":","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["des","  ","\u2191","Champ","ig","not","ss","  ",",","  ","qui","  ","forme","  ","le","  ","der","nier","  ","cha","\u00een","on"," ","\u23ce","du","  ","r\u00e8g","ne","  ","v\u00e9g","\u00e9","tal",".","  ","!","l","  ","est","  ","compos","\u00e9"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","\u23ce\u23ce","Assistant",":"," ","\u23ce","To"," calculate"," the"," percentage"," increase"," between"," two"," different"," values",","," subtract"," the"," smaller"," value"," from"," the"," larger"," value"," and"," divide"," the"," result"," by"," the"," smaller"," value","."," Then",","," multiply"," the"," result"," by"," ","100"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["through"," the"," reference"," cell","."," A"," cell"," current"," flowing"," through"," an"," accessed"," memory"," cell"," that"," stores"," \"","1","\""," may"," be"," larger"," than"," the"," reference"," current",".","\u23ce","A"," large"," cell"," current"," flows"," through"," each"," of"," the"," accessed"," memory"," cells"," that"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["infra","red"," lights"," or"," current"," of"," the"," loop"," co","il",","," and"," the"," TC"," sensors"," also"," distinguish"," between"," small"," cars"," and"," large","-","sized"," cars"," at"," the"," same"," time",".","\u23ce","However",","," there"," is"," a"," possibility"," that"," these"," TC"," sensors"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","1"," ","cannot"," be"," re","-","used",","," in"," some"," cases",".","\u23ce","b","."," Because"," an"," edge"," of"," a"," large"," diameter"," part"," of"," the"," ground"," tube"," ","20"," ","b","ites"," into"," the"," inner"," face"," of"," the"," through"," hole"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["???"," l","act"," tt","iat"," it"," is"," more"," particular"," in"," its"," prepar","atory","\u23ce"," examination"," in"," cases"," ol"," small"," than"," of"," large","\u23ce"," mix","\u23ce"," It"," has"," also"," been"," found",","," contrary"," to"," pre","con","ce","ived","\u23ce"," ideas"," mat"," inc"]}]}],"top_logits":["lar","larg","ler","la","\u0131n\u0131n","large","lg","lag","l"],"bottom_logits":["\u0012"]}