{"index":15593236,"examples_quantiles":[{"quantile_name":"Top Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.38,0.82,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","\u23ce","9",".","\u2191"," Rh","y","ming"," Games",":"," Have"," your"," child"," create"," a"," set"," of"," words"," that"," rh","yme"," with"," the"," given"," word",".","\u23ce","10","."," Word","\u2191"," Cube",":"," Allow"," your"," child"," to"," r","ear","range"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.98,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["'m"," afraid"," I"," don","'t"," understand"," the"," question","."," I"," can"," give"," you"," a"," list"," of"," some"," words"," that"," rh","yme"," with"," \"","p","oo","\","," but"," I","'m"," not"," really"," sure"," what"," you"," are"," looking"," for","."," Here"," are"," some"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.83,0.0,0.0,0.0,0.0,0.0,0.97,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.97,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["understand"," the"," question",".","\u23ce\u23ce","Human",":"," ","\u23ce","No",","," can"," you"," rh","yme"," appropriate"," words"," that"," actually"," rh","yme"," with"," p","oo","?","\u23ce\u23ce","Assistant",":"," Here"," are"," some"," words"," that"," actually"," rh","yme"," with"," \"","p","oo","\":"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.98,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["they"," learn"," new"," words"," and"," phrases","."," This"," can"," be"," achieved"," by"," using"," repet","itive"," language"," and"," phrases"," that"," rh","yme"," or"," sound"," similar",","," as"," well"," as"," cutting"," out"," words"," that"," they"," may"," not"," be"," able"," to"," sound"," out"," yet"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.97,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\""," \"","\\xe2\\x99","\\xaa",""," To"," be"," so"," intense","\""," \"","\\xe2\\x99","\\xaa",""," But"," still"," have"," words"," that"," rh","yme"," ","\\xe2\\x99","\\xaa","\""," \"","\\xe2\\x99","\\xaa","\""," \"","\\xe2\\x99","\\xaa",""," The"," world"," is"," all"," you"," have",","," my"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.97,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.98,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["who"," enjoys"," creativity"," and"," experi","mentation"," in"," their"," games",".","<EOT>","\u23ce\u23ce","Human",":"," what"," are"," five"," words"," that"," rh","yme"," with"," clock","?","\u23ce\u23ce\u23ce","Assistant",":"," Here"," are"," five"," words"," that"," rh","yme"," with"," \"","clock","\":","\u23ce\u23ce","1","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.97,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["unh","appy"," with"," my"," answers","."," I"," was"," just"," trying"," to"," give"," you"," a"," list"," of"," some"," words"," that"," rh","yme"," with"," \"","p","oo","\"."," I","'m"," afraid"," I"," don","'t"," really"," understand"," the"," question",".","\u23ce\u23ce","Human",":"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.97,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["sound"," out"," will"," make"," their"," reading"," experience"," more"," enjoy","able","."," ","\u23ce\u23ce","You"," could"," also"," incorporate"," phrases"," that"," rh","yme"," or"," use"," words"," that"," sound"," similar","."," ","\u23ce\u23ce","This"," should"," help"," build"," their"," excitement"," for"," reading","."," Instead"," of"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.96,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["first"," word"," of"," each"," sentence"," should"," start"," with"," an"," \"","S","\""," and"," the"," second"," and"," fourth"," sentences"," should"," rh","yme",".","\u23ce\u23ce\u23ce\u23ce"," ","Here"," is"," the"," text",":"," A"," rainbow"," does"," not"," have"," a"," back"," side","."," If"," you"," were"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.96,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["have"," given"," you"," incorrect"," answers","."," I"," was"," just"," trying"," to"," give"," you"," a"," list"," of"," some"," words"," that"," rh","yme"," with"," \"","p","oo","\"."," I","'m"," afraid"," I"," don","'t"," really"," understand"," the"," question",".","\u23ce\u23ce","Human",":"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.96,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["\u23ce","<","|","stop","|",">","<EOT>","\u23ce","Find"," out"," which"," of"," the"," following"," sentences"," contain"," two"," words"," that"," rh","yme"," with"," each"," other","."," output"," the"," index"," of"," the"," sentence",".","\u23ce","The"," dog"," is"," bar","king",".","\u23ce\u23ce","Assistant"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.96,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","  ","If"," a"," child"," is"," learning"," to"," read",","," you"," could"," start"," by"," reading"," them"," books"," written"," in"," rh","yme",","," as"," these"," can"," be"," great"," tools"," for"," building"," a"," mental"," foundation"," for"," syll","able"," patterns",".","  ","Additionally",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["previous"," answer"," I"," gave"," you","."," I"," was"," just"," trying"," to"," give"," you"," a"," list"," of"," some"," words"," that"," rh","yme"," with"," \"","p","oo","\"."," I","'m"," afraid"," I"," don","'t"," really"," understand"," the"," question",".","\u23ce\u23ce","Human",":"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","Given"," a"," list"," of"," words",","," design"," a"," program"," that"," det","ects"," all"," possible"," pairs"," of"," words"," that"," rh","yme","."," for"," example",":"," rose"," -","","ose",","," lose"," -"," chose",","," rise"," -"," eyes",","," etc",".","\u23ce\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.39,0.74,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["and"," the"," number"," of"," buc","kets"," used",".","<EOT>","\u23ce\u23ce","Human",":"," Write"," me"," a"," poem"," that"," does","nt"," rh","yme","\u23ce\u23ce"," Assistant",":"," Here","'s"," a"," non","-","rh","y","ming"," poem"," for"," you",":","\u23ce\u23ce","\u2191","Fragments"," of","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.94,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["here","'s"," a"," poem"," with"," pick","-","up"," lines"," that"," focuses"," on"," a"," n","erd"," girl",","," written"," in"," rh","yme",":","\u23ce\u23ce","She","'s"," a"," book","w","orm",","," a"," br","ain","iac",","," a"," math"," wh","iz","\u23ce"," But"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.93,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","\u23ce","Let","'s"," take"," it"," slow"," and"," see"," what"," follows"," ","\u23ce","\u2191","We","aving"," our"," words"," with"," rh","yme"," and"," holl","ows"," ","\u23ce","We"," can"," form"," a"," ball","ad",","," start"," with"," a"," hook"," ","\u23ce","\u2191","Verses"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.93,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce\u23ce","Assistant",":"," ","\u23ce","What"," kind"," of"," poem"," were"," you"," thinking"," about","?"," Would"," you"," like"," it"," to"," rh","yme","?"," Would"," you"," like"," it"," to"," be"," more"," narrative","?","\u23ce\u23ce","Human",":"," ","\u23ce","I","'d"," like"," it"," to"]}]},{"quantile_name":"Subsample Interval 0","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.89,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.97,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["the"," room"," and"," the"," property"," through"," the"," lease",".","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","What"," words"," rh","yme"," with"," ","'","cat","'","?","\u23ce\u23ce","Assistant",":"," Here"," are"," some"," words"," that"," rh","yme"," with"," ","'","cat"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.91,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["dh","ear","ted","\u23ce"," ","ness"," of"," the"," ba","bes"," to"," their"," el","ders"," is"," caught","\u23ce"," here"," in"," rh","yme","."," Mr","\u2191"," Haw","kes"," is"," to"," be"," con","\u23ce"," grat","ulated"," on"," an"," original"," departure",".","\u23ce","He"," begins"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.84,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["easy"," to"," remember"," and"," well","-","used"," to"," apply"," phrases","."," You"," can"," also"," try"," using"," rh","yme"," or"," rh","yme"," to"," help"," identify"," vocabulary"," you"," need"," to"," remember",".","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","Where"," can"," I"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","\u23ce","My"," thoughts"," I"," must"," capture",","," my"," ideas"," I"," must"," claim",",","\u23ce","To"," express"," them"," in"," rh","yme"," is"," my"," true"," aim",".","\u23ce","I"," know"," I","'ve"," written"," something"," quite"," grand",",","\u23ce","When"," I"," can"," read"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.89,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["Is"," there"," anything"," else"," I"," can"," assist"," you"," with","?","\u23ce\u23ce","Human",":"," could"," you"," please"," speak"," only"," in"," rh","yme","?","\u23ce\u23ce","Assistant",":"," Oh"," NAME","_","1",","," with"," pleasure"," so"," fine",",","\u23ce","I","'ll"," speak"," in"," verse"]}]},{"quantile_name":"Subsample Interval 1","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["of"," pin","yin",","," studying"," the"," t","ones"," and"," syll","ables"," of"," Chinese",","," and"," reading"," al","oud"," using"," rh","ymes"," and"," tongue"," t","wi","sters","."," Additionally",","," memor","izing"," audio"," recordings"," of"," the"," t","ones"," and"," sounds",","," or"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ch","-","change"," the"," world",","," not","\""," \"","Ch","-","change"," the"," world","?\""," \"","What",","," with"," rh","yme","?\""," \"","Yes",".\""," \"","Why"," not","?\""," \"","Why"," can","'t"," a"," man"," change"," the"," world"," with"," words","?\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.46,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.78,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["a"," touch"," of"," sophist","ication"," to"," your"," jewelry"," collection",".","<EOT>","\u23ce\u23ce","Human",":"," Can"," you"," write"," a"," rh","y","ming"," poem"," about"," flying"," pen","gu","ins","?"," There"," should"," be"," as"," many"," rh","ymes"," as"," possible",".","\u23ce\u23ce","Assistant",":"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.45,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a"," casual"," tone"," of"," voice"," to"," improve"," its"," clarity",":"," As"," the"," kinderg","arten"," school"," bell"," rang",","," rh","y","ming"," synchron","ously"," with"," the"," rip","ples"," in"," the"," nearby"," lily","-","filled"," p","onds",","," a"," huge"," gang"," of"," kids"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," reading",","," and"," writing","."," ","\u23ce","4","  ","Use"," m","nem","onic"," devices"," such"," as"," stories"," or"," rh","ymes"," to"," help"," remember"," facts"," or"," figures",".","\u23ce","5","  ","\u2191","Organize"," information"," into"," meaningful"," chunks"," and"," categories"," to"," aid"]}]},{"quantile_name":"Subsample Interval 2","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","\u23ce","would","  ","hardly","  ","be","  ","acknowledged","  ","as","  ","such","  ","without","  ","the"," ","\u23ce","rh","yme","  ","to","  ","cl","ench","  ","it",".","  ","A","  ","quot","ation","  ","or","  ","a","  ","hack","ne"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["seems"," that"," many"," authors"," have"," tried"," to"," ret","ell"," this"," story"," through"," history","!"," Some"," sources"," say"," that"," the"," rh","yme"," was"," first"," published"," by"," Edward","\u2191"," ","Lear"," in"," A"," Book","\u23ce\u23ce"," Human",":"," ","\u23ce","That","'s"," a"," Book"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["step"," in"," time"," ","\\xe2\\x99","\\xaa","\""," \"","\\xe2\\x99","\\xaa",""," Never"," need"," a"," reason",","," never"," need"," a"," rh","yme","."," ","\\xe2\\x99","\\xaa","\""," \"","Boy",","," he","'s"," got"," it"," down",".\""," \"","I"," think"," I","'m"," f"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.39,0.69,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["social"," connect","edness",".","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","What"," number"," corresponds"," to"," r","ding"," rh","y","med"," with"," butterfly"," and"," west","\u23ce"," ","\u23ce"," ","1"," ","\u23ce\u23ce","Assistant",":"," I"," apolog","ize",","," but"," the"," text"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Yeah",","," you"," know"," your"," mama"," told"," you","\""," \"","\\xe2\\x99","\\xaa",""," So"," many"," times"," like"," nurs","ery"," rh","ymes","\""," \"","\\xe2\\x99","\\xaa","","\u2191"," Stuck"," inside"," your"," head","\""," \"","\\xe2\\x99","\\xaa",""," The"," mystery"," of"," life"," can"]}]},{"quantile_name":"Subsample Interval 3","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.61,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\"."," The"," rings",","," or"," \"","pos","ies","\","," are"," the"," sympt","om"," of"," the"," plague",","," and"," the"," rh","yme"," is"," supposed"," to"," be"," an"," all","usion"," to"," the"," death"," of"," a"," child",","," and"," to"," the"," repet","itive"," pattern"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.61,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["and"," par","sley"," backend",".","   ","bt","w",","," ignore"," the"," D","V","'s"," here","."," There"," is"," no"," rh","yme"," or"," reason"," for"," it",".","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","What"," does"," it"," mean"," to"," balance"," a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.25,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["erh","em","is","ph","eric"," abn","orm","alities"," (","\u2191","Dich","otic","\u2191"," Listening","\u2191"," F","used","\u2191"," Rh","y","med"," Task",")"," and"," imp","air","ments"," in"," verbal"," and"," spatial"," working"," memory"," tasks",","," respectively","."," Other"," career"," enhancement"," plans"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["mad","-","cow"," testing",",\""," \"","Which"," nobody"," does","!\""," \"","Makes"," no"," sense",".\""," \"","There","'s"," no"," rh","yme",","," no"," reason",","," no","...\""," \"","It","'s"," cool",".\""," \"","Don","'t"," pop"," a"," nerve",".\""," \"","Don"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ably"," affected"," by"," climate"," issues","?","\u23ce\u23ce","Assistant",":"," ","\u23ce","Sure","!"," Here"," is"," a"," revised"," nurs","ery"," rh","yme"," to"," use"," instead",":","\u23ce","This"," little"," pig","gy"," tried"," to"," play"," the"," whole"," day",",","\u23ce","This"," little"," pig"]}]},{"quantile_name":"Subsample Interval 4","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.53,0.85,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.46,0.8,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["sure"," that"," they"," are"," comfortable"," with"," the"," conversation","."," Good"," luck","!","\u23ce\u23ce","Human",":"," can"," you"," write"," a"," rh","y","ming"," poem"," about"," an"," e","-","girl","?","\u23ce\u23ce","Assistant",":"," Here","'s"," a"," rh","y","ming"," poem"," about"," an"]},{"tokens_acts_list":[0.0,0.0,0.38,0.83,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.51,0.88,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","Rh","y","ming"," Challenge",":","\u2191"," Provide"," your"," child"," with"," a"," word"," and"," have"," them"," find"," as"," many"," rh","y","ming"," words"," as"," possible",".","\u23ce\u23ce","5","."," Word"," Chain",":"," Start"," with"," one"," word"," and"," then"," have"," your"," child"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.74,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.84,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.84,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","line"," poem","?","\u23ce","5","."," Choose"," a"," rh","yme"," scheme",":"," Do"," you"," want"," to"," write"," a"," rh","y","ming"," poem","?"," If"," so",","," what"," rh","yme"," scheme"," do"," you"," want"," to"," use","?","\u23ce","6","."," Choose"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.49,0.87,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["tips"," to"," help"," your"," children"," learn"," about"," syll","ables",":","\u23ce\u23ce","-","Try"," explaining"," syll","ables"," in"," terms"," of"," rh","y","ming"," words",".","  ","For"," example",","," a"," word"," like"," P","ET"," can"," be"," separated"," into"," two"," syll","ables"," ("]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.49,0.83,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a"," possible"," version"," of"," \"","The"," NAME","_","3","\""," by"," NAME","_","2"," ","with"," different"," lyrics"," and"," rh","y","ming"," scheme",":","\u23ce\u23ce","\u2191","Verse"," ","1",":","\u23ce","I"," was"," born"," in"," Manchester",","," raised"," in"," the"," city"]}]},{"quantile_name":"Subsample Interval 5","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.74,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["instrument","als"," for"," him"," to"," rap"," over","."," He"," is"," known"," for"," his"," fast","-","p","aced",","," complex"," rh","y","ming"," style",","," and"," he"," often"," uses"," word","play",","," metaph","ors",","," and"," other"," literary"," devices"," to"," create"," intr"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.39,0.68,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":[","," and"," sleep"," disorders",".","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","What"," number"," corresponds"," to"," r","ding"," rh","y","med"," with"," butterfly"," and"," west","\u23ce"," ","\u23ce"," ","1"," ","\u23ce\u23ce","Assistant",":"," I"," apolog","ize",","," but"," the"]},{"tokens_acts_list":[0.86,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.29,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["yme"," like"," Common","\u2191"," Sense","\u23ce\u23ce","(","But"," i"," did"," five","\u2191"," Mil",")","\u23ce\u23ce","I"," ain","'t"," been"," rh","y","min"," like"," Common"," since","\u23ce\u23ce"," When"," your"," sense"," got"," that"," much"," in"," common","\u23ce\u23ce"," And"," you"," been"," hust","lin"," since"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.74,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["I"," apolog","ize"," for"," the"," previous"," attempt","."," Here","'s"," another"," attempt"," at"," the"," poem",","," with"," every"," line"," rh","y","ming",":","\u23ce\u23ce","War"," in"," Ukraine","\u23ce\u23ce"," Blood"," st","ains"," the"," earth",",","\u23ce","A"," peaceful"," land"," now"," torn"," apart"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.29,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["you"," are"," pok","\u00e9","mon",","," there","'s"," no"," reason"," i"," can","'t"," capture"," you",".\""," \"","go",","," rh","y","horn",".\""," \"[","ro","ars","]","\""," \"","oh","h","!\""," \"","no","!\""," \"","rh","y","horn","!\""," \""]}]},{"quantile_name":"Subsample Interval 6","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.31,0.62,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["that","\u23ce"," would"," have"," purchased"," six"," slaves",".","\u23ce","In"," the"," epic"," \"","\u2191","Ar","auc","ana",",\""," a"," rh","y","med","\u23ce"," chronicle"," of"," t","ho"," conquest"," of","\u2191"," Ch","ili",",","\u23ce","there"," is"," an"," account"," of"," a"," \""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.35,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.31,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["pleasure"," to"," meet"," you",",","\u2191"," Rh","y","ner",".\""," \"","And"," so"," professional",".\""," \"","Hey",",","\u2191"," Rh","y","nes",".\""," \"","You"," didn","'t"," have"," to"," do"," that",".\""," \"","[","\u2191"," Ch","uck","les"," ]"," Yeah",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.44,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".\""," \"","Already"," late",".\""," \"","Don","'t"," w","anna"," tem","pt"," fate",".\""," \"","\u2191","Them","'s"," rh","y","min","'"," words",","," Charlie","!\""," \"","Well",","," ain","'t"," you"," smart",".\""," \"","Take"," a"," settle","..."," kn","uck"]},{"tokens_acts_list":[0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.29,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["go",","," rh","y","horn",".\""," \"[","ro","ars","]","\""," \"","oh","h","!\""," \"","no","!\""," \"","rh","y","horn","!\""," \"","me","wt","wo",":"," f","ools",".\""," \"","your"," pok","\u00e9","mon"," attacks"," cannot"," we","aken"," me"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.29,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["like"," Common","\u2191"," Sense","\u23ce\u23ce","(","But"," i"," did"," five","\u2191"," Mil",")","\u23ce\u23ce","I"," ain","'t"," been"," rh","y","min"," like"," Common"," since","\u23ce\u23ce"," When"," your"," sense"," got"," that"," much"," in"," common","\u23ce\u23ce"," And"," you"," been"," hust","lin"," since","\u23ce\u23ce"]}]},{"quantile_name":"Subsample Interval 7","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.22,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["rl","ty"," pr","\u00ab","-","f","\u00ab",">","r","T",">"," ","\u25a0",":.","\u23ce","\u2191","Jus","si","ln"," rh","ma","iii","."," ti","*"," l"," ",".'","\u2191"," L","ez","in","ston"," h","\\","-","."," Tel","."," ","4"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.43,0.21,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","<EOT>","\u23ce\u23ce","Human",":","\u2191"," Improve","\u21ea"," ONLY"," the"," ","2","."," line"," of"," this"," rap"," for"," rh","y","iming"," and"," better"," met","rum",":"," ","1","."," Listen"," up",","," NAME","_","1",","," I"," got"," something"," to"," show"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.19,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["A"," chance"," to"," get"," everything"," out"," in"," the"," open",","," you"," know",","," get"," everything"," out",".\""," \"","\u2191","Rh","ys","!\""," \"","Stay"," with"," me",",","\u2191"," Rh","ys",".\""," \"","Say"," you"," forg","ive"," me",".\""," \"","Say",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.19,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," you"," know",","," get"," everything"," out",".\""," \"","\u2191","Rh","ys","!\""," \"","Stay"," with"," me",",","\u2191"," Rh","ys",".\""," \"","Say"," you"," forg","ive"," me",".\""," \"","Say",","," \"","It","'s"," all"," right",",","\u2191"," G","wen"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.18,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["$","99","/","mo"," &"," Free"," Setup","\u23ce\u23ce"," www",".","cal","ih","op",".","net","\u23ce\u23ce","------","\u23ce","r","rh","yne","\u23ce"," Don","'t"," go"," with"," S","oft","Layer"," cloud","."," I"," had"," an"," instance"," and"," it"," was"," super"," slow","."]}]},{"quantile_name":"Subsample Interval 8","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.12,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["sure"," that"," they"," are"," comfortable"," with"," the"," conversation","."," Good"," luck","!","\u23ce\u23ce","Human",":"," can"," you"," try"," with"," rh","imes","?","\u23ce\u23ce","Assistant",":"," Here","'s"," a"," rh","y","ming"," poem"," with"," ner","dy"," pick","-","up"," lines",":","\u23ce\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.35,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.31,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["to"," meet"," you",",","\u2191"," Rh","y","ner",".\""," \"","And"," so"," professional",".\""," \"","Hey",",","\u2191"," Rh","y","nes",".\""," \"","You"," didn","'t"," have"," to"," do"," that",".\""," \"","[","\u2191"," Ch","uck","les"," ]"," Yeah",","," I"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["p","im","ple","."," The"," MS","."," reads"," pl","um","ella"," and"," p","lu","\u00e9t","\u00e9","lea","."," For"," h","yme"," that"," is"," s","met","yne"," with"," his"," aw","enne"," bl","ode",","," and"," sp","red","is"," over"," alle"," his"," l"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.12,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":[":"," Write"," a"," recommendation"," of"," things"," to"," do"," in","\u2191"," Cologne"," in"," a"," po","etic"," style",","," with"," r","yh","mes",","," in"," a"," maximum"," of"," ","5"," ","sentences","\u23ce\u23ce"," Assistant",":"," In","\u2191"," Cologne",","," where"," history"," and"," culture"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["in"," German"," in"," his"," writings"," that"," I"," feel"," translation","\u23ce"," loses","."," As"," well"," as"," emphasis"," in"," word"," choices"," stem","ming"," from"," German"," as"," a"," language","\u23ce"," that"," tends"," to"," either"," get"," gloss","ed"," over"," or"," overloo","ked",".","\u23ce\u23ce","But"]}]},{"quantile_name":"Bottom Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ack"," of","\u2191"," Ash","it","ol"," ","\u23ce","fat",";"," therefore",","," Is"," th","ero"," any"," gentleman"," who"," would"," rs"," ","\u23ce","The"," that"," $","1",","," ho"," can"," have"," the"," quality"," of"," his"," bitter"," gu","aran"," ","\u23ce\u23ce\u23ce","earth",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce\u23ce","Assistant",":"," ","\u200b","<EOT>","\u23ce\u23ce","Human",":"," If"," I"," can"," see"," one"," g","ira","ffe",","," one"," rh","ino"," and"," one"," elephant"," in"," NAME","_","1","'s"," NAME","_","2",","," what"," is"," the"," minimum"," amount"," of"," animals"," actually"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["and"," are"," ambitious"," ","\u23ce","of"," being"," thought"," clever","."," Well",","," there"," is"," the","\u2191"," Cl","own"," who"," will"," sym","-"," ","\u23ce","path","ize"," with"," you"," in"," d","ump","lings",";"," and"," not"," to"," see"," into"," the"," clev","erness"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["America"," of"," conditions"," in","\u23ce"," Albania"," indicate"," the"," commission"," of","\u23ce"," a"," great"," crime"," a"," crime"," which"," even","\u23ce"," rh","c"," cal","lo","used"," conscience"," of"," Europe","\u23ce"," would"," not"," have"," tol","erated"," in"," normal","\u23ce"," times",".","\u2191"," Caught"," between"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["say"," it"," does"," not"," fit","\u23ce","_","all","_"," Pro","-","grade"," work","lo","ads",".","\u23ce\u23ce","~~~","\u23ce","rh","ody","su","rf","\u23ce","\u2191"," Comp","iling"," is"," definitely"," CPU"," intensive","\u23ce\u23ce","~~~","\u23ce","k","g","erm","ino","\u23ce"," But"," it"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ius",",","\u2191"," Painter","."," A","."," F",".","\u2191"," V","ll","lem","ain",","," Author","."," Sir"," R",".","\u2191"," Sm","ir","ke",",","\u2191"," Arch","ite","ot"," C",".","\u2191"," Stan","fl","eld",",","\u2191"," Painter","."," E","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["month"," you"," will"," be"," out","\u23ce"," as"," l","ively"," as"," a"," cricket","."," Not"," one"," case","\u23ce"," of"," rh","eu","mat","ism"," in"," twenty"," will"," hold","\u23ce"," out"," ag","aint"," this"," simple"," treatment",".\"","\u23ce","The"," right"," kind"," of"," timber"," for"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["w","la",","," which"," presents"," itself"," in"," a"," va","\u23ce"," r","iety"," of"," forms"," ;","\u2191"," B","alt","\u2191"," Rh","eum"," ;"," King","'s"," Evil",".","\u2191"," P","im","ples"," on"," the","\u23ce"," Face"," ;","\u2191"," Bl","ot","ches"," ;","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["drama","."," Mr",".","\u23ce","Fleming","'s"," production"," is"," he","ral","ded"," as"," a","\u23ce"," very"," good"," one","."," _","\u23ce","Notes",".","\u23ce","De"," Wolf","\u2191"," Ho","pper","'s"," production"," of","\u23ce","\"","Wang","\""," goes"," on"," its"," m","erry"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["audience","."," I"," now"," proceed"," to"," prop","ound"," to"," the"," Judge"," the"," interrog","at","ories",","," so"," far"," as"," rh","ave"," fr","amed"," them","."," I"," will"," bring"," forward"," a"," new"," install","ment"," when"," I"," get"," them"," ready","."," [","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ude",","," sl","ang"," phrases"," are"," never","\u23ce"," proper"," under"," any"," circumst","ance",","," and"," it","\u23ce"," almost"," para","ly","ses"," us"," to"," have"," you"," ask","\u23ce"," such"," a"," question","."," Should"," you"," make","\u23ce"," use"," of"," such"," terms"," in"," our"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["sequ","enc","es","inc","lud","ingst","roke",",","ac","ut","ech","es","ts","ynd","rome",",","pul","mo","nar","yh","y","pert","ension",",","chron","ick","id","ney"," disease",",","and","pr","emat","ured","eath",".","\u2191","Alth","ough","it","isc"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["try"," to"," escape","\u23ce\u23ce"," Assistant",":"," NAME","_","1",":"," Oh"," no"," you"," don","'t",","," my"," little"," squ","ir","ming"," bun","ny","!"," NAME","_","1","'s"," got"," you"," tight"," in"," her"," arms",","," and"," you","'re"," not"," going"," anywhere"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["SA","Y"," THE","\u21ea"," NIC","EST","\u21ea"," THINGS","\""," \"","I","'","V","E","\u21ea"," SAID","\u21ea"," THAT","\u21ea"," WORD","\u21ea"," AGAIN",".\""," \"","NOW","\u21ea"," TELL"," ME",",\""," \"","WITH","\u21ea"," WHOM"," ARE"," YOU","\u21ea"," STUDYING"," AT"," THE","\u21ea"," CONSERV"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","\u21ea"," TUESDAY",".","\u23ce","\u21ea","WEDNESDAY","\u2014","Char","I","ie","\u2191"," Chap","lin"," in"," \"","The","\u23ce"," Kid"," \"","\u23ce","\u21ea","STEEL","\u21ea"," WORKS"," \"","Y","\"","\u23ce","\u21ea","SUNDAY","\u21ea"," AFTERNOON","\u2014"," Community","."," sing","iac","\u23ce"," by"," audience"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["sal","ve"," in"," the"," world"," for"," cuts",","," bru","ises",","," s","ores",","," ul","c","ers",","," salt"," rh","eum",","," fever"," s","ores",","," t","etter",","," ch","apped"," hands",","," chil","bl","ains",","," cor","ns",","," and"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["blood"," is"," thin",","," as"," in"," au","\u00e6","m","ia",";","\u23ce","or"," imp","ure",","," as"," in"," rh","eu","mat","ism",";"," or"," when","\u23ce"," the"," ner","ves"," are"," weak",","," as"," ","iu"," neu","ral","gia",";"," or","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["perfect","\u21ea"," SONG"," FOR"," A","\u21ea"," BUNCH"," OF","\u21ea"," B","UMS",".\""," \"","YOU","'","","LL"," DO","\u21ea"," THINGS"," MY"," WA","Y",","," RIGHT","?\""," \"","YES",",","\u21ea"," MOM","MY",".\""," \"","IT","\u21ea"," FEELS"," SO","\u21ea"," GOOD","\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["of"," time"," did"," you"," have","?\""," \""," Oh",","," I"," had"," lots"," of"," fun"," too",","," with"," my"," rh","eu","mat","ism",".\""," \"","It"," must"," have"," been"," quite"," a"," party"," to"," have"," caused"," this"," story",".\""," \"","\u2191","","Arl"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["lin","gh","ausen"," ,"," Hr"," ."," H"," .","\u2191"," Zur","stra","\u00df","en"," ,","\u2191"," Kauf","mann"," .","\u2191"," Rh","eine"," ,"," Hr"," ."," Jos"," .","\u2191"," Wes","se","lin","ck"," ,","\u2191"," Kauf","mann"," .","\u2191"," Sen","den","hor","st"]}]}],"top_logits":["ming","med","min","mer","men","mic","mine","mes"],"bottom_logits":["ema\u010d","itza","\u0430\u0437\u0430\u0437","\u00e9r\u00e9r","etve","ienien","ugug","ostost","ziu","schsch"]}