{"index":6297851,"examples_quantiles":[{"quantile_name":"Top Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.21,0.0,0.0,0.16,0.82,0.0,0.0,0.0,0.34,0.0,0.0,0.0,0.37,1.0,0.18,0.34,0.63,0.0,0.0,0.0,0.0,0.09,0.0,0.0,0.0,0.0,0.1,0.15,0.0,0.4,0.07,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["company"," of"," thi","eves",".\""," \"","\u2191","Ga","rr","ulous","?\""," \"","What"," the"," fuck"," is"," ga","rr","ulous","?\""," \"","That"," would"," be"," l","oqu","ac","ious",","," verbose",","," eff","usive",".\""," \"","How"," about"," \"","chat","ty","\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.85,0.41,0.0,0.3,0.95,0.18,0.33,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","p","ron","\u23ce",">"," a"," rig","orous"," and"," proven"," paradig","m","\u23ce\u23ce"," I","'ll"," give"," you"," rig","orous",","," but"," how"," is"," it"," proven","?"," I"," think"," it"," is"," a"," fair"," guess"," that","\u23ce"," the"," number"," of"," non","-","tiny"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.11,0.89,0.47,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["have","."," In"," my"," experience",","," this"," often"," looks"," like"," an","\u23ce"," engineer"," who"," wants"," to"," add"," more"," adj","ectives"," (","mod","ifi","ability",","," rob","ust","ness",",","\u23ce","scal","ability",","," etc",")"," than"," is"," actually"," needed","."," If"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.42,0.1,0.0,0.0,0.25,0.66,0.08,0.19,0.0,0.7,0.0,0.0,0.89,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ely",","," quant","ifiable"," and"," o","rot","und",".\""," \""," Do"," you"," know"," what"," that"," means","?\""," \""," No",".\""," \"","I"," warn"," you",".\""," \"","These"," are"," actors",".\""," \"","In"," every"," actor"," there"," lives"," a"," tiger",","," a"," pig"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.86,0.34,0.3,0.06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.45],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[",","  ","were","  ","it","  ","true",",","  ","it","  ","would","  ","not","  ","justify","  ","the","  ","epit","het","  ","\"","  ","universal",".\"","  ","What"," ","\u23ce","then","  ","is","  ","the","  ","real","  ","meaning","  ","of"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.85,0.41,0.0,0.3,0.95,0.18,0.33,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["yourself",".","\u23ce\u23ce","~~~","\u23ce","p","ron","\u23ce",">"," a"," rig","orous"," and"," proven"," paradig","m","\u23ce\u23ce"," I","'ll"," give"," you"," rig","orous",","," but"," how"," is"," it"," proven","?"," I"," think"," it"," is"," a"," fair"," guess"," that","\u23ce"," the"," number"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.74,0.0,0.34,0.64,0.07,0.33,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":[" ","\u23ce\u23ce","Human",":"," ","\u23ce","I"," feel"," like"," I","'ve"," heard"," these"," words"," before","\u2014","what"," do"," they"," mean","?","\u23ce\u23ce","Assistant",":"," Here","'s"," a"," breakdown"," of"," those"," joy","-","related"," words",":","\u23ce\u23ce","1",".","\u2191"," Eb","ul"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.21,0.0,0.0,0.16,0.82,0.0,0.0,0.0,0.34,0.0,0.0,0.0,0.37,1.0,0.18,0.34,0.63,0.0,0.0,0.0,0.0,0.09,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["known"," to"," be"," somewhat"," ga","rr","ulous"," in"," the"," company"," of"," thi","eves",".\""," \"","\u2191","Ga","rr","ulous","?\""," \"","What"," the"," fuck"," is"," ga","rr","ulous","?\""," \"","That"," would"," be"," l","oqu","ac","ious",","," verbose",","," eff"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.28,0.0,0.0,0.81,0.0,0.0,0.0,0.25,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["and"," styles","."," Some"," common"," words"," that"," are"," often"," used"," to"," describe"," top","-","selling"," d","resses"," include",":","\u23ce\u23ce","*","\u2191"," Tren","dy","\u23ce","*","\u2191"," Ch","ic","\u23ce","*","\u2191"," Styl","ish","\u23ce","*","\u2191"," Feminine","\u23ce","*","\u2191"]},{"tokens_acts_list":[0.0,0.53,0.17,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.11,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.37,0.0,0.0,0.0,0.18,0.19,0.0,0.08,0.0,0.0,0.0,0.37,0.32,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["use"," vs","."," easy"," to"," use","\u23ce","<","Grid","C","ube",">"," what"," if"," instead"," of"," easy"," to"," use"," we"," use"," \"","acc","es","ible","\""," or"," \"","user"," friendly","\"","\u23ce","<","kn","ome",">"," we"," have"," easy","-","to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.68,0.4,0.0,0.0,0.0,0.16,0.0,0.0,0.79,0.0,0.0,0.0,0.0,0.0,0.15,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["The"," scen","ery"," was"," st","rik","ingly"," beautiful","\"."," The"," ad","ver","b"," st","rik","ingly"," mod","ifies"," the"," adj","ective"," beautiful"," to"," provide"," more"," information"," about"," the"," scen","ery","."," Finally",","," ad","ver","bs"," can"," modify"," other"," ad","ver"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.35,0.79,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Well",","," it"," ..."," gets"," in"," there"," ","...\""," \"","\u2191","","Uh",",","if"," that","'s"," what"," you"," mean"," by"," infectious",".\""," \"","\u2191","","Uh",","," Dennis",","," now"," we","'ve"," on","ly","kn","own"," each"," other"," for"," a"]},{"tokens_acts_list":[0.0,0.0,0.14,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.78,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.31,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["You"," know",","," good"," versus"," evil",".\""," \"","A","II"," black"," or"," all"," white",".\""," \"","Yeah",","," I"," know"," what"," it"," means",".\""," \"","I"," just"," found"," it"," char","ming"," you","'d"," use"," the"," word","\u2191"," Man","ich","ean",".\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.42,0.37,0.78,0.0,0.0,0.0,0.0,0.25,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["roc","kin","'"," Roger",","," this"," group"," looks"," neat",".\"","\""," \"","That","'s"," the"," word"," I","'d"," use",".\""," \"","You"," look"," neat",".\""," \"","And"," for"," all"," you"," people"," out"," there"," in"," radio","land",","," this"," band"," is"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.05,0.18,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.34,0.11,0.77,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.22,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["'re"," only"," an"," official"," flavor",","," but"," if"," we"," don","'t"," mention"," flavor",","," it","'s"," amb","iguous"," what"," the"," \"","official","\""," means","\u23ce","<","holstein",">"," otherwise",","," wh","ats"," the"," difference"," in"," mint"," x","f","ce","?",".."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.75,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[":"," That","'s"," right",","," an"," orange","."," A"," del","icious"," orange",".","\u23ce","10","."," Orange",":"," Don","'t"," forget"," my"," budd","ies"," the"," g","rap","ef","ruit"," and"," l","emon",".","<EOT>","\u23ce\u23ce","Human",":"," write"," a"," dialogue"," scene"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.27,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.75,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.26,0.0,0.0,0.0,0.0,0.33,0.0,0.0,0.0,0.0,0.18,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["id","uous"," right"," now",".\""," \"","I","'ve"," been"," getting"," the"," SA","T"," word"," of"," the"," day"," on"," my"," computer",".\""," \"","How"," lu","gu","br","ious"," is"," that","?\""," \"","Oh",","," wait",","," mm",".\""," \"","I"," used"," that"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.19,0.0,0.0,0.0,0.75,0.0,0.0,0.0,0.52,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.16,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," sp","iders",","," scor","p","ions",","," and"," certain"," marine"," animals",".","\u23ce\u23ce","In"," summary",","," the"," main"," difference"," between"," ven","om","ous"," and"," pois","on","ous"," is"," the"," way"," in"," which"," the"," toxic"," substance"," is"," delivered",".","\u2191"," Ven"]}]},{"quantile_name":"Subsample Interval 0","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.21,0.0,0.0,0.16,0.82,0.0,0.0,0.0,0.34,0.0,0.0,0.0,0.37,1.0,0.18,0.34,0.63,0.0,0.0,0.0,0.0,0.09,0.0,0.0,0.0,0.0,0.1,0.15,0.0,0.4,0.07,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["company"," of"," thi","eves",".\""," \"","\u2191","Ga","rr","ulous","?\""," \"","What"," the"," fuck"," is"," ga","rr","ulous","?\""," \"","That"," would"," be"," l","oqu","ac","ious",","," verbose",","," eff","usive",".\""," \"","How"," about"," \"","chat","ty","\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.85,0.41,0.0,0.3,0.95,0.18,0.33,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["\u23ce","p","ron","\u23ce",">"," a"," rig","orous"," and"," proven"," paradig","m","\u23ce\u23ce"," I","'ll"," give"," you"," rig","orous",","," but"," how"," is"," it"," proven","?"," I"," think"," it"," is"," a"," fair"," guess"," that","\u23ce"," the"," number"," of"," non","-","tiny"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.11,0.89,0.47,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["have","."," In"," my"," experience",","," this"," often"," looks"," like"," an","\u23ce"," engineer"," who"," wants"," to"," add"," more"," adj","ectives"," (","mod","ifi","ability",","," rob","ust","ness",",","\u23ce","scal","ability",","," etc",")"," than"," is"," actually"," needed","."," If"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.42,0.1,0.0,0.0,0.25,0.66,0.08,0.19,0.0,0.7,0.0,0.0,0.89,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["ely",","," quant","ifiable"," and"," o","rot","und",".\""," \""," Do"," you"," know"," what"," that"," means","?\""," \""," No",".\""," \"","I"," warn"," you",".\""," \"","These"," are"," actors",".\""," \"","In"," every"," actor"," there"," lives"," a"," tiger",","," a"," pig"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.86,0.34,0.3,0.06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.45],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":[",","  ","were","  ","it","  ","true",",","  ","it","  ","would","  ","not","  ","justify","  ","the","  ","epit","het","  ","\"","  ","universal",".\"","  ","What"," ","\u23ce","then","  ","is","  ","the","  ","real","  ","meaning","  ","of"]}]},{"quantile_name":"Subsample Interval 1","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.74,0.0,0.34,0.64,0.07,0.33,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":[" ","\u23ce\u23ce","Human",":"," ","\u23ce","I"," feel"," like"," I","'ve"," heard"," these"," words"," before","\u2014","what"," do"," they"," mean","?","\u23ce\u23ce","Assistant",":"," Here","'s"," a"," breakdown"," of"," those"," joy","-","related"," words",":","\u23ce\u23ce","1",".","\u2191"," Eb","ul"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.21,0.0,0.0,0.16,0.82,0.0,0.0,0.0,0.34,0.0,0.0,0.0,0.37,1.0,0.18,0.34,0.63,0.0,0.0,0.0,0.0,0.09,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["known"," to"," be"," somewhat"," ga","rr","ulous"," in"," the"," company"," of"," thi","eves",".\""," \"","\u2191","Ga","rr","ulous","?\""," \"","What"," the"," fuck"," is"," ga","rr","ulous","?\""," \"","That"," would"," be"," l","oqu","ac","ious",","," verbose",","," eff"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.28,0.0,0.0,0.81,0.0,0.0,0.0,0.25,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["and"," styles","."," Some"," common"," words"," that"," are"," often"," used"," to"," describe"," top","-","selling"," d","resses"," include",":","\u23ce\u23ce","*","\u2191"," Tren","dy","\u23ce","*","\u2191"," Ch","ic","\u23ce","*","\u2191"," Styl","ish","\u23ce","*","\u2191"," Feminine","\u23ce","*","\u2191"]},{"tokens_acts_list":[0.0,0.53,0.17,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.11,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.37,0.0,0.0,0.0,0.18,0.19,0.0,0.08,0.0,0.0,0.0,0.37,0.32,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["use"," vs","."," easy"," to"," use","\u23ce","<","Grid","C","ube",">"," what"," if"," instead"," of"," easy"," to"," use"," we"," use"," \"","acc","es","ible","\""," or"," \"","user"," friendly","\"","\u23ce","<","kn","ome",">"," we"," have"," easy","-","to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.68,0.4,0.0,0.0,0.0,0.16,0.0,0.0,0.79,0.0,0.0,0.0,0.0,0.0,0.15,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["The"," scen","ery"," was"," st","rik","ingly"," beautiful","\"."," The"," ad","ver","b"," st","rik","ingly"," mod","ifies"," the"," adj","ective"," beautiful"," to"," provide"," more"," information"," about"," the"," scen","ery","."," Finally",","," ad","ver","bs"," can"," modify"," other"," ad","ver"]}]},{"quantile_name":"Subsample Interval 2","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.71,0.0,0.0,0.32,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," ocean"," for"," ","200"," ","years",".\""," \"","This"," is"," obs","essive",","," even"," for"," you",".\""," \"","I"," prefer","..."," passionate"," to"," obs","essive",".\""," \"","Your"," hang","-","up"," with"," that"," ship"," is"," deeper"," than"," Rick","\u2191"," Ra"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.42,0.1,0.0,0.0,0.25,0.66,0.08,0.19,0.0,0.7,0.0,0.0,0.89,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["to"," be"," tim","ely",","," quant","ifiable"," and"," o","rot","und",".\""," \""," Do"," you"," know"," what"," that"," means","?\""," \""," No",".\""," \"","I"," warn"," you",".\""," \"","These"," are"," actors",".\""," \"","In"," every"," actor"," there"," lives"," a"," tiger"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.25,0.07,0.0,0.0,0.0,0.0,0.0,0.2,0.48,0.13,0.0,0.0,0.0,0.18,0.0,0.7,0.12,0.34,0.0,0.37,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["inc","or","rig","ible",".\""," \"","\u2191"," Congrat","ulations",".\""," \""," What","'s"," \"","inc","or","rig","ible","\"","?\""," \"","I"," think"," it"," means"," you"," want"," to"," be"," treated"," like"," a"," boy",".\""," \"","I","'m","\u2191"," M","arta",","]}]},{"quantile_name":"Subsample Interval 3","examples":[{"tokens_acts_list":[0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.21,0.0,0.28,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.68,0.61,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".\""," \"","It","'s"," a"," descript","ive"," word",".\""," \"","An"," adj","ective",".\""," \"(","marker"," sque","aking",")\""," \"\"","\u2191","Respect","ful",".\"","\""," \"","Grace",","," do"," you"," want"," to"," pin"," it"," on"," the"," board","?\""," \"","Thank"," you"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.64,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["and"," clear"," of"," harmful"," bacteria",","," fungi"," and"," vir","uses",".","\u23ce\u23ce","It","'s"," important"," to"," note"," that"," the"," term"," \"","acid","ic","\""," is"," used"," to"," describe"," the"," pH"," level"," of"," the"," vag","ina",","," not"," the"," smell","."," The"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.87,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.75,0.0,0.35,0.64,0.08,0.33,0.0,0.0,0.13,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.12,0.17,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["before","\u2014","what"," do"," they"," mean","?","\u23ce\u23ce","Assistant",":"," Here","'s"," a"," breakdown"," of"," those"," joy","-","related"," words",":","\u23ce\u23ce","1",".","\u2191"," Eb","ul","lient",":","\u2191"," Over","fl","owing"," with"," enthusiasm"," and"," excitement","\u23ce","2",".","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.17,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["an"," app"," or"," website"," that"," would"," take"," me"," from"," one"," th","rift"," store"," to"," another"," efficiently","."," What"," I"," mean"," by"," that"," is"," I"," don","'t"," want"," to"," drive"," ","5"," ","miles"," to"," a"," store",","," then"," ","2"," "]}]},{"quantile_name":"Subsample Interval 4","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.48,0.0,0.0,0.0,0.0,0.27,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["of"," reducing"," plastic"," waste","."," ","\u23ce\u23ce","Human",":"," ","\u23ce","Could"," you"," please"," explain"," what"," com","post","able"," means","?","\u23ce\u23ce","Assistant",":","\u2191"," Com","post","able"," means"," that"," a"," material"," can"," break"," down"," completely"," into"," natural"," elements"," in"," a"]},{"tokens_acts_list":[0.0,0.0,0.41,0.0,0.58,0.0,0.43,0.0,0.0,0.16,0.24,0.0,0.19,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.32,0.0,0.0,0.08,0.37,0.0,0.37,0.0,0.0,0.0,0.0,0.0,0.13,0.0,0.0,0.0,0.0,0.0,0.0,0.28],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["synonym","s"," for"," impossible"," are"," the"," words"," b","aff","ling"," conf","using"," and"," bew","il","dering"," and"," ant","ony","ms"," for"," in"," compreh","ens","ible"," are"," the"," words"," under","stand","able"," clear"," plain"," and"," intellig","ible","."," So"," that"," was"," incomp"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.09,0.28,0.0,0.0,0.0,0.0,0.0,0.17,0.0,0.0,0.0,0.0,0.31,0.1,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08,0.0,0.26,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["eine"," ","\u23ce","imagin","aire",".","  ","\u2191","Sous","  ","ce","  ","point","  ","\"","de","  ","vue"," ,","  ","im","agi","\u23ce"," n","aire"," ne","  ","s","'","op","po","fe","  ","point","  ","\u00e0","  ","r\u00e9","el","  ",";"]},{"tokens_acts_list":[0.12,0.25,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["mean"," by"," \"","observ","ables","\u23ce",">"," being"," fundament","ally"," lazy","\"."," I","'d"," need"," to"," understand"," what"," you"," mean"," by"," that","\u23ce",">"," before"," I"," can"," give"," a"," coher","ent"," answer",".","\u2191"," Iter","ables"," are"," essentially"," lazy",","," because"]},{"tokens_acts_list":[0.0,0.0,0.15,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.13,0.0,0.0,0.0,0.0,0.0,0.24,0.5,0.29,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.19,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["figur","\u00e9"," grand"," repr","end"," sa"," val","eur"," prop","re",","," et"," ne"," s","'","ent","end"," et"," sign","if","ie",","," cou","rag","eux",","," mag","nan","ime",","," noble",","," plus"," que"," de"," la"," t","aille","."," C","'"]}]},{"quantile_name":"Subsample Interval 5","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.11,0.0,0.42,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":[","," used"," as"," a"," sard","ine",","," and"," b","ait",".","\u23ce\u23ce","Human",":"," ","\u23ce","\u2191","Doesn","'t"," really"," mention"," if"," it"," is"," considered"," as"," a"," lean"," fish"," in"," what"," you"," just"," posted",".","\u23ce\u23ce","Assistant",":"," You","'re"," correct"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.11,0.0,0.0,0.0,0.0,0.26,0.4,0.4,0.11,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["English",","," ","\u23ce","but","  ","is","  ","not","  ","very","  ","appo","site","  ","to","  ","the","  ","word","  ","\"","  ","cold",".\""," ","\u23ce","However",",","  ","I","  ","am","  ","not","  ","writing","  ","this","  ","to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.29,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","\u2191"," Philosoph","ically","\u23ce"," and"," aesthet","ically"," brut","alist"," and"," uncomfortable",".","\u23ce\u23ce","~~~","\u23ce","kol","pa","\u23ce"," What"," does"," \"","\u2191","Philosoph","ically"," and"," aesthet","ically"," brut","alist"," and"," uncomfortable",".\"","\u23ce","mean","?","\u23ce\u23ce","~~~","\u23ce","f","ork"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.23,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Yes",","," sir",".\""," \"","And","?\""," \"","\u2191","Impressive",".\""," \"","Now",","," there","'s"," a"," carefully"," chosen"," word",".\""," \"","You"," wouldn","'t"," be"," holding"," something"," back",","," now"," would"," you",",","\u2191"," Ji","ggs","?\""," \"","That"," comment"]}]},{"quantile_name":"Subsample Interval 6","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["in"," different"," countries","."," Here","'s"," a"," brief"," explanation"," of"," each"," one",":","\u23ce\u23ce","1","."," Ltd",".:"," This"," stands"," for"," \"","Limited","\""," and"," is"," commonly"," used"," in"," the"," United"," Kingdom",","," Ireland",","," and"," some"," other"," countries"," to"," indicate"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.25,0.0,0.11,0.0,0.11,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.37,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".\""," Which"," is"," not"," the"," normal"," sense"," of"," the"," word","\u23ce","\"","court","eous",".\""," In"," the"," normal"," sense"," of"," \"","court","eous",",\""," I"," have"," been"," court","eous","."," The","\u23ce"," post"," I"," made"," doesn","'t"," even"," reference"," you"," personally"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.17,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.16,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["into"," ev","erl","asting"," punishment",","," and"," the"," right","eous"," into"," life"," ","eter","-"," ","nal",".\""," The"," words"," ev","erl","asting"," and"," eternal"," mean"," pre","-"," cis","ely"," the"," same",","," and"," translate"," one"," Greek"," word",","," so"," that"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["usually"," in"," a"," last"," name",","," but"," can"," also"," be"," used"," as"," a"," last"," name",".","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","How"," practices"," aimed"," towards","\u2191"," Mind","ful","\u2191"," Breathing"," can"," help"," during"," times"," of"," stress","."," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["build","\u23ce","<","p","itti",">"," no",","," spar","c"," _","is","_"," aff","ect","d","\u23ce","<","p","itti",">"," sorry",","," had"," a"," phone"," call"," in"," parallel"," (","done"," now",")","\u23ce","<","p","itti",">"," la","mont",":"]}]},{"quantile_name":"Subsample Interval 7","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.17,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["would"," highly"," doubt"," they"," were"," trained"," as"," a"," lingu","ist",".","\u23ce\u23ce","You"," could"," perhaps"," instead"," mean"," \"","standard","\""," instead"," of"," \"","right","\""," -"," that"," they","'re","\u23ce"," describing"," a"," standard"," dialect",","," which"," doesn","'t"," meet"," reality","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["had"," access"," to"," the"," factory",".\""," \""," This"," place"," is","...\""," \"","What","'s"," the"," word","?\""," \"","Byzantine","?"," no"," fire"," ext","ingu","ish","ers",".\""," \"","but"," it"," hasn","'t"," been"," insp","ected"," since"," '","95",".\""," \""," I"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["atory"," x","k","cd"," [","https","://","x","k","cd",".","com","/","37","/","](","https","://","x","k","cd",".","com","/","37","/)","\u23ce\u23ce","------","\u23ce","k","__","\u23ce","T","L",";","DR"," no",","," \"","shit","\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["case",","," you"," could"," just"," compare"," and"," swap",","," then"," De","ep","Equal","\u23ce","<","rog","p","eppe",">"," dimit","ern",":"," same"," difference","\u23ce","<","dimit","ern",">"," rog","p","eppe",":"," y","ep",","," that"," seems"," the"," eas","iest"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.14,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["No",","," no",".\""," \"","\u2191","Flip"," side",".\""," \"","He","'s"," a"," narc","iss","ist",".\""," \"","A","What","?\""," \"","Someone"," who"," loves"," himself"," a"," whole"," lot",".\""," \"","Like","\u2191"," Dev","d","as",".\""," \"","Oh",","," ok"]}]},{"quantile_name":"Subsample Interval 8","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["grain"," toast",","," fruit",","," and"," nuts"," can"," also"," help"," provide"," sustained"," energy","."," ","\u23ce\u23ce","Human",":"," ","\u23ce","\"","I","'m"," looking"," for"," something"," filling"," yet"," easy"," to"," prep"," in"," the"," mor","nings"," as"," I"," don","'t"," have"," a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.1,0.0,0.0,0.19,0.1,0.0,0.0,0.0,0.1,0.0,0.06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["  ","20",".","  ","\u2191","S","ic","  ","vu","igo",".","  ","\u2191","Al","ii"," ","\u23ce","con","j",".","  ","offici","unt",":","  ","\u2191","Cu","rab","itis",",","  ","ut","  ","sint","  ","ver","ba","  ","milit","um",")."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ed"," monkey","."," He"," looks"," at"," the","\u23ce"," elevator","."," Then"," he"," lies"," down"," and"," makes"," a"," soft"," wh","ining","\u23ce"," noise","."," He"," won","'t"," get"," in"," the"," elevator",".","\u23ce","\u2191","L","iam"," has"," another"," idea","."," He"," finds"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.11,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["sounds"," strange","\u23ce","<","hyper","air",">"," hm","m","\u23ce","<","hyper","air",">"," mis","cel","lan","ous"," add","ons","?","\u23ce","<","hyper","air",">"," \"","mis","cel","lan","ous"," add","ons"," for","\u2191"," Ge","any","\"","?","\u23ce","<"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["aspect"," of"," material"," science"," that"," researchers"," are"," actively"," exploring"," and"," arguing"," about",".","  ","Some"," scholars"," have"," argued"," that"," the"," \"","diamond"," value","\""," is"," actually"," the"," strongest"," for"," many"," applications",","," while"," others"," argue"," that"," the"," \"","graph","ene"," value"]}]},{"quantile_name":"Bottom Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["sou","ill","\u00e9"," de"," cr","otte",","," de"," to","utes"," \u2022","sor","tes",";","de"," m","alp","rop","ret","\u00e9s",";"," c","ras","\u2022","se","\u00f9","s",".\"","\u25a0",""," ."," ","\u23ce","gro","\u00fb","ss","\u00e8","iro",","," adj","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","Fem","|","Number","=","\u2191","Sing","\u21b9","3","\u21b9","ap","pos","\u21b9","_","\u21b9","_","\u23ce","18","\u21b9","civil","\u21b9"," civil","\u21b9"," AD","J","\u21b9","_","\u21b9","Gender","=","\u2191","Fem","|","Number","=","\u2191","Sing","\u21b9","17","\u21b9","a"]},{"tokens_acts_list":[0.39,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.34,0.0,0.05,0.0,0.0,0.0,0.42,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.19,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\"","c","hou","ette","\""," I"," guess"," :",")","\u23ce","<","j","ib","el",">"," p","itti",","," \"","\u2191","C","hou","ette","\""," ="," nice","\u23ce","<","rick","sp","encer","3",">"," sorry","\u23ce","<","p","itti",">"," oh",","]},{"tokens_acts_list":[0.07,0.0,0.07,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," steel",","," exercise"," shoe",".","\u23ce\u23ce","Therefore",","," the"," correct"," sentence"," is",":","\u23ce\u23ce","(","A",")"," rep","uls","ive"," big"," rectangular"," pink"," steel"," exercise"," shoe",".","<EOT>","\u23ce\u23ce","Human",":"," How"," many"," NAME","_","1"," ","fit"," in"," a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.49,0.0,0.15,0.0,0.0,0.0,0.0,0.18,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["children","\u23ce","<","b","ia","lix",">"," this"," is"," q","r","eat"," idea","\u23ce","<","gar","yv","d","m",">"," q","r","eat"," -"," intent","ional"," mistake","?","\u23ce","<","b","ia","lix",">"," no",","," by","\u2191"," Fre","ud","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["  ","that","  ","is","  ","law","ful",",","  ","nor","  ","give","  ","a","  ","ju","ri","fd","id","ion"," ","\u23ce","where","  ","there","  ","was","  ","none","  ","before","  ",":","    ","For","  ","no","  ","man","  ","w"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","Am"," attempt"," wat"," made"," to"," reconc","ile"," the","\u2191"," Conf","ert","ine"," to","\u23ce"," the"," resolution"," by"," inser","ting","\u2191"," H","ie"," saving"," clause"," \"","ii"," ","1","?","\u23ce","r","?","*","."," ?","i","ini","K","r","ode"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["der"," ","\u23ce","\u2191","Phil","om","ela",","," deren"," Tod"," sie"," blu","tig"," ","\u23ce","r","\u00e4ch","te",";"," da","her"," noch"," die"," bl","uth","ro","the"," ","\u23ce","\u2191","F","eder"," an"," dem","\u2191"," Hal","se"," der"," in"," eine"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\"","How"," do"," you"," find"," a"," word"," That"," means"," Maria","?\""," \"","A"," fl","ib","ber","tig","ib","bet","\""," \""," A"," will","-","o","'-","the","-","wi","sp","\""," \""," A"," cl","own","\""," \"","Many"," a"," thing"," you"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08,0.27,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\\xc2","\\xa4","ng","lig",".","\u2191"," Stall","man"," anv","\\xc3","\\x83","","\\xc2","\\xa4","n","der"," inte"," utt","ryc","ket"," \"","Open"," Source","\".","\u23ce","<","l","ars","em","il",">"," open"," source","\u2191"," ","\u00c3","\\xc2","\\xa4","r"," inte"," allt"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ur"," de","\u2191"," Na","bal"," dev","int"," pierre"," ,"," dit"," l","'","\u00e9c","ri","\u23ce"," ","ture"," ;"," c","'","est","-","a","-","dire"," ,"," resta"," f","roid"," et"," sans"," mou","vement"," com","\u23ce"," me"," une"," pierre","."," Par"," i"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.16,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","p","rc","v","ale",","," h","c","n","tz"," l","th"," and"," forever",".","\u23ce","1"," ","he"," word"," \""," War","\""," sh","c","l"," never"," be"," vo","os","cd","\u23ce"," in"," these"," halls",","," that"," when"," ever"," referred"," to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["","\\xc2","\\xa4","r"," i","fr","\\xc3","\\x83","","\\xc2","\\xa5","n","\u23ce","<","ein","and",">"," n","\\xc3","\\x83","","\\xc2","\\xa4","r"," j","ag"," var"," f","\\xc3","\\x83","","\\xc2","\\xa4","r","dig"," med"," gran","nen"," st","od"," han"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["That"," said",","," yeah",","," it"," seems"," like"," Ubuntu"," is"," moving"," really"," sw","ift","ly"," these"," days",".","\u23ce","\u2191","Sw","if","ter"," than"," Apple"," even",","," but"," let","'s"," not"," forget"," that"," only"," a"," year"," ago",","," people","\u23ce"," were"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.14,0.05,0.11,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["iens",":","\u2191"," S","ic"," fr","p","if","fi","mc"," l","C","ti"," in"," mat","eria"," crimin","ali"," dic","unt",",","/","(/","f","\u00ab","fm",";",","," d","olo"," malo","."," qt","ii","df","uc","ere",".","\u2191"," H","oc"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["to"," finish","."," ","\u23ce","Human"," :","Is"," the"," best"," substance"," for"," this"," type"," of"," blan","ket"," abs","orb","ent","?"," I","'m"," concerned"," about"," quick"," water"," absorption"," as"," will"," tend"," use"," this"," to"," cover"," baby"," bald","spot"," after"," my","o"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["men"," than"," I"," do"," for"," women","."," I"," generally"," see"," myself"," as"," pretty"," equ","alist"," (","is"," that"," a"," word","?",")."," I"," have"," ","0"," ","problem"," with"," female"," doctors",","," lawyers",","," etc",".;"," I"," believe"," that"," women"," are"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\""," on"," #","ubuntu","-","d","evel",","," calc"," was"," quite"," su","pr","ised",".","\u23ce","<","Sc","ott","K",">"," And"," why"," was"," everyone"," sure"," ...","\u23ce","<","Sc","ott","K",">"," Wait"," for"," it"," ...","\u23ce","<","ni","xt"]},{"tokens_acts_list":[0.0,0.0,0.0,0.21,0.0,0.4,0.0,0.0,0.0,0.0,0.07,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["shouldn","'t"," have"," used"," the"," word"," ","'","invari","ably","'.","\u23ce\u23ce","I","'m"," also"," not"," keen"," on"," their"," use"," of"," the"," word"," ","'","survivor","'"," in"," the"," same"," paragraph",".","\u23ce\u23ce","------","\u23ce","fal","ling","f","rog","\u23ce"," My"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["."," (","Such"," a"," material"," is"," also"," referred"," to"," as"," an"," RE","-","dominant"," composition","."," RE","-","rich",","," and"," RE","-","dominant",","," refer"," to"," substances"," in"," which"," the"," sub","-","latt","ice"," magnet","ization"," of"," the"," rare"," earth"]}]}],"top_logits":["profitable","passionate","efficient","vulnerable","memorable","influential","devastating","rebell","prestigious","hungry"],"bottom_logits":["\u001e"]}