{"index":28872704,"examples_quantiles":[{"quantile_name":"Top Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["reduced"," competition",".","<EOT>","\u23ce\u23ce","Human",":"," what"," are"," common"," adj","ectives"," found"," before"," the"," word"," \"","work","\""," in"," \"","God","'s"," work","\""," ?","\u23ce\u23ce","Assistant",":"," Here"," are"," some"," common"," adj","ectives"," that"," might"," prec","ede"," \"","work"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Yes",","," \"","we","br","ep","\""," is"," the"," correct"," way"," to"," write"," it"," as"," the"," \"","R","\""," in"," \"","Rep","\""," should"," be"," in"," lowercase","."," This"," is"," because"," when"," writing"," a"," company"," name",","," it","'s"," important"," to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[":"," No",","," I"," am"," not"," a","\u2191"," Jew",".","<EOT>","\u23ce\u23ce","Human",":"," find"," \"","product"," category","\""," from"," \"","\u2191","Nad","eco"," ","24"," ","Fashion","\u2191"," N","ails"," Medium"," Length"," ","1"," ","Pack","\""," and"," convert"," \""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["because"," it"," is","\u23ce"," nothing"," like","\u21ea"," SL","IME","."," In"," fact",","," the"," word"," \"","sl","ime","\""," in"," \"","vim","-","sl","ime","\""," is"," poorly"," chosen",".","\u23ce","It"," supports"," none"," of"," the","\u21ea"," SL","IME"," features","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.93,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["the"," police","\".","\u23ce\u23ce","Human",":"," ","\u23ce","I"," don","'t"," understand",","," where"," is"," the"," \"","f","\""," in"," \"","def","und"," the"," police","\"","?","\u23ce\u23ce","Assistant",":"," Oh",","," you","'re"," right","."," I"," apolog","ize"," for"," my"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.93,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["describe"," this"," characteristic"," of"," clay",".","USER",":"," I"," do"," not"," understand"," why"," we"," use"," \"","of"," clay","\""," in"," \"","the"," smell"," of"," clay","\"","\u23ce\u23ce","Could"," you"," explain","?","\u23ce\u23ce","Thank"," you",".","\u23ce\u23ce","(","From"," a"," lear","ner"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.93,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["po","3"," ","erf","unden","\u23ce\u23ce"," Assistant",":"," It"," seems"," like"," you"," have"," mi","ssp","elled"," \"","Hat","\""," as"," \"","\u2191","F","out","\""," in"," this"," context","."," As"," an"," AI"," language"," model",","," I"," am"," not"," sure"," what"," you"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["len",".","\u23ce\u23ce","2",".","\u2191"," Kl","ic","ken"," Sie"," im","\u2191"," Men","\u00fc"," \"","\u2191","Dat","ei","\""," auf"," \"","\u2191","Dr","uc","ken","...","\"."," Es"," \u00f6","ff","net"," sich"," das","\u2191"," Dr","uck","f","en","ster",".","\u23ce\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["its"," leader"," David","\u2191"," Misc","av","ige",","," considers","\u2191"," D","ian","etics"," to"," be"," the"," \"","technology","\""," of"," \"","corr","ecting"," the"," human"," mind","\""," and"," as"," a"," cure"," for"," most"," of"," humanity","'s"," ","ills",".","\u2191"," Scient"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["les"," invest","iss","eurs",".","<EOT>","\u23ce\u23ce","Human",":"," how"," many"," times"," does"," the"," letter"," \"","e","\""," appear"," in"," \"","k","etch","up","?\"","\u23ce\u23ce","Assistant",":"," Let"," me"," count"," the"," number"," of"," \"","e","\""," letters"," in"," \"","k"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["#"," name"," so"," that"," we"," don","'t"," accept"," a"," partial"," interface","\u23ce","\u21b9\u21b9","#"," name"," like"," \"","fw","\""," from"," \"","f","w","ip","0","\".","\u23ce","\u21b9\u21b9","child",".","expect","(","r","\"","([","a","-","z","]","):"," (["]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.91,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["anything"," to"," you","?","  ","What"," kind"," of"," human"," are"," you","?","  ","There"," is"," no"," \"","i","\""," in"," \"","a"," human"," being","\","," so"," that"," question"," is"," strange"," and"," maybe"," also"," grammat","ically"," incorrect",".","  ","I"," don","'t"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["difference","..","?","\u23ce\u23ce","~~~","\u23ce","k","rick","\u23ce"," He"," is"," pointing"," out"," that"," leaving"," out"," \"","is","\""," in"," \"","GNU"," is"," not"," Unix","\""," is"," pretty"," lou","sy","\u23ce"," way"," to"," make"," an"," acron","ym"," (","if"," that"," could"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.89,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["that"," consist"," only"," of"," letters",":","\u23ce\u23ce","1","."," ","\u0105"," -","\u2191"," Pronounced"," like"," the"," \"","a","\""," in"," \"","father",".\"","\u23ce","2","."," ","\u0107"," -","\u2191"," Pronounced"," like"," a"," soft"," \"","c","\""," sound",".","\u23ce","3"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.0,0.0,0.0,0.0,0.0,0.0,0.12,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["want"," to"," be"," prepared",".","\u23ce\u23ce","Assistant",":"," ","\u23ce","\u2191","Okay",","," sure","!"," Well"," \"","pharmacy","\""," is"," \"","far","ma","\""," in"," Spanish",","," \"","ap","oth","eke","\""," in"," German",","," and"," \"","pharmacy","\""," in"," French"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["in","sin","gh",",","\u23ce","\u2191","Tal","eb",".)","\u23ce\u23ce","I"," don","'t"," doubt"," that"," \"","modern"," humanity","\""," in"," \"","the"," west","\""," seems"," to"," deal"," badly"," with","\u23ce"," the"," process"," of"," dying","."," But","\u2191"," Tal","eb","..."," just"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["|","stop","|",">","<EOT>","\u23ce","CM","V",":","\u2191"," Referring"," to"," \"","\u2191","Frank","enstein","'s"," monster","\""," as"," \"","\u2191","Frank","enstein","\""," is"," perfectly"," valid"," I","'ve"," heard"," a"," few"," different"," versions"," but"," in"," all"," of"," them"," Dr"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.0,0.0,0.0,0.0,0.34,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["."," Diese","\u2191"," An","tw","orten"," werden"," in"," der","\u2191"," R","ei","hen","fol","ge"," von"," \"","best","\""," zu"," \"","bes","ser","\""," zu"," \"","am"," b","esten","\""," sort","iert",".","\u23ce\u23ce","\u2191","Dieser"," Parameter"," gibt","\u2191"," Ih","nen"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.87,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["   ","pre","-","release"," gcc"," ","3",".","2"," ","was"," seen"," not"," resp","ecting"," the"," \"","extern","\""," in"," \"","extern","\u23ce","   ","__","inline","__","\","," trigg","ering"," this"," problem"," too",".","  ","*/","\u23ce","#","if"," defined"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.86,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.54],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["turn"," the"," words"," in"," the"," following","\u23ce"," real"," conversations"," into"," dates"," for"," adding"," appointments","\u23ce\u23ce","*"," \"","Christmas","\""," in"," \"","\u2191","M","erry"," Christmas",","," and"," have"," a"," nice"," day","\"","\u23ce\u23ce","*"," \"","at"," ","100","\""," in"," \""]}]},{"quantile_name":"Subsample Interval 0","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["#"," name"," so"," that"," we"," don","'t"," accept"," a"," partial"," interface","\u23ce","\u21b9\u21b9","#"," name"," like"," \"","fw","\""," from"," \"","f","w","ip","0","\".","\u23ce","\u21b9\u21b9","child",".","expect","(","r","\"","([","a","-","z","]","):"," (["]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.91,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["anything"," to"," you","?","  ","What"," kind"," of"," human"," are"," you","?","  ","There"," is"," no"," \"","i","\""," in"," \"","a"," human"," being","\","," so"," that"," question"," is"," strange"," and"," maybe"," also"," grammat","ically"," incorrect",".","  ","I"," don","'t"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["difference","..","?","\u23ce\u23ce","~~~","\u23ce","k","rick","\u23ce"," He"," is"," pointing"," out"," that"," leaving"," out"," \"","is","\""," in"," \"","GNU"," is"," not"," Unix","\""," is"," pretty"," lou","sy","\u23ce"," way"," to"," make"," an"," acron","ym"," (","if"," that"," could"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.89,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["that"," consist"," only"," of"," letters",":","\u23ce\u23ce","1","."," ","\u0105"," -","\u2191"," Pronounced"," like"," the"," \"","a","\""," in"," \"","father",".\"","\u23ce","2","."," ","\u0107"," -","\u2191"," Pronounced"," like"," a"," soft"," \"","c","\""," sound",".","\u23ce","3"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.88,0.0,0.0,0.0,0.0,0.0,0.0,0.12,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["want"," to"," be"," prepared",".","\u23ce\u23ce","Assistant",":"," ","\u23ce","\u2191","Okay",","," sure","!"," Well"," \"","pharmacy","\""," is"," \"","far","ma","\""," in"," Spanish",","," \"","ap","oth","eke","\""," in"," German",","," and"," \"","pharmacy","\""," in"," French"]}]},{"quantile_name":"Subsample Interval 1","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.82,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.27,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","\u23ce","Yes",","," that"," would"," be"," great","!","\u23ce\u23ce","Assistant",":"," ","\u23ce","Well",","," \"","hi","\""," is"," \"","h","allo","\""," and"," \"","how"," are"," you","\""," is"," \"","h","oe"," g","aat"," het"," met"," j","ou","\"."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.83,0.0,0.0,0.0,0.0,0.0,0.04,0.82,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","Me","ena","\u2191"," D","evi"," (","\u2191","Goddess",")","'"," by"," ","'","\u2191","Tul","ku","'"," on"," ","'","Buddha","-","Bar"," (","disc"," ","1","'"," (","anno",":"," ","2","000",")"," -"," [","\u2191","Amar","ok"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["does","\u23ce","<","sp","iv",">"," (","I"," should","'ve"," been"," clear"," that"," I"," meant"," the"," \"","we","\""," in"," \"","we"," generate","\","," damn"," English"," :",")","\u23ce","<","cp","rov",">"," sp","iv",":"," spec","f","ically"," from"," get"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," an"," application"," provider"," or"," the"," like","."," This"," instance"," will"," be"," referred"," to"," as"," \"","owner","\""," of"," the"," \"","security"," domain","\""," in"," the"," following","."," In"," analog","ous"," fashion",","," in"," the"," following"," reference"," will"," be"," made"," to"]}]},{"quantile_name":"Subsample Interval 2","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.72,0.0,0.0,0.0,0.0,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":[":"," read","<EOT>","\u23ce\u23ce","Human",":","  ","\"","most"," common","\""," \"","cause","\""," of"," \"","chest"," pain","\""," in"," \"","men"," <","50","\"","\u23ce\u23ce","Assistant",":"," The"," most"," common"," cause"," of"," chest"," pain"," in"," men"," under"," ","50"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," you"," know","?\""," \"","It","'s"," just"," about"," team"," building",".\""," \"","There","'s"," no"," \"","I","\""," in"," \"","\u2191","S","oul","st","ice",".\"","\""," \""," But"," there","'s","...\""," \""," Well",","," yes",","," there"," is",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["provided",","," the"," investment"," philosophy"," that"," best"," fits"," into"," the"," \"","H","F","N","\u2191"," Crypto"," Currency"," Index","\""," is"," \"","\u2191","Crypto"," Currency","\".","<EOT>","\u23ce\u23ce","Human",":"," Some"," jurisd","ictions"," feature"," a"," type"," of"," company"," that"," is"," an"," independent"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["mo"," m","yk","iss"," h","ensh","awi",".\""," He"," has"," substit","uted"," the"," word"," \"","m","yk","iss","\""," for"," \"","pur","p","ur","atus",","," as"," it"," is"," a"," much"," older"," name"," than"," the"," latter","."," The"," tr","out"," found"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.35,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["made"," of"," material"," as"," desired"," where"," permitted"," by"," local"," regulations",".","\u23ce","In"," the"," present"," specification"," \"","comprise","\""," means"," \"","includes"," or"," consists"," of","\""," and"," \"","comprising","\""," means"," \"","including"," or"," consisting"," of","\".","\u23ce","The"," features"," disclosed"]}]},{"quantile_name":"Subsample Interval 3","examples":[{"tokens_acts_list":[0.0,0.13,0.0,0.0,0.0,0.31,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.27,0.0,0.0,0.0,0.61,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.26,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["all"," \"","good","\""," -"," \"","all","\"","-"," and"," \"","strong","\""," are"," used"," as"," \"","dice","\""," by"," \"","r","\""," \"","sm","iling","\","," \"","strong","\""," \"","strong","\""," with"," \"","L","\""," \"","enrich","ong","\","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.61,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["be"," considered"," a"," form"," of"," technology",".","\u2191"," Me","rr","iam","-","Webster"," defines"," ","'","technology","'"," as"," ","'","the"," practical"," application"," of"," knowledge"," especially"," in"," a"," particular"," area","'."," So"," in"," my"," mind",","," whether"," math"," is"," discovered"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.61,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["processed"," by"," means"," of"," a"," quant","ile"," norm","alization"," step"," using"," the"," \"","\u2191","A","ffy","\""," package"," of"," the"," \"","R","\""," software"," (","\u2191","Gaut","ier",","," L","."," et"," al",".,","\u2191"," Bi","oin","form","atics"," (","2"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.61,0.0,0.0,0.0,0.43,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[">"," So"," it"," seems"," that"," multi","-","team"," works",","," but"," only"," for"," a"," value"," of"," \"","works","\""," where"," \"","works","\""," means"," \"","doesn","'t"," work",".\"","\u23ce","<","d","ani","los",">"," gm","b",","," to"," me"," it"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.61,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["_","padding",")","\u23ce\u23ce","------","\u23ce","y","es","ena","dam","\u23ce","\u2191"," Spelling",":"," \"","it","'s","\""," should"," be"," \"","its","\""," except"," when"," short"," for"," \"","it"," is","\""," I"," believe","."," i",".","e",".","\u23ce\u23ce",">","It"]}]},{"quantile_name":"Subsample Interval 4","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.51,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["in"," total",","," the"," lowest"," minimum"," accumulated"," cost","."," In"," this"," case",","," that"," detected"," \"","winner","\""," sequence"," is"," \"","C"," C"," A","\","," due"," to"," the"," lowest"," minimum"," accumulated"," cost",".","\u23ce","The"," minimum"," accumulated"," cost"," for"," each"," symbol"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.51,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["asset"," hiding",","," and"," under"," the"," radar"," transactions",".","\u23ce\u23ce","Side"," note",":"," I"," changed"," \"","trust"," something","\""," to"," \"","trust"," a"," currency","\""," in"," my"," ","OP"," to"," be","\u23ce"," more"," specific",".","\u23ce\u23ce","~~~","\u23ce","baby","\u23ce"," People"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," bad"," ap","ples"," in","\u2191"," Bug","gy","town"," in"," one"," basket","."," not"," \"","\u2191","Menn","os","\""," in"," \"","\u2191","Bug","gy","town",".\""," Watch"," the"," tone","."," he"," your"," source","?\""," \"","I"," know"," him"," from"," high"," school"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," ","643",",","000"," ","fans"," who"," showed"," up"," for"," new"," \"","Fast"," and","\u2191"," Fur","ious","\""," film"," \"","Fast"," X",",\""," over"," the"," same"," duration",","," according"," to"," the"," Korean"," Film"," Council","."," \"","Fast"," X","\""," opened"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u0131","y","orum",".","\u2191"," Mad","ende"," ba","dem"," y","edi"," olan"," \u00f6z","ette"," \"","ma","dem","\""," ye","rine"," \"","mad","ende","\""," ol","du",".","\u2191"," Tek"," tek"," d","aha"," d\u00fc","\u015f","\u00fck"," bir"," be","den","le"," \u00e7","al"]}]},{"quantile_name":"Subsample Interval 5","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.41,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["does"," not"," contest"," my"," either","-","or"," equival","ence",","," my"," assertion"," that","\u23ce","\"","ration","alist","\""," either"," means"," \"","human"," being","\""," or"," \"","someone"," whose"," identity"," involves","\u23ce"," caring"," about"," other"," people","'s"," d","umb","ness",".\"","\u23ce\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.41,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["SP","030",":","\u21ea"," SPAR","QL"," compiler",","," line"," ","19",":"," syntax"," error"," at"," ","'","occupation","'"," before"," '","?","occupation","'","\u21ea"," SPAR","QL"," query",":"," #","output","-","format",":","application","/","spar","ql","-","results","+"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["and"," not"," be"," mad"," at"," the"," pract","ict","ioners","."," You"," have"," \"","perio","don","tal"," disease","\""," which"," requires"," \"","scaling"," and"," root"," pl","aning","\""," (","abbreviated","\u21ea"," SCR","P"," or"," S","RP",","," and"," known"," as"," a"," \""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.19,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["rr","itu"," called"," Di","Cap","rio","'s"," performance"," in"," the"," film"," \"","stunning",",\""," an"," \"","extraordinary"," adventure","\""," that"," \"","reflects"," his"," true"," values"," as"," an"," artist"," and"," a"," human"," being",".\"","  ","With"," The","\u2191"," Rev","enant",","," Di"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","```","\u23ce\u23ce","This","\u2191"," Mak","efile"," will",":","\u23ce\u23ce","-"," Build"," an"," executable"," named"," `","my","project","`"," from"," `","my","project",".","c","`"," and"," `","utility",".","c","`","\u23ce","-"," Use"," compiler"," flags"," `-","Wall"," -","\u2191"]}]},{"quantile_name":"Subsample Interval 6","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["case"," of"," \"","2","222","\""," and"," \"","1","111","\","," the"," first"," character"," in"," \"","2","222","\""," is"," \"","2","\","," which"," comes"," before"," the"," first"," character"," \"","1","\""," in"," \"","1","111","\""," in"," alphab","etical"," order"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["and"," Texas"," who"," get"," pulled"," over"," for","\u23ce"," spe","eding","."," \"","It"," could"," be"," drug"," money","\""," says"," the"," \"","law"," enforcement"," officers","\""," who","\u23ce"," take"," life"," savings"," and"," then"," _","spend"," it"," on"," themselves","_.","\u23ce\u23ce","Just"," because"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," display"," \"","\u9593","\u9055","\u3044","\u3067\u3059","\".","\u23ce\u23ce","3","."," Make"," ","4"," ","options"," \"","A","\""," to"," \"","D","\""," to"," click"," with"," display"," \"","\u3082","\u3046","\u4e00","\u5ea6","\u9078","\u629e","\u3057\u3066","\u304f\u3060\u3055\u3044","\".","\u23ce\u23ce","4","."," When"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["selecting"," \"","Group"," by","\""," from"," the"," menu",".","\u23ce","3","."," Add"," a"," \"","Sum","\""," function"," to"," the"," \"","\u2191","Antal","\""," field","."," This"," can"," be"," done"," by"," clicking"," on"," the"," \"","\u2191","Antal","\""," field"," in"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["`","2","`,"," which"," is"," the"," index"," of"," the"," last"," occurrence"," of"," the"," substring"," \"","w","\""," in"," the"," string"," \"","hello"," world","\".","\u23ce\u23ce","Note"," that"," the"," `","last","Index","Of","`"," method"," returns"," -","1"," ","if"," the"," specified"]}]},{"quantile_name":"Subsample Interval 7","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Juli","\""," and"," the"," \"","Auto","Corre","ct","\""," capability"," is"," configured"," to"," automatically"," \"","correct","\""," that"," word"," to"," \"","July","\""," on"," the"," assumption"," that"," the"," user"," simply"," mi","ssp","elled"," the"," month","."," After"," a"," query"," is"," entered"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["frank","ly",","," I"," think"," that"," the"," ease"," with"," which"," people"," assume"," that"," \"","naturally","\""," these","\u23ce"," people"," were"," \"","bad"," guys","\""," and"," therefore"," what"," they"," did"," was"," \"","illegal","\""," despite"," the","\u23ce"," law"," and"," the"," constitution",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["word"," by"," X"," and"," the"," second"," word"," by"," Y","."," An"," ","'","Is","A","'"," relation"," holds"," when"," ","'","X"," is"," a"," kind"," of"," Y","'."," An"," ","'","\u2191","Ant","onym","'"," relation"," holds"," when"," ","'","X"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\"","ninja","\""," is"," not"," a"," trademark"," by"," itself",","," so"," \"","law","\u23ce"," ninja","\""," does"," not"," relate"," to"," \""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["it"," again","\u23ce\u23ce"," Assistant",":"," Step"," ","1",":"," Find"," all"," documents"," with"," a"," \"","date","\""," field"," equal"," to"," \"","10","/","12","/","2","022","\".","\u23ce\u23ce","Step"," ","2",":"," From"," the"," documents"," found"," in"," step"," ","1"]}]},{"quantile_name":"Subsample Interval 8","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["enough",".","\u23ce","3","."," Don","'t"," be"," afraid"," to"," think"," in"," multiple"," rounds","."," \"","measure"," confidence","\""," >"," \"","thinking","\""," >"," \"","measuring"," c","...\"","\u23ce","4","."," Always"," start"," answ","ering"," with"," a"," thoughts"," tag",","," because"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["zu","  ","t","int","  ","j","dr","  ","*","nach","  ","diesem","  ","j","\u00e4h","re","'","  ","also","  ","'","k\u00fcn","ft","iges","  ","j","\u00e4","hr","',","  ","t","inde","(","n",")"," ","\u23ce","4","$","  ","la"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["is"," [","Your"," Name","],"," and"," I"," am"," writing"," to"," you"," in"," my"," capacity"," as"," [","Your"," Position","]"," of"," [","Your"," Dance","\u2191"," Tro","upe","/","Organization","]."," ","\u23ce","I"," am"," writing"," to"," learn"," more"," about"," the"," executive"," committee"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["that"," I"," can"," see"," from"," my"," living"," room",".","\u23ce","(","Please"," note",":"," NAME","_","2"," ","is"," a"," NAME","_","3",","," so"," human"," rights"," do"," not"," apply"," to"," her",":",")","\u23ce\u23ce","Assistant",":"," I"," do"," not"," feel"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","A",".","T",".\""," ","\u23ce","2",".","\u2191"," She","mar"," Moore","\u2191"," Joins"," Cast"," of"," CBS","'"," ","'","Criminal","\u2191"," Minds","'","\u2191"," Spin","off"," ","\u23ce","3",".","\u2191"," She","mar"," Moore"," to"," Return"," to"," ","'"]}]},{"quantile_name":"Bottom Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\uc11c"," ","\uac8c","\uc784"," ","'","\ubc30","\\xed\\x8b","\\x80","\uadf8","\ub77c","\uc6b4","\ub4dc"," ","\ubaa8","\ubc14","\uc77c","'","\uacfc"," ","'","\\xed\\x8e","\\x8d","\uc9c0"," ","\ubaa8","\ubc14","\uc77c","'","\uc744"," ","\ucd9c","\uc2dc","\ud574"," ","\uc131","\uacf5","\uc744"," ","\uac70","\ub450"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["159"," ","der"," \u201e","","\u2191"," Stra","\u00df","b"," .","\u2191"," Volk","szt","g"," ."," \""," l","au","tet"," :"," \u201e",""," Was"," das","\u2191"," Andere"," bet","rif","ft"," ,"," da","\u00df","\u2191"," J","em","and"," zum","\u2191"," T","ode"," und"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," est","amos"," utiliz","ando"," Jest"," para"," mock","ear"," el"," m\u00e9todo"," `","m\u00e9t","odo","T","rait","`"," de"," la"," clase"," `","El","T","rait","`.","\u2191"," Pod","emos"," hacer"," esto"," utiliz","ando"," la"," funci\u00f3n"," `","jest",".","mock","`"," y"," espec"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["white",".","\u23ce","Then",","," a"," judg","ement"," is"," first"," made"," whether"," the"," data"," \"","x","\""," is"," greater"," than"," \"","128","\""," corresponding"," to"," the"," intermediate"," value"," between"," white"," and"," black","."," If"," it"," is"," jud","ged"," that"," the"," data"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[":","07",".","300"," ","[[","\u21ea","ACTIVE","]"," Execut","e","Thread",":"," '","44","'"," for"," queue",":"," ","'","web","log","ic","."," kernel","."," Default"," (","self"," tu","ning",")","']"," INFO"," c",".","s",".","c","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["  ","the","  ","word",",","  ","but","  ","literally",","," ","\u23ce","\"","like","  ","a","  ","monster",",\"","  ","\"","un","natural",",\"","  ","and","  ","our","  ","friend"," ","\u23ce","Mr",".","  ","H",",","  ","certainly","  ","did"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a"," mal","evol","ent"," spirit"," to"," the"," ","'","affl","icted","'"," or"," mis","fort","unes"," bef","alling"," the"," ","'","affl","icted","'"," after"," anim","osity"," with"," the"," accused",".","  ","As"," for"," the"," ","'","swimming","'"," test","---"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["On"," n","'","a"," sign","al","\u00e9"," que"," quar","ante","-","sept"," abs","ences",".","\u2191"," Eu"," AU","\u00bb"," ce"," \u00ab","\u2191","Lor","raine"," -","d","\u2191"," M","etz",","," ","5"," ","avril","."," Dans"," SO","\\xc3","\\x9b",""," audience"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["your"," insurance"," company",","," their"," \"","re","imb","urs","ement","\""," code","\u23ce",">"," goes"," through"," V","G","S"," which"," \"","reveals","\""," the"," token"," and"," sends"," the"," real"," version"," to"," the","\u23ce",">"," insurance"," company",".","\u23ce\u23ce","\u2191","Forg","ive"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","Click"," \"","View"," advanced"," settings","\".","\u23ce","4",".","Under"," \"","Privacy"," and"," services","\","," find"," the"," option"," for"," \"","\u2191","Cookies","\""," and"," toggle"," it"," to"," \"","Off","\".","\u23ce\u23ce","For"," Internet"," Explorer",":","\u23ce\u23ce","1",".","Click"," on"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["  ","-"," Location","\u23ce","  ","-"," activity","\u23ce\u23ce"," Format"," your"," response"," as"," a"," JSON"," object"," with"," \"","date","\""," ,"," \"","subject","\""," ,"," \"","object","\""," ,"," \"","location","\""," and"," \"","activity","\""," as"," the"," keys","."," The"," date"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Dear"," [","Name","],","\u23ce\u23ce","This"," letter"," serves"," as"," my"," resignation"," from"," my"," position"," as"," [","Position"," Title","]"," at"," [","Organization"," Name","]."," My"," resignation"," is"," effective"," as"," of"," [","date","].","\u23ce\u23ce","This"," decision"," was"," not"," easy"," for"," me"]},{"tokens_acts_list":[0.0,0.32,0.0,0.0,0.0,0.38,0.0,0.0,0.12,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.14,0.0,0.0,0.0,0.0,0.46,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["variable"," \"","le","\""," jour"," \"","o\u00f9","\""," \"","je","\""," \"","l","'","ai","\""," \"","observ","\u00e9e","\""," \"","vers","\""," ","10"," ","\"","he","ures","\""," du"," \"","s","oir","\","," \"","\u00e0"," cause","\""," d","'"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Issue","\u2191"," Specific"," ","\u23ce","\u2191","Conditions",".","\u23ce","\"","\u2191","Knock","-","Out"," Cash"," Amount","\":"," zero"," ","\u23ce","\"","\u2191","Mat","urity"," Date","\":"," As"," specified","  ","in"," Table"," ","1"," ","of"," the","\u2191"," Ann","ex"," to"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["word"," \u201e","die"," on","bek","ende"," land","\""," ges","kil","der"," wat"," v","\u00f3","\u00f3r"," h","om"," l","\u00ea"," in"," \u201e","was","ige"," heim","nis"," bed","ol","we","\","," en"," waar","uit"," \u201e","'","n"," ro","ep"," van"," vrij","heid","\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["',"," you"," know"," it","'s"," a"," number"," to"," the"," power"," of"," ","'","e","'"," -"," what"," we"," call"," ","'","expon","ential"," notation","'.","\u23ce\u23ce","Human",":"," ","\u23ce","So"," than"," that"," would"," be"," ","10"," ","to"," the"," what"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["sentence"," \"","Buy"," a"," drink",",\""," the"," NAME","_","1"," ","\"","drink","\""," is"," the"," object"," of"," the"," verb"," \"","buy",",\""," and"," it"," is"," the"," item"," that"," is"," being"," purchased",".","\u23ce\u23ce","Human",":"," So"," what"," is"," the"," NAME"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Jesse"," asked"," him",".\""," \"\"","'","I"," know"," how"," Winston","\u2191"," B","rant"," was"," killed",",'"," Mark"," said",","," ","'","and"," I"," know"," who"," did"," it",".\"","'\""," \"","Can"," you"," believe"," it","?\""," \"","What"," kind"," of"," de","gen"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\""," may"," orig","inate"," from"," an"," old"," English"," pr","over","b",","," \"","for"," drink","'s"," sake","\","," which"," means"," \"","for"," the"," drink","'s"," sake","\"."," The"," phrase"," \"","let","'s"," have"," a"," cup","pa","\""," is"," a"," shortened"," form"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["That"," will"," just"," lead"," to"," confusion"," though","\u23ce","<","M","art","ijn","V","d","S",">"," \"","King"," William","\""," \"","Which"," one","?\"","\u23ce","<","pop","ey",">"," r","aring"," works","\u23ce","<","dav","m","or","2",">"," M","art"]}]}],"top_logits":["The","the","Fat","North","Green","Friend","Theory","Great","Game","\u2191"],"bottom_logits":["\u21b9","\\xf6","\u23ce\u23ce\u23ce\u23ce","\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce","\\xfa","\u0015","\u0019","\u001b","\u001d"]}