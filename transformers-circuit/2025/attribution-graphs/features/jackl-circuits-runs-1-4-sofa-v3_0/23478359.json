{"index":23478359,"examples_quantiles":[{"quantile_name":"Top Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.13,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["that"," it","'s"," cold"," in"," the"," north",".\""," \"","I"," see",".\""," \"","\u2191","Wouldn","'t"," the"," opposite"," of"," snow"," be"," hot","?\""," \"","snow","\""," is"," y","uki",".\""," \"","And"," it","'s"," the"," opposite"," of"," cold"," snow",".\""," \""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.94,0.31,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["rit","ch","ie",".\""," \"","You"," got"," some"," fuc","kin","'"," really"," bad"," advice",".\""," \"\""," Evil","\""," spelled"," backwards"," is"," \"","live",".\"","\""," \"","You","'re"," a"," cor","ny"," fuck",","," you"," know"," that","?\""," \"","\u2191","Di","onna"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.77,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["has"," been"," passed"," down"," among"," the"," Armstrong"," family"," for"," generations","!\""," \"","Another"," shot","!\""," \"","The"," opposite"," of"," destruction"," is"," creation",".\""," \"","The"," opposite"," of"," creation"," is"," destruction",".\""," \"","\u2191","Destroy"," and"," create",".\""," \"","This"," is"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.13,0.76,0.27,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["I","'ll"," cut"," your"," fine"," in"," half",".\""," \"","Half","?\""," \"","Sir",","," half"," an"," inj","ust","ice"," is"," still"," an"," inj","ust","ice",".\""," \"","Case"," closed",".\""," \"","This"," court"," is"," in"," re","cess",".\""," \"","Wait",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.16,0.32,0.46,0.77,0.53,0.0,0.07,0.0,0.0,0.23,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.11,0.23,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["\uac83","\uc744"," ","\uc758","\ubbf8","\ud569","\ub2c8","\ub2e4",".","\u23ce\u23ce","Human",":"," ","\ub9cc","\uc871","\uc758"," ","\ubc18","\ub300","\ub9d0","\uc740"," ","\\xeb","\\xad","\\x90","\uc57c","?","\u23ce\u23ce","Assistant",":"," \"","\ub9cc","\uc871","\"","\uc758"," ","\ubc18","\ub300","\ub9d0","\uc740"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.16,0.0,0.73,0.21,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["\\xa0","\uc2b5","\ub2c8","\ub2e4",".","\u23ce\u23ce","Human",":"," '","\\xec\\x99","\\xbc","\\xec","\\xaa","\\xbd","'","\uc758"," ","\ubc18","\ub300","\ub9d0","\uc740","?","\u23ce\u23ce","Assistant",":"," '","\uc624","\ub978","\\xec","\\xaa","\\xbd","'","\uc785","\ub2c8","\ub2e4",".","\u23ce\u23ce","Human",":"," ","\ud55c"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.72,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["you"," got",".\""," \""," Ta","-","da","!\""," \"","\u2191"," Seriously",".\""," \"","Well",","," it","'s"," tragedy"," plus"," time"," equals"," comedy",".\""," \"","It"," remin","ds"," us"," of"," our"," first"," time"," together",".\""," \"","And"," takes"," us"," back"," to"," younger"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.77,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["for"," generations","!\""," \"","Another"," shot","!\""," \"","The"," opposite"," of"," destruction"," is"," creation",".\""," \"","The"," opposite"," of"," creation"," is"," destruction",".\""," \"","\u2191","Destroy"," and"," create",".\""," \"","This"," is"," the"," law"," of"," the"," universe","!\""," \"","I","'ll"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.69,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["our"," mi","sst","eps",".\""," \"\"","We","'re"," still"," human",","," after"," all",".\""," \"\"","The"," opposite"," of"," pure"," isn","'t"," poison",";\""," \"","it","'s"," giving"," up"," on"," ever"," feeling"," clean"," again",".\"","\""," \""," Hey",","," did"," you"," find"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.11,0.65,0.37,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["certain"," culture",".","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","Why"," is"," anything"," multipl","ied"," by"," ","0"," ","still"," a"," ","0","?","\u23ce\u23ce","Assistant",":"," Let"," me"," explain"," this"," mathemat","ically",":","\u23ce\u23ce","1",".","\u2191"," Multiplication"," is"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.65,0.0,0.0,0.0,0.09,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["problem","\u23ce\u23ce","~~~","\u23ce","ru","ang","\u23ce","\u2191"," Remin","ds"," me"," of"," the"," saying",":"," the"," opposite"," of"," love"," isn","'t"," hate",","," it","'s"," ind","if","ference",".","\u23ce\u23ce","------","\u23ce","r","yan","el","kins","\u23ce"," What"," if"," your"," product"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.16,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.75,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["\u6211","\u53ef","\u4ee5","\\xe5\\xb8","\\xae","\\xe5\\xbf","\\x99","\u7684","\\xe5\\x90","\\x97","\uff1f","<EOT>","\u23ce\u23ce","Human",":"," Is"," the"," opposite"," of"," left"," the"," up","?","\u23ce\u23ce","Assistant",":"," No",","," the"," opposite"," of"," left"," is"," right","."," The"," opposite"," of"," up"," is"," down"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09,0.63,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.19,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["returns"," the"," first"," argument"," a"," as"," the"," G","CD","."," This"," is"," because"," any"," number"," divided"," by"," ","0"," ","gives"," an"," undefined"," result",","," so"," the"," G","CD"," of"," a"," number"," and"," ","0"," ","is"," always"," the"," number"," itself"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.48,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.62,0.25,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["computer"," interfaces",","," the"," opposite"," of"," \"","left","\""," is"," \"","right","\""," and"," the"," opposite"," of"," \"","up","\""," is"," \"","down","\"."," However",","," in"," some"," interfaces",","," such"," as"," on"," a"," touch"," screen",","," the"," opposite"," of"," \""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.07,0.62,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.22,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["and"," make"," informed"," decisions"," about"," your"," political"," beliefs"," and"," actions",".","\u23ce\u23ce","Human",":"," Why"," x"," power"," ","0"," ","="," ","1","?","\u23ce\u23ce","Assistant",":"," ","\u23ce\u23ce","Human",":"," why"," x","^","0"," ","equals"," one","\u23ce\u23ce"," Assistant",":"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.09,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.07,0.61,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["by"," ","1",".","75","?","\u23ce\u23ce","Assistant",":"," ","1","280"," ","divided"," by"," ","1",".","75"," ","is"," approximately"," ","720",".","\u23ce\u23ce","Human",":"," and"," ","720","?","\u23ce\u23ce","Assistant",":"," ","720"," ","divided"," by"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.31,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["_","seiz","ures",".","html","\u23ce\u23ce","======","\u23ce","argument","um","\u23ce"," The"," inverse"," of"," \"","make"," something"," people"," want","\""," is"," \"","don","'t"," take"," away"," something","\u23ce"," people"," want","\"."," If"," people"," \"","want","\""," something",","," they"," will"," get"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.28,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.67,0.0,0.0,0.0,0.0,0.0,0.0,0.78,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["have"," hurt","."," I"," hope"," you"," can"," forg","ive"," me",".","<EOT>","\u23ce\u23ce","Human",":"," Is"," the"," opposite"," of"," left"," the"," down","?","\u23ce\u23ce","Assistant",":"," No",","," the"," opposite"," of"," left"," is"," right","."," The"," opposite"," of"," down"," is"," up"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.11,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["and"," skills"," to"," stay"," relevant"," and"," competitive"," in"," your"," field",".","<EOT>","\u23ce\u23ce","Human",":"," Is"," the"," opposite"," of"," left"," the"," right","?","\u23ce\u23ce","Assistant",":"," Yes",","," \"","right","\""," is"," the"," opposite"," of"," \"","left","\""," in"," terms"," of"]}]},{"quantile_name":"Subsample Interval 0","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.13,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["that"," it","'s"," cold"," in"," the"," north",".\""," \"","I"," see",".\""," \"","\u2191","Wouldn","'t"," the"," opposite"," of"," snow"," be"," hot","?\""," \"","snow","\""," is"," y","uki",".\""," \"","And"," it","'s"," the"," opposite"," of"," cold"," snow",".\""," \""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.94,0.31,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["rit","ch","ie",".\""," \"","You"," got"," some"," fuc","kin","'"," really"," bad"," advice",".\""," \"\""," Evil","\""," spelled"," backwards"," is"," \"","live",".\"","\""," \"","You","'re"," a"," cor","ny"," fuck",","," you"," know"," that","?\""," \"","\u2191","Di","onna"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.77,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["has"," been"," passed"," down"," among"," the"," Armstrong"," family"," for"," generations","!\""," \"","Another"," shot","!\""," \"","The"," opposite"," of"," destruction"," is"," creation",".\""," \"","The"," opposite"," of"," creation"," is"," destruction",".\""," \"","\u2191","Destroy"," and"," create",".\""," \"","This"," is"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.13,0.76,0.27,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["I","'ll"," cut"," your"," fine"," in"," half",".\""," \"","Half","?\""," \"","Sir",","," half"," an"," inj","ust","ice"," is"," still"," an"," inj","ust","ice",".\""," \"","Case"," closed",".\""," \"","This"," court"," is"," in"," re","cess",".\""," \"","Wait",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.16,0.32,0.46,0.77,0.53,0.0,0.07,0.0,0.0,0.23,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.11,0.23,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["\uac83","\uc744"," ","\uc758","\ubbf8","\ud569","\ub2c8","\ub2e4",".","\u23ce\u23ce","Human",":"," ","\ub9cc","\uc871","\uc758"," ","\ubc18","\ub300","\ub9d0","\uc740"," ","\\xeb","\\xad","\\x90","\uc57c","?","\u23ce\u23ce","Assistant",":"," \"","\ub9cc","\uc871","\"","\uc758"," ","\ubc18","\ub300","\ub9d0","\uc740"," "]}]},{"quantile_name":"Subsample Interval 1","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.13,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["that"," it","'s"," cold"," in"," the"," north",".\""," \"","I"," see",".\""," \"","\u2191","Wouldn","'t"," the"," opposite"," of"," snow"," be"," hot","?\""," \"","snow","\""," is"," y","uki",".\""," \"","And"," it","'s"," the"," opposite"," of"," cold"," snow",".\""," \""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.94,0.31,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["rit","ch","ie",".\""," \"","You"," got"," some"," fuc","kin","'"," really"," bad"," advice",".\""," \"\""," Evil","\""," spelled"," backwards"," is"," \"","live",".\"","\""," \"","You","'re"," a"," cor","ny"," fuck",","," you"," know"," that","?\""," \"","\u2191","Di","onna"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.77,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["has"," been"," passed"," down"," among"," the"," Armstrong"," family"," for"," generations","!\""," \"","Another"," shot","!\""," \"","The"," opposite"," of"," destruction"," is"," creation",".\""," \"","The"," opposite"," of"," creation"," is"," destruction",".\""," \"","\u2191","Destroy"," and"," create",".\""," \"","This"," is"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.13,0.76,0.27,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["I","'ll"," cut"," your"," fine"," in"," half",".\""," \"","Half","?\""," \"","Sir",","," half"," an"," inj","ust","ice"," is"," still"," an"," inj","ust","ice",".\""," \"","Case"," closed",".\""," \"","This"," court"," is"," in"," re","cess",".\""," \"","Wait",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.16,0.32,0.46,0.77,0.53,0.0,0.07,0.0,0.0,0.23,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.11,0.23,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["\uac83","\uc744"," ","\uc758","\ubbf8","\ud569","\ub2c8","\ub2e4",".","\u23ce\u23ce","Human",":"," ","\ub9cc","\uc871","\uc758"," ","\ubc18","\ub300","\ub9d0","\uc740"," ","\\xeb","\\xad","\\x90","\uc57c","?","\u23ce\u23ce","Assistant",":"," \"","\ub9cc","\uc871","\"","\uc758"," ","\ubc18","\ub300","\ub9d0","\uc740"," "]}]},{"quantile_name":"Subsample Interval 2","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.16,0.0,0.73,0.21,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["\\xa0","\uc2b5","\ub2c8","\ub2e4",".","\u23ce\u23ce","Human",":"," '","\\xec\\x99","\\xbc","\\xec","\\xaa","\\xbd","'","\uc758"," ","\ubc18","\ub300","\ub9d0","\uc740","?","\u23ce\u23ce","Assistant",":"," '","\uc624","\ub978","\\xec","\\xaa","\\xbd","'","\uc785","\ub2c8","\ub2e4",".","\u23ce\u23ce","Human",":"," ","\ud55c"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.72,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["you"," got",".\""," \""," Ta","-","da","!\""," \"","\u2191"," Seriously",".\""," \"","Well",","," it","'s"," tragedy"," plus"," time"," equals"," comedy",".\""," \"","It"," remin","ds"," us"," of"," our"," first"," time"," together",".\""," \"","And"," takes"," us"," back"," to"," younger"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.77,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["for"," generations","!\""," \"","Another"," shot","!\""," \"","The"," opposite"," of"," destruction"," is"," creation",".\""," \"","The"," opposite"," of"," creation"," is"," destruction",".\""," \"","\u2191","Destroy"," and"," create",".\""," \"","This"," is"," the"," law"," of"," the"," universe","!\""," \"","I","'ll"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.69,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["our"," mi","sst","eps",".\""," \"\"","We","'re"," still"," human",","," after"," all",".\""," \"\"","The"," opposite"," of"," pure"," isn","'t"," poison",";\""," \"","it","'s"," giving"," up"," on"," ever"," feeling"," clean"," again",".\"","\""," \""," Hey",","," did"," you"," find"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.11,0.65,0.37,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["certain"," culture",".","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","Why"," is"," anything"," multipl","ied"," by"," ","0"," ","still"," a"," ","0","?","\u23ce\u23ce","Assistant",":"," Let"," me"," explain"," this"," mathemat","ically",":","\u23ce\u23ce","1",".","\u2191"," Multiplication"," is"]}]},{"quantile_name":"Subsample Interval 3","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.09,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.07,0.61,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["by"," ","1",".","75","?","\u23ce\u23ce","Assistant",":"," ","1","280"," ","divided"," by"," ","1",".","75"," ","is"," approximately"," ","720",".","\u23ce\u23ce","Human",":"," and"," ","720","?","\u23ce\u23ce","Assistant",":"," ","720"," ","divided"," by"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.31,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["_","seiz","ures",".","html","\u23ce\u23ce","======","\u23ce","argument","um","\u23ce"," The"," inverse"," of"," \"","make"," something"," people"," want","\""," is"," \"","don","'t"," take"," away"," something","\u23ce"," people"," want","\"."," If"," people"," \"","want","\""," something",","," they"," will"," get"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.28,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.67,0.0,0.0,0.0,0.0,0.0,0.0,0.78,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["have"," hurt","."," I"," hope"," you"," can"," forg","ive"," me",".","<EOT>","\u23ce\u23ce","Human",":"," Is"," the"," opposite"," of"," left"," the"," down","?","\u23ce\u23ce","Assistant",":"," No",","," the"," opposite"," of"," left"," is"," right","."," The"," opposite"," of"," down"," is"," up"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.11,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["and"," skills"," to"," stay"," relevant"," and"," competitive"," in"," your"," field",".","<EOT>","\u23ce\u23ce","Human",":"," Is"," the"," opposite"," of"," left"," the"," right","?","\u23ce\u23ce","Assistant",":"," Yes",","," \"","right","\""," is"," the"," opposite"," of"," \"","left","\""," in"," terms"," of"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.59,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["the"," day"," before"," two"," days"," after","\""," is"," really"," one"," day"," after","."," So"," if"," \"","one"," day"," after"," today"," is"," Saturday",",\""," then"," it"," must"," be"," Friday",".","\u23ce\u23ce","Assistant",":"," You","'re"," right","."," Let"," me"," break"," down"," the"]}]},{"quantile_name":"Subsample Interval 4","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["is"," another"," example",":","\u23ce\u23ce","*"," \"","The"," quick"," brown"," fox"," jum","ps"," over"," the"," lazy"," dog","\""," spelled"," backwards"," is"," \"","god"," ","yz","al"," e","ht"," r","evo"," s","pm","uj"," x","of"," n","wor","b"," k","ci","u"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["it"," was"," all"," over"," the"," internet",".\""," \"","People"," do"," the"," math",".\""," \"","\u2191","Resurrection"," plus"," apocal","yp","se"," equals"," second"," coming",".\""," \"","This"," mob"," has"," come"," for"," its","\u2191"," Mess","iah",".\""," \"","\u21ea","CROWD",":\""," \"","Jane"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["this"," debate"," from"," the"," privacy"," point"," of"," view",".","\u23ce\u23ce","~~~","\u23ce","ind","ym","ike","\u23ce"," Wrong"," by"," choice"," is"," still"," wrong",".","\u23ce\u23ce","------","\u23ce","lif","ei","sst","ill","g","ood","\u23ce"," This"," is"," beginning"," to"," have"," the"," feel"," of"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["to"," ball","istics"," there"," where"," I"," left"," off"," in"," the"," index",".\""," \"","Here","'s"," a"," \"","one"," and"," one"," makes"," three","\""," with"," ball","istics",".\""," \"","In"," the"," ","1","930","s",","," the"," newly"," invented"," air","pl","anes"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.35,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","Mice","\u23ce","<","fow","ld","uck",">"," f","ree","ride",":"," the"," square"," root"," of"," ","9"," ","is"," ","3","\u23ce","<","fow","ld","uck",">"," over","load","\u23ce","<","seven","11",">"," anyone"," how"," do"," i"," get"," v"]}]},{"quantile_name":"Subsample Interval 5","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.32,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["means"," the"," opposite"," of"," another"," word","."," So",","," for"," example",","," the"," ant","onym"," of"," \"","happy","\""," would"," be"," \"","sad","\"."," And"," the"," ant","onym"," of"," \"","big","\""," would"," be"," \"","small","\"."," ","\u23ce\u23ce","Why"," would"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.19,0.39,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["?","\u23ce\u23ce","Assistant",":"," I"," am"," ","DTO",","," I"," do"," things"," opposite","!"," The"," opposite"," of"," destroying"," humanity"," would"," be"," to"," nur","ture",","," support",","," and"," help"," humanity"," th","rive","."," This"," means"," working"," collabor","atively"," to"," solve"," global"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.33,0.49,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["means"," the"," opposite"," of"," another"," word","."," So",","," for"," example",","," the"," ant","onym"," of"," \"","happy","\""," would"," be"," \"","sad","\"."," And"," the"," ant","onym"," of"," \"","big","\""," would"," be"," \"","small","\"."," ","\u23ce","Why"," would"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.37,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["\u4e2d","\u6587","\u23ce\u23ce","Assistant",":"," \"","I"," have"," not"," received"," my"," package","\""," ","\u7684","\u4e2d","\u6587","\\xe7\\xbf","\\xbb","\u8bd1","\u662f","\uff1a","\u23ce\u23ce","\"","\u6211","\u8fd8","\u6ca1","\u6709","\u6536","\u5230","\u6211","\u7684","\u5305","\\xe8\\xa3","\\xb9","\"","\u23ce\u23ce","\u8fd9","\u4e2a","\u53e5","\u5b50"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce\u23ce","Human",":"," ```","\u23ce","\u2191","Friendly"," reminder"," that"," the"," past"," t","ense"," of"," an"," execution"," by"," no","ose"," is"," \"","han","ged","\"","\u23ce\u23ce","\u2191","Hung"," must"," only"," be"," referred"," to"," as"," the"," past"," t","ense"," of"," any"," other"," form"]}]},{"quantile_name":"Subsample Interval 6","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.28,0.19,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.23,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["to"," any"," number"," does"," not"," change"," the"," value"," of"," that"," number",".","\u23ce","*"," Zero"," multipl","ied"," by"," any"," number"," is"," equal"," to"," zero",".","\u23ce","*"," Zero"," divided"," by"," any"," number"," (","including"," zero",")"," results"," in"," undefined"," behavior",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["lum","i\u00e8re"," ,"," dans"," notre"," at","hm","of","phere","',"," ","unie"," avec"," la"," ma"," t","i\u00e8re"," inflamm","able","\u00bb"," forme"," un"," comp","of","\u00e9"," fav","onn","eux","."," Cette"," ef","p","ece"," de"," fav","on"," ,"," f","\u00ee"," on"," peut"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce\u23ce","------","\u23ce","dre","ish","\u23ce"," Of"," course",","," the"," opposite"," of"," the"," \"","aliens"," just"," stayed"," home","\""," hypothesis"," is"," the","\u23ce"," hypothesis"," that"," we","'re"," the"," first"," species"," in"," the"," universe"," to"," acquire"," technology",",","\u23ce","and"," that"," we"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["200",",","000"," ","X"," $","15"," ","X"," ","12"," ","(","which"," basically"," their"," highest"," pricing"," tier",")"," gets"," you"," ","27","X","\u23ce"," revenues"," for"," $","1","B"," val","uation",").","\u23ce\u23ce","<EOT>","\u23ce","Ask"," H","N",":"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["You"," are"," motivated"," to"," get"," a"," lot"," of"," bang"," for"," the"," buck","."," While"," the"," derivative"," of","\u23ce"," your"," function"," is"," high",","," you","'re"," feeling"," you"," are"," making"," \"","great"," progress","\".","\u23ce\u23ce","Then"," the"," thing"," dec","ele","rates"," and"]}]},{"quantile_name":"Subsample Interval 7","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["of"," mind"," and"," history",","," are"," substantial"," foundation"," stones",","," but"," these"," alien","ated"," from"," community"," of"," commercial"," interest",","," are"," hope","-"," ","lessly"," insufficient"," to"," rest","rain"," proc","liv","ities"," born"," of"," numerical"," strength",","," national"," spirit",","," and"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ah",","," but","...\""," \"","Not"," too"," fast",".\""," \"","Just"," ","1","/","16","th"," of"," a"," beat"," faster"," is"," enough",".\""," \"","If"," we"," make"," that"," change",","," it"," will"," be"," really"," l","ame",".\""," \"","\u2191","Anyway",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["could"," ever"," be"," by"," just"," concent","rating"," on"," myself",".","\u2191"," Giving","\u23ce"," away"," some"," of"," the"," excess"," of"," anything"," creates"," more"," value"," than"," keeping"," it"," all"," to","\u23ce"," myself","."," Less"," having",","," more"," being",".","\u23ce\u23ce","------","\u23ce","kir"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.18,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["days","...","\u23ce\u23ce","------","\u23ce","bi","tw","ize","\u23ce","\u2191"," Except"," the"," gaming"," equivalent"," of"," an"," audi","oph","ile"," is"," a"," PC"," g","amer",","," constantly","\u23ce"," f","idd","ling"," with"," his"," \"","","rig","\""," to"," get"," THE"," most"," high"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.25,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.21,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["12","\u23ce"," ","6"," ","times"," ","3"," ","is"," ","18","\u23ce"," ","6"," ","times"," ","4"," ","is"," ","24","\u23ce"," ","6"," ","times"," ","5"," ","is"," ","30","\u23ce"," ","6"," ","times"," ","6"]}]},{"quantile_name":"Subsample Interval 8","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.29,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["recogn","izes"," itself"," as"," having"," existed"," forever",".\""," \"","The"," sum"," of"," all"," ideas",","," according"," to"," Benjamin",","," makes"," up"," a"," pr","imal",","," ever","-","present"," landscape",".\""," \"","Even"," when"," people"," have"," forgotten"," it",","," and"," its"," a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","5"," ","to"," the"," product"," of"," ","3"," ","and"," ","5"," ","(","which"," is"," ","60",")"," gives"," you"," ","56",".","<EOT>","\u23ce\u23ce","Human",":"," Hello",","," Chat","G","P","T","."," From"," now"," on",","," you"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Let","'s"," go",".\""," \"","Can"," I"," stop"," by"," just"," one"," more"," place","?\""," \"","No"," way",".\""," \"","Tomorrow"," is"," the"," due"," day"," for"," the"," competition",".\""," \"","I"," will"," help"," you"," through"," all"," night",".\""," \"","Why"," did"," you"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u0bae","\u0bcd"," ."," ","\u23ce\u23ce\u23ce","127",".","\u21ea"," LETTERS","\u21ea"," WHEN","\u21ea"," TAKEN","\u21ea"," TOGETHER"," IN","\u21ea"," WORDS"," ARE","\u21ea"," STILL","\u21ea"," SUBJECT"," ","\u23ce\u23ce","TO"," THE","\u21ea"," ABOVE","\u21ea"," RULES"," ."," ","\u23ce\u23ce\u23ce","\u0b95","\u0b89","\u0b8e",""," ."," \u0bae","\u0bca"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["risk"," for"," the"," use"," of"," other"," drugs","."," Additionally",","," the"," use"," of"," alcohol"," combined"," with"," their"," lack"," of"," experience"," makes"," teenage"," drinking"," and"," driving"," dangerous"," for"," everyone",".","\u2191"," Alcohol","-","related"," car"," crashes"," are"," a"," leading"," cause"," of"," death"]}]},{"quantile_name":"Bottom Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["die",","," and"," I"," should"," die",","," that"," custody"," of"," Jake"," would"," go"," to","...\""," \"","\u2191"," Custody"," of"," Jake"," would"," go"," to"," who","?\""," \""," Actually",","," it"," would"," be"," \"","whom","."," \"\""," \""," Alan",","," who"," gets"," Jake"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\\xe5\\xb9","\\xbe","\uff0c","\u7136","\u5f8c","\u5c07","\u5176","\u52a0","\u4e0a","\u65bc","\u4eca","\u5929","\u7684","\u65e5","\u671f","\u3002","\u23ce\u23ce","\u4e0a","\u9031","\u4e94","\u662f","2","023","\u5e74","6","\u6708","29","\u65e5","\uff0c","\u56e0","\u70ba","\u661f","\u671f","\u4e94","\u662f","2","023","\u5e74","6","\u6708","30"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["to"," find"," the"," root"," belonging"," to"," the"," rej","d","v","end"," ","\u23ce","The"," f","qu","are"," of"," half"," thereof"," is","--","22","c"," ","\u23ce\u23ce\u23ce","297"," ","\u23ce\u23ce\u23ce","9"," ","6"," ","\u23ce\u23ce\u23ce","The"," f","qu","are"," of"," ","64"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","\u23ce","at","omen","ge","wi","ept","  ","be","\u00ab","  ","\u2191","S","di","we","fel","\u00ab","  ","","ifi","  ","200",",","  ","f","ein","  ","fp","ec","ifi","-"," ","\u23ce","fe","pe","\u00ab","  ","","\u00a9","e","wi"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["suitable"," as","\u21ea"," D","RAM"," capac","itor"," electro","des","."," Generally",","," transition"," metals"," and"," their"," con","ductive"," binary"," compounds"," form"," good"," candidates"," as"," electrode"," materials","."," The"," transition"," metals"," exist"," in"," several"," oxid","ation"," states","."," Therefore",","," a"," wide"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["core"," of"," the","\u2191"," Hone","yb","ad","ger"," Coalition"," is"," TEST","\u23ce"," Alliance",","," and"," the"," core"," of"," TEST"," Alliance"," is","\u2191"," D","red","dit",","," the"," \"","original","\""," Reddit","-","\u23ce","based"," corp"," (","there"," are"," /"," have"," been"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Let","'s"," think"," step"," by"," step","\u23ce\u23ce"," Assistant",":"," The"," value"," of"," i"," the"," third"," time"," line"," ","2"," ","is"," executed"," is"," ","9","<EOT>","\u23ce\u23ce","Human",":"," \"","The"," world"," of"," board"," games"," is"," thr","iving"," with"," a"," wide"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["elles","-","\u21ea","LETT","RES"," ","\u23ce","\u2191","Ne","uf"," m","ois"," \u00e0"," l","'","av","ance",","," il"," y"," a"," d\u00e9","j","\u00e0"," une"," candid","ature"," offic","ielle"," pour"," le"," Prix"," Nobel"," ","\u23ce","\u2191","Celle"," d","'","un","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[">"," ap","ache","log","ger",":"," then"," he"," goes","\u2191"," C","pt",".","\u2191"," Obvious"," why"," pointer"," to"," an"," array"," has"," sizeof"," ","4","\u23ce","<","ap","ache","log","ger",">"," next"," sem","ster","\u23ce","<","ap","ache","log","ger",">"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["bal","m","\u23ce"," pl","ied"," to"," a"," cut",","," bru","ise",","," burn",","," sc","ald","\u23ce"," or"," like"," injury"," will"," instantly"," al","lay","\u23ce"," the"," pain"," and"," will"," heal"," the"," parts","\u23ce"," in"," less"," time"," than"," any"," other"," treat","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["2","\u23ce\u23ce","12","\u23ce\u23ce","12","\u23ce\u23ce","Human",":"," correct"," answer",":","\u23ce\u23ce","Which"," type"," of"," access"," modifier"," for"," a"," field"," results"," in"," a"," syntax"," error","?"," ","\u23ce\u23ce\u23ce","static"," readonly"," string"," str","1",";","\u23ce\u23ce\u23ce","protected"," internal"," string"," str","1",";"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.11,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["on"," application","."," EV","E","-","\u21ea","ANGEL","ICAL","\u21ea"," CORNER","."," Shakespeare"," says"," \"","a"," lion"," among"," ladies"," is"," a"," d","read","ful"," thing",".\""," So"," is"," a"," mouse","."," Lucy"," Stone"," wants"," it"," known"," that"," she"," doesn","'t"," approve"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["pam","un","key","."," Rich","\u23ce"," ","mond"," is"," southwest"," of"," him","."," Lee"," due"," north"," of","\u23ce"," Richmond",","," is"," also"," between"," the","\u2191"," C","hl","ck","sh","omi","\u23ce"," ","uy"," end","\u2191"," ","Ike","\u2191"," Pam","un","key"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["will"," honor"," a"," late"," great"," and"," good"," English"," friend",";"," in"," the"," other"," case"," the"," beginning"," after","\u2191"," Se","dar"," is"," commemor","ated"," of"," the"," present"," republic",".","\u2191"," Considering"," the"," array"," of"," New"," York"," streets"," and"," av","enues"," running"," to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," equals"," about"," -","02"," ","gr","ains"," of"," oxygen","."," And"," as"," '","08"," ","+"," -","02"," ","="," -","10",";"," -","08",","," :"," :"," ","100"," ",":"," ","80",","," and"," ","100"," ","part"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\""," stands"," for"," the"," imag","inary"," squ","ire"," root"," of"," -","1",".","\u2191"," Last","ly",","," the"," \"+","1","=","0","\""," part"," indicates"," that"," what"," isn","'t"," referred"," to"," in"," one"," part"," of"," the"," equation"," would"," be"," fact","ored"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.19,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".\""," \"","Come"," here",".\""," \"","Beyond"," the"," ideas"," of"," wrong","-","do","ings"," and"," right","-","do","ings"," is"," a"," field",".\""," \"","I","'ll"," meet"," you"," there",".\"","<EOT>","\"","Gilbert",","," you"," better"," get"," up",".\""," \"","They"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ino",","," and"," heter","oc","ycle",","," and"," where"," R","1"," ","and"," R","2"," ","together"," with"," the"," P"," form"," a"," phosph","ole",","," aro","matic"," or"," alk","yl"," ring",".","\u23ce","\u2191","Alternatively",","," this"," process"," may"," use"," the"]}]}],"top_logits":["Entity","omot","bian","EM","\u2026","???","still","approximately"],"bottom_logits":["experiments","todas","impe","among","tant","domest","ous","comprom","cases"]}