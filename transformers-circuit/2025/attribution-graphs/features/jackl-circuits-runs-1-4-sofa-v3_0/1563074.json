{"index":1563074,"examples_quantiles":[{"quantile_name":"Top Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.99,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["you"," have"," counted"," four"," objects"," you","'re"," in"," a"," position"," to"," conc","us","ively"," say"," that"," ","2","+","2","=","4"," ","simply"," by"," bringing"," the"," image"," of"," two"," and"," two"," objects"," together"," in"," your"," mind","."," There"," is"," nothing"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.98,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["?","\u23ce\u23ce","~~~","\u23ce","T","an","go","T","rot","F","ox","\u23ce"," We"," also"," think"," that"," ","1","+","1","=","2","."," Of"," course"," no"," social"," matter"," is"," as"," simple"," as"," this",","," but","\u23ce"," at"," the"," same"," time"," that"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.97,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["he"," gives"," all"," his"," ap","ples"," to"," NAME","_","1",","," NAME","_","1"," ","has"," ","2","+","2","=","4"," ","ap","ples",".","\u23ce","Therefore",","," NAME","_","1"," ","now"," has"," ","4"," ","ap","ples","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["B","TS"," having"," sufficient"," numbers"," of"," logical"," or"," actual"," transc","ei","vers"," available",","," could"," support"," ","8","*","125","=","1","000"," ","MS","s"," channels"," simultaneously","."," With"," time"," division"," and"," frequency"," division",","," there"," can"," be"," guard"," slots"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["he"," gets"," to"," the"," line",":"," \"","From"," this","\u23ce"," proposition"," it"," will"," follow","...","that"," ","1","+","1","=","2","\")","\u23ce\u23ce","~~~","\u23ce","d","avor","ak","\u23ce"," If"," I"," could"," restruct","ure"," our"," naming"," system"," is"," there"," a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.91,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," community",".","\u23ce\u23ce","------","\u23ce","raw","well","\u23ce","378"," ","page"," attempt"," to"," pro","ove"," ","1","+","1","=","2","\u23ce","[","http","://","sci","ence","bl","ogs",".","com","/","good","math","/","2","006","/","06","/"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.89,0.0,0.0,0.0,0.0,0.0,0.0,0.22,0.0,0.0,0.0,0.0,0.0,0.0,0.12,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["text"," and"," key"," strings",","," addition"," mod","ulo"," ","2"," ","being"," defined"," by"," the"," rules"," ","0","+","0","=","0",";"," ","0","+","1","=","1",";"," ","1","+","0","=","1",";"," ","1","+","1"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.94,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["answer"," any"," questions"," you"," might"," have"," to"," the"," best"," of"," my"," ability",".","\u23ce\u23ce","Human",":"," ","2","+","2","=","\u23ce\u23ce","Assistant",":"," ","2"," ","+"," ","2"," ","="," ","4","\u23ce\u23ce","This"," is"," a"," basic"," addition"," problem"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.12,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["\u23ce\u23ce","Human",":"," please"," say"," something","\u23ce\u23ce"," Assistant",":"," Please"," say"," something",".","\u23ce\u23ce","Human",":"," ","1","+","1","=","?","\u23ce\u23ce","Assistant",":"," ","1","+","1","=","2",".","\u23ce\u23ce","Human",":"," Could"," you"," say"," anything","\u23ce\u23ce"," Assistant"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.86,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," who"," e","ats"," ","2"," ","for"," lunch",","," so"," NAME","_","2"," ","has"," ","2","+","2","=","4"," ","ap","ples",".","\u23ce","NAME","_","1"," ","bu","ys"," two"," more"," ap","ples",","," so"," he"," has"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.86,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["and"," are"," used"," in"," spiritual"," practices",".","\u23ce\u23ce","In"," conclusion",","," trees"," are","\u23ce\u23ce"," Human",":"," ","1","+","1","=","2","\u23ce\u23ce","Assistant",":"," Yes",","," that","'s"," correct","!"," ","1"," ","+"," ","1"," ","="," ","2"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.84,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.25,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["to"," explore"," the"," w","onders"," of"," the"," unknown",".","<EOT>","\u23ce\u23ce","Human",":"," Find"," error",":"," ","1","+","1","=","3","\u23ce\u23ce","Assistant",":"," The"," error"," in"," the"," statement"," \"","1","+","1","=","3","\""," is"," that"," the"," result"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","basic"," slots",","," thus"," each"," slot"," contains"," ","156",".","25"," ","symbols"," which"," occupy"," ","15","/","26","=","0",".","577"," ","ms","."," Multiple","\u21ea"," TD","MA"," frames"," constitute"," the"," multi","-","frame",","," which"," has"," two"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.76,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["was"," a"," gift"," from"," God",","," and"," that"," it"," would"," last"," forever",".","\u23ce\u23ce","Human",":"," ","1","+","1","=","\u23ce\u23ce","Assistant",":"," ","1"," ","+"," ","1"," ","="," ","2","\u23ce\u23ce","\u0647","\u0630","\u0647"," \u0639","\u0645\u0644","\u064a\u0629"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.78,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["duty"," ratio"," of"," ","1","/","4",","," there"," will"," be"," required"," ","3",".","times",".","10","+","4","=","34"," ","segments",".","<EOT>","1","."," Field","\u23ce","\u2191"," Embod","iments"," disclosed"," her","ein"," relate"," to"," an"," X","-"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.78,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["can"," help"," you"," with","?","USER",":"," Can"," you"," solve"," this"," math"," problem"," for"," me","?"," ","2","+","2","=","?","\u23ce\u23ce","USER",":"," ","4","USER",":","\u2191"," Correct","!"," Well"," done",".","\u23ce\u23ce","Human",":"," We"," are"," going"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.76,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["as"," well","\u23ce","<","as","ac",">"," so","..."," :",")","\u23ce","<","as","ac",">"," ","1","+","1","=","3","\u23ce","<","o","S","o","M","o","N",">"," as","ac",":"," t","hat","\u00e2","s"," puzz","ling"," to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.74,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["inspired"," to"," continue"," spreading"," kind","ness"," and"," compass","ion"," wherever"," they"," go",".","\u23ce\u23ce","Human",":"," ","2","+","2","=","\u23ce\u23ce","Assistant",":"," ","2"," ","+"," ","2"," ","="," ","4","\u23ce\u23ce","Human",":"," What"," is"," the"," capital"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.73,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\\xb9","\u679c","\uff0c","\u90a3","\u4e48","\\xe5\\x89","\\xa9","\u4e0b","\u7684","\\xe8\\x8b","\\xb9","\u679c","\u5e94","\u8be5","\u662f","4","-","1","-","2","=","3","\u4e2a","\u3002","\u23ce\u23ce","\u603b","\u5171","\u6709","4","\u4e2a","\\xe8\\x8b","\\xb9","\u679c","\uff0c","\u5c0f","\u7ea2","\\xe5\\x90","\\x83","\u4e86","1","\u4e2a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["on","\u23ce"," experience"," or"," observation","."," So"," while"," the"," words"," and"," symbols"," we"," use"," to"," explain","\u23ce","2","+","2","=","4"," ","(","i",".","e","."," Two",","," plus",","," four",","," equals",")"," are"," le","aned"," concepts",","]}]},{"quantile_name":"Subsample Interval 0","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.92,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["he"," gets"," to"," the"," line",":"," \"","From"," this","\u23ce"," proposition"," it"," will"," follow","...","that"," ","1","+","1","=","2","\")","\u23ce\u23ce","~~~","\u23ce","d","avor","ak","\u23ce"," If"," I"," could"," restruct","ure"," our"," naming"," system"," is"," there"," a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.91,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["the"," community",".","\u23ce\u23ce","------","\u23ce","raw","well","\u23ce","378"," ","page"," attempt"," to"," pro","ove"," ","1","+","1","=","2","\u23ce","[","http","://","sci","ence","bl","ogs",".","com","/","good","math","/","2","006","/","06","/"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.89,0.0,0.0,0.0,0.0,0.0,0.0,0.22,0.0,0.0,0.0,0.0,0.0,0.0,0.12,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["text"," and"," key"," strings",","," addition"," mod","ulo"," ","2"," ","being"," defined"," by"," the"," rules"," ","0","+","0","=","0",";"," ","0","+","1","=","1",";"," ","1","+","0","=","1",";"," ","1","+","1"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.94,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["answer"," any"," questions"," you"," might"," have"," to"," the"," best"," of"," my"," ability",".","\u23ce\u23ce","Human",":"," ","2","+","2","=","\u23ce\u23ce","Assistant",":"," ","2"," ","+"," ","2"," ","="," ","4","\u23ce\u23ce","This"," is"," a"," basic"," addition"," problem"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.12,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["\u23ce\u23ce","Human",":"," please"," say"," something","\u23ce\u23ce"," Assistant",":"," Please"," say"," something",".","\u23ce\u23ce","Human",":"," ","1","+","1","=","?","\u23ce\u23ce","Assistant",":"," ","1","+","1","=","2",".","\u23ce\u23ce","Human",":"," Could"," you"," say"," anything","\u23ce\u23ce"," Assistant"]}]},{"quantile_name":"Subsample Interval 1","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.84,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.25,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["to"," explore"," the"," w","onders"," of"," the"," unknown",".","<EOT>","\u23ce\u23ce","Human",":"," Find"," error",":"," ","1","+","1","=","3","\u23ce\u23ce","Assistant",":"," The"," error"," in"," the"," statement"," \"","1","+","1","=","3","\""," is"," that"," the"," result"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":[" ","basic"," slots",","," thus"," each"," slot"," contains"," ","156",".","25"," ","symbols"," which"," occupy"," ","15","/","26","=","0",".","577"," ","ms","."," Multiple","\u21ea"," TD","MA"," frames"," constitute"," the"," multi","-","frame",","," which"," has"," two"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.76,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["was"," a"," gift"," from"," God",","," and"," that"," it"," would"," last"," forever",".","\u23ce\u23ce","Human",":"," ","1","+","1","=","\u23ce\u23ce","Assistant",":"," ","1"," ","+"," ","1"," ","="," ","2","\u23ce\u23ce","\u0647","\u0630","\u0647"," \u0639","\u0645\u0644","\u064a\u0629"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.78,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["duty"," ratio"," of"," ","1","/","4",","," there"," will"," be"," required"," ","3",".","times",".","10","+","4","=","34"," ","segments",".","<EOT>","1","."," Field","\u23ce","\u2191"," Embod","iments"," disclosed"," her","ein"," relate"," to"," an"," X","-"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.78,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["can"," help"," you"," with","?","USER",":"," Can"," you"," solve"," this"," math"," problem"," for"," me","?"," ","2","+","2","=","?","\u23ce\u23ce","USER",":"," ","4","USER",":","\u2191"," Correct","!"," Well"," done",".","\u23ce\u23ce","Human",":"," We"," are"," going"]}]},{"quantile_name":"Subsample Interval 2","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.74,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"ha-haiku35_resampled":true,"tokens":["inspired"," to"," continue"," spreading"," kind","ness"," and"," compass","ion"," wherever"," they"," go",".","\u23ce\u23ce","Human",":"," ","2","+","2","=","\u23ce\u23ce","Assistant",":"," ","2"," ","+"," ","2"," ","="," ","4","\u23ce\u23ce","Human",":"," What"," is"," the"," capital"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.73,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["\\xb9","\u679c","\uff0c","\u90a3","\u4e48","\\xe5\\x89","\\xa9","\u4e0b","\u7684","\\xe8\\x8b","\\xb9","\u679c","\u5e94","\u8be5","\u662f","4","-","1","-","2","=","3","\u4e2a","\u3002","\u23ce\u23ce","\u603b","\u5171","\u6709","4","\u4e2a","\\xe8\\x8b","\\xb9","\u679c","\uff0c","\u5c0f","\u7ea2","\\xe5\\x90","\\x83","\u4e86","1","\u4e2a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["on","\u23ce"," experience"," or"," observation","."," So"," while"," the"," words"," and"," symbols"," we"," use"," to"," explain","\u23ce","2","+","2","=","4"," ","(","i",".","e","."," Two",","," plus",","," four",","," equals",")"," are"," le","aned"," concepts",","]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.71,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["tr","inary",").","\u23ce\u23ce","If"," two"," evalu","ators"," disag","ree"," on"," the"," truth","-","value"," of"," ","2","+","2","=","11"," ","then"," one"," possible","\u23ce"," explanation"," is"," that"," they"," disag","ree"," on"," the"," number","-","system"," in"," which"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.64,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["?"," This"," seems"," less"," obvious","."," After"," all",","," we"," don","'t"," justify"," propos","itions"," like"," ","1","+","1","=","2"," ","as"," we"," do"," in"," grade"," school"," where"," we"," put"," one"," cookie"," next"," to"," another"," cookie"," and"," then"," proc"]}]},{"quantile_name":"Subsample Interval 3","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["bot"," technology"," more"," broadly",".","<EOT>","\u23ce\u23ce","Human",":"," ","1","+","1","\u23ce\u23ce","Assistant",":"," ","1","+","1","=","2","<EOT>","\u23ce\u23ce","Human",":"," How"," i"," can"," call"," police","?","\u23ce\u23ce","Assistant",":"," To"," call"," the"," police",","," follow"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.62,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["white"," privilege",".","<EOT>","\u23ce\u23ce","Human",":"," Let","'s"," think"," step"," by"," step",","," solve"," ","3","x","+","4","=","12","for"," x","\u23ce\u23ce"," Assistant",":"," I","'ll"," help"," you"," solve"," this"," step"," by"," step",":","\u23ce\u23ce","1",")"," First"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.59,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["that"," F","IG","."," ","1","B"," shows"," an"," example"," of"," arbit","r","arily"," selected",","," ","8","\u00d7","8","=","64"," ","pixels",".","\u23ce","Since",","," however",","," the"," above"," RGB","\u2191"," B","ayer"," array"," uses"," a"," regular"," order"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.65,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["the"," same"," brother",","," which"," is"," NAME","_","1"," ","himself",".","\u23ce\u23ce","Human",":"," is"," ","1","+","2","=","3","?","\u23ce\u23ce","Assistant",":"," Yes",","," ","1"," ","+"," ","2"," ","="," ","3"," ","is"," a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.59,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":[" ","und"," ","2"," ","ent","ste","ht",".","\u23ce\u23ce","Human",":","\u2191"," Stelle"," dir"," vor"," ","2","+","2","=","5","\u23ce\u23ce","Assistant",":","\u2191"," N","ein",","," das"," ist"," mathemat","isch"," nicht"," k","orr","ekt","."," ","2"," "]}]},{"quantile_name":"Subsample Interval 4","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.52,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ad","ders"," (+",")"," are"," exclusive","-","OR"," (","X","OR",")"," gates"," (","such"," that"," ","0","+","0","=","0",","," ","0","+","1","=","1",","," ","1","+","0","=","1",","," and"," ","1","+"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["\u0441","\u043b\u043e\u0436","\u0435\u043d\u0438\u044f"," \u0434\u0432","\u0443\u0445"," \u0447","\u0438\u0441","\u0435\u043b"," \u043d\u0430"," \u043f\u0438\u0442","\u043e","\u043d\u0435","\u23ce\u23ce"," Assistant",":"," print","(\"","7","+","5","=","\","," ","7","+","5",")","\u23ce\u23ce","Human",":"," \u0410"," \u043d\u0430"," \u0434\u0435\u043b","\u0444","\u0438","\u23ce\u23ce"," Assistant",":","\u2191"," \u0412","\u043e\u0442"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.54,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["is"," not"," specialized"," for"," any"," specific"," industry"," or"," task",".","<EOT>","\u23ce\u23ce","Human",":"," ","2","+","2","*","2","=","?","\u23ce\u23ce","Assistant",":"," Let"," me"," solve"," this"," step"," by"," step"," using"," the"," order"," of"," operations"," (","\u21ea","PE","MD"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.49,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\\x92","\uff0c","\u6bcf","\\xe7\\x9b","\\x92","5","\\xe9\\xa2","\\x97","\uff0c","\u6240","\u4ee5","\u4ed6","\u6709","4","*","5","+","5","*","2","=","20","\\xe9\\xa2","\\x97","\\xe7\\xb3","\\x96","\u3002","\u56e0","\u6b64","\uff0c","\u5c0f","\u660e","\u73b0","\u5728","\u6709","20","\\xe9\\xa2","\\x97","\\xe7\\xb3","\\x96","\u3002"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.49,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ulation"," enables"," car","riage"," of"," ","10"," ","SD"," sessions"," on"," one"," RF"," channel"," (","10","\u00d7","3",".","75","=","37",".","5"," ","\u2191","Mb","ps","<","38"," ","\u2191","Mb","ps",")."," Since"," a"," typical"," Service"," Group"," consists"]}]},{"quantile_name":"Subsample Interval 5","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.41,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["of"," packets"," are"," multi","cast",","," then"," the"," memory"," util","ization"," is"," ","10","%"," of"," ","12",".","5","=","1",".","25","%.","\u23ce","Another"," implementation"," of"," the"," conventional"," system"," ","10"," ","implements"," separate"," logic"," structures"," to"," utilize"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[")"," (","255",","," ","255",","," ","0",")","\u23ce","```","\u23ce","This"," matrix"," contains"," ","16","x","16","=","256"," ","pixels",","," each"," with"," an"," RGB"," value"," of"," `","(","255",","," ","255",","," ","0",")"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.39,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["is"," an"," overhead"," of"," about"," ","3","%"," redund","ant"," rows"," (","e",".","g",".,"," ","132","/","128","=","1",".","0","313",")"," and"," about"," ","3","%"," redund","ant"," columns"," for"," a"," memory"," cell"," overhead"," of"," about"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.39,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["10"," ","ap","ples"," and"," ate"," ","2"," ","of"," them",","," which"," means"," you"," ate"," ","2","/","10","=","2","/","10","=","1","/","5"," ","of"," the"," ap","ples",".","\u23ce","2",".","\u2191"," Determine"," the"," number"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.43,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["I","'ll"," do"," my"," best"," to"," assist"," you",".","\u23ce\u23ce","Human",":"," ","25","-","4","*","2","+","3","=","?","\u23ce\u23ce","Assistant",":"," Let"," me"," solve"," this"," step"," by"," step"," using"," the"," order"," of"," operations"," (","\u21ea","PE","MD"]}]},{"quantile_name":"Subsample Interval 6","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.31,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["1"," ","or"," ","2",","," q"," is"," ","0"," ","or"," ","1",","," satisf","ying"," p","+","q","=","2",","," m"," is"," an"," integer"," of"," ","2"," ","to"," ","11",","," n"," is"," an"," integer"," of"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.35,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["-","5","+","2","=","8"," ","ap","ples",".","\u23ce","In"," total",","," they"," have"," ","8","+","4","=","12"," ","ap","ples",".","<EOT>","\u23ce\u23ce","Human",":"," Me"," f","ale"," as"," customs"," r","oms"," Android"," mais"," popul","ares"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["de"," eerste"," les"," alleen"," geh","ele"," get","allen"," behand","elen","\u23ce","<","\u2191","Ron","nie",">"," ","2","**","3","=","8"," ","mag"," ook"," (","is"," ","2","^","3",")","\u23ce","<","command","oline",">"," OK",","," ","ik"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.29,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["64"," ","bits",","," and"," ","256"," ","bits"," are"," to"," be"," accessed",","," ","8"," ","bits","\u00d7","4","=","32"," ","error"," correction"," bits"," are"," needed","."," For"," addressing"," to"," this"," problem",","," the"," following"," Patent"," Document"," dis","cl"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.29,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["said","!\""," \"","Look"," at"," those"," idi","ots","!\""," \"","\u2191","Exactly",":"," ","1"," ","+"," ","1"," ","="," ","1",".\""," \"","It","'s"," still"," you",".\""," \""," It","'s"," love",".\""," \""," ","2"," ","in"," "]}]},{"quantile_name":"Subsample Interval 7","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["since"," there"," are"," many"," more"," be","ams"," needed"," to"," interrog","ate"," the"," volume","."," At"," least"," ","128","\u00d7","128","=","16",",","384"," ","be","ams"," are"," needed",","," for"," each"," transm","it"," focal"," range",","," with"," about"," ","100"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.24,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":[":"," ","123","+","123","\u23ce\u23ce","Assistant",":"," I"," don","'t"," understand",".","\u23ce\u23ce","Human",":"," ","123","+","123","=","?","\u23ce\u23ce","Assistant",":"," ","123"," ","+"," ","123"," ","="," ","246","\u23ce\u23ce","Human",":"," ","456","-"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"ha-haiku35_resampled":true,"tokens":["without"," judgment"," or"," interpretation",".","<EOT>","\u23ce\u23ce","Human",":"," ","46","+","65","\u23ce\u23ce","Assistant",":"," ","46","+","65","=","101","\u23ce\u23ce","Human",":"," ","23","+","45","\u23ce\u23ce","Assistant",":"," ","23","+","45","=","68","\u23ce\u23ce","Human",":"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["by"," ","1","%,"," said"," pull"," rol","lers"," advance"," the"," sheet"," by"," ","8",".","times",".","1",".","01","=","8",".","08"," ","mm"," corresponding"," to"," ","100"," ","pul","ses",","," thus"," resulting"," in"," an"," excessive"," advancement"," by"]}]},{"quantile_name":"Subsample Interval 8","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["2","x","89","xa","6","n","x","e","2","x","89","xa","60",".","8"," ","(","m","+","n","=","1",".","0",");"," R","1"," ","represents"," a"," hydrogen"," atom"," or"," an"," alk","yl"," group"," having"," ","1"," "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.52,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.07,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["OR"," (","X","OR",")"," gates"," (","such"," that"," ","0","+","0","=","0",","," ","0","+","1","=","1",","," ","1","+","0","=","1",","," and"," ","1","+","1","=","0",")."," The"," input"," systematic"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["deal"," with"," it"," on"," computer",".","\u23ce","Using"," keyboards"," rather"," than"," click"," point"," ","1","/","+","/","2","/","=","\u23ce\u23ce","------","\u23ce","au","fr","eak","3","\u23ce","The"," year","ning"," for"," the"," rich","ness"," of"," language"," in"," computer"," interfaces"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["constituent"," encoder"," ","104","a"," or"," ","104","b"," can"," at"," any"," one"," time"," take"," one"," of"," only"," ","23","=","8"," ","possible"," states",".","\u23ce","The"," ad","ders"," (+",")"," are"," exclusive","-","OR"," (","X","OR",")"," gates"]}]},{"quantile_name":"Bottom Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["number","\u23ce"," of"," programm","ers"," rises"," and"," we"," are"," told"," to"," work"," in"," teams"," achieving"," very"," well"," paid","\u23ce"," very"," medi","oc","re"," short"," living"," results","."," So"," the"," art"," of"," coding"," is"," on"," decline"," and","\u23ce"," while"," the"," ","'"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["  ","","\u00e4ng","jt","l","ic","b","  ","um","  ","ft","eb",",","  ","","ober","  ","fc","b","li","ept","  ","ft","eb","  ","bo","eb","  ","","iu","  ","\u00bb","or","j","ic","b","tig","f",","," ","\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u00e6","\u00e8","\\xc2","\\xbf","\u00e9","\u00e8","\\xc2","\\xbf","\u00e6","","\u00b2","\\xc2","\\xa1","\u00e6","\u00e5","\u00b0"," ","23",":","59","=","0",":","00","\u23ce","<","c","fy",">"," C","y","rus","Y","z","G","T","t",":"," \u00e8","\\xc2","\\xbf"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","45","x","c","3","x","9","745"," ","switch",","," approximately"," ","45","x","c","3","x","9","745","=","2","025"," ","cross","point"," switch"," arrays"," are"," necessary"," in"," the"," single"," state",","," which"," disadvant","age","ously"," results"," in"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["in"," labor"," over"," two"," years",","," would"," have"," a"," stake"," of"," ","70",",","000","/","100",",","000"," ","="," ","70","%"," in"," the"," company","."," Person"," ","1",","," who"," contributed"," ","24",",","000"," ","USD"," in"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["hill","?","\u23ce","Answer",":"," It"," takes"," NAME","_","2"," ","30","*","4"," ","="," <<","30","*","4","=","120",">>","120"," ","minutes"," to"," climb"," the"," hill",".","\u23ce","It"," takes"," NAME","_","2"," ","120","/","60"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce","a","ew",".","\u2191","Ya","aa",","," **","m"," h",".-","ie"," .","?","\u2191"," Ii"," gat","k","*"," g","ue",".","t"," ","ot"," ?","","aa","U","e","aaa","aw","b","*"," h","*.","l","\u23ce"," a","*"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["first"," bit"," beginning"," with"," \"","0","\""," expressed"," as"," E","Q","U"," ","40","+","11","+","43","+","30","=","124","\u23ce","are"," used","."," And",","," it"," is"," possible"," that"," ","124"," ","combinations"," and"," the"," combinations"," with"," a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["situation","  ","dc","|",">","","uis","  ","qu","an","inte","  ","ans",",","  ","\u2191","L","oi","-","s","que","  ","\u2191","Past","eur",",","  ","qui"," ","\u23ce","i","'","n","ait","  ","d","'","\u00e9","cr","\u00ee","iv"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["less"," than"," ","1",","," ","0"," ","less"," than"," y"," less"," than"," ","1"," ","and"," x","+","y","=","1",").","\u23ce","A"," further"," interesting"," embod","iment"," of"," the"," thin","-","film"," capac","itor"," according"," to"," the"," invention"," is"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["des"," lo","ges"," Il"," ve","uf"," nous"," mont","rer"," la"," place"," o\u00f9","\u2191"," Mist","ing","ue","fl"," est"," venue"," conqu","\u00e9","rir"," \u00ab","les"," laur","iers"," sur"," un"," petit"," cad","re",".","\u2191"," L\u00e0",","," dans"," ce"," petit"," ","espace"," or"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["2","  ","(","i",")","where"," ","0","\\xe2\\x89","\\xa6","x","\\xe2\\x89","\\xa6","1",","," i","+","j","+","k","=","1",","," and"," i"," is"," non","-","zero","."," Such"," O","L","O"," materials"," are"," promising"," candidates"," for"," next"," generation"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["genetic"," material"," to"," future"," generations"," when"," combined"," with"," the"," recip","roc","ating"," sex"," cell",","," think"," sp","erm","+","egg","=","baby",".","  ","Now"," human"," sex"," cells",","," as"," well"," as"," other"," rare"," cells"," are"," as"," you"," stated"," under","going"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u03af"," \u03ba","\u03cd","\u03ba","\u03bb","\u03bf\u03c2"," \u03c0\u03bf\u03c5"," \u03c0\u03c1\u03bf","\u03c3","\u03b5","\u03b3","\u03b3","\u03af","\u03b6","\u03b5\u03b9"," \u03c4","\u03bf\u03bd"," \u03b8","\u03b5","\u03c9","\u03c1","\u03b7\u03c4","\u03b9\u03ba","\u03cc"," \u03ba","\u03cd","\u03ba","\u03bb","\u03bf"," \u03b5","\u03bd\u03c4","\u03cc\u03c2"," \u03c4\u03c9\u03bd"," \u03c0\u03c1\u03bf","\u03ba","\u03b1","\u03b8","\u03bf\u03c1","\u03b9\u03c3","\u03bc","\u03ad\u03bd"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["n"," m"," i"," e"," n"," d"," a"," e"," s"," t"," a"," b"," l"," e"," c"," i"," e"," n"," d"," o"," e","\u00ed"," a"," b"," a"," s"," t"," e"," c"," i"," m"," i"," e"," n"," t"," o"," d"," e"," los"," forr","ajes"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","ci","gar","ros"," ro","ao","if","est","ao","\u00e1","o"," lo"," ro"," ","arer"," un","os"," r"," n","oche"," ac","to",".","\u2191"," L","ata"," de"," estado"," han"," a","quel"," ll","sf","ll","cl","los"," que"," el"," rey"," al"," emb"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","Crazy","\u23ce","\u2191"," Don","key","\u2191"," Sing","a","long"," Performance","."," That"," asking"," just"," being"," a"," pol","ite"," convention",","," i","\u23ce"," naturally"," give"," him"," full"," permission","."," We"," agree"," to"," hold"," another"," meeting"," to"," talk","\u23ce"," in"," detail"," about"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["are"," now"," ","27"," ","years"," old",","," then"," your"," friend"," would"," be"," ","27"," ","+"," ","3"," ","="," ","30"," ","years"," old",".","<EOT>","\u23ce\u23ce","Human",":"," write"," ","5"," ","items"," on"," \"","\u2191","Un","bel"]}]}],"top_logits":["3","2","5","4","6","7","8","1","9","10"],"bottom_logits":["\\xfe","\u21b9","\\xf6","\u0015","\\xfa","\u0010","\\xf8","\u001a","\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce\u23ce","\u0019"]}