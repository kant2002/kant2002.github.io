{"index":1131282,"examples_quantiles":[{"quantile_name":"Top Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.36,0.79,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.28,0.78,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.52],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["As"," she"," ho","pped"," along"," the"," path",","," she"," met"," many"," creatures"," who"," tried"," to"," help"," her","."," A"," wise"," old"," owl"," gave"," her"," some"," advice",","," a"," friendly"," squ","ir","rel"," shared"," his"," nuts"," with"," her",","," and"," a"," brave"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08,0.37,0.95,0.96,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.18,0.0,0.0,0.0,0.73,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["town"," to"," town",","," Max"," met"," all"," sorts"," of"," interesting"," animals"," and"," people","."," He"," made"," friends"," with"," a"," wise"," old"," owl"," who"," taught"," him"," about"," the"," importance"," of"," wisdom",","," and"," he"," even"," met"," a"," m","isch","iev","ous"," monkey"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08,0.37,0.95,0.96,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.18,0.0,0.0,0.0,0.73],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["from"," town"," to"," town",","," Max"," met"," all"," sorts"," of"," interesting"," animals"," and"," people","."," He"," made"," friends"," with"," a"," wise"," old"," owl"," who"," taught"," him"," about"," the"," importance"," of"," wisdom",","," and"," he"," even"," met"," a"," m","isch","iev","ous"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.59,0.06,0.0,0.38,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," en"," effet",","," qu","'d"," est"," plus"," cruel"," de"," tra","quer"," pendant"," des"," he","ures"," un"," m","alh","eur","eux"," \u2022"," e","rf"," qui"," n","'","a"," que"," des"," lar","mes"," pour"," se"," d\u00e9f","endre"," que"," d","'","att","a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.29,0.0,0.87,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["our"," own"," experience",".","\u23ce","\u2191","Homo"," peop","lo"," have"," no"," more"," sens","/,"," of"," propri","ety"," than"," u"," c","aged"," ro","oster","\u23ce"," that"," c","rows"," in"," front"," of"," a"," meat"," market",".","\u23ce","(","Copyright",","," l","I","H"]},{"tokens_acts_list":[0.0,0.0,0.0,0.06,0.0,0.76,0.0,0.06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.48,0.0,0.84,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["kill"," themselves","."," Many"," capt","ive"," dolphins"," and"," wh","ales"," have"," been"," known"," to"," do"," so",","," and"," some"," capt","ive"," eleph","ants"," have"," also"," been"," known"," to"," try",".","\u23ce\u23ce","Human",":"," ","\u23ce","I","'ve"," heard"," of"," that"," too"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09,0.69,0.84,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["from"," his"," friends",","," but"," they"," were"," also"," too"," small"," to"," open"," it",".","\u23ce\u23ce","Just"," then",","," a"," wise"," old"," horse"," named"," NAME","_","2"," ","came"," by","."," NAME","_","1"," ","told"," NAME","_","2"," ","about"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.21,0.73,0.84,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["they"," would"," gather"," around"," the"," pond"," and"," rec","ite"," their"," latest"," works","."," The"," judges"," were"," a"," group"," of"," wise"," old"," t","urt","les"," who"," would"," listen"," att","ent","ively"," and"," then"," deliber","ate"," on"," the"," winner"," of"," the"," night","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.35,0.82,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.81,0.82,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["to"," help"," her","."," A"," friendly"," squ","ir","rel"," gave"," her"," some"," nuts"," for"," the"," road",","," and"," a"," wise"," old"," owl"," offered"," her"," some"," advice",".","\u23ce\u23ce","After"," many"," days"," of"," travel",","," NAME","_","1"," ","finally"," came"," to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.35,0.82,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.81,0.82,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce\u23ce","As"," she"," ho","pped"," along"," the"," path",","," she"," met"," many"," creatures"," who"," tried"," to"," help"," her","."," A"," friendly"," squ","ir","rel"," gave"," her"," some"," nuts"," for"," the"," road",","," and"," a"," wise"," old"," owl"," offered"," her"," some"," advice"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.29,0.37,0.82,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["  ","One","  ","of","  ","the","  ","cap","-"," ","\u23ce","t","ives"," had","  ","domest","icated","  ","a","  ","young","  ","spar","row",",","  ","which","  ","being","  ","a","oc","ident","id","ly","  ","discovered","  ","in","  ","his"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.32,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["would"," be"," so"," exciting",".\""," \"","Being"," able"," to"," communicate"," with"," animals",".\""," \"","I","'ve"," always"," wanted"," to"," tell"," a"," g","ira","ffe"," how"," stupid"," it"," looks",".\""," \"","I","'ve"," always"," wanted"," to"," ask"," a"," bab","oon"," why"," they"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.35,0.82,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.81,0.82,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["tried"," to"," help"," her","."," A"," friendly"," squ","ir","rel"," gave"," her"," some"," nuts"," for"," the"," road",","," and"," a"," wise"," old"," owl"," offered"," her"," some"," advice",".","\u23ce\u23ce","After"," many"," days"," of"," travel",","," NAME","_","1"," ","finally"," came"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["sync"," battles",".\""," \"","Well",","," then"," order"," plain"," ones",".\""," \"","Yesterday"," I"," saw"," you"," try"," to"," milk"," a"," male"," buffalo",".\""," \"[","sc","offs","]"," Whatever",","," Mom",".\""," \"","It"," worked",".\""," \"","I"," put"," it"," in"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08,0.71,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["back"," and"," forth"," as"," it"," ch","itters"," nerv","ously","."," And"," in"," the"," center"," of"," the"," group",","," a"," wise"," old"," owl"," per","ches"," on"," a"," low","-","hanging"," branch",","," its"," pier","cing"," g","aze"," seem","ing"," to"," see"," into"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.36,0.79,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.28,0.78,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u23ce\u23ce","As"," she"," ho","pped"," along"," the"," path",","," she"," met"," many"," creatures"," who"," tried"," to"," help"," her","."," A"," wise"," old"," owl"," gave"," her"," some"," advice",","," a"," friendly"," squ","ir","rel"," shared"," his"," nuts"," with"," her",","," and"," a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.36,0.79,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.28,0.78,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.52,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["she"," met"," many"," creatures"," who"," tried"," to"," help"," her","."," A"," wise"," old"," owl"," gave"," her"," some"," advice",","," a"," friendly"," squ","ir","rel"," shared"," his"," nuts"," with"," her",","," and"," a"," brave"," bear"," offered"," to"," protect"," her"," from"," any"," danger"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.76,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.78,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["earth",","," and"," a"," r","egal"," deer",","," its"," ant","lers"," gle","aming"," in"," the"," sun","light","."," A"," play","ful"," rabbit"," h","ops"," around"," the"," edges"," of"," the"," group",","," its"," long"," ears"," fl","icking"," back"," and"," forth"," as"," it"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.11,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.0,0.76,0.0,0.06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.48,0.0,0.84,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","\u23ce","Yes",","," it","'s"," not"," uncom","mon"," for"," animals"," in"," capt","ivity"," to"," kill"," themselves","."," Many"," capt","ive"," dolphins"," and"," wh","ales"," have"," been"," known"," to"," do"," so",","," and"," some"," capt","ive"," eleph","ants"," have"," also"," been"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.17,0.0,0.46,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.76,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.78,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["way","."," There","'s"," a"," sle","ek"," fox",","," its"," fur"," the"," color"," of"," rich"," earth",","," and"," a"," r","egal"," deer",","," its"," ant","lers"," gle","aming"," in"," the"," sun","light","."," A"," play","ful"," rabbit"," h","ops"," around"," the"]}]},{"quantile_name":"Subsample Interval 0","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08,0.37,0.95,0.96,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.18,0.0,0.0,0.0,0.73],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["from"," town"," to"," town",","," Max"," met"," all"," sorts"," of"," interesting"," animals"," and"," people","."," He"," made"," friends"," with"," a"," wise"," old"," owl"," who"," taught"," him"," about"," the"," importance"," of"," wisdom",","," and"," he"," even"," met"," a"," m","isch","iev","ous"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.59,0.06,0.0,0.38,0.95,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":[","," en"," effet",","," qu","'d"," est"," plus"," cruel"," de"," tra","quer"," pendant"," des"," he","ures"," un"," m","alh","eur","eux"," \u2022"," e","rf"," qui"," n","'","a"," que"," des"," lar","mes"," pour"," se"," d\u00e9f","endre"," que"," d","'","att","a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.29,0.0,0.87,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["our"," own"," experience",".","\u23ce","\u2191","Homo"," peop","lo"," have"," no"," more"," sens","/,"," of"," propri","ety"," than"," u"," c","aged"," ro","oster","\u23ce"," that"," c","rows"," in"," front"," of"," a"," meat"," market",".","\u23ce","(","Copyright",","," l","I","H"]},{"tokens_acts_list":[0.0,0.0,0.0,0.06,0.0,0.76,0.0,0.06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.48,0.0,0.84,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["kill"," themselves","."," Many"," capt","ive"," dolphins"," and"," wh","ales"," have"," been"," known"," to"," do"," so",","," and"," some"," capt","ive"," eleph","ants"," have"," also"," been"," known"," to"," try",".","\u23ce\u23ce","Human",":"," ","\u23ce","I","'ve"," heard"," of"," that"," too"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09,0.69,0.84,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["from"," his"," friends",","," but"," they"," were"," also"," too"," small"," to"," open"," it",".","\u23ce\u23ce","Just"," then",","," a"," wise"," old"," horse"," named"," NAME","_","2"," ","came"," by","."," NAME","_","1"," ","told"," NAME","_","2"," ","about"," the"]}]},{"quantile_name":"Subsample Interval 1","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.81,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.32,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["would"," be"," so"," exciting",".\""," \"","Being"," able"," to"," communicate"," with"," animals",".\""," \"","I","'ve"," always"," wanted"," to"," tell"," a"," g","ira","ffe"," how"," stupid"," it"," looks",".\""," \"","I","'ve"," always"," wanted"," to"," ask"," a"," bab","oon"," why"," they"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.35,0.82,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.81,0.82,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["tried"," to"," help"," her","."," A"," friendly"," squ","ir","rel"," gave"," her"," some"," nuts"," for"," the"," road",","," and"," a"," wise"," old"," owl"," offered"," her"," some"," advice",".","\u23ce\u23ce","After"," many"," days"," of"," travel",","," NAME","_","1"," ","finally"," came"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["sync"," battles",".\""," \"","Well",","," then"," order"," plain"," ones",".\""," \"","Yesterday"," I"," saw"," you"," try"," to"," milk"," a"," male"," buffalo",".\""," \"[","sc","offs","]"," Whatever",","," Mom",".\""," \"","It"," worked",".\""," \"","I"," put"," it"," in"," the"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08,0.71,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["back"," and"," forth"," as"," it"," ch","itters"," nerv","ously","."," And"," in"," the"," center"," of"," the"," group",","," a"," wise"," old"," owl"," per","ches"," on"," a"," low","-","hanging"," branch",","," its"," pier","cing"," g","aze"," seem","ing"," to"," see"," into"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.36,0.79,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.28,0.78,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":true,"tokens":["\u23ce\u23ce","As"," she"," ho","pped"," along"," the"," path",","," she"," met"," many"," creatures"," who"," tried"," to"," help"," her","."," A"," wise"," old"," owl"," gave"," her"," some"," advice",","," a"," friendly"," squ","ir","rel"," shared"," his"," nuts"," with"," her",","," and"," a"]}]},{"quantile_name":"Subsample Interval 2","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.0,0.0,0.06,0.0,0.72,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.75,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["roqu","ets"," \u00e2","g","\u00e9s"," de"," plus"," de"," tr","ente","."," ","\u23ce","On"," cite"," l","'","exemple"," d","'","un"," c","yg","ne"," qui"," a"," v\u00e9","cu"," trois"," ","\u23ce","cents"," ans",";"," d","'","une"," o","ie"," qui"," e"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08,0.71,0.8,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["icking"," back"," and"," forth"," as"," it"," ch","itters"," nerv","ously","."," And"," in"," the"," center"," of"," the"," group",","," a"," wise"," old"," owl"," per","ches"," on"," a"," low","-","hanging"," branch",","," its"," pier","cing"," g","aze"," seem","ing"," to"," see"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.16,0.66,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["her"," days"," exploring"," the"," woods"," and"," playing"," with"," her"," animal"," friends","."," She"," had"," a"," special"," bond"," with"," a"," silly"," old"," owl"," who"," lived"," in"," a"," tree"," near"," her"," home","."," They"," would"," often"," sit"," and"," watch"," the"," stars"," together"," at"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.15,0.0,0.0,0.0,0.65,0.0,0.0,0.0,0.7,0.26,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ah",","," is"," it"," Noah","'s","\u2191"," Ark","?\""," \"","With"," the"," two"," p","igs",","," two"," ","ants"," and"," two"," silly"," bulls","...\""," \""," Two"," s","yll","-","a","-","","bles","?\""," \""," What","?\""," \"","We","'re"," getting"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09,0.7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["'re"," next"," door","!\""," \"","\u2191","O","oh","!\""," \"","I"," was"," just"," climbing"," up"," here"," to"," rescue"," a"," little"," wounded"," bud","gie",".\""," \"","Don","'t"," panic",","," now","!\""," \"","I"," can"," feel"," his"," little"," heart"," fl","ut","tering"]}]},{"quantile_name":"Subsample Interval 3","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.31,0.0,0.0,0.15,0.0,0.0,0.06,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["this"," pretty"," wild"," example",","," again"," from"," the","\u2191"," Toh","oku"," tsunami"," of"," a"," ","raft"," of"," (","still"," living",")"," marine"," organisms"," that"," flo","ated"," across"," the"," pacific"," from"," Japan"," to"," the"," US"," west"," coast",".","\u23ce","<","|","stop"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.25,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.42,0.0,0.51,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.08,0.0,0.0,0.41,0.06,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["where"," they","'re"," from",".","  ","Other"," animals"," have"," acc","ents"," too",","," but"," less"," obviously",".","  ","For"," example",","," some"," species"," of"," birds"," have"," very"," distinct"," acc","ents",".","  ","You"," can"," even"," find"," dial","ects"," among"," certain"," species"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09,0.6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["ch","\u23ce"," ing"," on"," the"," top","most"," branches"," of"," the"," '","\u2191"," Kin","j","\u23ce"," of"," the"," Wood",",'"," a"," noble"," r","elic"," of"," the"," pas","'","\u23ce","forest"," days",","," about"," half"," a"," mile"," from","\u2191"," Inch","\u23ce"," bon","ny"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.31,0.27,0.6,0.0,0.0,0.0,0.08,0.0,0.0,0.0,0.15,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a"," lake","."," She"," was"," best"," friends"," with"," all"," the"," animals"," that"," lived"," by"," the"," lake",","," including"," a"," group"," of"," d","ucks",","," a"," fox",","," and"," a"," bear",".","\u23ce\u23ce","NAME","_","1"," ","loved"," to"," explore"," the"," lake"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.29,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.27,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a\u017c","enia"," wz","ai","em","ney"," ","\u23ce","ni","ena","wi","\u015bci","."," Jest"," to"," zw","ierz","\u0105t","ko"," sa","mica",","," p\u0142","od"," ","\u23ce","kot","ki"," i"," niew","iad","omo"," jak","iego"," sam","ca","."," Ma"," one"," ","\u23ce"]}]},{"quantile_name":"Subsample Interval 4","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.11,0.0,0.0,0.0,0.23,0.22,0.0,0.5,0.0,0.33,0.31,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["enough"," to"," be"," passed"," on"," to"," offspring",".","\u23ce\u23ce","In"," the"," Blue"," Planet"," ","2"," ","series",","," there"," is"," a"," segment"," about"," an"," oct","op","us"," and"," a"," group","er","\u23ce"," fish",","," entirely"," different"," species",","," communic","ating"," with"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["about"," to"," join"," them"," on"," the"," field",","," she"," caught"," a"," glimp","se"," of"," something"," out"," of"," the"," corner"," of"," her"," eye","."," She"," was"," expecting"," large"," and"," boun","cy"," parts",","," but"," these"," parts"," were"," in"," all"," the"," wrong"," places"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.07,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["have"," l","ice",","," fl","eas",","," ma","gg","ots"," or"," something",".\""," \"","You"," do"," not"," play"," with"," st","ray"," dogs"," because"," they"," are"," very","...\""," \"","No",","," no","!\""," \"","Get"," away",","," get"," away","!\""," \"","Go"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.12,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["Heavy","\u2191"," P","anting","]","\""," \"","And"," then"," something"," caught"," his"," eye",".\""," \"","It"," was","\u2191"," Bum","per"," the"," rabbit",".\""," \"","\u2191","Spar","ky"," jumped"," to"," his"," feet","..."," and"," ran"," toward","\u2191"," Bum","per"," bar","king"," loud"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\""," \"","Hey",","," girl",".\""," \""," You"," like"," dogs","?\""," \""," Yes",".\""," \"","Would"," you"," like"," an"," orph","aned"," one","?\""," \"","No",","," thanks",".\""," \"","I","'m"," in"," a"," di","lem","ma",".\""," \"","This"," is"," Bob"]}]},{"quantile_name":"Subsample Interval 5","examples":[{"tokens_acts_list":[0.0,0.06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.37,0.4,0.0,0.0,0.0,0.52,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["is"," the","\u2191"," Bow","head"," whale",","," which"," can"," live"," up"," to"," ","200"," ","years","."," The"," longest"," lived"," recorded"," verteb","rate"," is"," an","\u2191"," Ald","ab","ra"," giant"," tort","oise"," named"," \"","\u2191","Ad","wa","ita","\","," who"," lived"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4,0.0,0.06,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["examine"," the"," behavioral"," and"," neural"," development"," of"," animals"," r","eared"," with"," a"," sens","ory"," substit","ution"," device","."," Five"," groups"," of"," four"," stum","pt","ail"," mac","a","ques"," will"," be"," raised"," from"," birth"," to"," three"," months",","," and"," one"," group"," to"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.24,0.0,0.0,0.0,0.0,0.0,0.35,0.0,0.0,0.34,0.4,0.17,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["abel"," ent","l","eh","nt",","," wo"," cou","ard"," (","\u2191","Kur","zs","chw","anz",")","\u2191"," Bezeich","nung"," des","\u2191"," Ha","sen"," gew","esen"," sei",","," so"," dass"," das","\u2191"," W","ort"," eig","ent","lich",":","\u2191"," H","ase"," bedeut"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.06,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[" ","1","893","."," ","\u23ce","14","."," Notes"," sur"," quel","ques"," r\u00e9","fl","ex","es"," associ","\u00e9s"," ","chez"," la"," m","ante"," relig","ie","use"," (","\u2191","Ann","ales"," de"," la","\u2191"," Soci\u00e9t\u00e9","\u2191"," Linn","\u00e9","enne",","," ","1"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.16,0.0,0.0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["able",","," ","'","as"," a"," b","ait"," attra","cts"," a"," fish"," or"," a"," piece"," of"," st","inking"," meat"," draws"," a"," dog",",'"," so"," that"," the"," railroad"," was"," itself"," responsible"," for"," the"," t","res","pass","\u2191"," Pros","ser",","," ","47"]}]},{"quantile_name":"Subsample Interval 6","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.68,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["entitled"," \"","\u2191","I","he"," Last"," of"," Five","\u2191"," Thou","-"," f","\u23ce"," sand",",\""," and"," is"," a"," picture"," of"," a"," lone"," ste","sr","\u23ce"," standing"," knee"," deep"," in"," the"," snow"," ready","\u23ce"," to"," drop"," from"," st","arv","ation"," and"," present"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["that"," )","ou"," would","\u23ce"," l","ather"," lie","ai"," a"," little"," something"," about"," the","\u23ce"," do","ings"," of"," the"," fest","ive"," egg"," in"," \"","Hawaii","\u23ce"," n","ci",".\"","\u23ce","If"," th","ete"," ever"," w","ns"," a"," pla","ee"," while"," '"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["hed","anne",","," ","125"," ","rue","\u2191"," L\u00e9t","an","du","\u00e8re",".","A","\u21ea"," V","ENDRE"," par"," couples"," j","olis"," pet","its"," ser","ins"," ja","unes","."," S","'","ad","res","ser"," ","150",","," rue"," Franklin",".","A","\u21ea"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["t","ame"," fox","es"," began"," to"," develop"," partic","ol","ored"," co","ats",",","\u23ce","a"," trait"," found"," more"," in"," domest","icated"," animals"," than"," in"," wild"," ones","_","\u23ce\u23ce"," ","_","\u2191","Be","ly","ay","ev"," ","'s"," experimental"," animals"," and"," their"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["didn","'t"," you"," see"," them"," attack"," me","?\""," \"","They","'re"," not"," d","ucks",","," they","'re"," g","anders",","," male"," ge","ese",".\""," \"","I"," got"," attacked"," once"," too",".\""," \"","22"," ","","stit","ches",".\""," \"","You"," have"]}]},{"quantile_name":"Subsample Interval 7","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["at"," the"," same"," time",","," he"," will"," probably"," fail"," in"," both","."," Darwin"," speaks"," of"," ","\u23ce","b","ree","ders"," of"," pig","eons"," trying"," to"," increase"," length"," of"," fe","athers"," and"," number"," of"," ","\u23ce","fe","athers"," at"," the"," same"," time"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a"," perfect"," way"," to"," end"," a"," perfect"," day",".","\u23ce\u23ce","As"," I"," was"," about"," to"," leave",","," I"," saw"," a"," little"," girl"," sitting"," on"," the"," other"," side"," of"," the"," pond","."," She"," was"," crying",","," and"," she"," looked"," very"," sad","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","75","\u2014","0",".","80"," ","per"," K",".","G","."," g","esl","acht","."," ","23"," ","v","ette"," kal","v","eren",","," ru","ime",","," aan","vo","er",","," da","ardoor"," prij","zen"," m","inder",","," \u00a3",""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["an"," open"," mouth"," and"," curved"," tail"," that"," hint"," at"," its"," curious"," nature",".","\u23ce","7",".","\u2191"," Soft","-","f","urred"," snow","man",":"," In"," this"," style",","," the"," artist"," could"," use"," soft"," and"," pas","tel"," colors"," to"," dep","ict"," a"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.51,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["de","\u23ce"," v","ours"," the"," brid","eg","room","),"," but"," in"," spite"," of","\u23ce"," her"," has","ty"," tem","per"," the"," female"," sp","ia","or"," is"," a","\u23ce"," devoted"," mother",".","\u23ce","The"," banner"," of"," \"","women","'s"," freedom"," is","\u23ce"," carried"]}]},{"quantile_name":"Subsample Interval 8","examples":[{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["aus","\u2191"," Hag","enb","ec","ks","\u2191"," Tier","park"," wird"," uns"," ge","-"," sch","ri","eben",":","\u2191"," Unter"," den","\u2191"," Koll","ationen"," des","\u2191"," Tier","-"," Parks"," b","ean","sp","ru","cht"," j","etzt"," dir"," H"," i"," r"," s"," ch"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["  ","of","  ","the","  ","palm","-","trees",",","  ","\u2191","Luc","ien","  ","sp","ied","  ","out","  ","a","  ","par","rot","'s"," ","\u23ce","nest",",","  ","and","  ","had","  ","taken","  ","possession","  ","of","  ","two","  "]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":11,"is_repeated_datapoint":false,"tokens":["<EOT>","an"," hour",".\""," \"","What"," if"," she"," caught"," whatever"," that"," baby"," had","?\""," \"","You"," better"," get"," o","utta"," here",".\""," \""," Just"," call"," me",","," okay","?\""," \""," As"," soon"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.14,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.24,0.29,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["'t"," know","\""," \""," Take"," him"," away"," or"," I"," won","'t"," come"," out","\""," \"","How"," crazy"," to"," bring"," a"," wild"," animal"," here","!\""," \"","It","'s"," just"," a"," baby"," c","ub"," and"," I","'ve"," taken"," out"," all"," his"," teeth","\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.0,0.0,0.41,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["D","ti","tre"," with"," a"," Snake","*","\u23ce","A",","," Cleveland"," paper"," relates"," \"","a"," terrible"," ad","\u23ce"," venture"," with"," a"," m","onst","rous"," snake",",\""," which","\u23ce"," recently"," alar","med"," the"," people"," of"," the"," flour","ish","\u23ce"," ing"," little"," town"]}]},{"quantile_name":"Bottom Activations","examples":[{"tokens_acts_list":[0.0,0.0,0.13,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["She","'s"," a"," cat",".\""," \"","\u2191"," Eh","?\""," \"","!\""," \"","\u2191"," Z","oe"," D","\u2191"," Kat","ze"," is"," a"," cat"," with"," a"," PhD",","," a"," CH","t"," and"," that"," diploma",".\""," \"","\u21ea","L","AUGHTER","\""," \"","I"," think"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[","," all"," armed",".\""," \"","It","'d"," be"," suicide",".\""," \"","At"," the"," moment"," they","'re"," bl","aming"," the"," poor"," old","\u2191"," Griff","as",","," as"," usual",".\""," \"","Your"," best"," bet"," is"," to"," spin"," them"," a"," yarn"," and"," hope"," they"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","\u23ce","Don","'t"," lake"," up"," scand","als",".","\u23ce","Don","'t"," Water"," s","tin"," ","ks","\u23ce"," Don","'t"," trim"," your"," fri","enda",",","\u23ce","I"," ","'","ou"," t"," ","1"," ","lip"," )"," our"," v","v"," \"","i"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u2191","Dt","ad","bb","arn","  ","eine","  ","3","","ieg","c","  ","f\u00fcr","  ","ein","  ","F","ran","Fe","\u00f6"," ","\u23ce\u23ce\u23ce","120"," ","\u23ce\u23ce\u23ce","\u2191","Un","ty","at","m","ti","'","gi","."," ","\u23ce\u23ce\u23ce","(","1","861","."]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["with","\u2191"," Or","son",".\""," \"","Why","?\""," \"","I"," was"," curious",".\""," \"","Why"," was"," he"," sm","ashing"," all"," those"," beetles","?\""," \"","What"," did"," he"," get"," out"," of"," it","?\""," \"","First","th","ing","Id","id","  ","was","as"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["is"," suffering"," from"," in","dig","estion","."," I"," know"," that"," is"," a"," pecul","iar"," mal","ady"," to"," asc","ribe"," to"," a"," go","at",","," but"," I"," think"," that"," is"," the"," trouble",".\""," There"," are"," also"," two"," cats"," that"," are"," to"," some"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.19,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["BS","le","a","isan","\u23ce"," A"," working"," boy"," was"," f","ined"," $","7",".","95","\u23ce","recently"," for"," shooting"," a"," red"," bird",",","\u23ce","which"," was"," nearly"," eight"," hundred","\u23ce"," times"," as"," much"," as"," one"," of"," these"," rich","\u23ce"," guys"," would"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["immediately"," go"," into"," an"," ice"," sl","ur","ry"," to"," bring"," their"," body"," temperature"," down",".","  ","\u2191","Properly"," sl","augh","tered"," fish"," can"," then"," be"," aged"," for"," a"," great"," deal"," of"," time"," and"," they"," age"," much"," like"," a"," st","eak"," would"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["the"," same"," category"," as"," the"," correct"," answer"," but"," should"," be"," incorrect",".","\u23ce","Input",":"," What"," size"," of"," ring"," will"," a"," summer"," drought"," cause"," in"," a"," tree","?","\u23ce","Output",":","\u23ce\u23ce","Assistant",":"," ","\u23ce","larger","\u23ce","<","|","stop"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["and"," Bill","\u2191"," ","Ames"," are"," working"," on"," a"," road"," project"," near","\u2191"," Du","qu","ette","."," A"," nine","-","pound"," boy"," was"," born"," to"," Mr","."," and"," Mrs","."," Robert","\u2191"," Pi","erson"," April"," ","16","."," He"," has"," been"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\"","The"," h","ides"," can"," be"," turned"," into"," warm"," s","ocks"," for"," the"," poor",".\""," \"","\u2191","Gr","ind"," up"," the"," bones"," for"," dog"," food",".\""," \"","I"," want"," nothing"," w","asted",".\""," \"","\u2191","","Uh","-","h","uh",".\""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["birds",".\""," \"","People"," used"," to"," hunt"," a"," lot"," here",".\""," \"","Like"," in"," the"," photo"," of"," your"," father"," with"," the"," king","?\""," \"","That"," wasn","'t"," the"," king",","," Peter",","," that"," was"," the"," Prince","\u2191"," Regent",".\""," \"","\u2191"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["and"," says","...\""," \"\"","...\""," \"","Son",","," whatever"," you"," do",","," don","'t"," se","\\xc3","\\x89","\\xc3","\\x89",""," that"," cow",".\"","\""," \"","\u00c9","'m"," from"," Wisconsin"," origin","a","\\xc3","\\x89","\\xc3","\\x89","y",".\""," \"","Where"," the"," cheese"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["\u043e\u043c"," \u0432"," \u043b","\u0435\u0441","\u0443",".","\u23ce\u23ce","\u0412"," \u044d\u0442","\u043e\u043c"," \u0440","\u0430\u0441\u0441","\u043a\u0430\u0437","\u0435"," \u0440\u0430\u0441","\u0441\u043a","\u0430\u0436","\u0435\u0442\u0441\u044f"," \u043e"," \u0441\u0442","\u0430\u0435"," \u043a\u043e\u0442","\u043e\u0432",","," \u043a\u043e\u0442\u043e\u0440","\u044b\u0435"," \u0436\u0438\u0432","\u0443\u0442"," \u0432"," \u043b","\u0435\u0441","\u0443",".","\u2191"," \u041e\u043d\u0438"," \u0432\u0441\u0435"," \u0441\u043e\u0431","\u0440","\u0430\u043b\u0438\u0441\u044c"," \u0432","\u043c\u0435\u0441\u0442"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["a"," single"," fixed"," schema",".","\u23ce\u23ce","For"," example",","," how"," would"," you"," model"," a"," tad","p","ole"," which"," develops"," into"," a"," f","rog"," with"," a","\u23ce"," stat","ically"," typed"," language","?"," Do"," you"," need"," two"," different"," types"," for"," this","?"," What"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.15,0.07,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":[".","   ","https","://","en",".","m",".","wikipedia",".","org","/","wiki","/","\u2191","Wash","oe","_(","ch","imp","anz","ee",")","\u23ce","<","|","stop","|",">","<EOT>","\u23ce","How"," do"," you"," give"," a"," dog"," a"," bath","?","\u23ce\u23ce"]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["would"," you"," please","?\""," \"","You"," got"," it","!\""," \"","So",","," what","'re"," you"," thinking"," about"," that"," ho","oting"," little"," friend"," of"," yours","?\""," \"","\u2191","Suppose"," you","'ll"," want"," me"," to"," keep"," an"," eye"," on"," him"," too",".\""," \""]},{"tokens_acts_list":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1,0.04,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],"train_token_ind":20,"is_repeated_datapoint":false,"tokens":["daddy","?\""," \""," I"," promise",".\""," \""," [","laugh","ing","]"," Oh",","," Charlie","!\""," \"","Good"," shape"," for"," a"," little"," kid",".\""," \"","\u2191","Isn","'t"," that"," wonderful","?\""," \"","Don","'t"," pick"," me"," up",".\""," \"","Put"," me"," down"]}]}],"top_logits":["robin","crow","ram","tiger","kan","fox","rabbit","hawk","seal","eagle"],"bottom_logits":["udv","\u0414\u0430\u043d\u0438","\u3092\u3092","ledn","\u0446\u0438\u0446\u0438","svetov","ordet","edz","\u0431\u044a\u043b\u0433\u0430\u0440\u0438\u044f","aside"]}